[
  {
    "control_id": "AU-13",
    "control_name": "Monitoring for Information Disclosure",
    "family": "Audit and Accountability",
    "family_id": "au",
    "official_text": "Monitor organization-defined open-source information and/or information sites at organization-defined frequency for evidence of unauthorized disclosure of organizational information. If an information disclosure is discovered: (a) Notify organization-defined personnel or roles; and (b) Take the following additional actions: organization-defined additional actions.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "plain_english_explanation": "Organizations must establish a program to monitor publicly available information sources such as social media, code repositories, and news sites for unauthorized disclosure of sensitive organizational data. When information disclosure is discovered, organizations must promptly notify relevant personnel and take remedial actions to mitigate the impact.",
    "example_implementation": "Implement a monitored information disclosure program through the following steps: (1) Identify and document open-source information sites relevant to organizational operations (e.g., GitHub, GitLab, Pastebin, social media); (2) Establish monitoring frequency (e.g., daily, weekly); (3) Configure automated or manual monitoring tools to scan for organizational identifiers, employee names, internal system references, code snippets, configuration data, or other sensitive information; (4) Document findings in a central repository with timestamps and locations; (5) Establish escalation procedures for critical disclosures; (6) Implement response procedures including site notification, content removal requests, and incident documentation.",
    "non_technical_guidance": "1. Establish an information disclosure monitoring program as part of incident response\n2. Identify and maintain a list of relevant open-source information sites\n3. Define monitoring frequency appropriate to organizational risk tolerance\n4. Assign roles and responsibilities for monitoring and response activities\n5. Document procedures for escalating and responding to disclosures\n6. Coordinate with legal and public relations departments for disclosure responses\n7. Maintain logs of monitoring activities and discovered disclosures\n8. Periodically review effectiveness of monitoring and response procedures\n9. Train relevant personnel on information disclosure identification and response\n10. Integrate with incident response and breach notification procedures",
    "is_technical": false,
    "enhancements": [
      "AU-13.1",
      "AU-13.2",
      "AU-13.3"
    ],
    "related_controls": [
      "AC-22",
      "IR-4",
      "IR-6",
      "PE-3",
      "PM-12",
      "RA-5",
      "SC-7",
      "SI-4",
      "SI-20"
    ],
    "supplemental_guidance": "Open-source information includes social networking sites, code-sharing platforms and repositories, and publicly accessible forums. Unauthorized disclosure of information is a form of data leakage that can result in the compromise of confidentiality, integrity, and availability of organizational information. Discovery techniques and processes may include automated tools, manual research, social engineering testing, and web crawling. Organizations should consider monitoring dark web marketplaces and underground forums for sensitive organizational data. The definition of unauthorized disclosure should be precise and aligned with organizational classification and sensitivity standards.",
    "implementation_scripts": {
      "linux": {
        "description": "Automated monitoring script for detecting organizational information in open-source repositories and websites",
        "script": "#!/bin/bash\n# AU-13 Information Disclosure Monitoring Script\n# This script implements basic information disclosure monitoring on RHEL systems\n\nMONITORING_DIR=\"/var/log/au-13-monitoring\"\nREPORT_DIR=\"${MONITORING_DIR}/reports\"\nALERT_EMAIL=\"${AU_13_ALERT_EMAIL:-security@organization.local}\"\nMONITORING_TERMS_FILE=\"${MONITORING_DIR}/terms.txt\"\nMONITORING_SITES_FILE=\"${MONITORING_DIR}/sites.txt\"\n\n# Create monitoring directory structure\nmkdir -p ${REPORT_DIR}\n\n# Default monitoring terms if not configured\nif [ ! -f ${MONITORING_TERMS_FILE} ]; then\n  cat > ${MONITORING_TERMS_FILE} << 'EOF'\norganization-name\ninternal-system-name\nemployee-email-pattern\ninternal-ip-range\ninternal-domain-name\nproject-codename\nconfidential-system\nEOF\nfi\n\n# Default monitoring sites if not configured\nif [ ! -f ${MONITORING_SITES_FILE} ]; then\n  cat > ${MONITORING_SITES_FILE} << 'EOF'\nhttps://github.com\nhttps://gitlab.com\nhttps://pastebin.com\nhttps://reddit.com\nhttps://twitter.com\nhttps://linkedin.com\nEOF\nfi\n\n# Function to check for term in site\ncheck_site_for_terms() {\n  local site=$1\n  local timestamp=$(date '+%Y-%m-%d %H:%M:%S')\n  local findings_file=\"${REPORT_DIR}/findings-$(date +%Y%m%d).log\"\n  \n  # Attempt to query site via search API or web crawling (simplified)\n  while IFS= read -r term; do\n    # Use curl with organization search patterns\n    response=$(curl -s \"${site}/search?q=${term}\" 2>/dev/null | grep -i \"${term}\" || true)\n    \n    if [ -n \"${response}\" ]; then\n      echo \"[${timestamp}] DISCLOSURE DETECTED: ${term} found at ${site}\" >> ${findings_file}\n      echo \"Details: ${response}\" >> ${findings_file}\n    fi\n  done < ${MONITORING_TERMS_FILE}\n}\n\n# Main monitoring loop\nwhile IFS= read -r site; do\n  check_site_for_terms \"${site}\"\ndone < ${MONITORING_SITES_FILE}\n\n# Generate monitoring report\nFINDINGS=$(find ${REPORT_DIR} -name \"findings-$(date +%Y%m%d).log\" -exec wc -l {} \\;)\necho \"AU-13 Monitoring Report - $(date)\" > ${REPORT_DIR}/summary-$(date +%Y%m%d).txt\necho \"Sites Monitored: $(wc -l < ${MONITORING_SITES_FILE})\" >> ${REPORT_DIR}/summary-$(date +%Y%m%d).txt\necho \"Monitoring Terms: $(wc -l < ${MONITORING_TERMS_FILE})\" >> ${REPORT_DIR}/summary-$(date +%Y%m%d).txt\necho \"Findings: ${FINDINGS}\" >> ${REPORT_DIR}/summary-$(date +%Y%m%d).txt\n\n# Send alert if findings detected\nif [ $(grep -r \"DISCLOSURE DETECTED\" ${REPORT_DIR} 2>/dev/null | wc -l) -gt 0 ]; then\n  mail -s \"AU-13 ALERT: Information Disclosure Detected\" ${ALERT_EMAIL} < ${REPORT_DIR}/summary-$(date +%Y%m%d).txt\n  logger -t AU-13 \"Information disclosure detected - alert sent to ${ALERT_EMAIL}\"\nfi\n\nexit 0"
      },
      "windows": {
        "description": "PowerShell script for information disclosure monitoring on Windows systems",
        "script": "# AU-13 Information Disclosure Monitoring Script for Windows\n# This script implements basic information disclosure monitoring on Windows systems\n\n$MonitoringDir = \"C:\\Windows\\System32\\au-13-monitoring\"\n$ReportDir = \"${MonitoringDir}\\reports\"\n$AlertEmail = $env:AU_13_ALERT_EMAIL -or \"security@organization.local\"\n$MonitoringTermsFile = \"${MonitoringDir}\\terms.txt\"\n$MonitoringSitesFile = \"${MonitoringDir}\\sites.txt\"\n\n# Create monitoring directory structure\nif (-not (Test-Path $MonitoringDir)) {\n  New-Item -ItemType Directory -Path $MonitoringDir -Force | Out-Null\n}\nif (-not (Test-Path $ReportDir)) {\n  New-Item -ItemType Directory -Path $ReportDir -Force | Out-Null\n}\n\n# Create default monitoring terms if not configured\nif (-not (Test-Path $MonitoringTermsFile)) {\n  @\"  \norganization-name\ninternal-system-name\nemployee-email-pattern\ninternal-ip-range\ninternal-domain-name\nproject-codename\nconfidential-system\n\"@ | Out-File -FilePath $MonitoringTermsFile -Encoding UTF8\n}\n\n# Create default monitoring sites if not configured\nif (-not (Test-Path $MonitoringSitesFile)) {\n  @\"\nhttps://github.com\nhttps://gitlab.com\nhttps://pastebin.com\nhttps://reddit.com\nhttps://twitter.com\nhttps://linkedin.com\n\"@ | Out-File -FilePath $MonitoringSitesFile -Encoding UTF8\n}\n\n# Function to check for terms in sites\nfunction Check-SiteForTerms {\n  param(\n    [string]$Site\n  )\n  \n  $timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n  $findingsFile = \"${ReportDir}\\findings-$(Get-Date -Format 'yyyyMMdd').log\"\n  \n  Get-Content $MonitoringTermsFile | ForEach-Object {\n    $term = $_\n    try {\n      $response = Invoke-WebRequest -Uri \"${Site}/search?q=${term}\" -ErrorAction SilentlyContinue\n      if ($response.Content -match [regex]::Escape($term)) {\n        \"[${timestamp}] DISCLOSURE DETECTED: ${term} found at ${Site}\" | Out-File -FilePath $findingsFile -Append -Encoding UTF8\n        \"Details: $($response.Content.Substring(0, 200))\" | Out-File -FilePath $findingsFile -Append -Encoding UTF8\n      }\n    } catch {\n      # Site access failed or timeout\n    }\n  }\n}\n\n# Main monitoring loop\nGet-Content $MonitoringSitesFile | ForEach-Object {\n  Check-SiteForTerms $_\n}\n\n# Generate monitoring report\n$timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n$sitesCount = @(Get-Content $MonitoringSitesFile).Count\n$termsCount = @(Get-Content $MonitoringTermsFile).Count\n$summaryFile = \"${ReportDir}\\summary-$(Get-Date -Format 'yyyyMMdd').txt\"\n\n@\"\nAU-13 Monitoring Report - ${timestamp}\nSites Monitored: ${sitesCount}\nMonitoring Terms: ${termsCount}\n\"@ | Out-File -FilePath $summaryFile -Encoding UTF8\n\n# Send alert if findings detected\nif ((Get-Content \"${ReportDir}\\findings-$(Get-Date -Format 'yyyyMMdd').log\" -ErrorAction SilentlyContinue | Select-String \"DISCLOSURE DETECTED\") -ne $null) {\n  Write-EventLog -LogName \"Security\" -Source \"AU-13\" -EventId 1000 -Message \"Information disclosure detected - review findings\"\n  # Optional: Send email alert using Send-MailMessage\n}\n\nWrite-Host \"AU-13 monitoring completed\"\nExit 0"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-20T00:00:00.000000Z",
      "has_scripts": true
    },
    "cac_metadata": {
      "implementation_type": "organizational",
      "last_analyzed": "2025-11-20T00:00:00.000000Z",
      "source": "NIST SP 800-53 Rev 5",
      "implementation_guidance": "AU-13 is an organizational control requiring defined monitoring processes for information disclosure. ComplianceAsCode RHEL profiles do not include specific technical implementations for this control, as it is primarily operational and policy-driven. Organizations should implement monitoring tools and processes based on their risk assessment and resource availability."
    },
    "stig_id": null,
    "ai_guidance": "Implement information disclosure monitoring as a continuous activity. Focus on: (1) Establishing a comprehensive list of relevant open-source platforms; (2) Automating searches for organizational identifiers, employee information, and technical data; (3) Integrating monitoring with incident response processes; (4) Regularly reviewing and updating monitoring targets based on emerging threats and new platforms; (5) Training personnel on identification and reporting of disclosed information. Consider implementing commercial threat intelligence services for dark web monitoring."
  },
  {
    "control_id": "AU-13.1",
    "control_name": "Use of Automated Tools",
    "family": "Audit and Accountability",
    "family_id": "au",
    "official_text": "Monitor open-source information and information sites using organization-defined automated mechanisms.",
    "parent_control": "AU-13",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "plain_english_explanation": "Organizations should deploy automated tools and systems to continuously scan open-source information sites for unauthorized disclosure of organizational data. Automation increases monitoring frequency, reduces human oversight errors, and enables real-time alerting when disclosures are detected.",
    "example_implementation": "Implement automated information disclosure monitoring through: (1) Deploy commercial threat intelligence platforms (e.g., Recorded Future, Digital Shadows, Flashpoint) or open-source tools (e.g., TheHarvester, Shodan, Google dorking scripts) to automatically search for organizational identifiers; (2) Configure API integrations with GitHub, GitLab, and other code repositories to detect exposed credentials, configuration files, and proprietary code; (3) Implement web scraping and monitoring tools to track mentions of organization in forums and chat systems; (4) Deploy dark web monitoring services to detect organizational data in underground marketplaces; (5) Establish automated correlation engines to identify patterns of data disclosure; (6) Configure alerting rules to notify security teams immediately upon detection of configured monitoring terms; (7) Document all automated tools, their capabilities, and monitoring parameters in control documentation.",
    "non_technical_guidance": "1. Evaluate commercial threat intelligence and monitoring solutions\n2. Assess open-source monitoring tools for effectiveness and maintenance burden\n3. Define monitoring automation scope and parameters\n4. Establish alert thresholds and escalation procedures\n5. Document automation rules and detection patterns\n6. Regularly validate monitoring tool accuracy through testing\n7. Maintain audit logs of monitoring activities\n8. Coordinate with IT operations for tool deployment and maintenance\n9. Establish service level agreements for alert response times\n10. Budget for commercial threat intelligence services if selected",
    "is_technical": true,
    "enhancements": [],
    "related_controls": [
      "AU-13",
      "IR-4",
      "SI-4",
      "SI-20"
    ],
    "supplemental_guidance": "Automated mechanisms may include commercial threat intelligence platforms, custom scripting using APIs of social media and code repository platforms, web crawling and scraping tools, dark web monitoring services, and machine learning-based anomaly detection. Automation should be coupled with incident response procedures to ensure timely notification and remediation of detected disclosures. Organizations should validate the accuracy of automated tools through periodic testing with simulated disclosures.",
    "implementation_scripts": {
      "linux": {
        "description": "Python script for automated information disclosure monitoring using open-source tools",
        "script": "#!/usr/bin/env python3\n# AU-13.1 Automated Information Disclosure Monitoring Script\n# Requires: requests, python-dotenv, yara, shodan\n\nimport os\nimport json\nimport subprocess\nimport requests\nfrom datetime import datetime\nfrom dotenv import load_dotenv\nimport logging\n\n# Configuration\nload_dotenv()\nMONITORING_CONFIG = {\n    'github_token': os.getenv('GITHUB_TOKEN'),\n    'shodan_api_key': os.getenv('SHODAN_API_KEY'),\n    'alert_webhook': os.getenv('ALERT_WEBHOOK'),\n    'monitoring_terms': os.getenv('MONITORING_TERMS', '').split(',')\n}\n\n# Setup logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('/var/log/au-13-1-monitoring.log'),\n        logging.StreamHandler()\n    ]\n)\nlogger = logging.getLogger('AU-13.1-Monitor')\n\nclass GitHubMonitor:\n    \"\"\"Monitor GitHub for information disclosure\"\"\"\n    \n    def __init__(self, api_token):\n        self.api_token = api_token\n        self.base_url = 'https://api.github.com'\n        self.headers = {'Authorization': f'token {api_token}'}\n    \n    def search_repositories(self, search_terms):\n        \"\"\"Search GitHub repositories for sensitive terms\"\"\"\n        findings = []\n        for term in search_terms:\n            try:\n                # Search public repositories\n                search_url = f'{self.base_url}/search/code?q={term}+in:file'\n                response = requests.get(search_url, headers=self.headers)\n                \n                if response.status_code == 200:\n                    data = response.json()\n                    if data.get('total_count', 0) > 0:\n                        for item in data.get('items', []):\n                            findings.append({\n                                'source': 'GitHub',\n                                'term': term,\n                                'repository': item.get('repository', {}).get('full_name'),\n                                'file': item.get('path'),\n                                'url': item.get('html_url'),\n                                'timestamp': datetime.now().isoformat()\n                            })\n                            logger.warning(f'Information disclosure detected: {term} in {item.get(\"repository\", {}).get(\"full_name\")}')\n            except Exception as e:\n                logger.error(f'GitHub search error for term {term}: {str(e)}')\n        \n        return findings\n\nclass ShodanMonitor:\n    \"\"\"Monitor Shodan for information disclosure\"\"\"\n    \n    def __init__(self, api_key):\n        self.api_key = api_key\n        self.base_url = 'https://api.shodan.io'\n    \n    def search_devices(self, search_terms):\n        \"\"\"Search Shodan for organizational information\"\"\"\n        findings = []\n        for term in search_terms:\n            try:\n                search_url = f'{self.base_url}/shodan/host/search?key={self.api_key}&query={term}'\n                response = requests.get(search_url)\n                \n                if response.status_code == 200:\n                    data = response.json()\n                    for match in data.get('matches', []):\n                        findings.append({\n                            'source': 'Shodan',\n                            'term': term,\n                            'ip': match.get('ip_str'),\n                            'port': match.get('port'),\n                            'organization': match.get('org'),\n                            'timestamp': datetime.now().isoformat()\n                        })\n                        logger.warning(f'Organizational infrastructure exposed: {match.get(\"ip_str\")}:{match.get(\"port\")}')\n            except Exception as e:\n                logger.error(f'Shodan search error for term {term}: {str(e)}')\n        \n        return findings\n\nclass AlertManager:\n    \"\"\"Send alerts when disclosures are detected\"\"\"\n    \n    def __init__(self, webhook_url):\n        self.webhook_url = webhook_url\n    \n    def send_alert(self, finding):\n        \"\"\"Send alert to configured webhook\"\"\"\n        try:\n            if self.webhook_url:\n                payload = {\n                    'alert_type': 'INFORMATION_DISCLOSURE',\n                    'timestamp': datetime.now().isoformat(),\n                    'finding': finding\n                }\n                requests.post(self.webhook_url, json=payload)\n                logger.info(f'Alert sent for finding: {finding}')\n        except Exception as e:\n            logger.error(f'Alert sending error: {str(e)}')\n\ndef main():\n    \"\"\"Main monitoring function\"\"\"\n    logger.info('AU-13.1 automated monitoring started')\n    \n    all_findings = []\n    \n    # Initialize monitors\n    if MONITORING_CONFIG['github_token']:\n        github_monitor = GitHubMonitor(MONITORING_CONFIG['github_token'])\n        findings = github_monitor.search_repositories(MONITORING_CONFIG['monitoring_terms'])\n        all_findings.extend(findings)\n    \n    if MONITORING_CONFIG['shodan_api_key']:\n        shodan_monitor = ShodanMonitor(MONITORING_CONFIG['shodan_api_key'])\n        findings = shodan_monitor.search_devices(MONITORING_CONFIG['monitoring_terms'])\n        all_findings.extend(findings)\n    \n    # Send alerts for findings\n    alert_manager = AlertManager(MONITORING_CONFIG['alert_webhook'])\n    for finding in all_findings:\n        alert_manager.send_alert(finding)\n    \n    # Log findings summary\n    logger.info(f'Monitoring completed. Total findings: {len(all_findings)}')\n    \n    return 0 if len(all_findings) == 0 else 1\n\nif __name__ == '__main__':\n    exit(main())"
      },
      "windows": {
        "description": "PowerShell script for automated information disclosure monitoring",
        "script": "# AU-13.1 Automated Information Disclosure Monitoring Script for Windows\n# Requires: PowerShell 5.0+\n\nparam(\n    [string]$ConfigFile = \"C:\\Windows\\System32\\au-13-config.json\",\n    [string]$LogPath = \"C:\\Windows\\Logs\\AU-13\"\n)\n\n# Load configuration\nif (Test-Path $ConfigFile) {\n    $config = Get-Content $ConfigFile | ConvertFrom-Json\n} else {\n    Write-Error \"Configuration file not found: $ConfigFile\"\n    exit 1\n}\n\n# Ensure log directory exists\nif (-not (Test-Path $LogPath)) {\n    New-Item -ItemType Directory -Path $LogPath -Force | Out-Null\n}\n\n# Setup logging\nfunction Write-AuLog {\n    param([string]$Message, [string]$Level = \"INFO\")\n    $timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    $logMessage = \"[$timestamp] [$Level] $Message\"\n    Add-Content -Path \"${LogPath}\\au-13-1-monitoring.log\" -Value $logMessage\n    Write-Host $logMessage\n}\n\n# Monitor GitHub for disclosures\nfunction Monitor-GitHub {\n    param([string[]]$SearchTerms, [string]$ApiToken)\n    \n    $findings = @()\n    $headers = @{\n        'Authorization' = \"token $ApiToken\"\n        'Accept' = 'application/vnd.github.v3+json'\n    }\n    \n    foreach ($term in $SearchTerms) {\n        try {\n            $searchUrl = \"https://api.github.com/search/code?q=$term+in:file\"\n            $response = Invoke-WebRequest -Uri $searchUrl -Headers $headers -ErrorAction Stop\n            $data = $response.Content | ConvertFrom-Json\n            \n            if ($data.total_count -gt 0) {\n                foreach ($item in $data.items) {\n                    $finding = @{\n                        source = 'GitHub'\n                        term = $term\n                        repository = $item.repository.full_name\n                        file = $item.path\n                        url = $item.html_url\n                        timestamp = Get-Date -Format o\n                    }\n                    $findings += $finding\n                    Write-AuLog \"Information disclosure detected: $term in $($item.repository.full_name)\" \"WARN\"\n                }\n            }\n        } catch {\n            Write-AuLog \"GitHub search error for term $term : $($_.Exception.Message)\" \"ERROR\"\n        }\n    }\n    \n    return $findings\n}\n\n# Monitor public web for disclosures\nfunction Monitor-Web {\n    param([string[]]$SearchTerms)\n    \n    $findings = @()\n    \n    foreach ($term in $SearchTerms) {\n        try {\n            # Search using Bing Search API (requires API key)\n            $searchUrl = \"https://api.bing.microsoft.com/v7.0/search?q=$term\"\n            # This requires Bing Search API subscription - simplified example\n            Write-AuLog \"Web search initiated for term: $term\" \"INFO\"\n        } catch {\n            Write-AuLog \"Web search error for term $term : $($_.Exception.Message)\" \"ERROR\"\n        }\n    }\n    \n    return $findings\n}\n\n# Send alerts when findings detected\nfunction Send-Alert {\n    param([object]$Finding)\n    \n    if ($config.alert_email) {\n        try {\n            $subject = \"AU-13.1 ALERT: Information Disclosure Detected\"\n            $body = @\"\nInformation Disclosure Alert\nTime: $($Finding.timestamp)\nSource: $($Finding.source)\nTerm: $($Finding.term)\nDetails: $($Finding | ConvertTo-Json)\n\"@\n            # Send-MailMessage -SmtpServer $config.smtp_server -From $config.alert_from -To $config.alert_email -Subject $subject -Body $body\n            Write-AuLog \"Alert prepared for finding: $($Finding.term)\" \"INFO\"\n        } catch {\n            Write-AuLog \"Alert sending error: $($_.Exception.Message)\" \"ERROR\"\n        }\n    }\n    \n    # Log to Windows Event Log\n    Write-EventLog -LogName \"Security\" -Source \"AU-13\" -EventId 1001 -Message \"Information disclosure detected: $($Finding.term)\"\n}\n\n# Main execution\nWrite-AuLog \"AU-13.1 automated monitoring started\" \"INFO\"\n\n$allFindings = @()\n\n# GitHub monitoring\nif ($config.github_token) {\n    $findings = Monitor-GitHub -SearchTerms $config.monitoring_terms -ApiToken $config.github_token\n    $allFindings += $findings\n}\n\n# Web monitoring\nif ($config.enable_web_search) {\n    $findings = Monitor-Web -SearchTerms $config.monitoring_terms\n    $allFindings += $findings\n}\n\n# Send alerts for findings\nforeach ($finding in $allFindings) {\n    Send-Alert -Finding $finding\n}\n\nWrite-AuLog \"Monitoring completed. Total findings: $($allFindings.Count)\" \"INFO\"\n\nexit 0"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-20T00:00:00.000000Z",
      "has_scripts": true
    },
    "cac_metadata": {
      "implementation_type": "technical",
      "last_analyzed": "2025-11-20T00:00:00.000000Z",
      "source": "NIST SP 800-53 Rev 5",
      "implementation_guidance": "AU-13(1) requires automation of information disclosure monitoring. While ComplianceAsCode RHEL profiles focus on system-level audit controls, organizations should implement automated discovery and monitoring tools at the application or platform level. Recommended tools include commercial threat intelligence platforms, GitHub API-based monitoring, and custom Python/PowerShell scripts utilizing public APIs."
    },
    "stig_id": null,
    "ai_guidance": "Deploy a layered approach to automation: (1) Use GitHub/GitLab APIs to monitor code repositories in real-time; (2) Implement dark web monitoring for emerging threats; (3) Integrate threat intelligence APIs (Shodan, VirusTotal, AlienVault) for infrastructure discovery; (4) Use machine learning models to identify patterns of data leakage; (5) Establish baseline metrics for normal disclosure activity to detect anomalies. Focus on precision to reduce false positives and alert fatigue."
  },
  {
    "control_id": "AU-13.2",
    "control_name": "Review of Monitored Sites",
    "family": "Audit and Accountability",
    "family_id": "au",
    "official_text": "Review the list of open-source information sites being monitored at organization-defined frequency.",
    "parent_control": "AU-13",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "plain_english_explanation": "Organizations must regularly review and update the list of open-source information sites that are monitored for information disclosure. As new platforms emerge and organizational threat landscape evolves, the monitoring scope must be adjusted to remain effective and focused on relevant information sources.",
    "example_implementation": "Implement a formal review process for monitored sites through: (1) Establish a quarterly review schedule or event-driven review when new platforms emerge; (2) Maintain a master list of monitored sites with documentation of monitoring scope and justification; (3) Conduct review meetings with stakeholders including security, IT operations, and business owners; (4) Evaluate new platforms for relevance based on organizational operations and employee communities; (5) Document removal of obsolete or no longer relevant platforms; (6) Test monitoring coverage to ensure all configured sites are accessible and properly monitored; (7) Document review findings, decisions made, and approvals in control records; (8) Update monitoring tool configurations based on review outcomes; (9) Maintain audit trail of all changes to monitored sites list.",
    "non_technical_guidance": "1. Schedule formal reviews of monitored sites at defined intervals\n2. Identify business stakeholders who should participate in reviews\n3. Maintain current inventory of all monitored information platforms\n4. Assess new platforms emerging in market and relevant to organization\n5. Document justification for each monitored site\n6. Remove sites that no longer present disclosure risk\n7. Test monitoring coverage and effectiveness\n8. Document review decisions and approvals\n9. Update monitoring tool configurations\n10. Maintain audit evidence of review process and outcomes",
    "is_technical": false,
    "enhancements": [],
    "related_controls": [
      "AU-13",
      "AU-13.1",
      "CA-7",
      "PM-6"
    ],
    "supplemental_guidance": "The review of monitored sites should be aligned with organizational risk management processes and changes in the operating environment. As new social media platforms, code repositories, and forums emerge, the organization should assess whether they present information disclosure risks. The review frequency should be established based on organizational risk tolerance and the rate of platform emergence. Documentation of review decisions supports compliance demonstration and provides evidence of diligent monitoring program management.",
    "implementation_scripts": {
      "linux": {
        "description": "Bash script for managing and reviewing information disclosure monitoring sites",
        "script": "#!/bin/bash\n# AU-13.2 Monitoring Sites Review and Maintenance Script\n\nMONITORING_DIR=\"/var/lib/au-13-monitoring\"\nSITES_INVENTORY=\"${MONITORING_DIR}/sites-inventory.json\"\nREVIEW_LOG=\"${MONITORING_DIR}/sites-review.log\"\nARCHIVE_DIR=\"${MONITORING_DIR}/archive\"\n\n# Create directory structure\nmkdir -p ${MONITORING_DIR} ${ARCHIVE_DIR}\n\n# Initialize sites inventory if not exists\nif [ ! -f ${SITES_INVENTORY} ]; then\n  cat > ${SITES_INVENTORY} << 'EOF'\n{\n  \"monitored_sites\": [\n    {\n      \"url\": \"https://github.com\",\n      \"platform\": \"Code Repository\",\n      \"added_date\": \"2025-01-01\",\n      \"business_justification\": \"Public code repository where employee contributions may expose organizational code or infrastructure details\",\n      \"monitoring_method\": \"API and Web Search\",\n      \"risk_level\": \"HIGH\",\n      \"active\": true\n    },\n    {\n      \"url\": \"https://gitlab.com\",\n      \"platform\": \"Code Repository\",\n      \"added_date\": \"2025-01-01\",\n      \"business_justification\": \"Alternative code repository platform used by developers\",\n      \"monitoring_method\": \"API and Web Search\",\n      \"risk_level\": \"HIGH\",\n      \"active\": true\n    },\n    {\n      \"url\": \"https://twitter.com\",\n      \"platform\": \"Social Media\",\n      \"added_date\": \"2025-01-01\",\n      \"business_justification\": \"Social media platform where organizational announcements and employee information may be disclosed\",\n      \"monitoring_method\": \"Search and API\",\n      \"risk_level\": \"MEDIUM\",\n      \"active\": true\n    },\n    {\n      \"url\": \"https://linkedin.com\",\n      \"platform\": \"Social Media\",\n      \"added_date\": \"2025-01-01\",\n      \"business_justification\": \"Professional network where employee and organizational information is typically shared\",\n      \"monitoring_method\": \"Search and API\",\n      \"risk_level\": \"MEDIUM\",\n      \"active\": true\n    }\n  ],\n  \"last_review_date\": \"2025-11-20\",\n  \"next_review_date\": \"2026-02-20\",\n  \"review_frequency_days\": 90\n}\nEOF\nfi\n\n# Function to review site accessibility\nreview_site_accessibility() {\n  local url=$1\n  local timestamp=$(date '+%Y-%m-%d %H:%M:%S')\n  \n  echo \"[${timestamp}] Checking accessibility of ${url}...\" >> ${REVIEW_LOG}\n  \n  response=$(curl -s -I -m 5 \"${url}\" 2>&1)\n  http_code=$(echo \"${response}\" | grep -oP 'HTTP/\\d\\.\\d \\K[0-9]+')\n  \n  if [ -n \"${http_code}\" ] && [ \"${http_code}\" -lt 400 ]; then\n    echo \"[${timestamp}] ${url} - ACCESSIBLE (HTTP ${http_code})\" >> ${REVIEW_LOG}\n    return 0\n  else\n    echo \"[${timestamp}] ${url} - INACCESSIBLE (HTTP ${http_code})\" >> ${REVIEW_LOG}\n    return 1\n  fi\n}\n\n# Function to perform monitoring sites review\nperform_sites_review() {\n  local timestamp=$(date '+%Y-%m-%d %H:%M:%S')\n  local review_date=$(date '+%Y-%m-%d')\n  \n  echo \"\" >> ${REVIEW_LOG}\n  echo \"================================================================================\" >> ${REVIEW_LOG}\n  echo \"MONITORING SITES REVIEW - ${timestamp}\" >> ${REVIEW_LOG}\n  echo \"================================================================================\" >> ${REVIEW_LOG}\n  \n  # Backup current inventory\n  cp ${SITES_INVENTORY} ${ARCHIVE_DIR}/sites-inventory-${review_date}.json\n  \n  # Test each site\n  active_sites=$(grep -c '\"active\": true' ${SITES_INVENTORY})\n  total_sites=$(grep -c '\"url\"' ${SITES_INVENTORY})\n  \n  echo \"[${timestamp}] Total monitored sites: ${total_sites}\" >> ${REVIEW_LOG}\n  echo \"[${timestamp}] Active sites: ${active_sites}\" >> ${REVIEW_LOG}\n  \n  # Review each site for accessibility\n  grep -o '\"url\": \"[^\"]*\"' ${SITES_INVENTORY} | grep -o 'https://[^\"]*' | while read site; do\n    review_site_accessibility \"${site}\"\n  done\n  \n  # Generate summary\n  echo \"[${timestamp}] Sites review completed. See detailed log for results.\" >> ${REVIEW_LOG}\n  echo \"[${timestamp}] Recommended action: Review audit findings and update site list.\" >> ${REVIEW_LOG}\n  \n  # Log accessibility results\n  accessible=$(grep -c 'ACCESSIBLE' ${REVIEW_LOG})\n  inaccessible=$(grep -c 'INACCESSIBLE' ${REVIEW_LOG})\n  echo \"[${timestamp}] Summary: ${accessible} accessible, ${inaccessible} inaccessible\" >> ${REVIEW_LOG}\n}\n\n# Function to add new site\nadd_site() {\n  local url=$1\n  local platform=$2\n  local justification=$3\n  local timestamp=$(date '+%Y-%m-%d')\n  \n  # Note: Simplified addition - in production use jq for JSON manipulation\n  echo \"[$(date '+%Y-%m-%d %H:%M:%S')] Added site: ${url} (${platform}) - ${justification}\" >> ${REVIEW_LOG}\n}\n\n# Function to remove site\nremove_site() {\n  local url=$1\n  local reason=$2\n  \n  echo \"[$(date '+%Y-%m-%d %H:%M:%S')] Removed site: ${url} - Reason: ${reason}\" >> ${REVIEW_LOG}\n}\n\n# Main execution\necho \"AU-13.2 Sites Review and Maintenance\"\n\ncase \"${1:-review}\" in\n  review)\n    perform_sites_review\n    ;;\n  add)\n    add_site \"$2\" \"$3\" \"$4\"\n    ;;\n  remove)\n    remove_site \"$2\" \"$3\"\n    ;;\n  *)\n    echo \"Usage: $0 {review|add URL PLATFORM JUSTIFICATION|remove URL REASON}\"\n    exit 1\n    ;;\nesac\n\nexit 0"
      },
      "windows": {
        "description": "PowerShell script for managing and reviewing information disclosure monitoring sites",
        "script": "# AU-13.2 Monitoring Sites Review and Maintenance Script for Windows\n\nparam(\n    [ValidateSet('review', 'add', 'remove')]\n    [string]$Action = 'review',\n    [string]$Url,\n    [string]$Platform,\n    [string]$Justification,\n    [string]$Reason\n)\n\n$MonitoringDir = \"C:\\Windows\\System32\\au-13-monitoring\"\n$SitesInventory = \"${MonitoringDir}\\sites-inventory.json\"\n$ReviewLog = \"${MonitoringDir}\\sites-review.log\"\n$ArchiveDir = \"${MonitoringDir}\\archive\"\n\n# Create directories if needed\nif (-not (Test-Path $MonitoringDir)) {\n    New-Item -ItemType Directory -Path $MonitoringDir -Force | Out-Null\n}\nif (-not (Test-Path $ArchiveDir)) {\n    New-Item -ItemType Directory -Path $ArchiveDir -Force | Out-Null\n}\n\n# Helper function for logging\nfunction Write-ReviewLog {\n    param([string]$Message)\n    $timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    $logMessage = \"[${timestamp}] ${Message}\"\n    Add-Content -Path $ReviewLog -Value $logMessage\n    Write-Host $logMessage\n}\n\n# Initialize inventory if needed\nfunction Initialize-Inventory {\n    if (-not (Test-Path $SitesInventory)) {\n        $inventory = @{\n            monitored_sites = @(\n                @{\n                    url = \"https://github.com\"\n                    platform = \"Code Repository\"\n                    added_date = \"2025-01-01\"\n                    business_justification = \"Public code repository where employee contributions may expose organizational code\"\n                    monitoring_method = \"API and Web Search\"\n                    risk_level = \"HIGH\"\n                    active = $true\n                },\n                @{\n                    url = \"https://twitter.com\"\n                    platform = \"Social Media\"\n                    added_date = \"2025-01-01\"\n                    business_justification = \"Social media platform for organizational and employee information\"\n                    monitoring_method = \"Search and API\"\n                    risk_level = \"MEDIUM\"\n                    active = $true\n                }\n            )\n            last_review_date = (Get-Date -Format \"yyyy-MM-dd\")\n            next_review_date = (Get-Date).AddDays(90).ToString(\"yyyy-MM-dd\")\n            review_frequency_days = 90\n        }\n        $inventory | ConvertTo-Json | Out-File -FilePath $SitesInventory -Encoding UTF8\n        Write-ReviewLog \"Sites inventory initialized\"\n    }\n}\n\n# Review site accessibility\nfunction Test-SiteAccessibility {\n    param([string]$Url)\n    \n    try {\n        $response = Invoke-WebRequest -Uri $Url -Method Head -TimeoutSec 5 -ErrorAction Stop\n        Write-ReviewLog \"${Url} - ACCESSIBLE (HTTP $($response.StatusCode))\"\n        return $true\n    } catch {\n        Write-ReviewLog \"${Url} - INACCESSIBLE ($($_.Exception.Message))\"\n        return $false\n    }\n}\n\n# Perform comprehensive review\nfunction Invoke-SitesReview {\n    Write-ReviewLog \"===================================================\"\n    Write-ReviewLog \"MONITORING SITES REVIEW - $(Get-Date -Format 'yyyy-MM-dd HH:mm:ss')\"\n    Write-ReviewLog \"===================================================\"\n    \n    Initialize-Inventory\n    \n    # Backup current inventory\n    $backupPath = \"${ArchiveDir}\\sites-inventory-$(Get-Date -Format 'yyyyMMdd-HHmmss').json\"\n    Copy-Item -Path $SitesInventory -Destination $backupPath\n    Write-ReviewLog \"Inventory backed up to ${backupPath}\"\n    \n    # Load and review inventory\n    $inventory = Get-Content $SitesInventory | ConvertFrom-Json\n    \n    $activeSites = @($inventory.monitored_sites | Where-Object { $_.active -eq $true })\n    Write-ReviewLog \"Total monitored sites: $($inventory.monitored_sites.Count)\"\n    Write-ReviewLog \"Active sites: $($activeSites.Count)\"\n    \n    # Test accessibility\n    $accessible = 0\n    $inaccessible = 0\n    \n    foreach ($site in $activeSites) {\n        if (Test-SiteAccessibility -Url $site.url) {\n            $accessible++\n        } else {\n            $inaccessible++\n        }\n    }\n    \n    Write-ReviewLog \"Accessibility Summary: ${accessible} accessible, ${inaccessible} inaccessible\"\n    Write-ReviewLog \"Sites review completed - See detailed log for findings\"\n    \n    # Update review dates\n    $inventory.last_review_date = Get-Date -Format \"yyyy-MM-dd\"\n    $inventory.next_review_date = (Get-Date).AddDays(90).ToString(\"yyyy-MM-dd\")\n    \n    $inventory | ConvertTo-Json | Out-File -FilePath $SitesInventory -Encoding UTF8\n    Write-ReviewLog \"Inventory updated with next review date: $($inventory.next_review_date)\"\n}\n\n# Add new site\nfunction Add-MonitoredSite {\n    param(\n        [string]$Url,\n        [string]$Platform,\n        [string]$Justification\n    )\n    \n    Initialize-Inventory\n    $inventory = Get-Content $SitesInventory | ConvertFrom-Json\n    \n    $newSite = @{\n        url = $Url\n        platform = $Platform\n        added_date = Get-Date -Format \"yyyy-MM-dd\"\n        business_justification = $Justification\n        monitoring_method = \"API and Web Search\"\n        risk_level = \"MEDIUM\"\n        active = $true\n    }\n    \n    [array]$inventory.monitored_sites += $newSite\n    $inventory | ConvertTo-Json | Out-File -FilePath $SitesInventory -Encoding UTF8\n    \n    Write-ReviewLog \"Added site: ${Url} (${Platform}) - ${Justification}\"\n}\n\n# Remove site\nfunction Remove-MonitoredSite {\n    param(\n        [string]$Url,\n        [string]$Reason\n    )\n    \n    Initialize-Inventory\n    $inventory = Get-Content $SitesInventory | ConvertFrom-Json\n    \n    $inventory.monitored_sites = @($inventory.monitored_sites | Where-Object { $_.url -ne $Url })\n    $inventory | ConvertTo-Json | Out-File -FilePath $SitesInventory -Encoding UTF8\n    \n    Write-ReviewLog \"Removed site: ${Url} - Reason: ${Reason}\"\n}\n\n# Main execution\nswitch ($Action) {\n    'review' {\n        Invoke-SitesReview\n    }\n    'add' {\n        if (-not $Url -or -not $Platform -or -not $Justification) {\n            Write-Error \"add action requires: -Url, -Platform, -Justification\"\n            exit 1\n        }\n        Add-MonitoredSite -Url $Url -Platform $Platform -Justification $Justification\n    }\n    'remove' {\n        if (-not $Url -or -not $Reason) {\n            Write-Error \"remove action requires: -Url, -Reason\"\n            exit 1\n        }\n        Remove-MonitoredSite -Url $Url -Reason $Reason\n    }\n}\n\nexit 0"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-20T00:00:00.000000Z",
      "has_scripts": true
    },
    "cac_metadata": {
      "implementation_type": "organizational",
      "last_analyzed": "2025-11-20T00:00:00.000000Z",
      "source": "NIST SP 800-53 Rev 5",
      "implementation_guidance": "AU-13(2) requires periodic review of monitored information sites. Organizations should establish a documented review process with defined frequency (e.g., quarterly). ComplianceAsCode does not provide specific technical implementations for this control, as it is primarily operational and organizational in nature."
    },
    "stig_id": null,
    "ai_guidance": "Establish a formal review cycle tied to organizational risk management. Create a monitoring sites master list with metadata including platform category, business justification, risk rating, and monitoring method. Schedule quarterly reviews (or upon major organizational changes) to: (1) Validate continued relevance of monitored sites; (2) Test monitoring coverage for accessibility; (3) Identify new platforms emerging in relevant communities; (4) Remove obsolete or lower-risk platforms. Document all reviews with approvals and store in a version-controlled system."
  },
  {
    "control_id": "AU-13.3",
    "control_name": "Unauthorized Replication of Information",
    "family": "Audit and Accountability",
    "family_id": "au",
    "official_text": "Employ discovery techniques, processes, and tools to determine if external entities are replicating organizational information in an unauthorized manner.",
    "parent_control": "AU-13",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "plain_english_explanation": "Organizations must implement discovery methods to identify when external parties are copying, mirroring, or reproducing organizational information without authorization. This includes detecting unauthorized website mirrors, data copies in public repositories, credential trafficking, and information redistribution through unauthorized channels.",
    "example_implementation": "Implement unauthorized replication detection through: (1) Deploy web content fingerprinting tools that track unauthorized copies of organizational websites or content; (2) Implement copyright infringement monitoring services to detect reproductions of proprietary content; (3) Monitor dark web marketplaces for organizational databases, intellectual property, or credentials; (4) Use digital watermarking or content hash verification to identify unauthorized copies; (5) Employ threat intelligence services to monitor for organizational information distributed through unauthorized channels; (6) Establish processes to track and analyze clone/mirror sites that replicate organizational web properties; (7) Implement continuous monitoring of major cloud storage and file-sharing platforms for unauthorized organizational data copies; (8) Deploy data loss prevention (DLP) tools that track organizational information movement; (9) Document detection methodology, tools used, and findings in control records.",
    "non_technical_guidance": "1. Identify critical organizational information requiring replication monitoring\n2. Evaluate threat intelligence and monitoring services for replication detection\n3. Establish baseline of authorized information distribution channels\n4. Document procedures for investigating detected unauthorized replications\n5. Define response procedures for identified replication incidents\n6. Coordinate with legal and business teams on intellectual property protection\n7. Maintain inventory of known authorized mirrors or copies (e.g., CDNs, backup sites)\n8. Monitor dark web and underground forums for organizational information sales\n9. Track results of replication discovery efforts in audit logs\n10. Integrate findings with incident response and breach notification procedures",
    "is_technical": true,
    "enhancements": [],
    "related_controls": [
      "AU-13",
      "IR-4",
      "IR-6",
      "IR-7",
      "PM-12",
      "SI-4",
      "SI-20"
    ],
    "supplemental_guidance": "Unauthorized replication detection may employ content fingerprinting, cryptographic hashing, digital watermarking, web crawling for cloned content, dark web monitoring, threat intelligence services, and manual research. Organizations should coordinate with their legal departments to understand intellectual property protections and remediation options when unauthorized replications are discovered. The discovery process should be documented and repeatable, allowing for trending analysis of replication attempts. Organizations should differentiate between authorized mirroring or caching (e.g., search engines, CDNs) and truly unauthorized replications.",
    "implementation_scripts": {
      "linux": {
        "description": "Python script for detecting unauthorized replication of organizational information",
        "script": "#!/usr/bin/env python3\n# AU-13.3 Unauthorized Information Replication Detection\n# Requires: requests, beautifulsoup4, hashlib, urllib\n\nimport os\nimport json\nimport requests\nimport hashlib\nfrom datetime import datetime\nfrom urllib.parse import urlparse\nimport logging\nfrom difflib import SequenceMatcher\n\n# Configuration\nORG_SITES = os.getenv('ORG_SITES', '').split(',')\nDARK_WEB_MONITOR_URLS = [\n    # Example monitoring endpoints for dark web and threat intelligence\n    # These would be configured based on available services\n]\nLOG_FILE = '/var/log/au-13-3-replication.log'\n\n# Setup logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler(LOG_FILE),\n        logging.StreamHandler()\n    ]\n)\nlogger = logging.getLogger('AU-13.3')\n\nclass ContentFingerprinter:\n    \"\"\"Generate and track content fingerprints for replication detection\"\"\"\n    \n    def __init__(self):\n        self.fingerprints = {}\n    \n    def generate_fingerprint(self, content):\n        \"\"\"Generate SHA-256 fingerprint of content\"\"\"\n        return hashlib.sha256(content.encode()).hexdigest()\n    \n    def store_original(self, url, content):\n        \"\"\"Store fingerprint of original organizational content\"\"\"\n        fingerprint = self.generate_fingerprint(content)\n        self.fingerprints[url] = {\n            'fingerprint': fingerprint,\n            'stored_date': datetime.now().isoformat(),\n            'content_length': len(content)\n        }\n        logger.info(f'Stored fingerprint for {url}: {fingerprint}')\n    \n    def check_for_replication(self, url, content):\n        \"\"\"Check if content matches known organizational content\"\"\"\n        fingerprint = self.generate_fingerprint(content)\n        \n        for original_url, original_data in self.fingerprints.items():\n            if fingerprint == original_data['fingerprint']:\n                logger.warning(f'UNAUTHORIZED REPLICATION DETECTED: {url} duplicates {original_url}')\n                return True, original_url\n            \n            # Also check for partial matches (similarity > 80%)\n            similarity = SequenceMatcher(None, fingerprint, original_data['fingerprint']).ratio()\n            if similarity > 0.8:\n                logger.warning(f'SIMILAR CONTENT DETECTED: {url} has {similarity*100:.1f}% similarity to {original_url}')\n                return True, original_url\n        \n        return False, None\n\nclass WebMonitor:\n    \"\"\"Monitor web for unauthorized replications\"\"\"\n    \n    def __init__(self):\n        self.fingerprinter = ContentFingerprinter()\n        self.session = requests.Session()\n        self.session.headers.update({\n            'User-Agent': 'Mozilla/5.0 (Security Monitoring Bot)'\n        })\n    \n    def fetch_content(self, url):\n        \"\"\"Fetch content from URL\"\"\"\n        try:\n            response = self.session.get(url, timeout=10)\n            if response.status_code == 200:\n                return response.text\n        except requests.exceptions.RequestException as e:\n            logger.error(f'Error fetching {url}: {str(e)}')\n        return None\n    \n    def scan_for_mirrors(self, domain):\n        \"\"\"Scan for mirror/clone sites of organizational domain\"\"\"\n        findings = []\n        \n        # Common mirror domain patterns\n        patterns = [\n            f'{domain}-mirror.com',\n            f'{domain}.mirror.io',\n            f'mirror-{domain}.com',\n            f'{domain}-backup.com',\n            f'{domain}-clone.com'\n        ]\n        \n        for pattern in patterns:\n            try:\n                response = self.session.head(f'https://{pattern}', timeout=5)\n                if response.status_code < 400:\n                    logger.warning(f'MIRROR SITE DETECTED: {pattern} (HTTP {response.status_code})')\n                    findings.append(pattern)\n            except:\n                pass\n        \n        return findings\n    \n    def check_pastebin_for_exposure(self, search_terms):\n        \"\"\"Check Pastebin and similar services for organizational data\"\"\"\n        findings = []\n        \n        for term in search_terms:\n            try:\n                # Pastebin and similar services have search APIs\n                search_url = f'https://pastebin.com/search?q={term}'\n                response = self.session.get(search_url)\n                \n                if 'results' in response.text:\n                    logger.warning(f'PASTE SERVICE EXPOSURE: {term} found in paste services')\n                    findings.append(term)\n            except Exception as e:\n                logger.debug(f'Pastebin search error: {str(e)}')\n        \n        return findings\n\nclass DarkWebMonitor:\n    \"\"\"Monitor dark web and underground forums for organizational data\"\"\"\n    \n    def __init__(self):\n        self.logger = logger\n    \n    def check_threat_intelligence_feeds(self, search_terms):\n        \"\"\"Query threat intelligence services for organizational data\"\"\"\n        findings = []\n        \n        # This would integrate with threat intelligence APIs\n        # Examples: VirusTotal, AlienVault, Shodan\n        # Requires API keys and subscriptions\n        \n        logger.info('Dark web monitoring configured - integrate with threat intelligence services')\n        return findings\n    \n    def monitor_marketplaces(self, search_terms):\n        \"\"\"Monitor underground marketplaces for data sales\"\"\"\n        findings = []\n        \n        for term in search_terms:\n            logger.info(f'Monitoring marketplaces for: {term}')\n            # Integration with marketplace monitoring services\n            # Examples: Digital Shadows, Recorded Future, Flashpoint\n        \n        return findings\n\ndef main():\n    \"\"\"Main replication detection function\"\"\"\n    logger.info('AU-13.3 Unauthorized Replication Detection Started')\n    \n    all_findings = []\n    web_monitor = WebMonitor()\n    dark_web_monitor = DarkWebMonitor()\n    \n    # Get organizational sites\n    if not ORG_SITES or ORG_SITES[0] == '':\n        logger.error('ORG_SITES environment variable not configured')\n        return 1\n    \n    # Scan for mirrors/clones\n    for site in ORG_SITES:\n        domain = urlparse(site).netloc\n        mirrors = web_monitor.scan_for_mirrors(domain)\n        all_findings.extend(mirrors)\n    \n    # Check paste services\n    org_identifiers = os.getenv('ORG_IDENTIFIERS', '').split(',')\n    if org_identifiers:\n        paste_exposures = web_monitor.check_pastebin_for_exposure(org_identifiers)\n        all_findings.extend(paste_exposures)\n    \n    # Check dark web\n    ti_findings = dark_web_monitor.check_threat_intelligence_feeds(org_identifiers)\n    all_findings.extend(ti_findings)\n    \n    logger.info(f'Replication detection completed. Total findings: {len(all_findings)}')\n    \n    return 0 if len(all_findings) == 0 else 1\n\nif __name__ == '__main__':\n    exit(main())"
      },
      "windows": {
        "description": "PowerShell script for detecting unauthorized replication of organizational information",
        "script": "# AU-13.3 Unauthorized Information Replication Detection for Windows\n\nparam(\n    [string[]]$OrganizationalSites = @(\"https://www.organization.com\"),\n    [string[]]$SearchTerms = @(),\n    [string]$LogPath = \"C:\\Windows\\Logs\\AU-13\"\n)\n\n# Ensure log directory exists\nif (-not (Test-Path $LogPath)) {\n    New-Item -ItemType Directory -Path $LogPath -Force | Out-Null\n}\n\n$LogFile = \"${LogPath}\\au-13-3-replication.log\"\n\nfunction Write-ReplicationLog {\n    param([string]$Message, [string]$Level = \"INFO\")\n    $timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    $logMessage = \"[${timestamp}] [${Level}] ${Message}\"\n    Add-Content -Path $LogFile -Value $logMessage\n    Write-Host $logMessage\n}\n\nfunction Get-ContentFingerprint {\n    param([string]$Content)\n    \n    $hashObject = [System.Security.Cryptography.HashAlgorithm]::Create('SHA256')\n    $inputBytes = [System.Text.Encoding]::UTF8.GetBytes($Content)\n    $hashBytes = $hashObject.ComputeHash($inputBytes)\n    \n    return [System.BitConverter]::ToString($hashBytes).Replace(\"-\", \"\").ToLower()\n}\n\nfunction Test-MirrorSites {\n    param([string[]]$Domains)\n    \n    $findings = @()\n    \n    # Common mirror/clone patterns\n    $patterns = @(\n        '-mirror', '-backup', '-clone', '-copy', '-archive',\n        'mirror-', 'backup-', 'clone-'\n    )\n    \n    foreach ($domain in $Domains) {\n        foreach ($pattern in $patterns) {\n            $testDomain = $domain -replace 'https?://', '' -replace 'www.', ''\n            $testUrl = \"https://${testDomain}${pattern}.com\"\n            \n            try {\n                $response = Invoke-WebRequest -Uri $testUrl -Method Head -TimeoutSec 5 -ErrorAction Stop\n                Write-ReplicationLog \"MIRROR SITE DETECTED: ${testUrl} (HTTP $($response.StatusCode))\" \"WARN\"\n                $findings += @{\n                    type = 'mirror_site'\n                    url = $testUrl\n                    timestamp = Get-Date -Format o\n                }\n            } catch {\n                # Site not found or unreachable - expected for most patterns\n            }\n        }\n    }\n    \n    return $findings\n}\n\nfunction Test-PasteBinExposure {\n    param([string[]]$SearchTerms)\n    \n    $findings = @()\n    \n    foreach ($term in $SearchTerms) {\n        try {\n            $searchUrl = \"https://www.pastebin.com/search?q=$([System.Web.HttpUtility]::UrlEncode($term))\"\n            $response = Invoke-WebRequest -Uri $searchUrl -TimeoutSec 10 -ErrorAction Stop\n            \n            if ($response.Content -match 'results') {\n                Write-ReplicationLog \"PASTEBIN EXPOSURE: ${term} found in public paste services\" \"WARN\"\n                $findings += @{\n                    type = 'pastebin_exposure'\n                    term = $term\n                    timestamp = Get-Date -Format o\n                }\n            }\n        } catch {\n            Write-ReplicationLog \"Pastebin search error for ${term}: $($_.Exception.Message)\" \"DEBUG\"\n        }\n    }\n    \n    return $findings\n}\n\nfunction Test-RepositoryExposure {\n    param([string[]]$SearchTerms)\n    \n    $findings = @()\n    \n    # Check GitHub for exposed organizational code/data\n    foreach ($term in $SearchTerms) {\n        try {\n            $searchUrl = \"https://api.github.com/search/code?q=${term}+in:file\"\n            $response = Invoke-WebRequest -Uri $searchUrl -TimeoutSec 10 -ErrorAction Stop\n            $data = $response.Content | ConvertFrom-Json\n            \n            if ($data.total_count -gt 0) {\n                Write-ReplicationLog \"REPOSITORY EXPOSURE: ${term} found in public repositories\" \"WARN\"\n                $findings += @{\n                    type = 'repository_exposure'\n                    term = $term\n                    repository_count = $data.total_count\n                    timestamp = Get-Date -Format o\n                }\n            }\n        } catch {\n            Write-ReplicationLog \"Repository search error for ${term}: $($_.Exception.Message)\" \"DEBUG\"\n        }\n    }\n    \n    return $findings\n}\n\nfunction Generate-ReplicationReport {\n    param([object[]]$Findings)\n    \n    $reportFile = \"${LogPath}\\replication-report-$(Get-Date -Format 'yyyyMMdd').json\"\n    $report = @{\n        scan_date = Get-Date -Format o\n        total_findings = $Findings.Count\n        findings = $Findings\n    }\n    \n    $report | ConvertTo-Json | Out-File -FilePath $reportFile -Encoding UTF8\n    Write-ReplicationLog \"Report saved to ${reportFile}\"\n    \n    return $reportFile\n}\n\n# Main execution\nWrite-ReplicationLog \"AU-13.3 Unauthorized Replication Detection Started\"\n\n$allFindings = @()\n\n# Extract domains from sites\n$domains = @()\nforeach ($site in $OrganizationalSites) {\n    $domain = ([System.Uri]$site).Host\n    $domains += $domain\n}\n\n# Test for mirror sites\nif ($domains.Count -gt 0) {\n    $mirrorFindings = Test-MirrorSites -Domains $domains\n    $allFindings += $mirrorFindings\n}\n\n# Test for pastebin exposures\nif ($SearchTerms.Count -gt 0) {\n    $pastebinFindings = Test-PasteBinExposure -SearchTerms $SearchTerms\n    $allFindings += $pastebinFindings\n    \n    # Test for repository exposures\n    $repoFindings = Test-RepositoryExposure -SearchTerms $SearchTerms\n    $allFindings += $repoFindings\n}\n\n# Generate report\nif ($allFindings.Count -gt 0) {\n    Generate-ReplicationReport -Findings $allFindings\n    Write-EventLog -LogName \"Security\" -Source \"AU-13\" -EventId 1002 -Message \"Unauthorized replication detected - $($allFindings.Count) findings\"\n}\n\nWrite-ReplicationLog \"Detection completed. Total findings: $($allFindings.Count)\"\n\nexit 0"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-20T00:00:00.000000Z",
      "has_scripts": true
    },
    "cac_metadata": {
      "implementation_type": "technical",
      "last_analyzed": "2025-11-20T00:00:00.000000Z",
      "source": "NIST SP 800-53 Rev 5",
      "implementation_guidance": "AU-13(3) requires technical discovery mechanisms to identify unauthorized replication of organizational information. While ComplianceAsCode RHEL profiles do not provide specific implementations, organizations should deploy web monitoring tools, content fingerprinting mechanisms, and threat intelligence integrations to detect cloned websites, exposed data in repositories, and dark web distribution."
    },
    "stig_id": null,
    "ai_guidance": "Implement multi-layered replication detection: (1) Deploy web fingerprinting tools to detect cloned organizational websites; (2) Integrate with threat intelligence platforms for dark web monitoring (Recorded Future, Digital Shadows); (3) Monitor code repositories (GitHub, GitLab) for exposed credentials and proprietary code; (4) Track unauthorized copies of proprietary documents in cloud storage and file-sharing services; (5) Establish baseline of authorized copies (CDNs, disaster recovery sites); (6) Implement automated alerts for detected replications; (7) Maintain incident evidence and coordinate with legal teams for takedown requests. Focus on impact prioritization - prioritize detection of business-critical information replications."
  }
]
