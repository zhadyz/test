[
  {
    "control_id": "AU-7",
    "control_name": "Audit Record Reduction and Report Generation",
    "family": "Audit and Accountability",
    "family_id": "au",
    "official_text": "Provide and implement an audit record reduction and report generation capability that:\n1. Supports on-demand audit record review, analysis, and reporting requirements and after-the-fact investigations of incidents; and\n2. Does not alter the original content or time ordering of audit records.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": true,
      "high": true
    },
    "plain_english_explanation": "Organizations must implement tools and processes to efficiently manage large volumes of audit log data. The system must be able to reduce unnecessary audit information into meaningful summaries for analysis while preserving the original audit records unchanged. This allows security teams to review logs, identify anomalies, generate compliance reports, and investigate security incidents without losing data integrity.",
    "example_implementation": "Deploy automated audit log analysis tools such as auditd with aureport and ausearch utilities on RHEL systems. Configure centralized log collection with rsyslog or similar tools. Implement log aggregation platform with search and filtering capabilities (e.g., Splunk, ELK Stack, or native syslog solutions). Configure automated report generation for compliance reviews. Establish audit log retention policies aligned with organizational requirements.",
    "non_technical_guidance": "To implement AU-7 audit record reduction and report generation capability:\n1. Identify the categories of audit events your organization needs to monitor based on security policies and compliance requirements.\n2. Select and deploy audit management tools that can filter, sort, and search logs efficiently without modifying original records.\n3. Configure automated reports that are generated on a regular schedule or on-demand for management review.\n4. Establish procedures for log retention, archival, and disposal aligned with legal and regulatory requirements.\n5. Train audit reviewers on using the audit analysis tools to investigate incidents and identify trends.\n6. Regularly review the effectiveness of your audit reduction capability and adjust as needed to address new threats or compliance requirements.\n7. Maintain documentation of audit system configuration, report formats, and procedures.",
    "is_technical": false,
    "enhancements": [
      {
        "id": "AU-7.1",
        "title": "Automatic Processing",
        "official_text": "Provide and implement the capability to process, sort, and search audit records for events of interest based on the following content: [Assignment: organization-defined fields within audit records]."
      },
      {
        "id": "AU-7.2",
        "title": "Automatic Sort and Search",
        "official_text": "The system provides the capability to automatically sort and search audit records for events of interest based on [Assignment: organization-defined audit fields and search criteria]."
      }
    ],
    "related_controls": [
      "AU-2",
      "AU-4",
      "AU-5",
      "AU-6",
      "AU-9",
      "AU-11",
      "AU-12",
      "SI-4"
    ],
    "supplemental_guidance": "Audit record reduction is a process that manipulates collected audit log information and organizes it into a summary format that is more meaningful to analysts. Audit record reduction and report generation capabilities may come from different systems or organizational units than those conducting audit logging. The capability employs modern data mining techniques with advanced data filters to identify anomalous behavior in audit records. The report generation capability can generate customizable reports in various formats. Audit record reduction does not delete original audit records; rather, it creates organized views and summaries for analysis. Timestamp granularity must be maintained to ensure proper time ordering of events during reduction and reporting.",
    "implementation_scripts": {
      "linux": {
        "auditd_search_script": "#!/bin/bash\n# AU-7 Audit Record Search and Analysis Script\n# This script provides capabilities for searching and reporting on audit records\n\nauditd_search() {\n    local search_type=$1\n    local search_value=$2\n    local date_filter=$3\n    \n    case $search_type in\n        uid)\n            ausearch -u \"$search_value\" -ts recent\n            ;;\n        syscall)\n            ausearch -m SYSCALL -F syscall=$search_value -ts recent\n            ;;\n        success)\n            ausearch -m SYSCALL -F success=$search_value -ts recent\n            ;;\n        auid)\n            ausearch -ua \"$search_value\" -ts recent\n            ;;\n        exe)\n            ausearch -m EXECVE -F exe=$search_value -ts recent\n            ;;\n        name)\n            ausearch -m SYSCALL -F name=$search_value -ts recent\n            ;;\n        *)\n            echo \"Unknown search type: $search_type\"\n            return 1\n            ;;\n    esac\n}\n\n# Generate audit reports\naudit_report() {\n    echo \"=== Audit Summary Report ===\"\n    echo \"Report Generated: $(date)\"\n    echo \"\"\n    echo \"Total Audit Events:\"\n    ausearch -ts recent | wc -l\n    echo \"\"\n    echo \"Failed Login Attempts:\"\n    ausearch -m USER_LOGIN -F success=no -ts recent | wc -l\n    echo \"\"\n    echo \"Privileged Commands Executed:\"\n    ausearch -m EXECVE -F uid=0 -ts recent | wc -l\n    echo \"\"\n    echo \"File Access Events:\"\n    ausearch -m SYSCALL -F syscall=open -ts recent | wc -l\n}\n\n# Export audit records for analysis\naudit_export() {\n    local output_file=$1\n    local format=$2\n    \n    case $format in\n        csv)\n            ausearch -ts recent --format csv > \"$output_file\"\n            ;;\n        text)\n            ausearch -ts recent > \"$output_file\"\n            ;;\n        json)\n            ausearch -ts recent --format json > \"$output_file\"\n            ;;\n    esac\n}\n\n# Main execution\nif [ $# -lt 1 ]; then\n    echo \"Usage: $0 {search|report|export} [options]\"\n    exit 1\nfi\n\ncase \"$1\" in\n    search)\n        auditd_search \"$2\" \"$3\"\n        ;;\n    report)\n        audit_report\n        ;;\n    export)\n        audit_export \"$2\" \"${3:-text}\"\n        ;;\n    *)\n        echo \"Unknown command: $1\"\n        exit 1\n        ;;\nesac",
        "centralized_logging": "# Configure rsyslog for centralized audit log collection\n# Add to /etc/rsyslog.d/audit.conf\n\n# Forward all audit messages to a central server\n:programname, isequal, \"audispd\" @@audit-server.example.com:514\n\n# Alternative: using auditbeat for structured log forwarding\n# Configure in /etc/auditbeat/auditbeat.yml\nauditbeat.modules:\n- module: file_integrity\n  paths:\n    - /etc\n    - /usr/bin\n    - /usr/sbin\n\noutput.logstash:\n  hosts: [\"logstash.example.com:5000\"]",
        "aureport_automation": "#!/bin/bash\n# Generate daily audit reports for AU-7 compliance\n\nREPORT_DIR=\"/var/log/audit/reports\"\nDATE=$(date +%Y-%m-%d)\nREPORT_FILE=\"$REPORT_DIR/audit_report_$DATE.txt\"\n\nmkdir -p \"$REPORT_DIR\"\n\ncat > \"$REPORT_FILE\" << 'EOF'\n========================================\nDaily Audit Report\nGenerated: $(date)\n========================================\n\n### AUDIT EVENTS SUMMARY ###\nTotal Events: $(ausearch -ts recent | wc -l)\n\n### USER LOGIN FAILURES ###\n$(ausearch -m USER_LOGIN -F success=no -ts recent | aureport -u -i)\n\n### PRIVILEGE ESCALATION ###\n$(ausearch -m SYSCALL -F uid=0 -ts recent | aureport -e -i)\n\n### FILE MODIFICATIONS ###\n$(ausearch -m EXECVE -F exe=/usr/bin/passwd -ts recent | aureport -f -i)\n\nEOF\n\necho \"Report generated: $REPORT_FILE\""
      },
      "windows": {
        "powershell_audit_search": "$Script:AuditLogPath = \"C:\\Windows\\System32\\config\"\n$Script:EventLogNames = @('Security', 'Application', 'System')\n\nfunction Get-AuditSearchResults {\n    param(\n        [string]$EventType,\n        [string]$SearchValue,\n        [int]$HoursBack = 24\n    )\n    \n    $StartTime = (Get-Date).AddHours(-$HoursBack)\n    \n    switch($EventType) {\n        'FailedLogin' {\n            Get-WinEvent -FilterHashtable @{\n                LogName = 'Security'\n                ID = @(4625, 4771)\n                StartTime = $StartTime\n            } -ErrorAction SilentlyContinue\n        }\n        'SuccessfulLogin' {\n            Get-WinEvent -FilterHashtable @{\n                LogName = 'Security'\n                ID = @(4624, 4768)\n                StartTime = $StartTime\n            } -ErrorAction SilentlyContinue\n        }\n        'Privilege' {\n            Get-WinEvent -FilterHashtable @{\n                LogName = 'Security'\n                ID = @(4672, 4985)\n                StartTime = $StartTime\n            } -ErrorAction SilentlyContinue\n        }\n        'ObjectAccess' {\n            Get-WinEvent -FilterHashtable @{\n                LogName = 'Security'\n                ID = @(4656, 4657, 4658, 4660, 4661, 4663, 4666, 4667, 4668, 4670, 4690)\n                StartTime = $StartTime\n            } -ErrorAction SilentlyContinue\n        }\n        default {\n            Write-Error \"Unknown event type: $EventType\"\n        }\n    }\n}\n\nfunction New-AuditReport {\n    param(\n        [string]$OutputPath = \"C:\\Reports\",\n        [string]$Format = \"CSV\"\n    )\n    \n    if(-not (Test-Path $OutputPath)) {\n        New-Item -ItemType Directory -Path $OutputPath -Force | Out-Null\n    }\n    \n    $ReportDate = Get-Date -Format \"yyyy-MM-dd_HHmm\"\n    \n    foreach($LogName in $Script:EventLogNames) {\n        $OutputFile = Join-Path $OutputPath \"${LogName}_${ReportDate}.${Format.ToLower()}\"\n        \n        $Events = Get-WinEvent -LogName $LogName -MaxEvents 10000 -ErrorAction SilentlyContinue\n        \n        if($Format -eq 'CSV') {\n            $Events | Select-Object TimeCreated, Id, LevelDisplayName, ProviderName, Message | Export-Csv -Path $OutputFile -NoTypeInformation\n        } elseif($Format -eq 'JSON') {\n            $Events | Select-Object TimeCreated, Id, LevelDisplayName, ProviderName, Message | ConvertTo-Json | Out-File -Path $OutputFile\n        }\n        \n        Write-Host \"Report saved to: $OutputFile\"\n    }\n}\n\nfunction Search-AuditRecords {\n    param(\n        [string]$SearchField,\n        [string]$SearchValue\n    )\n    \n    $Events = Get-WinEvent -LogName Security -MaxEvents 100000 -ErrorAction SilentlyContinue\n    \n    switch($SearchField) {\n        'User' {\n            $Events | Where-Object { $_.Message -like \"*$SearchValue*\" }\n        }\n        'Computer' {\n            $Events | Where-Object { $_.MachineName -eq $SearchValue }\n        }\n        'EventID' {\n            $Events | Where-Object { $_.Id -eq $SearchValue }\n        }\n        default {\n            Write-Error \"Unknown search field: $SearchField\"\n        }\n    }\n}"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-20T00:00:00.000000Z",
      "has_scripts": true,
      "validation_status": "NIST SP 800-53 Rev 5 verified",
      "stig_applicable": true
    },
    "stig_id": "RHEL-08-030370",
    "cac_metadata": {
      "implementation_type": "auditd_with_report_generation",
      "last_analyzed": "2025-11-20T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "cac_status": "available",
      "cac_planned": true,
      "implementation_guidance": "Deploy auditd with ausearch and aureport utilities for audit record search and reduction. Configure centralized logging with rsyslog or ELK Stack. Implement automated daily audit reports. Maintain original audit logs while creating reduced summary views for analysis.",
      "rule_ids": [
        "RHEL-08-030370"
      ]
    },
    "ai_guidance": "AU-7 is critical for organizations processing significant audit volumes. Prioritize implementing search and filter capabilities over manual log review. Use structured logging (JSON) for easier parsing and analysis. Integrate with SIEM platforms for real-time anomaly detection. Ensure audit log immutability during reduction by maintaining original records separately from processed summaries. Test audit report accuracy quarterly to maintain compliance evidence. Automate daily reports to reduce manual effort and ensure timely review of security events."
  },
  {
    "control_id": "AU-7.1",
    "control_name": "Automatic Processing",
    "family": "Audit and Accountability",
    "family_id": "au",
    "official_text": "Provide and implement the capability to process, sort, and search audit records for events of interest based on the following content: [Assignment: organization-defined fields within audit records].",
    "parent_control": "AU-7",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": true,
      "high": true
    },
    "plain_english_explanation": "This enhancement requires organizations to automatically process and organize audit records based on specific fields that are important to their security operations. Rather than manually reviewing logs, the system must be able to automatically sort audit events by selected criteria (such as user ID, event type, timestamp, or status) to quickly identify events of interest. This automated capability must work on organization-defined audit fields determined during system design.",
    "example_implementation": "Configure auditd with custom rules to capture specific audit fields. Deploy ausearch with pre-defined queries for common event categories. Implement Splunk or ELK Stack with automated field extraction and tagging. Create automated alert rules based on field values (e.g., trigger alert when uid=0 events occur). Use log aggregation platforms to normalize and index audit records with consistent field structure.",
    "non_technical_guidance": "To implement AU-7(1) automatic processing capability:\n1. Identify which audit record fields are most important for your organization's security monitoring (e.g., user ID, timestamp, event type, success/failure status, source IP).\n2. Document these fields in your audit processing procedures and system configuration.\n3. Configure your audit tools to automatically extract and organize data based on these fields.\n4. Set up automated sorting and grouping rules so that related events are organized together.\n5. Validate that your automatic processing correctly identifies events of interest without losing important context.\n6. Establish procedures for updating the fields used in automatic processing as security needs evolve.\n7. Train security personnel to use the automatic processing features effectively.",
    "is_technical": true,
    "enhancements": [],
    "related_controls": [
      "AU-2",
      "AU-3",
      "AU-6",
      "AU-7",
      "AU-12"
    ],
    "supplemental_guidance": "Automatic processing of audit records enables rapid identification of security-relevant events without manual log review. Organizations should define the specific audit fields that are meaningful for their operations and security posture. Fields commonly selected include: user identification, authentication success/failure status, object accessed, operation performed, timestamp, source location, and system affected. The system must preserve the ability to view complete audit records while also providing processed summary views. Processing must be repeatable and auditable so that reviewers can understand how records were processed. Organizations should regularly review and validate that the automatic processing rules remain appropriate for current threat environment and organizational changes.",
    "implementation_scripts": {
      "linux": {
        "ausearch_configuration": "#!/bin/bash\n# AU-7(1) Automatic Processing Configuration for auditd\n# Define audit rules for automatic field extraction\n\n# Configure audit rules file: /etc/audit/rules.d/au-7.1.rules\n\ncat > /etc/audit/rules.d/au-7.1.rules << 'EOF'\n# Audit rule set for AU-7(1) Automatic Processing\n# This configuration enables systematic processing of audit records by predefined fields\n\n# System call auditing - capture user ID, success status, and syscall fields\n-a always,exit -F arch=b64 -S adjtimex,settimeofday -F auid>=1000 -F auid!=-1 -k time-change\n\n# File modification tracking - capture file path, user, operation type\n-a always,exit -F arch=b64 -S chmod,chown,fchownat,fchmod,fchmodat,open,openat,open_by_handle_at -F auid>=1000 -F auid!=-1 -F perm_mod -k perm_mod\n\n# User login tracking - capture uid, auid, success/failure\n-a always,exit -F arch=b64 -S execve -k exec\n\n# Authentication events - capture user name, authentication method, success status\n-w /var/log/audit/ -k audit-logs\n-w /var/log/faillog -p wa -k auth-logs\n-w /var/log/lastlog -p wa -k auth-logs\n\n# Privilege escalation tracking - capture uid, suid, sgid changes\n-a always,exit -F arch=b64 -S setuid,setgid,setreuid,setregid -F auid>=1000 -F auid!=-1 -k privilege-escalation\n\nEOF\n\naugenrules --load\nauditctl -l | grep -E 'time-change|perm_mod|exec|auth-logs|privilege-escalation'\necho \"AU-7(1) audit rules loaded successfully\"",
        "ausearch_preset_queries": "#!/bin/bash\n# AU-7(1) Preset Queries for Automatic Processing\n# These functions implement automatic field-based sorting and searching\n\n# Search by user ID field\nausearch_by_uid() {\n    local uid=$1\n    echo \"Processing audit records for UID: $uid\"\n    ausearch -u \"$uid\" --format text | awk '{print $NF}' FS=\"auid=\" | sort | uniq -c\n}\n\n# Search by timestamp range (automatic time-based sorting)\nausearch_by_timestamp() {\n    local start_time=\"$1\"\n    local end_time=\"$2\"\n    echo \"Processing audit records between $start_time and $end_time\"\n    ausearch -ts \"$start_time\" -te \"$end_time\" --format csv | sort -t, -k2,2\n}\n\n# Search by event success/failure field\nausearch_by_status() {\n    local status=$1  # 'yes' or 'no'\n    echo \"Processing audit records with success=$status\"\n    ausearch -m SYSCALL -F success=\"$status\" --format csv | wc -l\n    ausearch -m SYSCALL -F success=\"$status\" --format csv | head -20\n}\n\n# Automatic processing by syscall type\nausearch_by_syscall() {\n    local syscall=$1\n    echo \"Processing audit records for syscall: $syscall\"\n    ausearch -m SYSCALL -F syscall=\"$syscall\" --format csv | sort -t, -k3,3 | uniq\n}\n\n# Automatic processing by executable field\nausearch_by_executable() {\n    local exe=$1\n    echo \"Processing audit records for executable: $exe\"\n    ausearch -m EXECVE -F exe=\"$exe\" --format csv | wc -l\n    ausearch -m EXECVE -F exe=\"$exe\" --format csv | sort -t, -k7,7 -u\n}\n\n# Multi-field automatic processing query\nausearch_multifield() {\n    local uid=$1\n    local syscall=$2\n    local status=$3\n    echo \"Processing audit records: UID=$uid, Syscall=$syscall, Status=$status\"\n    ausearch -u \"$uid\" -m SYSCALL -F syscall=\"$syscall\" -F success=\"$status\" --format csv\n}\n\necho \"AU-7(1) Automatic Processing Functions Ready\"\necho \"Usage examples:\"\necho \"  ausearch_by_uid 1000\"\necho \"  ausearch_by_status yes\"\necho \"  ausearch_by_syscall 2\"",
        "field_extraction_pipeline": "#!/bin/bash\n# AU-7(1) Field Extraction and Automatic Processing Pipeline\n# Extracts predefined fields from audit logs for systematic processing\n\nFIELDS_CONFIG=\"/etc/audit/au-7.1-fields.conf\"\n\ncat > \"$FIELDS_CONFIG\" << 'EOF'\n# AU-7(1) Field Definitions for Automatic Processing\n# Each field represents an audit record component to be automatically extracted and indexed\n\nFIELDS_TO_EXTRACT=(\n    \"auid\"          # Audit User ID\n    \"uid\"           # User ID\n    \"gid\"           # Group ID\n    \"arch\"          # Architecture\n    \"syscall\"       # System Call\n    \"success\"       # Success/Failure Status\n    \"exit\"          # Exit Code\n    \"exe\"           # Executable Path\n    \"name\"          # Object Name\n    \"perm\"          # Permission Change\n    \"type\"          # Event Type\n    \"saddr\"         # Source Address\n    \"daddr\"         # Destination Address\n    \"sport\"         # Source Port\n    \"dport\"         # Destination Port\n)\nEOF\n\n# Automatic field extraction from raw audit logs\nextract_audit_fields() {\n    local input_file=\"$1\"\n    local output_file=\"${2:-audit_processed.csv}\"\n    \n    echo \"Extracting fields for automatic processing...\"\n    \n    # Convert raw audit records to structured CSV with extracted fields\n    ausearch --input-logs -ts recent | awk '\n    BEGIN { print \"timestamp,auid,uid,syscall,success,exe,name\" }\n    {\n        timestamp = $1 \" \" $2\n        auid = \"\"; uid = \"\"; syscall = \"\"; success = \"\"; exe = \"\"; name = \"\"\n        \n        split($0, parts, \" \")\n        for (i in parts) {\n            if (parts[i] ~ /^auid=/) auid = substr(parts[i], 6)\n            if (parts[i] ~ /^uid=/) uid = substr(parts[i], 5)\n            if (parts[i] ~ /^syscall=/) syscall = substr(parts[i], 9)\n            if (parts[i] ~ /^success=/) success = substr(parts[i], 9)\n            if (parts[i] ~ /^exe=/) exe = substr(parts[i], 5)\n            if (parts[i] ~ /^name=/) name = substr(parts[i], 6)\n        }\n        \n        printf \"%s,%s,%s,%s,%s,%s,%s\\n\", timestamp, auid, uid, syscall, success, exe, name\n    }' > \"$output_file\"\n    \n    echo \"Extracted fields saved to: $output_file\"\n    wc -l \"$output_file\"\n}\n\n# Sort extracted fields automatically\nsort_audit_fields() {\n    local csv_file=\"$1\"\n    local sort_field=\"${2:-auid}\"  # Default sort by auid\n    local output_file=\"${3:-audit_sorted.csv}\"\n    \n    echo \"Sorting audit records by field: $sort_field\"\n    \n    header=$(head -1 \"$csv_file\")\n    field_index=$(echo \"$header\" | tr ',' '\\n' | grep -n \"^$sort_field$\" | cut -d: -f1)\n    \n    (echo \"$header\"; tail -n +2 \"$csv_file\" | sort -t, -k\"$field_index\",\"$field_index\") > \"$output_file\"\n    \n    echo \"Sorted records saved to: $output_file\"\n}\n\necho \"AU-7(1) Field Extraction Pipeline Ready\""
      },
      "windows": {
        "powershell_field_extraction": "$AuditFields = @{\n    'Timestamp' = 'TimeCreated'\n    'UserID' = 'UserId'\n    'EventID' = 'Id'\n    'Computer' = 'MachineName'\n    'EventType' = 'LevelDisplayName'\n    'ProcessID' = 'ProcessId'\n    'Source' = 'ProviderName'\n}\n\nfunction Get-AuditFieldExtraction {\n    param(\n        [string]$LogName = 'Security',\n        [int]$MaxEvents = 1000,\n        [string]$SortField = 'Timestamp'\n    )\n    \n    $Events = Get-WinEvent -LogName $LogName -MaxEvents $MaxEvents -ErrorAction SilentlyContinue\n    \n    # Extract specified fields\n    $ExtractedData = $Events | Select-Object @{\n        Name = 'Timestamp'\n        Expression = { $_.TimeCreated }\n    }, @{\n        Name = 'UserID'\n        Expression = { $_.UserId }\n    }, @{\n        Name = 'EventID'\n        Expression = { $_.Id }\n    }, @{\n        Name = 'Computer'\n        Expression = { $_.MachineName }\n    }, @{\n        Name = 'EventType'\n        Expression = { $_.LevelDisplayName }\n    }, @{\n        Name = 'Message'\n        Expression = { $_.Message }\n    }\n    \n    # Automatic sorting by specified field\n    $SortedData = $ExtractedData | Sort-Object -Property $SortField\n    \n    return $SortedData\n}\n\nfunction Process-AuditFieldsByType {\n    param(\n        [Parameter(Mandatory=$true)]\n        [string]$FieldName,\n        [string]$FieldValue\n    )\n    \n    $LogName = 'Security'\n    \n    switch($FieldName) {\n        'EventID' {\n            Get-WinEvent -FilterHashtable @{\n                LogName = $LogName\n                Id = $FieldValue\n            } -MaxEvents 5000 -ErrorAction SilentlyContinue |\n            Group-Object -Property {$_.TimeCreated.Date} -NoElement\n        }\n        'Level' {\n            Get-WinEvent -FilterHashtable @{\n                LogName = $LogName\n            } -MaxEvents 10000 -ErrorAction SilentlyContinue |\n            Where-Object { $_.LevelDisplayName -eq $FieldValue } |\n            Group-Object -Property LevelDisplayName -NoElement\n        }\n        'Computer' {\n            Get-WinEvent -FilterHashtable @{\n                LogName = $LogName\n            } -MaxEvents 10000 -ErrorAction SilentlyContinue |\n            Where-Object { $_.MachineName -eq $FieldValue } |\n            Group-Object -Property MachineName | Select-Object Name, Count\n        }\n        'User' {\n            Get-WinEvent -FilterHashtable @{\n                LogName = $LogName\n            } -MaxEvents 10000 -ErrorAction SilentlyContinue |\n            Where-Object { $_.UserId -like \"*$FieldValue*\" } |\n            Group-Object -Property UserId | Select-Object Name, Count\n        }\n    }\n}\n\nfunction Export-ProcessedAuditFields {\n    param(\n        [string]$OutputPath = 'C:\\\\AuditProcessing',\n        [string]$Format = 'CSV'\n    )\n    \n    if (-not (Test-Path $OutputPath)) {\n        New-Item -ItemType Directory -Path $OutputPath -Force | Out-Null\n    }\n    \n    $ProcessedData = Get-AuditFieldExtraction -MaxEvents 100000\n    $Timestamp = Get-Date -Format 'yyyy-MM-dd_HHmmss'\n    $OutputFile = Join-Path $OutputPath \"au7_1_processed_$Timestamp.$($Format.ToLower())\"\n    \n    if ($Format -eq 'CSV') {\n        $ProcessedData | Export-Csv -Path $OutputFile -NoTypeInformation\n    } elseif ($Format -eq 'JSON') {\n        $ProcessedData | ConvertTo-Json | Out-File -Path $OutputFile\n    } elseif ($Format -eq 'XML') {\n        $ProcessedData | Export-Clixml -Path $OutputFile\n    }\n    \n    Write-Host \"Processed audit fields exported to: $OutputFile\"\n    return $OutputFile\n}"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-20T00:00:00.000000Z",
      "has_scripts": true,
      "validation_status": "NIST SP 800-53 Rev 5 verified",
      "stig_applicable": true
    },
    "stig_id": "RHEL-08-030371",
    "cac_metadata": {
      "implementation_type": "auditd_field_extraction",
      "last_analyzed": "2025-11-20T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "cac_status": "available",
      "cac_planned": true,
      "implementation_guidance": "Configure auditd rules to capture specific audit fields (auid, uid, syscall, success, exe, name). Implement ausearch with field-based queries for automatic record processing. Deploy tools for structured field extraction and indexing. Create automated processing pipelines that sort and organize records by predefined fields.",
      "rule_ids": [
        "RHEL-08-030371"
      ]
    },
    "ai_guidance": "AU-7(1) implementation requires careful planning of which audit fields provide value for your organization. Start with fields that directly support your security use cases (user identification, success/failure status, system calls). Implement field-based queries before building automated processing. Use structured logging formats (JSON) to simplify field extraction. Test field extraction accuracy on a sample of logs before automation. Document all organization-defined fields in your audit system configuration. Review field definitions at least annually to ensure continued relevance to security operations."
  },
  {
    "control_id": "AU-7.2",
    "control_name": "Automatic Sort and Search",
    "family": "Audit and Accountability",
    "family_id": "au",
    "official_text": "The system provides the capability to automatically sort and search audit records for events of interest based on [Assignment: organization-defined audit fields and search criteria].",
    "parent_control": "AU-7",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": true
    },
    "plain_english_explanation": "This enhancement extends AU-7.1 by requiring the system to not only process and sort audit records automatically, but also to provide search capabilities. The system must allow automated queries across audit records using organization-defined search criteria, enabling rapid location and retrieval of specific events without manual log review. This capability must support the organization's defined search parameters and audit fields.",
    "example_implementation": "Implement Elasticsearch or Splunk with automated indexing of audit fields. Configure pre-built search dashboards for common queries (failed logins, privilege escalation, file modifications). Deploy Kibana visualizations that automatically display sorted audit data by timestamp, user, or event type. Create saved searches that run automatically on schedules and trigger alerts based on defined criteria. Use auditd with ELK Stack for real-time searchable audit logs.",
    "non_technical_guidance": "To implement AU-7(2) automatic sort and search capability:\n1. Determine what types of searches your security team needs to perform regularly (e.g., find all events for a specific user, find all failed attempts, find events from a specific time period).\n2. Define the audit fields and search criteria that will be used for automatic searching.\n3. Configure your audit management system to maintain searchable indexes of audit records based on these criteria.\n4. Set up automated search functions that can retrieve matching records without requiring manual log parsing.\n5. Establish templates or quick-search options for common audit queries so that analysts can quickly find events of interest.\n6. Test the search capability to ensure results are accurate and complete.\n7. Train security staff to use the automated search features effectively.\n8. Regularly review search performance and update criteria based on evolving security needs.",
    "is_technical": true,
    "enhancements": [],
    "related_controls": [
      "AU-2",
      "AU-3",
      "AU-6",
      "AU-7",
      "AU-7.1",
      "AU-12"
    ],
    "supplemental_guidance": "Automatic sort and search capabilities enable rapid investigation of security events without manual log examination. Organizations should define search criteria that support their incident response procedures and compliance requirements. Search capabilities must function reliably on large volumes of audit data without performance degradation. The system should support both structured queries (field-based searches) and free-text searches when appropriate. Search results must be accurate and complete, returning all matching records within specified parameters. Organizations should implement role-based access controls on search capabilities to ensure that only authorized personnel can search for sensitive audit information. Regular testing and performance monitoring ensure that search capabilities remain effective as audit log volumes grow.",
    "implementation_scripts": {
      "linux": {
        "elasticsearch_index_configuration": "#!/bin/bash\n# AU-7.2 Elasticsearch Configuration for Automatic Sort and Search\n# This configuration enables rapid searchable indexing of audit records\n\n# Install Elasticsearch and Auditbeat\nsudo dnf install -y elasticsearch auditbeat\n\n# Configure Auditbeat to forward to Elasticsearch\ncat > /etc/auditbeat/auditbeat.yml << 'EOF'\nauditbeat.modules:\n- module: file_integrity\n  paths:\n    - /etc\n    - /usr/bin\n    - /usr/sbin\n  hash_types: [sha256]\n  scan_at_startup: true\n\nauditbeat.metrics:\n  enabled: true\n\noutput.elasticsearch:\n  hosts: [\"localhost:9200\"]\n  index: \"auditbeat-%{+yyyy.MM.dd}\"\n  bulk_max_size: 100\n\nlogging.level: info\nlogging.to_files: true\nlogging.files:\n  path: /var/log/auditbeat\nEOF\n\n# Start services\nsudo systemctl start auditbeat\nsudo systemctl enable auditbeat\n\necho \"Elasticsearch indexing configured for AU-7.2\"",
        "kibana_search_dashboard": "#!/bin/bash\n# Create Kibana dashboards and saved searches for AU-7.2\n# These enable automatic sort and search of audit records\n\nES_HOST=\"localhost:9200\"\nKIBANA_HOST=\"localhost:5601\"\n\n# Create index pattern\ncurl -X POST \"${ES_HOST}/_template/auditbeat-template\" -H 'Content-Type: application/json' -d '\n{\n  \"index_patterns\": [\"auditbeat-*\"],\n  \"settings\": {\n    \"number_of_shards\": 1,\n    \"number_of_replicas\": 0\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"timestamp\": {\"type\": \"date\"},\n      \"uid\": {\"type\": \"keyword\"},\n      \"auid\": {\"type\": \"keyword\"},\n      \"syscall\": {\"type\": \"keyword\"},\n      \"success\": {\"type\": \"keyword\"},\n      \"exe\": {\"type\": \"text\"},\n      \"hostname\": {\"type\": \"keyword\"},\n      \"process.pid\": {\"type\": \"integer\"}\n    }\n  }\n}'\n\necho \"Elasticsearch index template created\"\n\n# Create Kibana saved searches for common queries\necho \"Creating Kibana saved searches for common audit queries...\"\n\n# Saved search: Failed login attempts\ncurl -X POST \"${KIBANA_HOST}/api/saved_objects/search/failed_logins\" \\\n  -H 'Content-Type: application/json' \\\n  -H 'kbn-xsrf: true' \\\n  -d '{\n    \"attributes\": {\n      \"title\": \"Failed Login Attempts\",\n      \"description\": \"Shows all failed authentication attempts\",\n      \"kibanaSavedObjectMeta\": {\n        \"searchSourceJSON\": \"{\\\"index\\\":\\\"auditbeat-*\\\",\\\"query\\\":{\\\"match\\\":{\\\"event.outcome\\\":\\\"failure\\\"}}}\"\n      }\n    }\n  }'\n\n# Saved search: Privilege escalation events\ncurl -X POST \"${KIBANA_HOST}/api/saved_objects/search/privilege_escalation\" \\\n  -H 'Content-Type: application/json' \\\n  -H 'kbn-xsrf: true' \\\n  -d '{\n    \"attributes\": {\n      \"title\": \"Privilege Escalation Events\",\n      \"description\": \"Shows uid=0 and setuid/setgid events\",\n      \"kibanaSavedObjectMeta\": {\n        \"searchSourceJSON\": \"{\\\"index\\\":\\\"auditbeat-*\\\",\\\"query\\\":{\\\"bool\\\":{\\\"should\\\":[{\\\"match\\\":{\\\"user.id\\\":\\\"0\\\"}},{\\\"match\\\":{\\\"audit.syscall\\\":\\\"setuid\\\"}}]}}}\"\n      }\n    }\n  }'\n\n# Saved search: File modifications\ncurl -X POST \"${KIBANA_HOST}/api/saved_objects/search/file_modifications\" \\\n  -H 'Content-Type: application/json' \\\n  -H 'kbn-xsrf: true' \\\n  -d '{\n    \"attributes\": {\n      \"title\": \"File Modifications\",\n      \"description\": \"Shows all file write and modification events\",\n      \"kibanaSavedObjectMeta\": {\n        \"searchSourceJSON\": \"{\\\"index\\\":\\\"auditbeat-*\\\",\\\"query\\\":{\\\"match\\\":{\\\"file.change\\\":\\\"true\\\"}}}\"\n      }\n    }\n  }'\n\necho \"Kibana saved searches created\"\necho \"Access Kibana at: http://${KIBANA_HOST}\"",
        "splunk_index_configuration": "#!/bin/bash\n# AU-7.2 Splunk Configuration for Automatic Sort and Search\n# Configure Splunk to index audit records for searchable access\n\n# Create Splunk index for audit data\n/opt/splunk/bin/splunk add index audit_index -auth admin:changeme \\\n    -maxKBps 50000 \\\n    -tstatsHomePath default \\\n    -coldToFrozenDir \\$SPLUNK_HOME/var/lib/splunk/audit_index/frozendb \\\n    -maxConcurrentOptimizes 4 \\\n    -searchable true\n\n# Configure inputs.conf for audit data ingestion\ncat > /opt/splunk/etc/apps/search/local/inputs.conf << 'EOF'\n[monitor:///var/log/audit/audit.log]\ndisabled = 0\nindex = audit_index\nsourcetype = linux:audit\ntimestamp_fields = msg=audit\n\n[script:///opt/splunk/etc/apps/audit_app/bin/ausearch_stream.sh]\ninterval = 60\nsourcetype = linux:audit\nindex = audit_index\nEOF\n\n# Create saved searches in Splunk\necho \"Creating Splunk saved searches for AU-7.2...\"\n\n/opt/splunk/bin/splunk add saved-search \"AU-7.2 Failed Logins\" \\\n    \"search=sourcetype=linux:audit success=no\" \\\n    -auth admin:changeme\n\n/opt/splunk/bin/splunk add saved-search \"AU-7.2 Privilege Changes\" \\\n    \"search=sourcetype=linux:audit (uid=0 OR syscall=setuid OR syscall=setgid)\" \\\n    -auth admin:changeme\n\n/opt/splunk/bin/splunk add saved-search \"AU-7.2 File Modifications\" \\\n    \"search=sourcetype=linux:audit (syscall=open OR syscall=write) type=SYSCALL\" \\\n    -auth admin:changeme\n\necho \"Splunk index and saved searches configured for AU-7.2\""
      },
      "windows": {
        "splunk_windows_search": "$SplunkServer = \"localhost:8000\"\n$SplunkAuth = @{\n    Username = \"admin\"\n    Password = \"changeme\"\n}\n\nfunction Create-SplunkSearchQuery {\n    param(\n        [string]$QueryName,\n        [string]$SearchCriteria,\n        [string]$Description\n    )\n    \n    $Uri = \"http://${SplunkServer}/services/saved/searches\"\n    \n    $Body = @{\n        name = $QueryName\n        search = $SearchCriteria\n        description = $Description\n        is_scheduled = 1\n        cron_schedule = \"0 * * * *\"\n    } | ConvertTo-Json\n    \n    $Response = Invoke-RestMethod -Uri $Uri -Method Post -Body $Body -Credential (New-Object PSCredential $SplunkAuth.Username, (ConvertTo-SecureString $SplunkAuth.Password -AsPlainText -Force))\n    \n    return $Response\n}\n\nfunction Search-AuditRecordsAutomatically {\n    param(\n        [string]$SearchField,\n        [string]$SearchValue,\n        [int]$MaxResults = 10000\n    )\n    \n    $Uri = \"http://${SplunkServer}/services/search/jobs\"\n    \n    switch($SearchField) {\n        'EventID' {\n            $Search = \"sourcetype=WinEventLog:Security EventCode=$SearchValue | sort - _time\"\n        }\n        'User' {\n            $Search = \"sourcetype=WinEventLog:Security User=$SearchValue | sort - _time\"\n        }\n        'Computer' {\n            $Search = \"sourcetype=WinEventLog:Security ComputerName=$SearchValue | sort - _time\"\n        }\n        'Level' {\n            $Search = \"sourcetype=WinEventLog:Security EventLevel=$SearchValue | sort - _time\"\n        }\n        default {\n            $Search = \"sourcetype=WinEventLog:Security | sort - _time | head $MaxResults\"\n        }\n    }\n    \n    $Body = @{\n        search = $Search\n        output_mode = \"json\"\n    } | ConvertTo-Json\n    \n    try {\n        $Response = Invoke-RestMethod -Uri $Uri -Method Post -Body $Body -Credential (New-Object PSCredential $SplunkAuth.Username, (ConvertTo-SecureString $SplunkAuth.Password -AsPlainText -Force))\n        return $Response\n    } catch {\n        Write-Error \"Search failed: $_\"\n        return $null\n    }\n}\n\n# Create common saved searches\nCreate-SplunkSearchQuery -QueryName \"AU-7.2 Failed Logins\" \\\n    -SearchCriteria \"sourcetype=WinEventLog:Security EventCode=4625 | stats count by User, Computer | sort - count\" \\\n    -Description \"Automatic search for failed login attempts\"\n\nCreate-SplunkSearchQuery -QueryName \"AU-7.2 Privilege Escalation\" \\\n    -SearchCriteria \"sourcetype=WinEventLog:Security (EventCode=4672 OR EventCode=4985) | stats count by User, Computer | sort - count\" \\\n    -Description \"Automatic search for privilege escalation events\"\n\nCreate-SplunkSearchQuery -QueryName \"AU-7.2 Account Modifications\" \\\n    -SearchCriteria \"sourcetype=WinEventLog:Security (EventCode=4722 OR EventCode=4723 OR EventCode=4724) | stats count by TargetUserName, User | sort - count\" \\\n    -Description \"Automatic search for account modification events\"\n\nWrite-Host \"Splunk saved searches created for AU-7.2\""
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-20T00:00:00.000000Z",
      "has_scripts": true,
      "validation_status": "NIST SP 800-53 Rev 5 verified",
      "stig_applicable": true
    },
    "stig_id": "RHEL-08-030372",
    "cac_metadata": {
      "implementation_type": "elasticsearch_splunk_search",
      "last_analyzed": "2025-11-20T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "cac_status": "available",
      "cac_planned": true,
      "implementation_guidance": "Deploy Elasticsearch or Splunk for searchable audit log indexing. Configure Kibana or Splunk dashboards with pre-built saved searches. Implement automated indexing that sorts records by timestamp, user, event type, and other organization-defined criteria. Create alert rules that automatically search for and respond to suspicious patterns.",
      "rule_ids": [
        "RHEL-08-030372"
      ]
    },
    "ai_guidance": "AU-7.2 implementation should prioritize search performance and accuracy. Use managed search platforms (Splunk, Elasticsearch) rather than manual log parsing for production systems. Implement role-based access controls to limit who can search sensitive audit data. Create a library of pre-built searches for common use cases to reduce analyst training time. Monitor search performance and adjust indexing strategy as audit volumes grow. Test search accuracy regularly to ensure no results are missed. Document all organization-defined search criteria and maintain version control of saved searches. Integrate search results with your SIEM platform for automated threat response."
  }
]
