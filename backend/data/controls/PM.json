[
  {
    "control_id": "PM-1",
    "control_name": "Information Security Program Plan",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "a. Develop and disseminate an organization-wide information security program plan that: 1. Provides an overview of the requirements for the security program and a description of the security program management controls and common controls in place or planned for meeting those requirements; 2. Includes the identification and assignment of roles, responsibilities, management commitment, coordination among organizational entities, and compliance; 3. Reflects the coordination among organizational entities responsible for information security; and 4. Is approved by a senior official with responsibility and accountability for the risk being incurred to organizational operations (including mission, functions, image, and reputation), organizational assets, individuals, other organizations, and the Nation; b. Review and update the organization-wide information security program plan [Assignment: organization-defined frequency] and following [Assignment: organization-defined events]; and c. Protect the information security program plan from unauthorized disclosure and modification.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Establish a comprehensive information security program plan that provides strategic direction for protecting organizational information assets and coordinates security efforts across the enterprise.",
    "rationale": "An information security program plan serves as the foundational document for an organization's security posture. Without a comprehensive plan, security efforts become fragmented, responsibilities unclear, and resources misallocated. The plan ensures senior leadership commitment, clear accountability, and a unified approach to managing security risks across the organization.",
    "plain_english_explanation": "An Information Security Program Plan outlines how an organization will protect and secure its information and systems. This comprehensive document establishes the strategic framework for security governance, defines roles and responsibilities, and ensures all organizational units work together toward common security objectives.",
    "ai_guidance": "When implementing PM-1, organizations should develop a comprehensive information security program plan that serves as the authoritative document for all security activities. The plan must include several critical components: (1) An executive overview establishing the security program's mission, vision, and strategic objectives aligned with organizational goals; (2) A detailed inventory of security requirements derived from laws, regulations, contractual obligations, and industry standards such as FISMA, HIPAA, PCI-DSS, or sector-specific requirements; (3) A governance structure clearly defining roles and responsibilities for the CISO, security team members, system owners, and all personnel; (4) A description of all security controls, distinguishing between common controls (inherited by multiple systems), system-specific controls, and hybrid controls; (5) Resource allocation plans including budget, personnel, and technology investments; (6) A risk management strategy that integrates with the organization's enterprise risk management framework; (7) Performance metrics and key performance indicators to measure program effectiveness; (8) Coordination mechanisms between IT, security, privacy, legal, HR, and business units; and (9) A compliance verification process. The plan should be reviewed at least annually or when significant changes occur such as mergers, new regulations, or major security incidents. Version control and change management processes must be implemented to track plan evolution. Access to the plan should be restricted to authorized personnel on a need-to-know basis, as it contains sensitive information about security posture.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-2",
    "control_name": "Information Security Program Leadership Role",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Appoint a senior agency information security officer with the mission and resources to coordinate, develop, implement, and maintain an organization-wide information security program.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Establish clear executive leadership and accountability for the organization's information security program through appointment of a senior security officer with appropriate authority and resources.",
    "rationale": "Effective security programs require dedicated leadership at the senior executive level. Without a designated senior official with appropriate authority, security initiatives lack visibility, resources, and organizational influence needed to drive meaningful security improvements. The SAISO provides the critical link between technical security operations and executive decision-making.",
    "plain_english_explanation": "Assign a senior leader to oversee and manage the organization's information security program. This individual, often called the Chief Information Security Officer (CISO) or Senior Agency Information Security Officer (SAISO), must have the authority, resources, and organizational position to effectively coordinate security across all business units.",
    "ai_guidance": "PM-2 requires organizations to establish a formal Senior Agency Information Security Officer (SAISO) position, commonly known as the Chief Information Security Officer (CISO). Implementation involves several key considerations: (1) Position Authority - The SAISO must report at a sufficiently senior level, ideally directly to the CEO, CIO, or Board, to ensure security concerns receive appropriate executive attention and are not subordinated to competing IT priorities; (2) Independence - The security function should maintain appropriate independence from IT operations to avoid conflicts of interest when assessing security risks; (3) Resource Authority - The SAISO must control or significantly influence the security budget, staffing decisions, and procurement of security tools and services; (4) Scope - Responsibilities should span the entire organization including headquarters, regional offices, subsidiaries, and contractor operations handling organizational data; (5) Qualifications - The SAISO should possess relevant certifications (CISSP, CISM, etc.), extensive security experience, and demonstrated leadership capabilities; (6) Key Responsibilities - Include developing and maintaining the security program plan, advising senior leadership on risk decisions, coordinating incident response, overseeing security awareness training, managing security assessments, and ensuring compliance with applicable requirements; (7) Coordination - The SAISO must establish working relationships with legal counsel, privacy officer, HR, facilities, and business unit leaders; (8) Delegation - While the SAISO bears ultimate responsibility, authority may be delegated to qualified subordinates for specific functions; (9) Documentation - The appointment should be formalized through official correspondence or organization charts showing reporting relationships.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-3",
    "control_name": "Information Security and Privacy Resources",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "a. Include the resources needed to implement the information security and privacy programs in capital planning and investment requests and document all exceptions to this requirement; b. Prepare documentation required for addressing information security and privacy programs in capital planning and investment requests in accordance with applicable laws, executive orders, directives, policies, regulations, standards; and c. Make available for expenditure, the planned information security and privacy resources.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Ensure adequate financial and human resources are allocated to information security and privacy programs through formal capital planning and budget processes.",
    "rationale": "Security programs cannot succeed without adequate funding and staffing. By integrating security resource requirements into capital planning processes, organizations ensure security investments are evaluated alongside other business priorities and receive appropriate budget allocations. Documentation of exceptions creates accountability for risk acceptance decisions.",
    "plain_english_explanation": "Ensure that information security and privacy resources are properly budgeted through capital planning processes. This includes documenting security funding requirements, integrating them into investment requests, and making sure allocated funds are actually available for security program expenditures.",
    "ai_guidance": "PM-3 addresses the critical need for adequate resourcing of security and privacy programs. Implementation requires integration with organizational budget and capital planning cycles: (1) Capital Planning Integration - Security requirements must be included in OMB Exhibit 300 submissions (for federal agencies) or equivalent capital planning documents, ensuring security is not treated as an afterthought; (2) Budget Categories - Security resources should cover personnel costs (salaries, training, certifications), technology investments (security tools, licenses, infrastructure), professional services (assessments, penetration testing, consulting), and operational expenses (maintenance, subscriptions, incident response retainers); (3) Business Case Development - Security investments should be justified through quantitative risk analysis showing potential loss reduction, compliance cost avoidance, or operational efficiency gains; (4) Exception Documentation - When security resources are reduced or denied, document the business rationale, risk acceptance decision, and approving authority; (5) Multi-Year Planning - Security investments often require multi-year commitments for tools with subscription models or phased implementations; (6) Resource Availability - Ensure budgeted funds are actually accessible when needed, avoiding end-of-year freezes that delay critical security purchases; (7) Staffing Plans - Include projections for security team growth aligned with organizational expansion and evolving threat landscape; (8) Compliance Costs - Account for assessment fees, certification costs, and remediation expenses required by regulatory frameworks; (9) Contingency Reserves - Maintain funds for responding to unforeseen security incidents or emerging vulnerabilities requiring immediate remediation; (10) Performance Metrics - Track security spending efficiency through metrics like cost per protected endpoint or security investment as percentage of IT budget.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-4",
    "control_name": "Plan of Action and Milestones Process",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "a. Implement a process to ensure that plans of action and milestones for the information security, privacy, and supply chain risk management programs and associated organizational systems are developed and maintained; b. Review plans of action and milestones for consistency with the organizational risk management strategy and organization-wide priorities for risk response actions.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Establish a formal process for tracking, prioritizing, and remediating security weaknesses through Plans of Action and Milestones (POA&M) that align with organizational risk management strategy.",
    "rationale": "Security weaknesses are inevitable in complex environments. A formal POA&M process ensures findings from assessments, audits, and vulnerability scans are systematically tracked and remediated based on risk priority. Without this process, organizations lose visibility into their security posture and fail to address critical vulnerabilities in a timely manner.",
    "plain_english_explanation": "A Plan of Action and Milestones (POA&M) process helps organizations identify and address security weaknesses and track progress towards compliance with security standards. This systematic approach ensures vulnerabilities are remediated based on risk priority with clear accountability and deadlines.",
    "ai_guidance": "PM-4 establishes the POA&M process as the primary mechanism for tracking and remediating security weaknesses. Comprehensive implementation includes: (1) POA&M Structure - Each entry should contain: unique identifier, weakness description, source of finding (assessment, audit, scan), affected systems, responsible party, risk rating, planned remediation actions, resource requirements, milestone dates, and completion status; (2) Sources of Findings - POA&Ms aggregate weaknesses from multiple sources including security assessments, penetration tests, vulnerability scans, audit findings, incident lessons learned, and self-identified issues; (3) Risk Prioritization - Remediation should be prioritized using consistent risk criteria considering exploitability, potential impact, affected asset criticality, and compensating controls; (4) Milestone Tracking - Establish realistic remediation timelines: critical (30 days), high (90 days), moderate (180 days), low (365 days), with documented justification for extensions; (5) Resource Allocation - POA&M items requiring significant resources should be reflected in budget planning processes; (6) Stakeholder Accountability - Assign specific individuals (not generic roles) responsible for each remediation action with authority to implement changes; (7) Progress Monitoring - Conduct regular POA&M reviews (monthly for critical, quarterly for others) to assess progress and escalate delays; (8) Risk Acceptance - Items that cannot be remediated require formal risk acceptance documentation signed by appropriate authorizing official; (9) Tooling - Use GRC platforms or dedicated POA&M tracking tools to maintain visibility across distributed environments; (10) Reporting - Generate regular POA&M status reports for leadership showing aging analysis, completion rates, and risk trends; (11) Closure Verification - Require independent verification that remediation actions effectively address the original weakness before closing POA&M items.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-5",
    "control_name": "System Inventory",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Develop and update [Assignment: organization-defined frequency] an inventory of organizational systems.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Maintain a comprehensive and current inventory of all organizational information systems to support security management, authorization, and oversight activities.",
    "rationale": "You cannot protect what you do not know exists. A complete system inventory is essential for understanding the organization's attack surface, ensuring all systems receive appropriate security controls, and supporting authorization decisions. Without accurate inventory, systems may operate without authorization, miss security updates, or be forgotten during incident response.",
    "plain_english_explanation": "Keep track of all the information systems your organization uses. This inventory should identify each system's purpose, owner, authorization status, and interconnections with other systems. Regular updates ensure new systems are captured and decommissioned systems are removed.",
    "ai_guidance": "PM-5 requires organizations to maintain a comprehensive inventory of all information systems. Effective implementation includes: (1) Inventory Scope - Include all systems that process, store, or transmit organizational information: production systems, development/test environments, cloud services, SaaS applications, mobile applications, and contractor-operated systems; (2) Required Attributes - For each system, document: unique identifier, system name, description/purpose, system owner, authorizing official, authorization status and date, operational status (operational, under development, being modified), system boundaries, security categorization (FIPS 199), interconnected systems, hosting location, and technology stack; (3) Discovery Methods - Combine automated discovery tools (network scans, cloud asset inventory) with manual processes (interviews, procurement records) to identify all systems; (4) Shadow IT Detection - Implement processes to identify unauthorized systems or cloud services deployed outside normal IT governance; (5) Update Frequency - Review inventory at least annually and update within 30 days of significant changes such as new system deployment, major modifications, or decommissioning; (6) Integration Points - Link system inventory with asset management, configuration management, and authorization documentation; (7) Cloud Considerations - Track cloud service accounts, subscriptions, and deployed resources which may change rapidly; (8) Authorization Tracking - Use inventory to ensure all systems maintain current authorization and flag systems approaching reauthorization dates; (9) Reporting - Generate reports showing systems by status, categorization, owner, or authorization expiration to support management oversight; (10) Decommissioning - Document system retirements including data disposition and residual risk assessment.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-5.1",
    "control_name": "Inventory of Personally Identifiable Information",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Establish, maintain, and update [Assignment: organization-defined frequency] an inventory of all systems, applications, and projects that process personally identifiable information.",
    "parent_control": "PM-5",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": true,
    "stig_id": null,
    "intent": "Maintain a specialized inventory tracking all systems, applications, and projects that process, store, or transmit Personally Identifiable Information (PII) to support privacy risk management and compliance requirements.",
    "rationale": "PII requires enhanced protection under numerous laws and regulations including GDPR, CCPA, HIPAA, and the Privacy Act. Organizations must know exactly where PII resides to implement appropriate safeguards, respond to data subject requests, and manage privacy incidents. Without a PII inventory, organizations cannot effectively assess privacy risks or demonstrate compliance.",
    "plain_english_explanation": "Create and maintain a detailed inventory of every system, application, and project within your organization that handles personally identifiable information. This specialized inventory supports privacy compliance, data subject request fulfillment, and privacy impact assessments.",
    "ai_guidance": "PM-5.1 extends the system inventory requirement to specifically track PII processing. This technical control requires both procedural and automated approaches: (1) PII Definition - Establish organizational definition of PII aligned with applicable regulations, typically including: name, SSN, date of birth, address, phone, email, financial account numbers, medical records, biometric data, and unique identifiers; (2) Data Flow Mapping - Document how PII flows through systems from collection to deletion, identifying all processing points, storage locations, and transmission paths; (3) Discovery Techniques - Deploy data discovery and classification tools that scan databases, file systems, and cloud storage to identify PII; use pattern matching for structured data (SSN patterns, credit card formats) and machine learning for unstructured content; (4) Inventory Attributes - For each PII-processing system, document: types of PII processed, data subjects (employees, customers, citizens), collection purpose, legal basis, retention period, sharing with third parties, cross-border transfers, and applicable privacy requirements; (5) Cloud and SaaS - Track cloud services and SaaS applications that may store PII, including CRM systems, HR platforms, marketing tools, and analytics services; (6) Development Projects - Include projects under development that will process PII to ensure privacy by design principles are applied; (7) Third-Party Processing - Track processors and sub-processors handling PII on the organization's behalf; (8) Privacy Impact Assessment Linkage - Connect inventory to PIA/DPIA documentation for systems with significant privacy implications; (9) Data Subject Request Support - Use inventory to efficiently locate all PII for a specific individual when responding to access, correction, or deletion requests; (10) Update Triggers - Review after new system deployment, changes to data processing, regulatory updates, or privacy incidents.",
    "implementation_scripts": {
      "linux": {
        "bash": "#!/bin/bash\n# PM-5.1 PII Discovery Script for Linux Systems\n# Scans file systems and databases for potential PII\n\nset -euo pipefail\n\n# Configuration\nOUTPUT_DIR=\"/var/log/pii-inventory\"\nTIMESTAMP=$(date +%Y%m%d_%H%M%S)\nREPORT_FILE=\"${OUTPUT_DIR}/pii_scan_${TIMESTAMP}.json\"\nSCAN_PATHS=(\"/home\" \"/var/www\" \"/opt/data\" \"/srv\")\n\n# Create output directory\nmkdir -p \"${OUTPUT_DIR}\"\nchmod 700 \"${OUTPUT_DIR}\"\n\n# Initialize JSON report\necho '{' > \"${REPORT_FILE}\"\necho '  \"scan_timestamp\": \"'$(date -Iseconds)'\",' >> \"${REPORT_FILE}\"\necho '  \"hostname\": \"'$(hostname)'\",' >> \"${REPORT_FILE}\"\necho '  \"findings\": [' >> \"${REPORT_FILE}\"\n\nFIRST_FINDING=true\n\n# PII patterns for grep\ndeclare -A PII_PATTERNS\nPII_PATTERNS[\"SSN\"]='[0-9]{3}-[0-9]{2}-[0-9]{4}'\nPII_PATTERNS[\"CREDIT_CARD\"]='[0-9]{4}[- ]?[0-9]{4}[- ]?[0-9]{4}[- ]?[0-9]{4}'\nPII_PATTERNS[\"EMAIL\"]='[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\nPII_PATTERNS[\"PHONE_US\"]='\\(?[0-9]{3}\\)?[-.\\s]?[0-9]{3}[-.\\s]?[0-9]{4}'\nPII_PATTERNS[\"DOB\"]='(0[1-9]|1[0-2])/(0[1-9]|[12][0-9]|3[01])/(19|20)[0-9]{2}'\n\nlog_finding() {\n    local file=\"$1\"\n    local pii_type=\"$2\"\n    local line_count=\"$3\"\n    \n    if [ \"$FIRST_FINDING\" = false ]; then\n        echo ',' >> \"${REPORT_FILE}\"\n    fi\n    FIRST_FINDING=false\n    \n    cat >> \"${REPORT_FILE}\" << EOF\n    {\n      \"file_path\": \"${file}\",\n      \"pii_type\": \"${pii_type}\",\n      \"potential_matches\": ${line_count},\n      \"file_owner\": \"$(stat -c '%U' \"${file}\" 2>/dev/null || echo 'unknown')\",\n      \"file_permissions\": \"$(stat -c '%a' \"${file}\" 2>/dev/null || echo 'unknown')\",\n      \"last_modified\": \"$(stat -c '%y' \"${file}\" 2>/dev/null || echo 'unknown')\"\n    }\nEOF\n}\n\necho \"[INFO] Starting PII scan at $(date)\"\necho \"[INFO] Scanning paths: ${SCAN_PATHS[*]}\"\n\nfor scan_path in \"${SCAN_PATHS[@]}\"; do\n    if [ -d \"$scan_path\" ]; then\n        echo \"[INFO] Scanning: ${scan_path}\"\n        \n        # Find text files and common data formats\n        find \"$scan_path\" -type f \\( -name \"*.txt\" -o -name \"*.csv\" -o -name \"*.json\" -o -name \"*.xml\" -o -name \"*.log\" -o -name \"*.sql\" -o -name \"*.dump\" \\) 2>/dev/null | while read -r file; do\n            for pii_type in \"${!PII_PATTERNS[@]}\"; do\n                pattern=\"${PII_PATTERNS[$pii_type]}\"\n                match_count=$(grep -Ec \"$pattern\" \"$file\" 2>/dev/null || echo \"0\")\n                if [ \"$match_count\" -gt 0 ]; then\n                    log_finding \"$file\" \"$pii_type\" \"$match_count\"\n                fi\n            done\n        done\n    fi\ndone\n\n# Check for database files\necho \"[INFO] Checking for database files\"\nfind / -type f \\( -name \"*.db\" -o -name \"*.sqlite\" -o -name \"*.sqlite3\" -o -name \"*.mdb\" \\) 2>/dev/null | head -100 | while read -r dbfile; do\n    if [ \"$FIRST_FINDING\" = false ]; then\n        echo ',' >> \"${REPORT_FILE}\"\n    fi\n    FIRST_FINDING=false\n    echo '    {\"database_file\": \"'\"$dbfile\"'\", \"action_required\": \"manual_review\"}' >> \"${REPORT_FILE}\"\ndone\n\n# Check PostgreSQL databases if psql is available\nif command -v psql &> /dev/null; then\n    echo \"[INFO] PostgreSQL detected - listing databases with PII-related tables\"\n    sudo -u postgres psql -t -c \"SELECT datname FROM pg_database WHERE datistemplate = false;\" 2>/dev/null | while read -r db; do\n        db=$(echo \"$db\" | xargs)\n        if [ -n \"$db\" ]; then\n            # Look for tables with PII-related column names\n            pii_tables=$(sudo -u postgres psql -d \"$db\" -t -c \"SELECT table_name FROM information_schema.columns WHERE column_name ~* '(ssn|social_security|email|phone|address|birth|credit|name)' GROUP BY table_name;\" 2>/dev/null || echo \"\")\n            if [ -n \"$pii_tables\" ]; then\n                if [ \"$FIRST_FINDING\" = false ]; then\n                    echo ',' >> \"${REPORT_FILE}\"\n                fi\n                FIRST_FINDING=false\n                echo '    {\"postgresql_database\": \"'\"$db\"'\", \"potential_pii_tables\": \"'$(echo $pii_tables | tr '\\n' ',' | sed 's/,$//')'\"}' >> \"${REPORT_FILE}\"\n            fi\n        fi\n    done\nfi\n\n# Close JSON report\necho '' >> \"${REPORT_FILE}\"\necho '  ],' >> \"${REPORT_FILE}\"\necho '  \"scan_completed\": \"'$(date -Iseconds)'\"' >> \"${REPORT_FILE}\"\necho '}' >> \"${REPORT_FILE}\"\n\necho \"[INFO] PII scan completed. Report saved to: ${REPORT_FILE}\"\necho \"[IMPORTANT] Review findings and update PII inventory accordingly\"",
        "ansible": "---\n# PM-5.1 PII Inventory Management Playbook\n# Manages discovery and documentation of PII across systems\n\n- name: PM-5.1 PII Inventory Discovery and Management\n  hosts: all\n  become: yes\n  vars:\n    pii_inventory_dir: /var/log/pii-inventory\n    scan_paths:\n      - /home\n      - /var/www\n      - /opt/data\n      - /srv\n    pii_patterns:\n      ssn: '[0-9]{3}-[0-9]{2}-[0-9]{4}'\n      credit_card: '[0-9]{4}[- ]?[0-9]{4}[- ]?[0-9]{4}[- ]?[0-9]{4}'\n      email: '[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n      phone_us: '\\(?[0-9]{3}\\)?[-.\\s]?[0-9]{3}[-.\\s]?[0-9]{4}'\n    retention_days: 90\n\n  tasks:\n    - name: Create PII inventory directory\n      ansible.builtin.file:\n        path: \"{{ pii_inventory_dir }}\"\n        state: directory\n        mode: '0700'\n        owner: root\n        group: root\n\n    - name: Install required packages for PII scanning\n      ansible.builtin.package:\n        name:\n          - grep\n          - findutils\n          - jq\n        state: present\n\n    - name: Generate timestamp for scan\n      ansible.builtin.set_fact:\n        scan_timestamp: \"{{ ansible_date_time.iso8601 }}\"\n\n    - name: Initialize PII findings list\n      ansible.builtin.set_fact:\n        pii_findings: []\n\n    - name: Scan for files containing potential SSN patterns\n      ansible.builtin.shell: |\n        find {{ item }} -type f \\( -name '*.txt' -o -name '*.csv' -o -name '*.json' -o -name '*.xml' \\) -exec grep -l -E '{{ pii_patterns.ssn }}' {} \\; 2>/dev/null | head -100\n      register: ssn_files\n      loop: \"{{ scan_paths }}\"\n      ignore_errors: yes\n      changed_when: false\n\n    - name: Scan for files containing potential email patterns\n      ansible.builtin.shell: |\n        find {{ item }} -type f \\( -name '*.txt' -o -name '*.csv' -o -name '*.json' -o -name '*.xml' \\) -exec grep -l -E '{{ pii_patterns.email }}' {} \\; 2>/dev/null | head -100\n      register: email_files\n      loop: \"{{ scan_paths }}\"\n      ignore_errors: yes\n      changed_when: false\n\n    - name: Identify database files for manual review\n      ansible.builtin.find:\n        paths: \"/\"\n        patterns:\n          - \"*.db\"\n          - \"*.sqlite\"\n          - \"*.sqlite3\"\n        recurse: yes\n        file_type: file\n      register: database_files\n      ignore_errors: yes\n\n    - name: Check for PostgreSQL databases\n      ansible.builtin.shell: |\n        if command -v psql &> /dev/null; then\n          sudo -u postgres psql -t -c \"SELECT datname FROM pg_database WHERE datistemplate = false;\" 2>/dev/null\n        fi\n      register: postgres_databases\n      ignore_errors: yes\n      changed_when: false\n\n    - name: Check for MySQL databases\n      ansible.builtin.shell: |\n        if command -v mysql &> /dev/null; then\n          mysql -N -e \"SHOW DATABASES;\" 2>/dev/null\n        fi\n      register: mysql_databases\n      ignore_errors: yes\n      changed_when: false\n\n    - name: Generate PII inventory report\n      ansible.builtin.template:\n        src: pii_inventory_report.json.j2\n        dest: \"{{ pii_inventory_dir }}/pii_inventory_{{ ansible_date_time.date }}.json\"\n        mode: '0600'\n      vars:\n        report_data:\n          scan_timestamp: \"{{ scan_timestamp }}\"\n          hostname: \"{{ ansible_hostname }}\"\n          fqdn: \"{{ ansible_fqdn }}\"\n          ssn_pattern_files: \"{{ ssn_files.results | map(attribute='stdout_lines') | flatten | unique }}\"\n          email_pattern_files: \"{{ email_files.results | map(attribute='stdout_lines') | flatten | unique }}\"\n          database_files: \"{{ database_files.files | default([]) | map(attribute='path') | list }}\"\n          postgresql_databases: \"{{ postgres_databases.stdout_lines | default([]) }}\"\n          mysql_databases: \"{{ mysql_databases.stdout_lines | default([]) }}\"\n\n    - name: Clean up old inventory reports\n      ansible.builtin.find:\n        paths: \"{{ pii_inventory_dir }}\"\n        patterns: \"pii_inventory_*.json\"\n        age: \"{{ retention_days }}d\"\n      register: old_reports\n\n    - name: Remove old inventory reports\n      ansible.builtin.file:\n        path: \"{{ item.path }}\"\n        state: absent\n      loop: \"{{ old_reports.files }}\"\n\n    - name: Display scan summary\n      ansible.builtin.debug:\n        msg: |\n          PII Inventory Scan Complete\n          ===========================\n          Hostname: {{ ansible_hostname }}\n          Scan Time: {{ scan_timestamp }}\n          Files with SSN patterns: {{ ssn_files.results | map(attribute='stdout_lines') | flatten | length }}\n          Files with email patterns: {{ email_files.results | map(attribute='stdout_lines') | flatten | length }}\n          Database files found: {{ database_files.files | default([]) | length }}\n          PostgreSQL databases: {{ postgres_databases.stdout_lines | default([]) | length }}\n          MySQL databases: {{ mysql_databases.stdout_lines | default([]) | length }}\n          \n          Report saved to: {{ pii_inventory_dir }}/pii_inventory_{{ ansible_date_time.date }}.json\n          \n          NEXT STEPS:\n          1. Review identified files for actual PII content\n          2. Update centralized PII inventory\n          3. Verify appropriate controls on PII-containing systems\n          4. Document data flows and retention policies"
      },
      "windows": {
        "powershell": "# PM-5.1 PII Discovery Script for Windows\n# Scans file systems and databases for potential PII\n\n#Requires -RunAsAdministrator\n\nparam(\n    [string[]]$ScanPaths = @(\"C:\\Users\", \"C:\\inetpub\", \"D:\\Data\"),\n    [string]$OutputPath = \"C:\\SecurityLogs\\PII-Inventory\",\n    [int]$MaxFilesPerPath = 1000\n)\n\n$ErrorActionPreference = \"Continue\"\n$Timestamp = Get-Date -Format \"yyyyMMdd_HHmmss\"\n$ReportFile = Join-Path $OutputPath \"PII_Scan_$Timestamp.json\"\n\n# Create output directory\nif (-not (Test-Path $OutputPath)) {\n    New-Item -ItemType Directory -Path $OutputPath -Force | Out-Null\n}\n\n# PII patterns\n$PIIPatterns = @{\n    \"SSN\" = \"\\b\\d{3}-\\d{2}-\\d{4}\\b\"\n    \"CreditCard\" = \"\\b\\d{4}[- ]?\\d{4}[- ]?\\d{4}[- ]?\\d{4}\\b\"\n    \"Email\" = \"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b\"\n    \"PhoneUS\" = \"\\b\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b\"\n    \"DateOfBirth\" = \"\\b(0[1-9]|1[0-2])/(0[1-9]|[12]\\d|3[01])/(19|20)\\d{2}\\b\"\n}\n\n$FileExtensions = @(\"*.txt\", \"*.csv\", \"*.json\", \"*.xml\", \"*.log\", \"*.xlsx\", \"*.docx\")\n\n$Findings = @()\n\nWrite-Host \"[INFO] Starting PII Discovery Scan at $(Get-Date)\" -ForegroundColor Cyan\nWrite-Host \"[INFO] Scan paths: $($ScanPaths -join ', ')\" -ForegroundColor Cyan\n\nforeach ($scanPath in $ScanPaths) {\n    if (Test-Path $scanPath) {\n        Write-Host \"[INFO] Scanning: $scanPath\" -ForegroundColor Yellow\n        \n        foreach ($ext in $FileExtensions) {\n            try {\n                $files = Get-ChildItem -Path $scanPath -Filter $ext -Recurse -ErrorAction SilentlyContinue | \n                         Select-Object -First $MaxFilesPerPath\n                \n                foreach ($file in $files) {\n                    try {\n                        # Skip files larger than 50MB\n                        if ($file.Length -gt 52428800) {\n                            continue\n                        }\n                        \n                        $content = Get-Content -Path $file.FullName -Raw -ErrorAction SilentlyContinue\n                        if ($content) {\n                            foreach ($piiType in $PIIPatterns.Keys) {\n                                $matches = [regex]::Matches($content, $PIIPatterns[$piiType])\n                                if ($matches.Count -gt 0) {\n                                    $acl = Get-Acl -Path $file.FullName -ErrorAction SilentlyContinue\n                                    $Findings += [PSCustomObject]@{\n                                        FilePath = $file.FullName\n                                        PIIType = $piiType\n                                        PotentialMatches = $matches.Count\n                                        FileOwner = $acl.Owner\n                                        LastModified = $file.LastWriteTime.ToString(\"yyyy-MM-ddTHH:mm:ss\")\n                                        FileSizeKB = [math]::Round($file.Length / 1KB, 2)\n                                    }\n                                }\n                            }\n                        }\n                    } catch {\n                        # Skip files that can't be read\n                    }\n                }\n            } catch {\n                Write-Warning \"Error scanning $scanPath for $ext : $_\"\n            }\n        }\n    } else {\n        Write-Warning \"Path not found: $scanPath\"\n    }\n}\n\n# Check for database files\nWrite-Host \"[INFO] Scanning for database files...\" -ForegroundColor Yellow\n$dbExtensions = @(\"*.mdf\", \"*.ldf\", \"*.accdb\", \"*.mdb\", \"*.sqlite\", \"*.db\")\nforeach ($scanPath in $ScanPaths) {\n    if (Test-Path $scanPath) {\n        foreach ($ext in $dbExtensions) {\n            $dbFiles = Get-ChildItem -Path $scanPath -Filter $ext -Recurse -ErrorAction SilentlyContinue | \n                       Select-Object -First 50\n            foreach ($dbFile in $dbFiles) {\n                $Findings += [PSCustomObject]@{\n                    FilePath = $dbFile.FullName\n                    PIIType = \"DATABASE_FILE\"\n                    PotentialMatches = \"REQUIRES_MANUAL_REVIEW\"\n                    FileOwner = (Get-Acl -Path $dbFile.FullName -ErrorAction SilentlyContinue).Owner\n                    LastModified = $dbFile.LastWriteTime.ToString(\"yyyy-MM-ddTHH:mm:ss\")\n                    FileSizeKB = [math]::Round($dbFile.Length / 1KB, 2)\n                }\n            }\n        }\n    }\n}\n\n# Check SQL Server databases if available\nWrite-Host \"[INFO] Checking for SQL Server databases...\" -ForegroundColor Yellow\ntry {\n    $sqlInstances = Get-Service -Name \"MSSQL*\" -ErrorAction SilentlyContinue | \n                    Where-Object { $_.Status -eq \"Running\" }\n    \n    foreach ($instance in $sqlInstances) {\n        $instanceName = if ($instance.Name -eq \"MSSQLSERVER\") { \".\" } else { \".\\$($instance.Name.Replace('MSSQL$',''))\" }\n        \n        try {\n            $query = @\"\nSELECT \n    DB_NAME() as DatabaseName,\n    t.name as TableName,\n    c.name as ColumnName\nFROM sys.columns c\nJOIN sys.tables t ON c.object_id = t.object_id\nWHERE c.name LIKE '%ssn%' \n    OR c.name LIKE '%social%security%'\n    OR c.name LIKE '%email%'\n    OR c.name LIKE '%phone%'\n    OR c.name LIKE '%address%'\n    OR c.name LIKE '%birth%'\n    OR c.name LIKE '%credit%card%'\n\"@\n            $databases = Invoke-Sqlcmd -ServerInstance $instanceName -Query \"SELECT name FROM sys.databases WHERE database_id > 4\" -ErrorAction SilentlyContinue\n            \n            foreach ($db in $databases) {\n                $piiColumns = Invoke-Sqlcmd -ServerInstance $instanceName -Database $db.name -Query $query -ErrorAction SilentlyContinue\n                if ($piiColumns) {\n                    foreach ($col in $piiColumns) {\n                        $Findings += [PSCustomObject]@{\n                            FilePath = \"SQL:$instanceName/$($db.name)/$($col.TableName)\"\n                            PIIType = \"SQL_COLUMN_$($col.ColumnName)\"\n                            PotentialMatches = \"REQUIRES_DATA_SAMPLING\"\n                            FileOwner = \"SQL Server\"\n                            LastModified = (Get-Date).ToString(\"yyyy-MM-ddTHH:mm:ss\")\n                            FileSizeKB = \"N/A\"\n                        }\n                    }\n                }\n            }\n        } catch {\n            Write-Warning \"Unable to query SQL instance $instanceName : $_\"\n        }\n    }\n} catch {\n    Write-Host \"[INFO] No SQL Server instances found or accessible\" -ForegroundColor Gray\n}\n\n# Generate report\n$Report = [PSCustomObject]@{\n    ScanTimestamp = (Get-Date).ToString(\"yyyy-MM-ddTHH:mm:ssZ\")\n    Hostname = $env:COMPUTERNAME\n    FQDN = [System.Net.Dns]::GetHostEntry($env:COMPUTERNAME).HostName\n    ScanPaths = $ScanPaths\n    TotalFindings = $Findings.Count\n    FindingsByType = $Findings | Group-Object PIIType | ForEach-Object { @{ $_.Name = $_.Count } }\n    Findings = $Findings\n    ScanCompleted = (Get-Date).ToString(\"yyyy-MM-ddTHH:mm:ssZ\")\n}\n\n$Report | ConvertTo-Json -Depth 10 | Out-File -FilePath $ReportFile -Encoding UTF8\n\nWrite-Host \"`n[COMPLETE] PII Scan Results\" -ForegroundColor Green\nWrite-Host \"============================================\" -ForegroundColor Green\nWrite-Host \"Total findings: $($Findings.Count)\"\nWrite-Host \"Report saved to: $ReportFile\"\nWrite-Host \"`nFindings by Type:\" -ForegroundColor Cyan\n$Findings | Group-Object PIIType | ForEach-Object {\n    Write-Host \"  $($_.Name): $($_.Count)\"\n}\n\nWrite-Host \"`n[NEXT STEPS]\" -ForegroundColor Yellow\nWrite-Host \"1. Review identified files for actual PII content\"\nWrite-Host \"2. Update centralized PII inventory in GRC system\"\nWrite-Host \"3. Verify data protection controls on identified systems\"\nWrite-Host \"4. Document data flows and implement retention policies\""
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": true
    }
  },
  {
    "control_id": "PM-6",
    "control_name": "Measures of Performance",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Develop, monitor, and report on the results of information security and privacy measures of performance.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Establish metrics and key performance indicators to measure and report on the effectiveness of information security and privacy programs.",
    "rationale": "Without measurable performance indicators, organizations cannot objectively assess the effectiveness of their security investments or demonstrate improvement over time. Metrics enable data-driven decisions, justify resource requests, identify program weaknesses, and demonstrate compliance to stakeholders and auditors.",
    "plain_english_explanation": "This control requires you to track and report on how well your security measures are working. Develop specific metrics that measure security program effectiveness, monitor them regularly, and report results to leadership for decision-making.",
    "ai_guidance": "PM-6 establishes the requirement for security and privacy program metrics. Comprehensive implementation includes: (1) Metric Categories - Develop metrics across multiple dimensions: operational metrics (patch compliance rates, vulnerability remediation time, incident response time), programmatic metrics (training completion rates, assessment findings closure), technical metrics (system uptime, encryption coverage), and risk metrics (risk register trends, POA&M aging); (2) SMART Criteria - Ensure metrics are Specific, Measurable, Achievable, Relevant, and Time-bound; avoid vanity metrics that sound impressive but provide no actionable insight; (3) Data Collection - Establish automated data collection where possible through security tools, SIEM systems, and GRC platforms; manual data collection should be minimized to ensure accuracy and timeliness; (4) Baseline Establishment - Establish baseline measurements before setting improvement targets; understand current performance before committing to specific goals; (5) Benchmarking - Compare organizational metrics against industry standards, peer organizations, or regulatory expectations to contextualize performance; (6) Reporting Cadence - Establish regular reporting schedules: weekly operational metrics for security team, monthly summary for IT leadership, quarterly strategic metrics for executives, annual comprehensive review for board; (7) Visualization - Present metrics in accessible formats using dashboards, trend charts, and heat maps that communicate status clearly to diverse audiences; (8) Action Triggers - Define thresholds that trigger investigation or remediation action when metrics indicate declining performance; (9) Continuous Improvement - Use metrics to identify improvement opportunities and track the impact of security initiatives; (10) Example Metrics - Mean time to detect incidents (MTTD), mean time to respond (MTTR), percentage of systems with current patches, training completion rates, phishing simulation click rates, third-party risk assessment completion, vulnerability scan coverage.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-7",
    "control_name": "Enterprise Architecture",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Develop and maintain an enterprise architecture with consideration for information security, privacy, and the resulting risk to organizational operations and assets, individuals, other organizations, and the Nation.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Integrate information security and privacy considerations into enterprise architecture planning to ensure security is designed into systems and infrastructure rather than added as an afterthought.",
    "rationale": "Enterprise architecture provides the blueprint for organizational IT systems and their interconnections. When security is not integrated into architecture planning, organizations inherit systemic vulnerabilities, face costly retrofits, and struggle to achieve consistent security across the enterprise. Security-aware architecture enables defense in depth and supports risk-based decision making.",
    "plain_english_explanation": "Develop and keep up-to-date a plan for how your organization's IT systems work together, while also considering security and privacy risks. The enterprise architecture should incorporate security requirements from the design phase to ensure consistent protection across all systems.",
    "ai_guidance": "PM-7 requires integration of security and privacy into enterprise architecture frameworks. Implementation considerations include: (1) Architecture Frameworks - Align with established frameworks such as TOGAF, FEAF (Federal Enterprise Architecture Framework), or DODAF, incorporating security reference models and security architecture domains; (2) Security Reference Architecture - Develop security-specific reference architectures defining standard patterns for authentication, authorization, encryption, logging, network segmentation, and other security functions; (3) Business-Security Alignment - Ensure security architecture supports and enables business objectives rather than creating friction; architect for both protection and productivity; (4) Risk-Based Design - Use threat modeling and risk assessment results to inform architectural decisions; prioritize protection for high-value assets and high-risk interfaces; (5) Defense in Depth - Design multiple layers of security controls so that compromise of one layer does not result in complete system compromise; (6) Zero Trust Principles - Incorporate zero trust concepts including verify explicitly, use least privilege access, and assume breach; (7) Privacy by Design - Embed privacy principles into architecture including data minimization, purpose limitation, and privacy-enhancing technologies; (8) Cloud Integration - Address security considerations for hybrid and multi-cloud architectures including identity federation, data residency, and shared responsibility models; (9) Interconnection Security - Define security requirements for system interconnections, data flows, and API integrations; (10) Change Management - Ensure architectural changes undergo security review before implementation; maintain current documentation as systems evolve; (11) Technology Standards - Establish approved technology standards that include security requirements for operating systems, databases, middleware, and applications.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-7.1",
    "control_name": "Offloading",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Offload [Assignment: organization-defined non-essential functions or services] to other systems, system components, or an external provider.",
    "parent_control": "PM-7",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": true,
    "stig_id": null,
    "intent": "Reduce organizational risk by offloading non-essential or commodity functions to specialized external providers or dedicated systems that may provide better security, scalability, or cost efficiency.",
    "rationale": "Organizations should focus their security resources on protecting mission-critical functions while leveraging external expertise for commodity services. Offloading email to cloud providers, using managed security services, or consuming SaaS applications can improve security posture when providers offer superior security capabilities and the organization maintains appropriate oversight.",
    "plain_english_explanation": "Strategically move non-essential functions or services to external providers or dedicated systems when doing so improves security, reduces risk, or allows the organization to focus resources on core mission functions. This includes using cloud services, managed security providers, or shared service centers.",
    "ai_guidance": "PM-7.1 addresses the strategic decision to offload certain functions to external providers or dedicated systems. This technical control requires careful analysis and ongoing governance: (1) Function Assessment - Evaluate all organizational functions to identify candidates for offloading: non-core business functions, commodity IT services (email, collaboration), specialized functions requiring expertise (SOC operations, penetration testing), or functions with high compliance burden (payment processing); (2) Risk Analysis - For each candidate function, assess risks of retaining versus offloading including security capabilities, data sensitivity, regulatory requirements, provider reliability, and transition risks; (3) Provider Evaluation - Conduct thorough due diligence on potential providers including security certifications (SOC 2, ISO 27001, FedRAMP), contractual security requirements, incident response capabilities, and business continuity provisions; (4) Data Classification - Identify what data will be processed by external providers and ensure protection requirements can be met; some data may be too sensitive for external processing; (5) Shared Responsibility - Clearly define security responsibilities between organization and provider; document in contracts and service level agreements; (6) Architecture Integration - Design secure integration patterns for offloaded services including API security, identity federation, network connectivity, and data encryption in transit; (7) Monitoring and Oversight - Maintain visibility into provider security performance through regular assessments, continuous monitoring, and incident notification requirements; (8) Exit Strategy - Plan for provider transition or termination including data retrieval, service continuity, and knowledge transfer; (9) Compliance Implications - Ensure offloading arrangements meet regulatory requirements; some regulations restrict where data can be processed or require specific contractual provisions.",
    "implementation_scripts": {
      "linux": {
        "bash": "#!/bin/bash\n# PM-7.1 Architecture Offloading Verification Script\n# Verifies security configurations for offloaded services integration\n\nset -euo pipefail\n\nOUTPUT_DIR=\"/var/log/offload-verification\"\nTIMESTAMP=$(date +%Y%m%d_%H%M%S)\nREPORT_FILE=\"${OUTPUT_DIR}/offload_verification_${TIMESTAMP}.json\"\n\nmkdir -p \"${OUTPUT_DIR}\"\nchmod 700 \"${OUTPUT_DIR}\"\n\necho '{' > \"${REPORT_FILE}\"\necho '  \"verification_timestamp\": \"'$(date -Iseconds)'\",' >> \"${REPORT_FILE}\"\necho '  \"hostname\": \"'$(hostname)'\",' >> \"${REPORT_FILE}\"\necho '  \"checks\": [' >> \"${REPORT_FILE}\"\n\nFIRST_CHECK=true\n\nadd_check() {\n    local check_name=\"$1\"\n    local status=\"$2\"\n    local details=\"$3\"\n    \n    if [ \"$FIRST_CHECK\" = false ]; then\n        echo ',' >> \"${REPORT_FILE}\"\n    fi\n    FIRST_CHECK=false\n    \n    echo '    {\"check\": \"'\"$check_name\"'\", \"status\": \"'\"$status\"'\", \"details\": \"'\"$details\"'\"}' >> \"${REPORT_FILE}\"\n}\n\necho \"[INFO] Verifying offloaded service integrations...\"\n\n# Check 1: Verify TLS configuration for external API connections\necho \"[INFO] Checking TLS configuration for external endpoints...\"\nEXTERNAL_ENDPOINTS=(\n    \"login.microsoftonline.com:443\"\n    \"api.cloudprovider.com:443\"\n)\n\nfor endpoint in \"${EXTERNAL_ENDPOINTS[@]}\"; do\n    host=$(echo \"$endpoint\" | cut -d: -f1)\n    port=$(echo \"$endpoint\" | cut -d: -f2)\n    \n    if timeout 10 openssl s_client -connect \"$endpoint\" -tls1_2 </dev/null 2>/dev/null | grep -q \"Verify return code: 0\"; then\n        add_check \"TLS_${host}\" \"PASS\" \"TLS 1.2+ verified with valid certificate\"\n    else\n        add_check \"TLS_${host}\" \"FAIL\" \"Unable to verify TLS or certificate issue\"\n    fi\ndone\n\n# Check 2: Verify DNS resolution for cloud services\necho \"[INFO] Verifying DNS resolution for cloud services...\"\nCLOUD_SERVICES=(\"login.microsoftonline.com\" \"s3.amazonaws.com\" \"storage.googleapis.com\")\n\nfor service in \"${CLOUD_SERVICES[@]}\"; do\n    if dig +short \"$service\" | grep -qE '^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+$'; then\n        add_check \"DNS_${service}\" \"PASS\" \"DNS resolution successful\"\n    else\n        add_check \"DNS_${service}\" \"WARN\" \"DNS resolution failed or service not used\"\n    fi\ndone\n\n# Check 3: Verify firewall rules allow necessary outbound connections\necho \"[INFO] Checking firewall rules for outbound connections...\"\nif command -v iptables &> /dev/null; then\n    OUTBOUND_443=$(iptables -L OUTPUT -n 2>/dev/null | grep -c \"dpt:443\" || echo \"0\")\n    if [ \"$OUTBOUND_443\" -gt 0 ]; then\n        add_check \"Firewall_HTTPS_Outbound\" \"PASS\" \"Outbound HTTPS rules configured\"\n    else\n        add_check \"Firewall_HTTPS_Outbound\" \"INFO\" \"No explicit outbound HTTPS rules (may use default allow)\"\n    fi\nfi\n\n# Check 4: Verify proxy configuration if required\necho \"[INFO] Checking proxy configuration...\"\nif [ -n \"${https_proxy:-}\" ] || [ -n \"${HTTPS_PROXY:-}\" ]; then\n    add_check \"Proxy_Configuration\" \"PASS\" \"HTTPS proxy configured\"\nelse\n    add_check \"Proxy_Configuration\" \"INFO\" \"No proxy configured - direct connections\"\nfi\n\n# Check 5: Check for certificate trust store updates\necho \"[INFO] Verifying CA certificate trust store...\"\nif [ -d \"/etc/ssl/certs\" ]; then\n    CERT_COUNT=$(ls -1 /etc/ssl/certs/*.pem 2>/dev/null | wc -l)\n    TRUST_STORE_DATE=$(stat -c %Y /etc/ssl/certs/ca-certificates.crt 2>/dev/null || echo \"0\")\n    DAYS_OLD=$(( ($(date +%s) - TRUST_STORE_DATE) / 86400 ))\n    \n    if [ \"$DAYS_OLD\" -lt 90 ]; then\n        add_check \"CA_Trust_Store\" \"PASS\" \"Trust store updated within 90 days ($CERT_COUNT certs)\"\n    else\n        add_check \"CA_Trust_Store\" \"WARN\" \"Trust store is $DAYS_OLD days old - consider update\"\n    fi\nfi\n\n# Check 6: Verify logging for external service connections\necho \"[INFO] Checking logging configuration for external connections...\"\nif [ -f \"/etc/rsyslog.conf\" ] || [ -d \"/etc/rsyslog.d\" ]; then\n    add_check \"Syslog_Configuration\" \"PASS\" \"Syslog configured for connection logging\"\nelse\n    add_check \"Syslog_Configuration\" \"WARN\" \"Syslog not detected - verify logging mechanism\"\nfi\n\n# Check 7: Verify service account credentials are not exposed\necho \"[INFO] Checking for exposed service credentials...\"\nCREDENTIAL_PATTERNS=(\"AWS_SECRET\" \"AZURE_CLIENT_SECRET\" \"GCP_CREDENTIALS\" \"API_KEY\")\nEXPOSED_CREDS=0\n\nfor pattern in \"${CREDENTIAL_PATTERNS[@]}\"; do\n    if env | grep -qi \"$pattern\"; then\n        EXPOSED_CREDS=$((EXPOSED_CREDS + 1))\n    fi\ndone\n\nif [ \"$EXPOSED_CREDS\" -eq 0 ]; then\n    add_check \"Credential_Exposure\" \"PASS\" \"No obvious credential exposure in environment\"\nelse\n    add_check \"Credential_Exposure\" \"WARN\" \"$EXPOSED_CREDS credential-like variables in environment\"\nfi\n\n# Close JSON\necho '' >> \"${REPORT_FILE}\"\necho '  ],' >> \"${REPORT_FILE}\"\necho '  \"verification_completed\": \"'$(date -Iseconds)'\"' >> \"${REPORT_FILE}\"\necho '}' >> \"${REPORT_FILE}\"\n\necho \"[COMPLETE] Offloading verification report: ${REPORT_FILE}\"\necho \"[ACTION] Review findings and update architecture documentation accordingly\""
      },
      "windows": {
        "powershell": "# PM-7.1 Architecture Offloading Verification Script for Windows\n# Verifies security configurations for offloaded services integration\n\nparam(\n    [string]$OutputPath = \"C:\\SecurityLogs\\OffloadVerification\",\n    [string[]]$CloudEndpoints = @(\n        \"login.microsoftonline.com\",\n        \"graph.microsoft.com\",\n        \"management.azure.com\",\n        \"s3.amazonaws.com\"\n    )\n)\n\n$ErrorActionPreference = \"Continue\"\n$Timestamp = Get-Date -Format \"yyyyMMdd_HHmmss\"\n$ReportFile = Join-Path $OutputPath \"Offload_Verification_$Timestamp.json\"\n\n# Create output directory\nif (-not (Test-Path $OutputPath)) {\n    New-Item -ItemType Directory -Path $OutputPath -Force | Out-Null\n}\n\n$Checks = @()\n\nWrite-Host \"[INFO] PM-7.1 Offloading Architecture Verification\" -ForegroundColor Cyan\nWrite-Host \"============================================\" -ForegroundColor Cyan\n\n# Check 1: Verify TLS connectivity to cloud endpoints\nWrite-Host \"`n[INFO] Checking TLS connectivity to cloud services...\" -ForegroundColor Yellow\nforeach ($endpoint in $CloudEndpoints) {\n    try {\n        $tcpClient = New-Object System.Net.Sockets.TcpClient\n        $tcpClient.Connect($endpoint, 443)\n        \n        $sslStream = New-Object System.Net.Security.SslStream($tcpClient.GetStream())\n        $sslStream.AuthenticateAsClient($endpoint)\n        \n        $cert = $sslStream.RemoteCertificate\n        $certExpiry = [datetime]$cert.GetExpirationDateString()\n        $daysUntilExpiry = ($certExpiry - (Get-Date)).Days\n        \n        $Checks += [PSCustomObject]@{\n            Check = \"TLS_$endpoint\"\n            Status = if ($daysUntilExpiry -gt 30) { \"PASS\" } else { \"WARN\" }\n            Details = \"TLS connected, cert expires in $daysUntilExpiry days, Protocol: $($sslStream.SslProtocol)\"\n        }\n        \n        $sslStream.Close()\n        $tcpClient.Close()\n    } catch {\n        $Checks += [PSCustomObject]@{\n            Check = \"TLS_$endpoint\"\n            Status = \"FAIL\"\n            Details = \"Unable to establish TLS connection: $($_.Exception.Message)\"\n        }\n    }\n}\n\n# Check 2: Verify DNS resolution\nWrite-Host \"[INFO] Verifying DNS resolution for cloud services...\" -ForegroundColor Yellow\nforeach ($endpoint in $CloudEndpoints) {\n    try {\n        $dns = Resolve-DnsName -Name $endpoint -ErrorAction Stop\n        $Checks += [PSCustomObject]@{\n            Check = \"DNS_$endpoint\"\n            Status = \"PASS\"\n            Details = \"Resolved to $($dns.IPAddress -join ', ')\"\n        }\n    } catch {\n        $Checks += [PSCustomObject]@{\n            Check = \"DNS_$endpoint\"\n            Status = \"FAIL\"\n            Details = \"DNS resolution failed\"\n        }\n    }\n}\n\n# Check 3: Verify Windows Firewall allows outbound HTTPS\nWrite-Host \"[INFO] Checking Windows Firewall outbound rules...\" -ForegroundColor Yellow\ntry {\n    $httpsRules = Get-NetFirewallRule -Direction Outbound -Action Allow -ErrorAction Stop | \n                  Where-Object { $_.Enabled -eq $true } |\n                  Get-NetFirewallPortFilter -ErrorAction SilentlyContinue | \n                  Where-Object { $_.RemotePort -eq 443 }\n    \n    if ($httpsRules) {\n        $Checks += [PSCustomObject]@{\n            Check = \"Firewall_HTTPS_Outbound\"\n            Status = \"PASS\"\n            Details = \"$($httpsRules.Count) outbound HTTPS rules configured\"\n        }\n    } else {\n        $Checks += [PSCustomObject]@{\n            Check = \"Firewall_HTTPS_Outbound\"\n            Status = \"INFO\"\n            Details = \"No explicit HTTPS outbound rules - may use default policy\"\n        }\n    }\n} catch {\n    $Checks += [PSCustomObject]@{\n        Check = \"Firewall_HTTPS_Outbound\"\n        Status = \"WARN\"\n        Details = \"Unable to query firewall rules\"\n    }\n}\n\n# Check 4: Verify proxy configuration\nWrite-Host \"[INFO] Checking proxy configuration...\" -ForegroundColor Yellow\ntry {\n    $proxy = [System.Net.WebRequest]::GetSystemWebProxy()\n    $testUri = [Uri]\"https://login.microsoftonline.com\"\n    $proxyUri = $proxy.GetProxy($testUri)\n    \n    if ($proxyUri -eq $testUri) {\n        $Checks += [PSCustomObject]@{\n            Check = \"Proxy_Configuration\"\n            Status = \"INFO\"\n            Details = \"No proxy configured - direct connections\"\n        }\n    } else {\n        $Checks += [PSCustomObject]@{\n            Check = \"Proxy_Configuration\"\n            Status = \"PASS\"\n            Details = \"Proxy configured: $proxyUri\"\n        }\n    }\n} catch {\n    $Checks += [PSCustomObject]@{\n        Check = \"Proxy_Configuration\"\n        Status = \"WARN\"\n        Details = \"Unable to determine proxy configuration\"\n    }\n}\n\n# Check 5: Verify Azure AD / Entra ID connectivity\nWrite-Host \"[INFO] Checking Azure AD / Entra ID connectivity...\" -ForegroundColor Yellow\ntry {\n    $response = Invoke-RestMethod -Uri \"https://login.microsoftonline.com/common/discovery/instance?api-version=1.1&authorization_endpoint=https://login.microsoftonline.com/common/oauth2/authorize\" -Method GET -TimeoutSec 10\n    $Checks += [PSCustomObject]@{\n        Check = \"AzureAD_Connectivity\"\n        Status = \"PASS\"\n        Details = \"Successfully connected to Azure AD discovery endpoint\"\n    }\n} catch {\n    $Checks += [PSCustomObject]@{\n        Check = \"AzureAD_Connectivity\"\n        Status = \"WARN\"\n        Details = \"Unable to reach Azure AD: $($_.Exception.Message)\"\n    }\n}\n\n# Check 6: Verify service principal / managed identity configuration\nWrite-Host \"[INFO] Checking for Azure managed identity...\" -ForegroundColor Yellow\ntry {\n    $imdsResponse = Invoke-RestMethod -Uri \"http://169.254.169.254/metadata/identity/oauth2/token?api-version=2018-02-01&resource=https://management.azure.com/\" -Headers @{\"Metadata\"=\"true\"} -TimeoutSec 5 -ErrorAction Stop\n    $Checks += [PSCustomObject]@{\n        Check = \"Azure_Managed_Identity\"\n        Status = \"PASS\"\n        Details = \"Managed identity available and responsive\"\n    }\n} catch {\n    $Checks += [PSCustomObject]@{\n        Check = \"Azure_Managed_Identity\"\n        Status = \"INFO\"\n        Details = \"No managed identity or not running in Azure\"\n    }\n}\n\n# Check 7: Verify Windows Certificate Store\nWrite-Host \"[INFO] Checking certificate trust store...\" -ForegroundColor Yellow\ntry {\n    $rootCerts = Get-ChildItem -Path Cert:\\LocalMachine\\Root | Where-Object { $_.NotAfter -gt (Get-Date) }\n    $expiringSoon = $rootCerts | Where-Object { $_.NotAfter -lt (Get-Date).AddDays(90) }\n    \n    $Checks += [PSCustomObject]@{\n        Check = \"Certificate_Trust_Store\"\n        Status = if ($expiringSoon.Count -eq 0) { \"PASS\" } else { \"WARN\" }\n        Details = \"$($rootCerts.Count) valid root certificates, $($expiringSoon.Count) expiring within 90 days\"\n    }\n} catch {\n    $Checks += [PSCustomObject]@{\n        Check = \"Certificate_Trust_Store\"\n        Status = \"WARN\"\n        Details = \"Unable to query certificate store\"\n    }\n}\n\n# Check 8: Check for credential exposure\nWrite-Host \"[INFO] Checking for exposed credentials in environment...\" -ForegroundColor Yellow\n$sensitivePatterns = @(\"SECRET\", \"PASSWORD\", \"API_KEY\", \"TOKEN\", \"CREDENTIAL\")\n$exposedCount = 0\n\nforeach ($pattern in $sensitivePatterns) {\n    $matches = Get-ChildItem Env: | Where-Object { $_.Name -like \"*$pattern*\" }\n    $exposedCount += $matches.Count\n}\n\n$Checks += [PSCustomObject]@{\n    Check = \"Credential_Exposure_Check\"\n    Status = if ($exposedCount -eq 0) { \"PASS\" } else { \"WARN\" }\n    Details = \"$exposedCount environment variables match sensitive patterns\"\n}\n\n# Check 9: Verify Windows Event logging for connection tracking\nWrite-Host \"[INFO] Checking event logging configuration...\" -ForegroundColor Yellow\ntry {\n    $securityLog = Get-WinEvent -ListLog Security -ErrorAction Stop\n    $Checks += [PSCustomObject]@{\n        Check = \"Security_Event_Logging\"\n        Status = if ($securityLog.IsEnabled) { \"PASS\" } else { \"WARN\" }\n        Details = \"Security log enabled: $($securityLog.IsEnabled), Size: $([math]::Round($securityLog.MaximumSizeInBytes / 1MB, 2)) MB\"\n    }\n} catch {\n    $Checks += [PSCustomObject]@{\n        Check = \"Security_Event_Logging\"\n        Status = \"WARN\"\n        Details = \"Unable to query security event log\"\n    }\n}\n\n# Generate report\n$Report = [PSCustomObject]@{\n    VerificationTimestamp = (Get-Date).ToString(\"yyyy-MM-ddTHH:mm:ssZ\")\n    Hostname = $env:COMPUTERNAME\n    FQDN = [System.Net.Dns]::GetHostEntry($env:COMPUTERNAME).HostName\n    TestedEndpoints = $CloudEndpoints\n    TotalChecks = $Checks.Count\n    PassCount = ($Checks | Where-Object { $_.Status -eq \"PASS\" }).Count\n    WarnCount = ($Checks | Where-Object { $_.Status -eq \"WARN\" }).Count\n    FailCount = ($Checks | Where-Object { $_.Status -eq \"FAIL\" }).Count\n    Checks = $Checks\n    VerificationCompleted = (Get-Date).ToString(\"yyyy-MM-ddTHH:mm:ssZ\")\n}\n\n$Report | ConvertTo-Json -Depth 10 | Out-File -FilePath $ReportFile -Encoding UTF8\n\n# Display summary\nWrite-Host \"`n[COMPLETE] Offloading Verification Summary\" -ForegroundColor Green\nWrite-Host \"=========================================\" -ForegroundColor Green\nWrite-Host \"Total Checks: $($Checks.Count)\"\nWrite-Host \"Passed: $(($Checks | Where-Object { $_.Status -eq 'PASS' }).Count)\" -ForegroundColor Green\nWrite-Host \"Warnings: $(($Checks | Where-Object { $_.Status -eq 'WARN' }).Count)\" -ForegroundColor Yellow\nWrite-Host \"Failed: $(($Checks | Where-Object { $_.Status -eq 'FAIL' }).Count)\" -ForegroundColor Red\nWrite-Host \"`nReport saved to: $ReportFile\"\n\nWrite-Host \"`n[NEXT STEPS]\" -ForegroundColor Cyan\nWrite-Host \"1. Review any WARN or FAIL findings\"\nWrite-Host \"2. Verify service-level agreements with cloud providers\"\nWrite-Host \"3. Update architecture documentation with integration details\"\nWrite-Host \"4. Ensure monitoring is configured for offloaded services\""
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": true
    }
  },
  {
    "control_id": "PM-8",
    "control_name": "Critical Infrastructure Plan",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Address information security and privacy issues in the development, documentation, and updating of a critical infrastructure and key resources protection plan.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Ensure information security and privacy considerations are integrated into plans for protecting critical infrastructure and key resources that are essential to organizational mission and national security.",
    "rationale": "Critical infrastructure systems often control essential services such as power, water, transportation, and communications. These systems face unique threats including nation-state actors and sophisticated adversaries. Integrating security into critical infrastructure protection planning ensures these vital assets receive appropriate protection commensurate with their importance.",
    "plain_english_explanation": "Ensure that information security and privacy concerns are considered when creating and updating plans to protect critical infrastructure and key resources. This includes identifying critical assets, assessing threats, and implementing appropriate safeguards.",
    "ai_guidance": "PM-8 addresses the integration of security into critical infrastructure protection planning. Implementation requires coordination across multiple domains: (1) Critical Asset Identification - Identify systems and facilities that qualify as critical infrastructure based on CISA definitions (16 critical infrastructure sectors) and organizational mission impact analysis; consider both physical and cyber assets; (2) Dependency Mapping - Document dependencies between critical systems, supply chains, and external services; understand cascading failure scenarios; (3) Threat Assessment - Conduct threat assessments specific to critical infrastructure including nation-state actors, sophisticated criminal groups, insider threats, and physical security threats; leverage threat intelligence from CISA, FBI, and sector-specific ISACs; (4) Vulnerability Assessment - Perform regular assessments of critical systems including penetration testing, configuration reviews, and physical security assessments; prioritize remediation of findings affecting critical assets; (5) Protection Strategies - Develop layered protection strategies including: network segmentation and isolation, enhanced access controls, continuous monitoring, redundancy and failover capabilities, physical security measures, and supply chain risk management; (6) Incident Response - Develop specialized incident response procedures for critical infrastructure incidents including coordination with sector-specific agencies, restoration priorities, and communication plans; (7) Resilience Planning - Design for resilience with business continuity plans, disaster recovery procedures, and alternate processing capabilities; test plans regularly through exercises; (8) Regulatory Compliance - Address sector-specific requirements such as NERC CIP for energy, TSA security directives for transportation, or CFATS for chemical facilities; (9) Information Sharing - Participate in sector-specific information sharing organizations and coordinate with government partners; (10) Plan Maintenance - Review and update critical infrastructure protection plans at least annually and after significant changes or incidents.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-9",
    "control_name": "Risk Management Strategy",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Develop and implement a risk management strategy for the organization that: a. Establishes a clear expression of risk tolerance for the organization; b. Addresses risk mitigation strategies; c. Describes the methodology for assessing risk; d. Is reviewed and approved by the senior official or officials responsible for risk management; and e. Identifies the specific risk management activities that the organization will use to identify and address risk.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Establish a formal, organization-wide approach to identifying, assessing, and managing information security and privacy risks aligned with business objectives.",
    "rationale": "Without a documented risk management strategy, organizations cannot consistently prioritize security investments, allocate resources effectively, or make informed decisions about acceptable risk levels. A risk management strategy provides the foundation for all other security activities by defining how the organization will approach risk identification, assessment, response, and monitoring.",
    "plain_english_explanation": "A risk management strategy is your organization's master plan for dealing with security risks. It defines how much risk you're willing to accept, how you'll identify and evaluate threats, and what methods you'll use to address them. Think of it as a playbook that ensures everyone in the organization approaches risk decisions consistently.",
    "ai_guidance": "Organizations implementing PM-9 should develop a comprehensive risk management strategy that integrates with enterprise risk management frameworks. The strategy should clearly articulate the organization's risk tolerance levels using quantitative metrics where possible (e.g., maximum acceptable annual loss exposure, maximum downtime for critical systems). Include a risk assessment methodology that considers threat likelihood, vulnerability severity, and potential impact across confidentiality, integrity, and availability dimensions. The strategy should define roles and responsibilities for risk owners at various organizational levels, establish escalation procedures for risks exceeding tolerance thresholds, and specify how risk information will be communicated to stakeholders. Consider integrating threat intelligence feeds to inform risk assessments and ensure the strategy addresses emerging risks such as supply chain vulnerabilities, cloud security, and advanced persistent threats. The risk management strategy should be reviewed at least annually or when significant organizational changes occur, and should align with frameworks such as NIST RMF, ISO 27005, or FAIR methodology for consistency and auditability.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-10",
    "control_name": "Authorization Process",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Manage the security and privacy state of organizational systems and the environments in which those systems operate through authorization processes.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Ensure all information systems receive formal authorization to operate based on documented risk acceptance decisions by designated authorizing officials.",
    "rationale": "The authorization process ensures that senior leadership explicitly accepts the residual risks associated with operating information systems. This formal process creates accountability, ensures consistent risk evaluation across the organization, and provides a documented basis for continuing or terminating system operations based on security posture.",
    "plain_english_explanation": "The authorization process is a formal procedure where a designated authority reviews a system's security posture and officially approves it to operate. Before any system goes live, someone in leadership must sign off that they understand and accept any remaining security risks. This ensures accountability and prevents systems from operating without proper security review.",
    "ai_guidance": "Organizations implementing PM-10 should establish a formal System Authorization process aligned with the NIST Risk Management Framework (RMF). Define clear authorization boundaries that encompass all system components, data flows, and interconnections. Establish criteria for categorizing systems based on impact levels (low, moderate, high) and ensure appropriate rigor in the authorization process for each level. Designate Authorizing Officials (AOs) with sufficient organizational authority and provide them with comprehensive security authorization packages including System Security Plans (SSPs), Security Assessment Reports (SARs), and Plans of Action and Milestones (POA&Ms). Implement continuous authorization processes that leverage ongoing monitoring data to maintain authorization status between formal reauthorization cycles. Define clear triggers for reauthorization such as significant system changes, major security incidents, or the expiration of authorization periods (typically 3 years). Ensure the authorization process addresses interconnected systems, cloud services, and third-party components. Document all authorization decisions, conditions, and risk acceptance statements for audit purposes and maintain clear traceability between identified risks and authorization decisions.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-11",
    "control_name": "Mission and Business Process Definition",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Define organizational mission and business processes with consideration for information security and privacy and the resulting risk to organizational operations, organizational assets, individuals, other organizations, and the Nation.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Ensure security and privacy considerations are integrated into the definition of organizational mission and business processes from inception.",
    "rationale": "Security and privacy cannot be effectively implemented as afterthoughts. By integrating these considerations into mission and business process definitions, organizations ensure that security requirements are identified early, resources are allocated appropriately, and processes are designed with built-in protections rather than bolted-on controls.",
    "plain_english_explanation": "When your organization defines its mission and business processes, security and privacy should be baked in from the start, not added later. This means every time you design a new business process or update your mission, you should consider what information needs protection, what could go wrong, and how to build in safeguards. It's much easier and cheaper to build security into processes than to retrofit them later.",
    "ai_guidance": "Organizations implementing PM-11 should establish processes for integrating security and privacy considerations into strategic planning, business process design, and operational activities. Develop a mission-to-security mapping that identifies how each mission function depends on information systems and data, and what security properties are essential for mission success. Conduct Business Impact Analyses (BIAs) for critical processes to understand dependencies, recovery requirements, and acceptable downtime thresholds. Ensure that new business initiatives undergo security architecture review before implementation, with security requirements documented alongside functional requirements. Create a security-aware culture by including security stakeholders in business planning sessions and requiring security sign-off for significant process changes. Document the relationship between mission-essential functions, supporting information systems, and required security controls to ensure appropriate protection levels. Consider supply chain dependencies and third-party risks when defining business processes that rely on external providers. Regularly review mission and business process definitions to ensure they remain accurate and that security controls continue to align with operational needs.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-12",
    "control_name": "Insider Threat Program",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Implement an insider threat program that includes a cross-discipline insider threat incident handling team.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Establish a formal program to detect, prevent, and respond to threats from individuals with authorized access who may misuse that access to harm the organization.",
    "rationale": "Insider threats represent one of the most significant security risks because insiders have legitimate access to systems and data. A formal program ensures the organization has dedicated resources, processes, and cross-functional coordination to identify behavioral indicators, investigate potential threats, and respond appropriately while respecting employee privacy and legal requirements.",
    "plain_english_explanation": "An insider threat program helps protect your organization from employees, contractors, or other trusted individuals who might intentionally or accidentally cause harm. This involves a team from different departments (IT, HR, Legal, Security) working together to spot warning signs, investigate concerns, and respond to incidents. The goal is to catch problems early while being fair to employees.",
    "ai_guidance": "Organizations implementing PM-12 should establish a comprehensive Insider Threat Program that balances security needs with employee privacy rights and organizational culture. Form a cross-functional Insider Threat Working Group including representatives from Information Security, Human Resources, Legal Counsel, Physical Security, Counterintelligence (if applicable), and relevant business units. Develop clear definitions of insider threat indicators covering both technical behaviors (unusual data access patterns, attempts to bypass security controls, unauthorized system changes) and non-technical indicators (financial difficulties, expressed disgruntlement, unexplained affluence). Implement User and Entity Behavior Analytics (UEBA) tools to establish baseline behaviors and detect anomalies while ensuring compliance with privacy regulations and union agreements. Create clear policies that define acceptable monitoring practices, investigation procedures, and employee notification requirements. Establish relationships with law enforcement and legal counsel for cases requiring external involvement. Develop training programs to help employees recognize and report concerning behaviors without creating a culture of suspicion. Implement graduated response procedures ranging from increased monitoring to intervention and termination. Ensure the program addresses both malicious insiders and well-meaning employees who may inadvertently cause harm through negligence or social engineering.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-13",
    "control_name": "Security and Privacy Workforce",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Establish a security and privacy workforce development and improvement program.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Develop and maintain a skilled workforce capable of implementing, managing, and improving the organization's security and privacy programs.",
    "rationale": "Security and privacy programs are only as effective as the people implementing them. A formal workforce development program ensures the organization can recruit, train, and retain qualified professionals, keeps skills current with evolving threats and technologies, and builds internal expertise to reduce dependence on external consultants.",
    "plain_english_explanation": "Your security and privacy programs need skilled people to run them effectively. A workforce development program ensures you hire the right people, train them continuously, and help them grow in their careers. This includes identifying what skills you need, providing ongoing education, supporting certifications, and creating career paths that retain talented security professionals.",
    "ai_guidance": "Organizations implementing PM-13 should develop a comprehensive Security and Privacy Workforce Development Program that addresses recruitment, training, retention, and succession planning. Conduct a workforce skills assessment to identify current capabilities and gaps, mapping against frameworks like NICE Cybersecurity Workforce Framework or NIST SP 800-181. Develop role-based training curricula that address both technical competencies (security architecture, incident response, privacy engineering) and soft skills (risk communication, stakeholder management). Establish certification requirements for key roles and provide support for obtaining and maintaining certifications (CISSP, CISM, CIPP, Security+, etc.). Create career progression paths that allow security professionals to advance while remaining in technical roles, not just management tracks. Implement knowledge transfer programs including mentoring, job shadowing, and documentation of institutional knowledge. Partner with educational institutions for internship programs and to influence curriculum development. Allocate budget for conference attendance, training courses, and professional development activities. Track workforce metrics including turnover rates, time-to-fill for security positions, training completion rates, and certification achievement. Consider cross-training programs to ensure coverage during absences and to build well-rounded security teams. Address emerging skill needs in areas like cloud security, DevSecOps, privacy engineering, and AI/ML security.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-14",
    "control_name": "Testing, Training, and Monitoring",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Implement a process for ensuring that organizational plans for conducting security and privacy testing, training, and monitoring activities associated with organizational systems: a. Are developed and maintained; and b. Continue to be executed.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Ensure security and privacy testing, training, and monitoring activities are systematically planned, consistently executed, and continuously maintained across the organization.",
    "rationale": "Security controls degrade over time without regular testing, staff skills become outdated without ongoing training, and threats go undetected without continuous monitoring. A formal process ensures these critical activities happen consistently rather than sporadically, and that lessons learned drive improvements.",
    "plain_english_explanation": "This control ensures your organization has ongoing programs for testing security controls, training employees, and monitoring systems for problems. It's not enough to set up security once; you need to regularly verify controls work, keep staff skills current, and watch for threats. This control requires you to plan these activities and actually execute the plans consistently.",
    "ai_guidance": "Organizations implementing PM-14 should establish an integrated Testing, Training, and Monitoring (TTM) program that operates on defined schedules with clear accountability. For testing, develop an annual security assessment calendar that includes vulnerability scanning (at least monthly), penetration testing (at least annually), control effectiveness testing, and tabletop exercises. Ensure test results are documented, remediation is tracked, and trends are analyzed to identify systemic issues. For training, implement role-based security awareness training with initial and annual refresher requirements, supplemented by continuous education through simulated phishing, security newsletters, and just-in-time training for specific threats. Track training completion rates and correlate with security incident data to measure effectiveness. For monitoring, implement continuous monitoring capabilities that provide real-time visibility into security posture, including SIEM deployment, log aggregation, alerting, and automated compliance checking. Establish metrics and dashboards that track testing coverage, training completion, and monitoring effectiveness. Conduct periodic reviews of TTM activities to ensure they remain aligned with current threats and organizational changes. Integrate TTM findings into risk management processes and ensure senior leadership receives regular reports on program status and identified issues.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-15",
    "control_name": "Security and Privacy Groups and Associations",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Establish and institutionalize contact with selected groups and associations within the security and privacy communities: a. To facilitate ongoing security and privacy education and training for organizational personnel; b. To maintain currency with recommended security and privacy practices, techniques, and technologies; and c. To share current security and privacy information including threats, vulnerabilities, and incidents.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Leverage external security and privacy communities to enhance organizational capabilities through information sharing, education, and collaboration.",
    "rationale": "No organization can identify all threats or develop all solutions independently. Participation in security and privacy communities provides access to collective threat intelligence, best practices, and lessons learned that improve the organization's security posture while also contributing to the broader community's resilience.",
    "plain_english_explanation": "Your security team shouldn't work in isolation. By connecting with external security groups, industry associations, and professional organizations, you gain access to shared threat intelligence, best practices, and a network of peers facing similar challenges. This helps you stay current with evolving threats and learn from others' experiences without having to discover everything yourself.",
    "ai_guidance": "Organizations implementing PM-15 should establish formal relationships with relevant security and privacy communities appropriate to their industry and mission. Consider membership in sector-specific Information Sharing and Analysis Centers (ISACs) such as FS-ISAC for financial services, H-ISAC for healthcare, or MS-ISAC for state and local government. Participate in professional associations like ISACA, (ISC)2, ISSA, and IAPP that provide education, certification, and networking opportunities. Engage with vendor-specific security communities and user groups for technologies deployed in your environment. Subscribe to government threat information services such as CISA alerts, FBI InfraGard, and sector-specific bulletins. Establish protocols for sharing threat intelligence with trusted partners while protecting sensitive organizational information. Assign specific staff members responsibility for monitoring community communications and disseminating relevant information internally. Participate in industry working groups developing security standards and best practices relevant to your operations. Attend conferences and events to network with peers and learn about emerging threats and solutions. Document community relationships and periodically assess their value to ensure continued alignment with organizational needs. Consider contributing to the community through speaking engagements, published research, or participation in collaborative defense initiatives.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-16",
    "control_name": "Threat Awareness Program",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Implement a threat awareness program that includes a cross-organization information-sharing capability for threat intelligence.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Establish a formal program to maintain awareness of current and emerging threats and share threat intelligence across the organization to inform defensive measures.",
    "rationale": "Effective defense requires understanding the threat landscape. A formal threat awareness program ensures the organization systematically collects, analyzes, and disseminates threat intelligence to inform security decisions, prioritize defenses, and enable proactive response to emerging threats before they impact operations.",
    "plain_english_explanation": "A threat awareness program keeps your organization informed about current and emerging cyber threats. This involves gathering threat intelligence from multiple sources, analyzing how threats might affect your organization specifically, and sharing this information with people who need it to make security decisions. The goal is to stay ahead of attackers rather than always reacting after incidents occur.",
    "ai_guidance": "Organizations implementing PM-16 should establish a comprehensive Threat Awareness Program that integrates threat intelligence into security operations and strategic planning. Develop a threat intelligence capability that collects information from multiple sources including commercial threat feeds, government advisories, open-source intelligence, sector ISACs, and internal observations. Implement processes to contextualize raw threat data for your specific environment, considering your industry, technology stack, geographic presence, and threat actor motivations. Create threat profiles for adversaries likely to target your organization based on attribution data and targeting patterns. Establish cross-functional threat working groups that include representatives from security operations, risk management, business units, and executive leadership to ensure threat information reaches appropriate stakeholders. Develop communication protocols for sharing time-sensitive threat intelligence internally and with trusted external partners. Integrate threat intelligence into security tools including SIEM, firewalls, endpoint detection, and vulnerability management to enable automated response to known indicators of compromise. Track threat trends over time to identify patterns and inform strategic security investments. Conduct regular threat briefings for executive leadership to maintain awareness of the threat landscape and support risk-informed decision making.",
    "enhancements": [
      {
        "id": "PM-16.1",
        "title": "Automated Means for Sharing Threat Intelligence",
        "official_text": "Employ automated mechanisms to maximize the effectiveness of sharing threat intelligence information."
      }
    ],
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-16.1",
    "control_name": "Automated Means for Sharing Threat Intelligence",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Employ automated mechanisms to maximize the effectiveness of sharing threat intelligence information.",
    "parent_control": "PM-16",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": true,
    "stig_id": null,
    "intent": "Implement automated systems for collecting, processing, and sharing threat intelligence to enable rapid, scalable response to emerging threats.",
    "rationale": "Manual threat intelligence sharing cannot keep pace with the volume and velocity of modern cyber threats. Automated mechanisms enable real-time ingestion of threat data, immediate dissemination to defensive tools, and machine-speed response to known indicators of compromise, dramatically reducing the window of exposure to emerging threats.",
    "plain_english_explanation": "Instead of manually reading threat reports and updating security tools, automated threat intelligence sharing uses standard formats like STIX/TAXII to automatically receive threat data and push it to your firewalls, SIEM, and other security tools. This means when a new threat is identified anywhere in your sharing community, your defenses can be updated within minutes rather than days.",
    "ai_guidance": "Organizations implementing PM-16.1 should deploy automated threat intelligence platforms (TIPs) that support industry-standard formats and protocols for threat data exchange. Implement STIX (Structured Threat Information eXpression) for standardized threat data representation and TAXII (Trusted Automated eXchange of Intelligence Information) for automated transport. Configure connections to multiple threat intelligence feeds including commercial providers (Recorded Future, ThreatConnect, Anomali), open-source feeds (AlienVault OTX, Abuse.ch), government sources (CISA AIS, FBI FLASH), and sector ISACs. Implement automated enrichment pipelines that correlate incoming indicators with internal data to assess relevance and priority. Configure bidirectional integrations with security tools including SIEM, firewall, IPS/IDS, EDR, and email security gateways to automatically operationalize threat intelligence. Establish confidence scoring mechanisms to prevent false positives from automated blocking. Implement workflows for human review of high-impact automated actions. Deploy MISP (Malware Information Sharing Platform) or similar platforms for sharing threat intelligence with trusted partners. Monitor automation effectiveness through metrics including time-to-detect, time-to-block, and false positive rates. Ensure automated sharing respects traffic light protocol (TLP) markings and data sharing agreements with intelligence providers.",
    "implementation_scripts": {
      "linux": {
        "bash": "#!/bin/bash\n# PM-16.1: Automated Threat Intelligence Sharing - STIX/TAXII Integration\n# This script sets up automated threat feed collection using TAXII protocol\n\nset -e\n\n# Configuration\nTAXII_SERVER=\"https://taxii.example.com/services/collection-management/\"\nTAXII_COLLECTION=\"default\"\nSTIX_OUTPUT_DIR=\"/var/lib/threat-intel/stix\"\nLOG_FILE=\"/var/log/threat-intel/taxii-client.log\"\nAPI_KEY=\"${TAXII_API_KEY:-}\"\n\n# Create directories\nmkdir -p \"$STIX_OUTPUT_DIR\" /var/log/threat-intel\n\n# Log function\nlog() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" | tee -a \"$LOG_FILE\"\n}\n\nlog \"Starting TAXII threat feed collection\"\n\n# Install dependencies if not present\nif ! command -v taxii2-client &> /dev/null; then\n    log \"Installing TAXII client libraries\"\n    pip3 install taxii2-client stix2 || {\n        log \"ERROR: Failed to install required packages\"\n        exit 1\n    }\nfi\n\n# Python script for TAXII collection\ncat > /tmp/taxii_collector.py << 'PYTHON_SCRIPT'\n#!/usr/bin/env python3\nimport os\nimport json\nimport logging\nfrom datetime import datetime, timedelta\nfrom taxii2client.v21 import Server, Collection\nfrom stix2 import parse\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(__name__)\n\ndef fetch_threat_intelligence(server_url, collection_id, api_key=None, hours_back=24):\n    \"\"\"Fetch threat intelligence from TAXII server\"\"\"\n    try:\n        # Connect to TAXII server\n        headers = {'Authorization': f'Bearer {api_key}'} if api_key else {}\n        server = Server(server_url, headers=headers)\n        \n        logger.info(f\"Connected to TAXII server: {server_url}\")\n        \n        # Get API root and collections\n        api_root = server.api_roots[0]\n        collections = api_root.collections\n        \n        for collection in collections:\n            if collection.id == collection_id or collection_id == 'default':\n                logger.info(f\"Fetching from collection: {collection.title}\")\n                \n                # Calculate time range\n                end_time = datetime.utcnow()\n                start_time = end_time - timedelta(hours=hours_back)\n                \n                # Fetch objects\n                objects = collection.get_objects(\n                    added_after=start_time.isoformat() + 'Z'\n                )\n                \n                if objects and 'objects' in objects:\n                    return objects['objects']\n                    \n        return []\n        \n    except Exception as e:\n        logger.error(f\"Failed to fetch threat intelligence: {e}\")\n        return []\n\ndef process_indicators(stix_objects, output_dir):\n    \"\"\"Process STIX objects and extract indicators\"\"\"\n    indicators = {\n        'ip_addresses': [],\n        'domains': [],\n        'urls': [],\n        'file_hashes': [],\n        'email_addresses': []\n    }\n    \n    for obj in stix_objects:\n        try:\n            parsed = parse(obj, allow_custom=True)\n            \n            if parsed.type == 'indicator':\n                pattern = parsed.pattern\n                \n                # Extract IP addresses\n                if \"ipv4-addr:value\" in pattern or \"ipv6-addr:value\" in pattern:\n                    indicators['ip_addresses'].append({\n                        'value': extract_pattern_value(pattern),\n                        'confidence': getattr(parsed, 'confidence', 50),\n                        'valid_until': str(getattr(parsed, 'valid_until', '')),\n                        'description': getattr(parsed, 'description', '')\n                    })\n                \n                # Extract domains\n                elif \"domain-name:value\" in pattern:\n                    indicators['domains'].append({\n                        'value': extract_pattern_value(pattern),\n                        'confidence': getattr(parsed, 'confidence', 50),\n                        'valid_until': str(getattr(parsed, 'valid_until', ''))\n                    })\n                \n                # Extract file hashes\n                elif \"file:hashes\" in pattern:\n                    indicators['file_hashes'].append({\n                        'value': extract_pattern_value(pattern),\n                        'hash_type': detect_hash_type(extract_pattern_value(pattern)),\n                        'confidence': getattr(parsed, 'confidence', 50)\n                    })\n                    \n        except Exception as e:\n            logger.warning(f\"Failed to parse STIX object: {e}\")\n            continue\n    \n    # Save indicators to files for consumption by security tools\n    timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')\n    \n    for indicator_type, values in indicators.items():\n        if values:\n            output_file = os.path.join(output_dir, f'{indicator_type}_{timestamp}.json')\n            with open(output_file, 'w') as f:\n                json.dump(values, f, indent=2)\n            logger.info(f\"Saved {len(values)} {indicator_type} to {output_file}\")\n    \n    return indicators\n\ndef extract_pattern_value(pattern):\n    \"\"\"Extract value from STIX pattern\"\"\"\n    import re\n    match = re.search(r\"'([^']+)'\", pattern)\n    return match.group(1) if match else pattern\n\ndef detect_hash_type(hash_value):\n    \"\"\"Detect hash type based on length\"\"\"\n    length = len(hash_value)\n    if length == 32:\n        return 'md5'\n    elif length == 40:\n        return 'sha1'\n    elif length == 64:\n        return 'sha256'\n    elif length == 128:\n        return 'sha512'\n    return 'unknown'\n\nif __name__ == '__main__':\n    import sys\n    \n    server_url = os.environ.get('TAXII_SERVER', 'https://taxii.example.com/taxii2/')\n    collection_id = os.environ.get('TAXII_COLLECTION', 'default')\n    output_dir = os.environ.get('STIX_OUTPUT_DIR', '/var/lib/threat-intel/stix')\n    api_key = os.environ.get('TAXII_API_KEY', '')\n    \n    logger.info(\"Starting threat intelligence collection\")\n    \n    stix_objects = fetch_threat_intelligence(server_url, collection_id, api_key)\n    \n    if stix_objects:\n        logger.info(f\"Retrieved {len(stix_objects)} STIX objects\")\n        indicators = process_indicators(stix_objects, output_dir)\n        \n        total = sum(len(v) for v in indicators.values())\n        logger.info(f\"Processed {total} total indicators\")\n    else:\n        logger.info(\"No new threat intelligence available\")\n    \n    sys.exit(0)\nPYTHON_SCRIPT\n\nchmod +x /tmp/taxii_collector.py\n\n# Run the collector\nexport TAXII_SERVER TAXII_COLLECTION STIX_OUTPUT_DIR TAXII_API_KEY=\"$API_KEY\"\npython3 /tmp/taxii_collector.py\n\n# Create systemd timer for automated collection (runs every hour)\nif [ -d /etc/systemd/system ]; then\n    cat > /etc/systemd/system/threat-intel-collector.service << 'EOF'\n[Unit]\nDescription=Threat Intelligence Collector Service\nAfter=network.target\n\n[Service]\nType=oneshot\nExecStart=/usr/local/bin/threat-intel-collector.sh\nEnvironmentFile=/etc/threat-intel/config.env\n\n[Install]\nWantedBy=multi-user.target\nEOF\n\n    cat > /etc/systemd/system/threat-intel-collector.timer << 'EOF'\n[Unit]\nDescription=Run Threat Intelligence Collector hourly\n\n[Timer]\nOnCalendar=hourly\nPersistent=true\n\n[Install]\nWantedBy=timers.target\nEOF\n\n    log \"Created systemd timer for automated collection\"\nfi\n\nlog \"Threat intelligence collection completed successfully\"\nexit 0",
        "ansible": "---\n# PM-16.1: Automated Threat Intelligence Sharing - Ansible Playbook\n# Deploys and configures automated threat intelligence infrastructure\n\n- name: Deploy Automated Threat Intelligence Platform\n  hosts: threat_intel_servers\n  become: yes\n  vars:\n    threat_intel_dir: /opt/threat-intel\n    stix_output_dir: /var/lib/threat-intel/stix\n    log_dir: /var/log/threat-intel\n    misp_version: \"2.4\"\n    taxii_feeds:\n      - name: \"cisa_ais\"\n        url: \"https://taxii.cisa.gov/taxii2/\"\n        collection: \"default\"\n        enabled: true\n      - name: \"alienvault_otx\"\n        url: \"https://otx.alienvault.com/taxii/\"\n        collection: \"default\"\n        enabled: true\n    siem_integration:\n      type: \"splunk\"  # Options: splunk, elastic, qradar\n      host: \"{{ siem_host | default('localhost') }}\"\n      port: \"{{ siem_port | default('8089') }}\"\n\n  tasks:\n    - name: Create threat intelligence directories\n      file:\n        path: \"{{ item }}\"\n        state: directory\n        mode: '0750'\n        owner: root\n        group: security\n      loop:\n        - \"{{ threat_intel_dir }}\"\n        - \"{{ stix_output_dir }}\"\n        - \"{{ log_dir }}\"\n        - \"/etc/threat-intel\"\n\n    - name: Install required system packages\n      package:\n        name:\n          - python3\n          - python3-pip\n          - python3-venv\n          - git\n          - curl\n          - jq\n        state: present\n\n    - name: Create Python virtual environment for threat intel\n      command: python3 -m venv {{ threat_intel_dir }}/venv\n      args:\n        creates: \"{{ threat_intel_dir }}/venv/bin/python\"\n\n    - name: Install Python dependencies for STIX/TAXII\n      pip:\n        name:\n          - taxii2-client\n          - stix2\n          - stix2-patterns\n          - cabby\n          - requests\n          - pymisp\n        virtualenv: \"{{ threat_intel_dir }}/venv\"\n        state: present\n\n    - name: Deploy threat intelligence collector script\n      copy:\n        dest: \"{{ threat_intel_dir }}/collector.py\"\n        mode: '0750'\n        owner: root\n        group: security\n        content: |\n          #!/usr/bin/env python3\n          \"\"\"\n          Automated Threat Intelligence Collector\n          Fetches IOCs from configured TAXII feeds and processes for SIEM integration\n          \"\"\"\n          import os\n          import sys\n          import json\n          import logging\n          import hashlib\n          from datetime import datetime, timedelta\n          from pathlib import Path\n          \n          # Add virtual environment packages\n          sys.path.insert(0, '{{ threat_intel_dir }}/venv/lib/python3/site-packages')\n          \n          from taxii2client.v21 import Server, Collection\n          from stix2 import parse, Filter\n          import requests\n          \n          logging.basicConfig(\n              level=logging.INFO,\n              format='%(asctime)s [%(levelname)s] %(message)s',\n              handlers=[\n                  logging.FileHandler('{{ log_dir }}/collector.log'),\n                  logging.StreamHandler()\n              ]\n          )\n          logger = logging.getLogger('ThreatIntelCollector')\n          \n          class ThreatIntelCollector:\n              def __init__(self, config_file='/etc/threat-intel/feeds.json'):\n                  self.config = self._load_config(config_file)\n                  self.output_dir = Path('{{ stix_output_dir }}')\n                  self.indicators = []\n                  \n              def _load_config(self, config_file):\n                  try:\n                      with open(config_file) as f:\n                          return json.load(f)\n                  except FileNotFoundError:\n                      logger.warning(f\"Config file not found: {config_file}\")\n                      return {'feeds': []}\n                  \n              def collect_from_taxii(self, feed):\n                  \"\"\"Collect threat intelligence from TAXII feed\"\"\"\n                  try:\n                      logger.info(f\"Collecting from TAXII feed: {feed['name']}\")\n                      \n                      headers = {}\n                      if feed.get('api_key'):\n                          headers['Authorization'] = f\"Bearer {feed['api_key']}\"\n                      \n                      server = Server(feed['url'], headers=headers)\n                      api_root = server.api_roots[0]\n                      \n                      for collection in api_root.collections:\n                          if collection.can_read:\n                              # Get objects from last 24 hours\n                              added_after = (datetime.utcnow() - timedelta(hours=24)).isoformat() + 'Z'\n                              \n                              try:\n                                  response = collection.get_objects(added_after=added_after)\n                                  if response and 'objects' in response:\n                                      logger.info(f\"Retrieved {len(response['objects'])} objects from {collection.title}\")\n                                      self.indicators.extend(response['objects'])\n                              except Exception as e:\n                                  logger.error(f\"Error fetching from collection {collection.title}: {e}\")\n                                  \n                  except Exception as e:\n                      logger.error(f\"Failed to collect from {feed['name']}: {e}\")\n                      \n              def process_indicators(self):\n                  \"\"\"Process collected indicators and prepare for SIEM\"\"\"\n                  processed = {\n                      'malicious_ips': [],\n                      'malicious_domains': [],\n                      'malicious_urls': [],\n                      'malicious_hashes': [],\n                      'threat_actors': [],\n                      'campaigns': []\n                  }\n                  \n                  for obj in self.indicators:\n                      try:\n                          parsed = parse(obj, allow_custom=True)\n                          obj_type = getattr(parsed, 'type', 'unknown')\n                          \n                          if obj_type == 'indicator':\n                              pattern = getattr(parsed, 'pattern', '')\n                              self._extract_iocs(pattern, processed, parsed)\n                          elif obj_type == 'threat-actor':\n                              processed['threat_actors'].append({\n                                  'name': getattr(parsed, 'name', 'Unknown'),\n                                  'aliases': getattr(parsed, 'aliases', []),\n                                  'description': getattr(parsed, 'description', '')\n                              })\n                          elif obj_type == 'campaign':\n                              processed['campaigns'].append({\n                                  'name': getattr(parsed, 'name', 'Unknown'),\n                                  'first_seen': str(getattr(parsed, 'first_seen', '')),\n                                  'last_seen': str(getattr(parsed, 'last_seen', ''))\n                              })\n                              \n                      except Exception as e:\n                          logger.debug(f\"Error processing object: {e}\")\n                          continue\n                          \n                  return processed\n                  \n              def _extract_iocs(self, pattern, processed, parsed):\n                  \"\"\"Extract IOCs from STIX pattern\"\"\"\n                  import re\n                  \n                  confidence = getattr(parsed, 'confidence', 50)\n                  valid_until = str(getattr(parsed, 'valid_until', ''))\n                  \n                  # IP addresses\n                  if 'ipv4-addr:value' in pattern or 'ipv6-addr:value' in pattern:\n                      match = re.search(r\"'([^']+)'\", pattern)\n                      if match:\n                          processed['malicious_ips'].append({\n                              'value': match.group(1),\n                              'confidence': confidence,\n                              'valid_until': valid_until,\n                              'source': 'taxii'\n                          })\n                          \n                  # Domains\n                  elif 'domain-name:value' in pattern:\n                      match = re.search(r\"'([^']+)'\", pattern)\n                      if match:\n                          processed['malicious_domains'].append({\n                              'value': match.group(1),\n                              'confidence': confidence,\n                              'valid_until': valid_until,\n                              'source': 'taxii'\n                          })\n                          \n                  # File hashes\n                  elif 'file:hashes' in pattern:\n                      match = re.search(r\"'([a-fA-F0-9]+)'\", pattern)\n                      if match:\n                          hash_val = match.group(1)\n                          processed['malicious_hashes'].append({\n                              'value': hash_val,\n                              'type': self._detect_hash_type(hash_val),\n                              'confidence': confidence,\n                              'source': 'taxii'\n                          })\n                          \n              def _detect_hash_type(self, hash_val):\n                  length_map = {32: 'md5', 40: 'sha1', 64: 'sha256', 128: 'sha512'}\n                  return length_map.get(len(hash_val), 'unknown')\n                  \n              def export_for_siem(self, processed):\n                  \"\"\"Export processed indicators in SIEM-compatible format\"\"\"\n                  timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')\n                  \n                  # Create individual IOC files\n                  for ioc_type, iocs in processed.items():\n                      if iocs:\n                          output_file = self.output_dir / f\"{ioc_type}_{timestamp}.json\"\n                          with open(output_file, 'w') as f:\n                              json.dump(iocs, f, indent=2)\n                          logger.info(f\"Exported {len(iocs)} {ioc_type} to {output_file}\")\n                          \n                  # Create combined feed file for firewall integration\n                  all_ips = [ioc['value'] for ioc in processed.get('malicious_ips', [])]\n                  if all_ips:\n                      ip_blocklist = self.output_dir / 'ip_blocklist.txt'\n                      with open(ip_blocklist, 'w') as f:\n                          f.write('\\n'.join(sorted(set(all_ips))))\n                      logger.info(f\"Updated IP blocklist with {len(all_ips)} addresses\")\n                      \n                  all_domains = [ioc['value'] for ioc in processed.get('malicious_domains', [])]\n                  if all_domains:\n                      domain_blocklist = self.output_dir / 'domain_blocklist.txt'\n                      with open(domain_blocklist, 'w') as f:\n                          f.write('\\n'.join(sorted(set(all_domains))))\n                      logger.info(f\"Updated domain blocklist with {len(all_domains)} domains\")\n                      \n              def run(self):\n                  \"\"\"Main execution\"\"\"\n                  logger.info(\"Starting threat intelligence collection cycle\")\n                  \n                  for feed in self.config.get('feeds', []):\n                      if feed.get('enabled', True):\n                          self.collect_from_taxii(feed)\n                          \n                  if self.indicators:\n                      processed = self.process_indicators()\n                      self.export_for_siem(processed)\n                      \n                      total = sum(len(v) for v in processed.values())\n                      logger.info(f\"Collection complete: {total} indicators processed\")\n                  else:\n                      logger.info(\"No new indicators collected\")\n                      \n          if __name__ == '__main__':\n              collector = ThreatIntelCollector()\n              collector.run()\n\n    - name: Deploy feed configuration\n      copy:\n        dest: /etc/threat-intel/feeds.json\n        mode: '0640'\n        owner: root\n        group: security\n        content: |\n          {\n            \"feeds\": [\n              {% for feed in taxii_feeds %}\n              {\n                \"name\": \"{{ feed.name }}\",\n                \"url\": \"{{ feed.url }}\",\n                \"collection\": \"{{ feed.collection }}\",\n                \"enabled\": {{ feed.enabled | lower }},\n                \"api_key\": \"{{ feed.api_key | default('') }}\"\n              }{% if not loop.last %},{% endif %}\n              {% endfor %}\n            ]\n          }\n\n    - name: Create systemd service for threat intel collector\n      copy:\n        dest: /etc/systemd/system/threat-intel-collector.service\n        mode: '0644'\n        content: |\n          [Unit]\n          Description=Automated Threat Intelligence Collector\n          After=network.target\n          \n          [Service]\n          Type=oneshot\n          ExecStart={{ threat_intel_dir }}/venv/bin/python {{ threat_intel_dir }}/collector.py\n          User=root\n          Group=security\n          \n          [Install]\n          WantedBy=multi-user.target\n\n    - name: Create systemd timer for hourly collection\n      copy:\n        dest: /etc/systemd/system/threat-intel-collector.timer\n        mode: '0644'\n        content: |\n          [Unit]\n          Description=Run Threat Intelligence Collector Every Hour\n          \n          [Timer]\n          OnCalendar=hourly\n          RandomizedDelaySec=300\n          Persistent=true\n          \n          [Install]\n          WantedBy=timers.target\n\n    - name: Enable and start threat intel timer\n      systemd:\n        name: threat-intel-collector.timer\n        enabled: yes\n        state: started\n        daemon_reload: yes\n\n    - name: Run initial threat intelligence collection\n      command: \"{{ threat_intel_dir }}/venv/bin/python {{ threat_intel_dir }}/collector.py\"\n      register: initial_collection\n      changed_when: false\n\n    - name: Display collection results\n      debug:\n        var: initial_collection.stdout_lines\n\n    - name: Configure logrotate for threat intel logs\n      copy:\n        dest: /etc/logrotate.d/threat-intel\n        mode: '0644'\n        content: |\n          {{ log_dir }}/*.log {\n              daily\n              rotate 30\n              compress\n              delaycompress\n              missingok\n              notifempty\n              create 0640 root security\n          }\n\n  handlers:\n    - name: Restart threat intel collector\n      systemd:\n        name: threat-intel-collector.timer\n        state: restarted"
      },
      "windows": {
        "powershell": "# PM-16.1: Automated Threat Intelligence Sharing - Windows PowerShell\n# Configures automated threat feed integration for Windows environments\n\n<#\n.SYNOPSIS\n    Automated Threat Intelligence Feed Management for Windows\n    \n.DESCRIPTION\n    This script implements automated threat intelligence collection and\n    integration with Windows security tools including Windows Defender,\n    Windows Firewall, and SIEM systems via STIX/TAXII protocols.\n    \n.NOTES\n    Requires: PowerShell 5.1+, Administrator privileges\n    Control: PM-16.1 - Automated Means for Sharing Threat Intelligence\n#>\n\n[CmdletBinding()]\nparam(\n    [string]$ThreatIntelDir = \"C:\\ProgramData\\ThreatIntelligence\",\n    [string]$LogDir = \"C:\\ProgramData\\ThreatIntelligence\\Logs\",\n    [string]$ConfigFile = \"C:\\ProgramData\\ThreatIntelligence\\config.json\",\n    [switch]$InstallService,\n    [switch]$RunCollection\n)\n\n$ErrorActionPreference = 'Stop'\n\n# Initialize logging\nfunction Write-ThreatIntelLog {\n    param([string]$Message, [string]$Level = 'INFO')\n    \n    $timestamp = Get-Date -Format 'yyyy-MM-dd HH:mm:ss'\n    $logEntry = \"$timestamp [$Level] $Message\"\n    \n    if (-not (Test-Path $LogDir)) {\n        New-Item -ItemType Directory -Path $LogDir -Force | Out-Null\n    }\n    \n    $logFile = Join-Path $LogDir \"threat-intel-$(Get-Date -Format 'yyyyMMdd').log\"\n    Add-Content -Path $logFile -Value $logEntry\n    \n    switch ($Level) {\n        'ERROR' { Write-Host $logEntry -ForegroundColor Red }\n        'WARNING' { Write-Host $logEntry -ForegroundColor Yellow }\n        default { Write-Host $logEntry -ForegroundColor Green }\n    }\n}\n\n# Create directory structure\nfunction Initialize-ThreatIntelEnvironment {\n    Write-ThreatIntelLog \"Initializing threat intelligence environment\"\n    \n    $directories = @(\n        $ThreatIntelDir,\n        $LogDir,\n        \"$ThreatIntelDir\\IOCs\",\n        \"$ThreatIntelDir\\STIX\",\n        \"$ThreatIntelDir\\Blocklists\"\n    )\n    \n    foreach ($dir in $directories) {\n        if (-not (Test-Path $dir)) {\n            New-Item -ItemType Directory -Path $dir -Force | Out-Null\n            Write-ThreatIntelLog \"Created directory: $dir\"\n        }\n    }\n    \n    # Set restrictive permissions\n    $acl = Get-Acl $ThreatIntelDir\n    $acl.SetAccessRuleProtection($true, $false)\n    \n    $adminRule = New-Object System.Security.AccessControl.FileSystemAccessRule(\n        \"BUILTIN\\Administrators\", \"FullControl\", \"ContainerInherit,ObjectInherit\", \"None\", \"Allow\"\n    )\n    $systemRule = New-Object System.Security.AccessControl.FileSystemAccessRule(\n        \"NT AUTHORITY\\SYSTEM\", \"FullControl\", \"ContainerInherit,ObjectInherit\", \"None\", \"Allow\"\n    )\n    \n    $acl.SetAccessRule($adminRule)\n    $acl.SetAccessRule($systemRule)\n    Set-Acl -Path $ThreatIntelDir -AclObject $acl\n    \n    Write-ThreatIntelLog \"Environment initialized with secure permissions\"\n}\n\n# Default configuration\nfunction Initialize-ThreatIntelConfig {\n    if (-not (Test-Path $ConfigFile)) {\n        $defaultConfig = @{\n            feeds = @(\n                @{\n                    name = \"CISA_AIS\"\n                    url = \"https://taxii.cisa.gov/taxii2/\"\n                    collection = \"default\"\n                    enabled = $true\n                    apiKey = \"\"\n                },\n                @{\n                    name = \"AlienVault_OTX\"\n                    url = \"https://otx.alienvault.com/api/v1/\"\n                    type = \"otx\"\n                    enabled = $true\n                    apiKey = \"\"\n                }\n            )\n            integration = @{\n                updateDefender = $true\n                updateFirewall = $true\n                exportSIEM = $true\n                siemFormat = \"json\"\n            }\n            schedule = @{\n                collectionIntervalHours = 1\n                retentionDays = 30\n            }\n        }\n        \n        $defaultConfig | ConvertTo-Json -Depth 10 | Out-File $ConfigFile -Encoding UTF8\n        Write-ThreatIntelLog \"Created default configuration file: $ConfigFile\"\n    }\n    \n    return Get-Content $ConfigFile | ConvertFrom-Json\n}\n\n# Fetch threat intelligence from TAXII feed\nfunction Get-TAXIIThreatIntel {\n    param(\n        [string]$ServerUrl,\n        [string]$Collection,\n        [string]$ApiKey,\n        [int]$HoursBack = 24\n    )\n    \n    Write-ThreatIntelLog \"Fetching threat intelligence from: $ServerUrl\"\n    \n    $headers = @{\n        'Accept' = 'application/taxii+json;version=2.1'\n        'Content-Type' = 'application/taxii+json;version=2.1'\n    }\n    \n    if ($ApiKey) {\n        $headers['Authorization'] = \"Bearer $ApiKey\"\n    }\n    \n    try {\n        # Get API root discovery\n        $discovery = Invoke-RestMethod -Uri $ServerUrl -Headers $headers -Method Get\n        \n        if ($discovery.api_roots -and $discovery.api_roots.Count -gt 0) {\n            $apiRoot = $discovery.api_roots[0]\n            \n            # Get collections\n            $collectionsUrl = \"$apiRoot/collections/\"\n            $collections = Invoke-RestMethod -Uri $collectionsUrl -Headers $headers -Method Get\n            \n            $indicators = @()\n            \n            foreach ($col in $collections.collections) {\n                if ($col.can_read) {\n                    Write-ThreatIntelLog \"Fetching from collection: $($col.title)\"\n                    \n                    $addedAfter = (Get-Date).AddHours(-$HoursBack).ToUniversalTime().ToString('yyyy-MM-ddTHH:mm:ss.fffZ')\n                    $objectsUrl = \"$apiRoot/collections/$($col.id)/objects/?added_after=$addedAfter\"\n                    \n                    try {\n                        $response = Invoke-RestMethod -Uri $objectsUrl -Headers $headers -Method Get\n                        \n                        if ($response.objects) {\n                            $indicators += $response.objects\n                            Write-ThreatIntelLog \"Retrieved $($response.objects.Count) objects from $($col.title)\"\n                        }\n                    }\n                    catch {\n                        Write-ThreatIntelLog \"Failed to fetch from collection $($col.title): $_\" -Level 'WARNING'\n                    }\n                }\n            }\n            \n            return $indicators\n        }\n    }\n    catch {\n        Write-ThreatIntelLog \"Error connecting to TAXII server: $_\" -Level 'ERROR'\n        return @()\n    }\n    \n    return @()\n}\n\n# Process STIX indicators\nfunction ConvertFrom-STIXIndicators {\n    param([array]$STIXObjects)\n    \n    $processed = @{\n        IPs = @()\n        Domains = @()\n        URLs = @()\n        Hashes = @()\n        ThreatActors = @()\n    }\n    \n    foreach ($obj in $STIXObjects) {\n        try {\n            switch ($obj.type) {\n                'indicator' {\n                    $pattern = $obj.pattern\n                    \n                    # Extract IP addresses\n                    if ($pattern -match \"ipv[46]-addr:value\\s*=\\s*'([^']+)'\") {\n                        $processed.IPs += @{\n                            Value = $Matches[1]\n                            Confidence = if ($obj.confidence) { $obj.confidence } else { 50 }\n                            ValidUntil = $obj.valid_until\n                            Source = 'TAXII'\n                        }\n                    }\n                    \n                    # Extract domains\n                    if ($pattern -match \"domain-name:value\\s*=\\s*'([^']+)'\") {\n                        $processed.Domains += @{\n                            Value = $Matches[1]\n                            Confidence = if ($obj.confidence) { $obj.confidence } else { 50 }\n                            ValidUntil = $obj.valid_until\n                            Source = 'TAXII'\n                        }\n                    }\n                    \n                    # Extract file hashes\n                    if ($pattern -match \"file:hashes\\..*?=\\s*'([a-fA-F0-9]+)'\") {\n                        $hashValue = $Matches[1]\n                        $hashType = switch ($hashValue.Length) {\n                            32 { 'MD5' }\n                            40 { 'SHA1' }\n                            64 { 'SHA256' }\n                            128 { 'SHA512' }\n                            default { 'Unknown' }\n                        }\n                        \n                        $processed.Hashes += @{\n                            Value = $hashValue\n                            Type = $hashType\n                            Confidence = if ($obj.confidence) { $obj.confidence } else { 50 }\n                            Source = 'TAXII'\n                        }\n                    }\n                }\n                \n                'threat-actor' {\n                    $processed.ThreatActors += @{\n                        Name = $obj.name\n                        Aliases = $obj.aliases\n                        Description = $obj.description\n                    }\n                }\n            }\n        }\n        catch {\n            Write-ThreatIntelLog \"Error processing STIX object: $_\" -Level 'WARNING'\n        }\n    }\n    \n    return $processed\n}\n\n# Update Windows Defender with threat indicators\nfunction Update-DefenderIndicators {\n    param([hashtable]$Indicators)\n    \n    Write-ThreatIntelLog \"Updating Windows Defender with threat indicators\"\n    \n    # Add malicious IPs to Defender indicators\n    foreach ($ip in $Indicators.IPs | Where-Object { $_.Confidence -ge 70 }) {\n        try {\n            # Note: Requires Microsoft Defender for Endpoint\n            # Add-MpPreference -ExclusionIpAddress $ip.Value  # This excludes, we need the opposite\n            Write-ThreatIntelLog \"Flagged IP for monitoring: $($ip.Value)\"\n        }\n        catch {\n            Write-ThreatIntelLog \"Could not add IP indicator: $_\" -Level 'WARNING'\n        }\n    }\n    \n    # Add malicious file hashes\n    foreach ($hash in $Indicators.Hashes | Where-Object { $_.Confidence -ge 70 -and $_.Type -eq 'SHA256' }) {\n        try {\n            Add-MpPreference -ThreatIDDefaultAction_Ids $hash.Value -ThreatIDDefaultAction_Actions Quarantine\n            Write-ThreatIntelLog \"Added hash to Defender blocklist: $($hash.Value.Substring(0,16))...\"\n        }\n        catch {\n            Write-ThreatIntelLog \"Could not add hash indicator: $_\" -Level 'WARNING'\n        }\n    }\n    \n    Write-ThreatIntelLog \"Defender indicators updated\"\n}\n\n# Update Windows Firewall with malicious IPs\nfunction Update-FirewallBlocklist {\n    param([hashtable]$Indicators)\n    \n    Write-ThreatIntelLog \"Updating Windows Firewall blocklist\"\n    \n    $ruleName = \"ThreatIntel_BlockMaliciousIPs\"\n    \n    # Get high-confidence malicious IPs\n    $maliciousIPs = $Indicators.IPs | Where-Object { $_.Confidence -ge 80 } | Select-Object -ExpandProperty Value -Unique\n    \n    if ($maliciousIPs.Count -gt 0) {\n        # Remove existing rule if present\n        Get-NetFirewallRule -DisplayName $ruleName -ErrorAction SilentlyContinue | Remove-NetFirewallRule\n        \n        # Create new blocking rule\n        New-NetFirewallRule -DisplayName $ruleName `\n            -Direction Outbound `\n            -Action Block `\n            -RemoteAddress $maliciousIPs `\n            -Description \"Auto-generated rule blocking known malicious IPs from threat intelligence feeds\" `\n            -Enabled True\n            \n        Write-ThreatIntelLog \"Firewall rule created blocking $($maliciousIPs.Count) malicious IPs\"\n    }\n    else {\n        Write-ThreatIntelLog \"No high-confidence IPs to block\"\n    }\n}\n\n# Export indicators for SIEM integration\nfunction Export-SIEMIndicators {\n    param(\n        [hashtable]$Indicators,\n        [string]$OutputPath\n    )\n    \n    Write-ThreatIntelLog \"Exporting indicators for SIEM integration\"\n    \n    $timestamp = Get-Date -Format 'yyyyMMdd_HHmmss'\n    \n    # Export each indicator type\n    $exports = @{\n        'malicious_ips' = $Indicators.IPs\n        'malicious_domains' = $Indicators.Domains\n        'malicious_hashes' = $Indicators.Hashes\n        'threat_actors' = $Indicators.ThreatActors\n    }\n    \n    foreach ($type in $exports.Keys) {\n        if ($exports[$type].Count -gt 0) {\n            $outputFile = Join-Path $OutputPath \"${type}_${timestamp}.json\"\n            $exports[$type] | ConvertTo-Json -Depth 10 | Out-File $outputFile -Encoding UTF8\n            Write-ThreatIntelLog \"Exported $($exports[$type].Count) $type to $outputFile\"\n        }\n    }\n    \n    # Create plain-text blocklists for firewall/proxy integration\n    $ipBlocklist = Join-Path $OutputPath \"ip_blocklist.txt\"\n    $Indicators.IPs | Select-Object -ExpandProperty Value -Unique | Out-File $ipBlocklist -Encoding UTF8\n    \n    $domainBlocklist = Join-Path $OutputPath \"domain_blocklist.txt\"\n    $Indicators.Domains | Select-Object -ExpandProperty Value -Unique | Out-File $domainBlocklist -Encoding UTF8\n    \n    Write-ThreatIntelLog \"Blocklist files updated\"\n}\n\n# Create scheduled task for automated collection\nfunction Install-ThreatIntelScheduledTask {\n    Write-ThreatIntelLog \"Installing scheduled task for automated collection\"\n    \n    $taskName = \"ThreatIntelligenceCollector\"\n    $scriptPath = $MyInvocation.PSCommandPath\n    \n    # Remove existing task\n    Unregister-ScheduledTask -TaskName $taskName -Confirm:$false -ErrorAction SilentlyContinue\n    \n    # Create hourly trigger\n    $trigger = New-ScheduledTaskTrigger -Once -At (Get-Date) -RepetitionInterval (New-TimeSpan -Hours 1)\n    \n    # Create action\n    $action = New-ScheduledTaskAction -Execute 'powershell.exe' `\n        -Argument \"-ExecutionPolicy Bypass -File `\"$scriptPath`\" -RunCollection\"\n    \n    # Create principal (run as SYSTEM)\n    $principal = New-ScheduledTaskPrincipal -UserId 'NT AUTHORITY\\SYSTEM' -LogonType ServiceAccount -RunLevel Highest\n    \n    # Create settings\n    $settings = New-ScheduledTaskSettingsSet -StartWhenAvailable -DontStopOnIdleEnd -RestartCount 3 -RestartInterval (New-TimeSpan -Minutes 10)\n    \n    # Register task\n    Register-ScheduledTask -TaskName $taskName -Trigger $trigger -Action $action -Principal $principal -Settings $settings `\n        -Description \"Automated Threat Intelligence Collection for PM-16.1 compliance\"\n    \n    Write-ThreatIntelLog \"Scheduled task '$taskName' installed successfully\"\n}\n\n# Main execution\nfunction Start-ThreatIntelCollection {\n    Write-ThreatIntelLog \"========== Starting Threat Intelligence Collection ==========\"\n    \n    # Initialize environment\n    Initialize-ThreatIntelEnvironment\n    $config = Initialize-ThreatIntelConfig\n    \n    $allIndicators = @{\n        IPs = @()\n        Domains = @()\n        URLs = @()\n        Hashes = @()\n        ThreatActors = @()\n    }\n    \n    # Collect from each enabled feed\n    foreach ($feed in $config.feeds | Where-Object { $_.enabled }) {\n        Write-ThreatIntelLog \"Processing feed: $($feed.name)\"\n        \n        if ($feed.type -eq 'otx') {\n            # Handle AlienVault OTX differently\n            # OTX uses a different API structure\n            Write-ThreatIntelLog \"OTX feed requires API key configuration\" -Level 'WARNING'\n        }\n        else {\n            # Standard TAXII feed\n            $stixObjects = Get-TAXIIThreatIntel -ServerUrl $feed.url -Collection $feed.collection -ApiKey $feed.apiKey\n            \n            if ($stixObjects.Count -gt 0) {\n                $processed = ConvertFrom-STIXIndicators -STIXObjects $stixObjects\n                \n                $allIndicators.IPs += $processed.IPs\n                $allIndicators.Domains += $processed.Domains\n                $allIndicators.URLs += $processed.URLs\n                $allIndicators.Hashes += $processed.Hashes\n                $allIndicators.ThreatActors += $processed.ThreatActors\n            }\n        }\n    }\n    \n    # Process collected indicators\n    $totalIndicators = $allIndicators.IPs.Count + $allIndicators.Domains.Count + $allIndicators.Hashes.Count\n    Write-ThreatIntelLog \"Total indicators collected: $totalIndicators\"\n    \n    if ($totalIndicators -gt 0) {\n        # Update security tools based on configuration\n        if ($config.integration.updateDefender) {\n            Update-DefenderIndicators -Indicators $allIndicators\n        }\n        \n        if ($config.integration.updateFirewall) {\n            Update-FirewallBlocklist -Indicators $allIndicators\n        }\n        \n        if ($config.integration.exportSIEM) {\n            Export-SIEMIndicators -Indicators $allIndicators -OutputPath \"$ThreatIntelDir\\IOCs\"\n        }\n    }\n    \n    Write-ThreatIntelLog \"========== Collection Complete ==========\"\n}\n\n# Entry point\nif ($InstallService) {\n    Initialize-ThreatIntelEnvironment\n    Initialize-ThreatIntelConfig\n    Install-ThreatIntelScheduledTask\n    Write-ThreatIntelLog \"Service installation complete\"\n}\n\nif ($RunCollection) {\n    Start-ThreatIntelCollection\n}\n\nif (-not $InstallService -and -not $RunCollection) {\n    Write-Host @\"\n\nPM-16.1 Automated Threat Intelligence Sharing Script\n=====================================================\n\nUsage:\n  -InstallService    Install scheduled task for automated hourly collection\n  -RunCollection     Run threat intelligence collection immediately\n\nExamples:\n  .\\PM-16.1-ThreatIntel.ps1 -InstallService\n  .\\PM-16.1-ThreatIntel.ps1 -RunCollection\n\nConfiguration:\n  Edit $ConfigFile to configure threat feeds and integration settings.\n\n\"@\n}"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": true
    }
  },
  {
    "control_id": "PM-17",
    "control_name": "Protecting Controlled Unclassified Information on External Systems",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "a. Establish policy and procedures to ensure that requirements for the protection of controlled unclassified information (CUI) that is processed, stored, or transmitted on external systems, are implemented in accordance with applicable laws, executive orders, directives, policies, regulations, and standards; and b. Review and update the policy and procedures [Assignment: organization-defined frequency].",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Ensure that Controlled Unclassified Information (CUI) processed, stored, or transmitted on external systems receives equivalent protection to that provided on internal organizational systems.",
    "rationale": "Organizations increasingly rely on external systems (cloud services, contractor systems, partner networks) to process CUI. Without explicit policies and contractual requirements, CUI may be exposed to unauthorized access, modification, or disclosure. This control ensures that security requirements follow the data regardless of where it resides, maintaining confidentiality and integrity of sensitive government information across organizational boundaries.",
    "plain_english_explanation": "This control requires organizations to create and maintain policies ensuring that sensitive but unclassified government information (CUI) receives proper protection when stored or processed on systems outside the organization. This includes contractor systems, cloud services, and partner networks. Organizations must verify that external systems meet CUI protection requirements through contracts, agreements, and periodic assessments.",
    "ai_guidance": "When implementing PM-17, organizations must first understand what constitutes CUI and where it flows within their ecosystem. Begin by conducting a data flow analysis to identify all external systems that process, store, or transmit CUI. This includes cloud service providers, contractors, subcontractors, and business partners. Develop comprehensive policies that align with NIST SP 800-171 requirements for protecting CUI in non-federal systems. Ensure contracts and service level agreements explicitly require CUI protection measures, including encryption at rest and in transit, access controls, audit logging, and incident reporting. Implement a verification program to assess external system compliance, which may include third-party assessments, attestations (such as FedRAMP for cloud providers), or self-assessments against NIST 800-171. Establish procedures for authorizing external systems to process CUI and maintain an inventory of approved systems. Create incident response procedures that extend to external systems and establish clear communication channels for security events. Review policies annually or when significant changes occur in the threat landscape, regulatory requirements, or organizational relationships. Document all exceptions and risk acceptances with appropriate authorization levels.",
    "enhancements": [],
    "related_controls": [
      "AC-20",
      "CA-3",
      "PS-7",
      "SA-9",
      "SC-7"
    ],
    "supplemental_guidance": "This control applies to external systems owned by contractors, partners, or cloud service providers that process CUI on behalf of the organization. The protection requirements are primarily derived from NIST SP 800-171 and the CUI Registry.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-18",
    "control_name": "Privacy Program Plan",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "a. Develop and disseminate an organization-wide privacy program plan that provides an overview of the agency's privacy program, and: 1. Includes a description of the structure of the privacy program and the resources dedicated to the privacy program; 2. Provides an overview of the requirements for the privacy program and a description of the privacy program management controls and common controls in place or planned for meeting those requirements; 3. Includes the role of the senior agency official for privacy and the identification and assignment of roles of other privacy officials and staff and their responsibilities; 4. Describes the strategic goals and objectives of the privacy program and the rationale for those goals and objectives; 5. Includes a privacy risk management framework; and 6. Is reviewed and updated [Assignment: organization-defined frequency]; and b. Develop, disseminate, and implement operational privacy plans that describe how the organization implements privacy controls and how the privacy program is integrated into organizational operations.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Establish a comprehensive, documented privacy program that provides strategic direction, assigns responsibilities, and ensures privacy requirements are systematically addressed across the organization.",
    "rationale": "A formal privacy program plan is essential for demonstrating organizational commitment to privacy protection and ensuring consistent implementation of privacy controls. Without a documented plan, privacy efforts become ad hoc, inconsistent, and difficult to assess. The plan provides accountability through defined roles, enables resource allocation, supports compliance with privacy laws (HIPAA, GDPR, Privacy Act), and integrates privacy considerations into organizational decision-making processes.",
    "plain_english_explanation": "This control requires organizations to create and maintain a comprehensive written plan that describes their entire privacy program. The plan must explain the program's structure, who is responsible for what, what privacy goals the organization is trying to achieve, and how privacy risks will be managed. The plan should be a living document that is reviewed and updated regularly, and operational plans should translate the strategic vision into day-to-day privacy practices.",
    "ai_guidance": "When developing a Privacy Program Plan under PM-18, organizations should approach this as a foundational governance document that sets the tone for all privacy activities. Start by clearly defining the scope of the privacy program, including which laws, regulations, and organizational policies apply. Document the privacy program structure, including reporting relationships, committees, and integration points with security and legal functions. Identify the Senior Agency Official for Privacy (SAOP) and clearly articulate their authority and responsibilities. Map out all privacy roles across the organization, from dedicated privacy staff to system owners with privacy responsibilities. Develop strategic goals that align with organizational mission while addressing privacy risks - these should be measurable and time-bound. Create a privacy risk management framework that describes how privacy risks are identified, assessed, prioritized, and mitigated. Include procedures for privacy impact assessments (PIAs), privacy threshold analyses, and privacy control assessments. Address how the program integrates with system development lifecycle processes, procurement, and third-party risk management. Establish metrics and reporting mechanisms to demonstrate program effectiveness to leadership. The plan should reference but not duplicate content from related documents such as the information security plan. Review frequency should align with organizational risk tolerance - annually at minimum, or when significant changes occur.",
    "enhancements": [],
    "related_controls": [
      "PM-19",
      "PM-20",
      "PM-9",
      "AR-1",
      "AR-2",
      "PT-1"
    ],
    "supplemental_guidance": "The privacy program plan is a strategic document that provides the foundation for operational privacy activities. It should be developed in consultation with legal counsel, senior leadership, and other stakeholders with privacy responsibilities.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-19",
    "control_name": "Privacy Program Leadership Role",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Appoint a senior agency official for privacy with the authority, mission, accountability, and resources to coordinate, develop, and implement applicable privacy requirements and manage privacy risks through the organization-wide privacy program.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Ensure executive-level accountability for privacy through a designated senior official who has the authority, resources, and organizational position to effectively lead the privacy program.",
    "rationale": "Privacy programs require executive sponsorship and leadership to be effective. A designated senior official ensures that privacy considerations receive appropriate attention at the highest levels of decision-making, that adequate resources are allocated to privacy activities, and that there is clear accountability for privacy outcomes. Without such leadership, privacy initiatives often become fragmented, under-resourced, and disconnected from organizational strategy. This role is mandated by various privacy laws and serves as the authoritative voice for privacy within the organization.",
    "plain_english_explanation": "This control requires organizations to designate a senior official (often called the Chief Privacy Officer or Senior Agency Official for Privacy) who is responsible for leading the organization's privacy program. This person must have real authority to make decisions about privacy matters, be held accountable for privacy outcomes, and be given adequate staff and budget to do the job effectively. They coordinate all privacy activities across the organization and serve as the primary point of contact for privacy matters.",
    "ai_guidance": "Implementing PM-19 requires careful consideration of organizational structure, authority, and reporting relationships. The Senior Agency Official for Privacy (SAOP) should be positioned at an executive level with direct access to top leadership and the authority to influence organizational decisions that affect privacy. When selecting or appointing this role, consider individuals with a combination of legal expertise, technical understanding, and business acumen. The SAOP should have clear delegated authority to approve privacy policies, halt projects that pose unacceptable privacy risks, and represent the organization on privacy matters. Document the SAOP's responsibilities in a formal appointment letter or position description that includes: oversight of privacy impact assessments, review of system of records notices, management of privacy incidents, coordination with legal and security functions, training program oversight, and external privacy reporting. Ensure the SAOP has adequate staff support - the size of the privacy team should be commensurate with the organization's size and privacy risk profile. Establish a budget allocation process that provides predictable funding for privacy activities. Create reporting mechanisms so the SAOP can regularly brief senior leadership and the board (if applicable) on privacy program status, risks, and incidents. The SAOP should participate in key governance bodies such as the IT investment review board, data governance council, and enterprise risk management committee. Document succession planning to ensure continuity of privacy leadership.",
    "enhancements": [],
    "related_controls": [
      "PM-2",
      "PM-18",
      "PM-20",
      "AR-1"
    ],
    "supplemental_guidance": "The senior agency official for privacy is the organization's authoritative voice on privacy matters and should have sufficient independence to objectively assess privacy risks and advocate for privacy protections.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-20",
    "control_name": "Dissemination of Privacy Program Information",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Maintain a central resource webpage on the organization's principal public website that serves as a central source of information about the organization's privacy program and that: a. Ensures that the public has access to information about organizational privacy activities and can communicate with its senior agency official for privacy; b. Ensures that organizational privacy practices and reports are publicly available; and c. Employs publicly facing email addresses and/or other mechanisms to enable the public to provide feedback and/or direct questions to privacy offices regarding privacy practices.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Provide transparent, accessible public information about organizational privacy practices and establish channels for public communication with privacy officials.",
    "rationale": "Transparency is a fundamental privacy principle. Organizations that collect and process personal information have an obligation to inform individuals about their privacy practices. A centralized, public-facing privacy resource enables individuals to understand how their information is handled, access required privacy notices and reports, and communicate concerns to privacy officials. This transparency builds public trust, demonstrates organizational accountability, and fulfills legal requirements for public disclosure of privacy practices.",
    "plain_english_explanation": "This control requires organizations to maintain a dedicated privacy webpage on their public website that serves as a one-stop shop for privacy information. The page should explain how the organization handles personal information, provide access to privacy policies and required reports, and give the public a way to contact privacy officials with questions or concerns. This makes privacy practices transparent and accessible to everyone.",
    "ai_guidance": "When implementing PM-20, organizations should create a comprehensive, user-friendly privacy resource center on their public website. The privacy page should be easily discoverable from the homepage - typically linked in the footer and/or main navigation. Content should be written in plain language accessible to a general audience, avoiding legal jargon where possible. Key content should include: the organization's privacy policy, Privacy Act System of Records Notices (SORNs) for federal agencies, privacy impact assessments (PIAs), annual privacy reports, the SAOP's contact information, and information about how individuals can exercise their privacy rights (access, correction, etc.). Implement a dedicated privacy email address (e.g., privacy@organization.gov) that is monitored regularly and routes inquiries to appropriate staff. Consider implementing a web form for structured privacy inquiries. Establish response time standards for public inquiries and track metrics. Ensure the privacy page is accessible under Section 508/WCAG standards and available in multiple languages if required by law or organizational policy. The page should include information about cookies and tracking technologies used on the website itself. Update the page promptly when policies change or new reports are published. For federal agencies, ensure compliance with OMB requirements for privacy web content. Test the page periodically to ensure all links work and contact mechanisms function properly. Consider including FAQs addressing common privacy questions to reduce inquiry volume.",
    "enhancements": [
      {
        "id": "PM-20.1",
        "title": "Privacy Policies on Websites, Applications, and Digital Services",
        "official_text": "Develop and post privacy policies on all external-facing websites, mobile applications, and other digital services, that: a. Are written in plain language; b. Describe the organization's privacy practices regarding collection, use, retention, disclosure, and disposal of personally identifiable information; c. Are updated whenever the organization makes a substantive change to the privacy practices described; and d. Employ machine-readable privacy policies that reflect the organization's privacy practices."
      }
    ],
    "related_controls": [
      "PM-18",
      "PM-19",
      "AC-22",
      "TR-1",
      "TR-2"
    ],
    "supplemental_guidance": "The privacy webpage should be maintained and updated regularly to reflect current practices and ensure all required notices and reports are available to the public.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-20.1",
    "control_name": "Privacy Policies on Websites, Applications, and Digital Services",
    "family": "Program Management",
    "family_id": "PM",
    "parent_control": "PM-20",
    "official_text": "Develop and post privacy policies on all external-facing websites, mobile applications, and other digital services, that: a. Are written in plain language and are understandable to the general public; b. Describe the organization's privacy practices regarding collection, use, retention, disclosure, and disposal of personally identifiable information; c. Are updated whenever the organization makes a substantive change to the privacy practices described in the policy; and d. Employ machine-readable privacy policies that reflect the organization's privacy practices.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": true,
    "stig_id": null,
    "intent": "Ensure all external-facing digital services have accessible, comprehensive privacy policies that inform users about data handling practices and provide machine-readable policy data for automated processing.",
    "rationale": "Users interacting with websites, mobile applications, and digital services need clear information about how their personal data will be collected and used. Privacy policies are legally required in many jurisdictions (GDPR, CCPA, Privacy Act) and serve as the basis for informed consent. Machine-readable policies enable automated compliance checking, browser privacy features, and user preference management. Without consistent privacy policies across all digital touchpoints, organizations face legal risk, user distrust, and potential regulatory penalties.",
    "plain_english_explanation": "This control requires that every public-facing website, mobile app, and digital service has a privacy policy that explains in plain language what personal information is collected, how it is used, who it is shared with, how long it is kept, and how it is protected. The policy must be updated when practices change, and machine-readable formats should be used so browsers and automated tools can interpret the policy.",
    "ai_guidance": "Implementing PM-20.1 requires both content development and technical implementation across all digital properties. Start by inventorying all external-facing websites, mobile applications, APIs, and digital services that collect personal information. Develop a privacy policy template that addresses required elements: types of PII collected, purposes of collection, legal basis for processing, data retention periods, third-party disclosures, user rights, and contact information. Write policies in plain language (8th grade reading level target) and structure them with clear headings for scanability. For technical implementation, ensure privacy policies are linked from every page (typically footer) and prominently displayed during registration or data collection. Implement cookie consent banners that comply with GDPR/CCPA requirements, allowing users to accept, reject, or customize tracking preferences. Use the Platform for Privacy Preferences (P3P) format or newer standards like Do Not Track (DNT) headers for machine-readable policies. Implement schema.org PrivacyPolicy markup for SEO and machine interpretation. For mobile apps, integrate privacy policies into app store listings and in-app settings. Implement version control for policies and maintain an archive of previous versions with effective dates. Create automated testing to verify privacy policy links are functional across all properties. Establish a review process to update policies when new features are launched or data practices change. Monitor for GDPR consent compliance using automated scanning tools.",
    "enhancements": [],
    "related_controls": [
      "PM-20",
      "TR-1",
      "TR-2",
      "TR-3",
      "UL-1"
    ],
    "supplemental_guidance": "Machine-readable privacy policies facilitate automated compliance verification and enable user agents to process privacy information on behalf of individuals.",
    "implementation_scripts": {
      "linux": {
        "bash": "#!/bin/bash\n# PM-20.1: Privacy Policy Deployment and Compliance Checker\n# This script deploys privacy policy infrastructure and validates compliance\n\nset -euo pipefail\n\n# Configuration\nWEB_ROOT=\"${WEB_ROOT:-/var/www/html}\"\nPRIVACY_DIR=\"${WEB_ROOT}/privacy\"\nLOG_FILE=\"/var/log/privacy-policy-audit.log\"\nDATE=$(date +%Y-%m-%d)\n\nlog() {\n    echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\" | tee -a \"$LOG_FILE\"\n}\n\n# Create privacy policy directory structure\nmkdir -p \"${PRIVACY_DIR}\"\nmkdir -p \"${PRIVACY_DIR}/archive\"\nmkdir -p \"${PRIVACY_DIR}/machine-readable\"\n\nlog \"[PM-20.1] Starting privacy policy deployment and compliance check\"\n\n# Generate machine-readable privacy policy (JSON-LD format)\ncat > \"${PRIVACY_DIR}/machine-readable/privacy-policy.json\" << 'POLICY_JSON'\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"PrivacyPolicy\",\n  \"name\": \"Privacy Policy\",\n  \"url\": \"/privacy/policy.html\",\n  \"datePublished\": \"2025-01-01\",\n  \"dateModified\": \"2025-11-22\",\n  \"inLanguage\": \"en-US\",\n  \"publisher\": {\n    \"@type\": \"Organization\",\n    \"name\": \"Organization Name\"\n  },\n  \"mainEntity\": {\n    \"@type\": \"WebPage\",\n    \"description\": \"This privacy policy describes how we collect, use, and protect your personal information.\"\n  }\n}\nPOLICY_JSON\n\nlog \"Created machine-readable privacy policy in JSON-LD format\"\n\n# Generate P3P compact policy header configuration for Apache\ncat > \"${WEB_ROOT}/.htaccess.privacy\" << 'P3P_CONFIG'\n# P3P Compact Policy Header\n<IfModule mod_headers.c>\n    Header set P3P \"CP=\\\"NOI DSP COR NID ADMa OPTa OUR NOR\\\"\"\n    Header set X-Privacy-Policy \"/privacy/policy.html\"\n</IfModule>\n\n# Cookie consent requirement\n<IfModule mod_rewrite.c>\n    RewriteEngine On\n    # Redirect to cookie consent if not acknowledged\n    RewriteCond %{HTTP_COOKIE} !cookie_consent=accepted\n    RewriteCond %{REQUEST_URI} !^/privacy/\n    RewriteCond %{REQUEST_URI} !^/cookie-consent\n    # Note: Full implementation would redirect new users to consent page\n</IfModule>\nP3P_CONFIG\n\nlog \"Generated P3P and cookie consent configuration\"\n\n# Check all HTML files for privacy policy links\ncheck_privacy_links() {\n    log \"Checking HTML files for privacy policy links...\"\n    local missing_count=0\n    local checked_count=0\n    \n    while IFS= read -r -d '' file; do\n        checked_count=$((checked_count + 1))\n        if ! grep -qi 'privacy' \"$file\" 2>/dev/null; then\n            log \"WARNING: No privacy link found in: $file\"\n            missing_count=$((missing_count + 1))\n        fi\n    done < <(find \"$WEB_ROOT\" -name \"*.html\" -type f -print0 2>/dev/null)\n    \n    log \"Checked $checked_count HTML files, $missing_count missing privacy links\"\n    return $missing_count\n}\n\n# Validate privacy policy content requirements\nvalidate_policy_content() {\n    local policy_file=\"${PRIVACY_DIR}/policy.html\"\n    local requirements=(\"collect\" \"use\" \"retention\" \"disclosure\" \"rights\" \"contact\")\n    local missing=0\n    \n    if [[ -f \"$policy_file\" ]]; then\n        log \"Validating privacy policy content requirements...\"\n        for req in \"${requirements[@]}\"; do\n            if ! grep -qi \"$req\" \"$policy_file\"; then\n                log \"WARNING: Policy may be missing section on: $req\"\n                missing=$((missing + 1))\n            fi\n        done\n        log \"Policy validation complete: $((${#requirements[@]} - missing))/${#requirements[@]} required elements found\"\n    else\n        log \"WARNING: Privacy policy file not found at $policy_file\"\n        return 1\n    fi\n}\n\n# Check for GDPR cookie consent implementation\ncheck_cookie_consent() {\n    log \"Checking for cookie consent implementation...\"\n    \n    # Check for common cookie consent libraries\n    local consent_found=false\n    local consent_patterns=(\"cookieconsent\" \"gdpr\" \"cookie-notice\" \"CookieConsent\" \"tarteaucitron\")\n    \n    for pattern in \"${consent_patterns[@]}\"; do\n        if grep -rqi \"$pattern\" \"$WEB_ROOT\" --include=\"*.html\" --include=\"*.js\" 2>/dev/null; then\n            log \"Found cookie consent implementation: $pattern\"\n            consent_found=true\n            break\n        fi\n    done\n    \n    if [[ \"$consent_found\" == false ]]; then\n        log \"WARNING: No cookie consent mechanism detected\"\n    fi\n}\n\n# Archive current policy version\narchive_policy() {\n    local policy_file=\"${PRIVACY_DIR}/policy.html\"\n    if [[ -f \"$policy_file\" ]]; then\n        local archive_name=\"policy_${DATE}.html\"\n        cp \"$policy_file\" \"${PRIVACY_DIR}/archive/${archive_name}\"\n        log \"Archived current policy to ${archive_name}\"\n    fi\n}\n\n# Generate compliance report\ngenerate_report() {\n    local report_file=\"${PRIVACY_DIR}/compliance-report-${DATE}.txt\"\n    {\n        echo \"Privacy Policy Compliance Report\"\n        echo \"Generated: $(date)\"\n        echo \"=================================\"\n        echo \"\"\n        echo \"Checks Performed:\"\n        echo \"- Privacy policy links in HTML files\"\n        echo \"- Policy content requirements\"\n        echo \"- Cookie consent implementation\"\n        echo \"- Machine-readable policy availability\"\n        echo \"\"\n        echo \"See $LOG_FILE for detailed results\"\n    } > \"$report_file\"\n    \n    log \"Compliance report generated: $report_file\"\n}\n\n# Main execution\nmain() {\n    archive_policy\n    check_privacy_links || true\n    validate_policy_content || true\n    check_cookie_consent\n    generate_report\n    \n    log \"[PM-20.1] Privacy policy compliance check complete\"\n}\n\nmain \"$@\"",
        "ansible": "---\n# PM-20.1: Privacy Policies on Websites, Applications, and Digital Services\n# Ansible playbook for deploying privacy policy infrastructure\n\n- name: PM-20.1 Privacy Policy Deployment\n  hosts: webservers\n  become: yes\n  vars:\n    privacy_policy_dir: /var/www/html/privacy\n    web_root: /var/www/html\n    organization_name: \"{{ org_name | default('Organization Name') }}\"\n    privacy_contact_email: \"{{ privacy_email | default('privacy@example.com') }}\"\n    policy_effective_date: \"{{ ansible_date_time.date }}\"\n    gdpr_applicable: true\n    ccpa_applicable: true\n\n  tasks:\n    - name: Create privacy policy directory structure\n      file:\n        path: \"{{ item }}\"\n        state: directory\n        mode: '0755'\n        owner: www-data\n        group: www-data\n      loop:\n        - \"{{ privacy_policy_dir }}\"\n        - \"{{ privacy_policy_dir }}/archive\"\n        - \"{{ privacy_policy_dir }}/machine-readable\"\n        - \"{{ privacy_policy_dir }}/translations\"\n\n    - name: Deploy machine-readable privacy policy (JSON-LD)\n      copy:\n        dest: \"{{ privacy_policy_dir }}/machine-readable/privacy-policy.json\"\n        mode: '0644'\n        content: |\n          {\n            \"@context\": \"https://schema.org\",\n            \"@type\": \"PrivacyPolicy\",\n            \"name\": \"Privacy Policy\",\n            \"url\": \"/privacy/policy.html\",\n            \"datePublished\": \"2025-01-01\",\n            \"dateModified\": \"{{ policy_effective_date }}\",\n            \"inLanguage\": \"en-US\",\n            \"publisher\": {\n              \"@type\": \"Organization\",\n              \"name\": \"{{ organization_name }}\",\n              \"email\": \"{{ privacy_contact_email }}\"\n            }\n          }\n\n    - name: Deploy privacy policy HTML template\n      template:\n        src: privacy-policy.html.j2\n        dest: \"{{ privacy_policy_dir }}/policy.html\"\n        mode: '0644'\n        owner: www-data\n        group: www-data\n      notify: Archive previous policy\n\n    - name: Configure Apache P3P headers\n      blockinfile:\n        path: /etc/apache2/conf-available/privacy-headers.conf\n        create: yes\n        mode: '0644'\n        block: |\n          <IfModule mod_headers.c>\n              # P3P Compact Policy\n              Header set P3P \"CP=\\\"NOI DSP COR NID ADMa OPTa OUR NOR\\\"\"\n              # Privacy Policy Link\n              Header set X-Privacy-Policy \"/privacy/policy.html\"\n              # DNT Support\n              Header set Tk \"N\"\n          </IfModule>\n      when: ansible_os_family == 'Debian'\n      notify: Enable privacy headers\n\n    - name: Deploy cookie consent JavaScript\n      copy:\n        dest: \"{{ web_root }}/js/cookie-consent.js\"\n        mode: '0644'\n        content: |\n          // PM-20.1 Cookie Consent Implementation\n          (function() {\n            'use strict';\n            \n            var CONSENT_COOKIE = 'privacy_consent';\n            var CONSENT_DURATION = 365; // days\n            \n            function getCookie(name) {\n              var match = document.cookie.match(new RegExp('(^| )' + name + '=([^;]+)'));\n              return match ? match[2] : null;\n            }\n            \n            function setCookie(name, value, days) {\n              var expires = new Date();\n              expires.setTime(expires.getTime() + (days * 24 * 60 * 60 * 1000));\n              document.cookie = name + '=' + value + ';expires=' + expires.toUTCString() + ';path=/;SameSite=Lax';\n            }\n            \n            function showConsentBanner() {\n              var banner = document.createElement('div');\n              banner.id = 'cookie-consent-banner';\n              banner.innerHTML = '<div style=\"position:fixed;bottom:0;left:0;right:0;background:#333;color:#fff;padding:15px;z-index:9999;\">' +\n                '<p>We use cookies to improve your experience. By continuing to use this site, you consent to our use of cookies. ' +\n                '<a href=\"/privacy/policy.html\" style=\"color:#4CAF50;\">Privacy Policy</a></p>' +\n                '<button onclick=\"acceptCookies()\" style=\"background:#4CAF50;color:#fff;padding:10px 20px;border:none;cursor:pointer;margin-right:10px;\">Accept All</button>' +\n                '<button onclick=\"rejectCookies()\" style=\"background:#666;color:#fff;padding:10px 20px;border:none;cursor:pointer;\">Reject Non-Essential</button>' +\n                '</div>';\n              document.body.appendChild(banner);\n            }\n            \n            window.acceptCookies = function() {\n              setCookie(CONSENT_COOKIE, 'all', CONSENT_DURATION);\n              document.getElementById('cookie-consent-banner').remove();\n            };\n            \n            window.rejectCookies = function() {\n              setCookie(CONSENT_COOKIE, 'essential', CONSENT_DURATION);\n              document.getElementById('cookie-consent-banner').remove();\n            };\n            \n            // Check consent on page load\n            if (!getCookie(CONSENT_COOKIE)) {\n              if (document.readyState === 'complete') {\n                showConsentBanner();\n              } else {\n                window.addEventListener('load', showConsentBanner);\n              }\n            }\n          })();\n\n    - name: Check privacy policy links in HTML files\n      shell: |\n        find {{ web_root }} -name '*.html' -type f -exec grep -L -i 'privacy' {} \\;\n      register: missing_privacy_links\n      changed_when: false\n      failed_when: false\n\n    - name: Report files missing privacy links\n      debug:\n        msg: \"WARNING: The following files may be missing privacy policy links: {{ missing_privacy_links.stdout_lines }}\"\n      when: missing_privacy_links.stdout_lines | length > 0\n\n    - name: Create compliance audit log\n      lineinfile:\n        path: /var/log/privacy-compliance.log\n        line: \"{{ ansible_date_time.iso8601 }} - PM-20.1 privacy policy deployment completed on {{ inventory_hostname }}\"\n        create: yes\n        mode: '0640'\n\n  handlers:\n    - name: Archive previous policy\n      copy:\n        src: \"{{ privacy_policy_dir }}/policy.html\"\n        dest: \"{{ privacy_policy_dir }}/archive/policy_{{ ansible_date_time.date }}.html\"\n        remote_src: yes\n      ignore_errors: yes\n\n    - name: Enable privacy headers\n      command: a2enconf privacy-headers\n      notify: Reload Apache\n\n    - name: Reload Apache\n      service:\n        name: apache2\n        state: reloaded"
      },
      "windows": {
        "powershell": "# PM-20.1: Privacy Policies on Websites, Applications, and Digital Services\n# PowerShell script for IIS privacy policy deployment and compliance checking\n\n#Requires -RunAsAdministrator\n#Requires -Version 5.1\n\nparam(\n    [string]$WebRoot = \"C:\\inetpub\\wwwroot\",\n    [string]$SiteName = \"Default Web Site\",\n    [string]$OrganizationName = \"Organization Name\",\n    [string]$PrivacyEmail = \"privacy@example.com\"\n)\n\n$ErrorActionPreference = \"Stop\"\n$LogFile = \"C:\\Logs\\PrivacyPolicy\\compliance-$(Get-Date -Format 'yyyy-MM-dd').log\"\n$PrivacyDir = Join-Path $WebRoot \"privacy\"\n$Date = Get-Date -Format \"yyyy-MM-dd\"\n\n# Ensure log directory exists\n$LogDir = Split-Path $LogFile -Parent\nif (-not (Test-Path $LogDir)) {\n    New-Item -ItemType Directory -Path $LogDir -Force | Out-Null\n}\n\nfunction Write-Log {\n    param([string]$Message)\n    $Timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    $LogMessage = \"[$Timestamp] $Message\"\n    Add-Content -Path $LogFile -Value $LogMessage\n    Write-Host $LogMessage\n}\n\nfunction Initialize-PrivacyDirectories {\n    Write-Log \"[PM-20.1] Initializing privacy policy directory structure\"\n    \n    $Directories = @(\n        $PrivacyDir,\n        (Join-Path $PrivacyDir \"archive\"),\n        (Join-Path $PrivacyDir \"machine-readable\"),\n        (Join-Path $PrivacyDir \"translations\")\n    )\n    \n    foreach ($Dir in $Directories) {\n        if (-not (Test-Path $Dir)) {\n            New-Item -ItemType Directory -Path $Dir -Force | Out-Null\n            Write-Log \"Created directory: $Dir\"\n        }\n    }\n}\n\nfunction Deploy-MachineReadablePolicy {\n    Write-Log \"Deploying machine-readable privacy policy (JSON-LD)\"\n    \n    $PolicyJson = @{\n        '@context' = 'https://schema.org'\n        '@type' = 'PrivacyPolicy'\n        'name' = 'Privacy Policy'\n        'url' = '/privacy/policy.html'\n        'datePublished' = '2025-01-01'\n        'dateModified' = $Date\n        'inLanguage' = 'en-US'\n        'publisher' = @{\n            '@type' = 'Organization'\n            'name' = $OrganizationName\n            'email' = $PrivacyEmail\n        }\n    }\n    \n    $JsonPath = Join-Path $PrivacyDir \"machine-readable\\privacy-policy.json\"\n    $PolicyJson | ConvertTo-Json -Depth 10 | Set-Content -Path $JsonPath -Encoding UTF8\n    Write-Log \"Machine-readable policy deployed to: $JsonPath\"\n}\n\nfunction Set-IISPrivacyHeaders {\n    Write-Log \"Configuring IIS privacy headers\"\n    \n    Import-Module WebAdministration -ErrorAction SilentlyContinue\n    \n    # Add P3P header\n    try {\n        $P3PValue = 'CP=\"NOI DSP COR NID ADMa OPTa OUR NOR\"'\n        Set-WebConfigurationProperty -PSPath \"IIS:\\Sites\\$SiteName\" `\n            -Filter \"system.webServer/httpProtocol/customHeaders\" `\n            -Name \".\" `\n            -Value @{name='P3P';value=$P3PValue} `\n            -ErrorAction SilentlyContinue\n        Write-Log \"P3P header configured\"\n    } catch {\n        Write-Log \"WARNING: Could not set P3P header - $($_.Exception.Message)\"\n    }\n    \n    # Add privacy policy link header\n    try {\n        Set-WebConfigurationProperty -PSPath \"IIS:\\Sites\\$SiteName\" `\n            -Filter \"system.webServer/httpProtocol/customHeaders\" `\n            -Name \".\" `\n            -Value @{name='X-Privacy-Policy';value='/privacy/policy.html'} `\n            -ErrorAction SilentlyContinue\n        Write-Log \"X-Privacy-Policy header configured\"\n    } catch {\n        Write-Log \"WARNING: Could not set X-Privacy-Policy header - $($_.Exception.Message)\"\n    }\n}\n\nfunction Deploy-CookieConsentScript {\n    Write-Log \"Deploying cookie consent JavaScript\"\n    \n    $JsDir = Join-Path $WebRoot \"js\"\n    if (-not (Test-Path $JsDir)) {\n        New-Item -ItemType Directory -Path $JsDir -Force | Out-Null\n    }\n    \n    $CookieConsentJs = @'\n// PM-20.1 Cookie Consent Implementation\n(function() {\n    'use strict';\n    \n    var CONSENT_COOKIE = 'privacy_consent';\n    var CONSENT_DURATION = 365; // days\n    \n    function getCookie(name) {\n        var match = document.cookie.match(new RegExp('(^| )' + name + '=([^;]+)'));\n        return match ? match[2] : null;\n    }\n    \n    function setCookie(name, value, days) {\n        var expires = new Date();\n        expires.setTime(expires.getTime() + (days * 24 * 60 * 60 * 1000));\n        var secure = location.protocol === 'https:' ? ';Secure' : '';\n        document.cookie = name + '=' + value + ';expires=' + expires.toUTCString() + ';path=/;SameSite=Lax' + secure;\n    }\n    \n    function showConsentBanner() {\n        var banner = document.createElement('div');\n        banner.id = 'cookie-consent-banner';\n        banner.setAttribute('role', 'alertdialog');\n        banner.setAttribute('aria-labelledby', 'consent-title');\n        banner.innerHTML = \n            '<div style=\"position:fixed;bottom:0;left:0;right:0;background:#2c3e50;color:#fff;padding:20px;z-index:9999;box-shadow:0 -2px 10px rgba(0,0,0,0.3);\">' +\n            '<h3 id=\"consent-title\" style=\"margin:0 0 10px 0;\">Cookie Consent</h3>' +\n            '<p style=\"margin:0 0 15px 0;\">We use cookies to enhance your experience. By continuing to use this site, you consent to our use of cookies in accordance with our ' +\n            '<a href=\"/privacy/policy.html\" style=\"color:#3498db;text-decoration:underline;\">Privacy Policy</a>.</p>' +\n            '<div>' +\n            '<button onclick=\"window.acceptAllCookies()\" style=\"background:#27ae60;color:#fff;padding:10px 25px;border:none;cursor:pointer;margin-right:10px;border-radius:4px;\">Accept All</button>' +\n            '<button onclick=\"window.acceptEssentialOnly()\" style=\"background:#7f8c8d;color:#fff;padding:10px 25px;border:none;cursor:pointer;margin-right:10px;border-radius:4px;\">Essential Only</button>' +\n            '<button onclick=\"window.openCookieSettings()\" style=\"background:transparent;color:#3498db;padding:10px 25px;border:1px solid #3498db;cursor:pointer;border-radius:4px;\">Cookie Settings</button>' +\n            '</div></div>';\n        document.body.appendChild(banner);\n    }\n    \n    window.acceptAllCookies = function() {\n        setCookie(CONSENT_COOKIE, JSON.stringify({essential:true,analytics:true,marketing:true,timestamp:Date.now()}), CONSENT_DURATION);\n        closeBanner();\n    };\n    \n    window.acceptEssentialOnly = function() {\n        setCookie(CONSENT_COOKIE, JSON.stringify({essential:true,analytics:false,marketing:false,timestamp:Date.now()}), CONSENT_DURATION);\n        closeBanner();\n    };\n    \n    window.openCookieSettings = function() {\n        window.location.href = '/privacy/cookie-settings.html';\n    };\n    \n    function closeBanner() {\n        var banner = document.getElementById('cookie-consent-banner');\n        if (banner) banner.remove();\n    }\n    \n    // Initialize on page load\n    if (!getCookie(CONSENT_COOKIE)) {\n        if (document.readyState === 'complete') {\n            showConsentBanner();\n        } else {\n            window.addEventListener('load', showConsentBanner);\n        }\n    }\n})();\n'@\n    \n    $JsPath = Join-Path $JsDir \"cookie-consent.js\"\n    Set-Content -Path $JsPath -Value $CookieConsentJs -Encoding UTF8\n    Write-Log \"Cookie consent script deployed to: $JsPath\"\n}\n\nfunction Test-PrivacyLinks {\n    Write-Log \"Checking HTML files for privacy policy links\"\n    \n    $HtmlFiles = Get-ChildItem -Path $WebRoot -Filter \"*.html\" -Recurse -File\n    $MissingLinks = @()\n    \n    foreach ($File in $HtmlFiles) {\n        $Content = Get-Content -Path $File.FullName -Raw -ErrorAction SilentlyContinue\n        if ($Content -and $Content -notmatch 'privacy') {\n            $MissingLinks += $File.FullName\n        }\n    }\n    \n    if ($MissingLinks.Count -gt 0) {\n        Write-Log \"WARNING: $($MissingLinks.Count) files may be missing privacy links:\"\n        foreach ($File in $MissingLinks) {\n            Write-Log \"  - $File\"\n        }\n    } else {\n        Write-Log \"All HTML files contain privacy references\"\n    }\n    \n    return $MissingLinks\n}\n\nfunction Test-PolicyContent {\n    Write-Log \"Validating privacy policy content requirements\"\n    \n    $PolicyFile = Join-Path $PrivacyDir \"policy.html\"\n    $Requirements = @(\n        @{Name='Data Collection'; Pattern='collect'},\n        @{Name='Data Use'; Pattern='use|purpose'},\n        @{Name='Data Retention'; Pattern='retain|retention|storage'},\n        @{Name='Data Disclosure'; Pattern='disclos|share|third.party'},\n        @{Name='User Rights'; Pattern='rights|access|correct|delete'},\n        @{Name='Contact Information'; Pattern='contact|email'}\n    )\n    \n    if (Test-Path $PolicyFile) {\n        $Content = Get-Content -Path $PolicyFile -Raw\n        $Missing = @()\n        \n        foreach ($Req in $Requirements) {\n            if ($Content -notmatch $Req.Pattern) {\n                $Missing += $Req.Name\n            }\n        }\n        \n        if ($Missing.Count -gt 0) {\n            Write-Log \"WARNING: Policy may be missing required sections: $($Missing -join ', ')\"\n        } else {\n            Write-Log \"All required policy sections detected\"\n        }\n    } else {\n        Write-Log \"WARNING: Privacy policy file not found at: $PolicyFile\"\n    }\n}\n\nfunction Backup-CurrentPolicy {\n    $PolicyFile = Join-Path $PrivacyDir \"policy.html\"\n    if (Test-Path $PolicyFile) {\n        $ArchiveDir = Join-Path $PrivacyDir \"archive\"\n        $ArchiveName = \"policy_$Date.html\"\n        $ArchivePath = Join-Path $ArchiveDir $ArchiveName\n        Copy-Item -Path $PolicyFile -Destination $ArchivePath -Force\n        Write-Log \"Archived current policy to: $ArchivePath\"\n    }\n}\n\nfunction New-ComplianceReport {\n    Write-Log \"Generating compliance report\"\n    \n    $Report = @\"\nPM-20.1 Privacy Policy Compliance Report\n==========================================\nGenerated: $(Get-Date)\nWeb Root: $WebRoot\nSite Name: $SiteName\n\nChecks Performed:\n- Directory structure initialization\n- Machine-readable policy deployment (JSON-LD)\n- IIS privacy headers configuration\n- Cookie consent script deployment\n- Privacy link presence in HTML files\n- Policy content validation\n\nDetailed Results:\nSee log file: $LogFile\n\nRecommendations:\n1. Ensure all HTML pages include the cookie consent script\n2. Review privacy policy quarterly for accuracy\n3. Update policy when data practices change\n4. Test cookie consent functionality across browsers\n5. Validate machine-readable policy with schema.org validator\n\"@\n    \n    $ReportPath = Join-Path $PrivacyDir \"compliance-report-$Date.txt\"\n    Set-Content -Path $ReportPath -Value $Report -Encoding UTF8\n    Write-Log \"Compliance report saved to: $ReportPath\"\n}\n\n# Main execution\ntry {\n    Write-Log \"========================================\"\n    Write-Log \"[PM-20.1] Privacy Policy Deployment Starting\"\n    Write-Log \"========================================\"\n    \n    Initialize-PrivacyDirectories\n    Backup-CurrentPolicy\n    Deploy-MachineReadablePolicy\n    Set-IISPrivacyHeaders\n    Deploy-CookieConsentScript\n    Test-PrivacyLinks\n    Test-PolicyContent\n    New-ComplianceReport\n    \n    Write-Log \"========================================\"\n    Write-Log \"[PM-20.1] Privacy Policy Deployment Complete\"\n    Write-Log \"========================================\"\n    \n} catch {\n    Write-Log \"ERROR: $($_.Exception.Message)\"\n    throw\n}"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": true
    }
  },
  {
    "control_id": "PM-21",
    "control_name": "Accounting of Disclosures",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "a. Develop and maintain an accurate accounting of disclosures of personally identifiable information, including: 1. Date, nature, and purpose of each disclosure of a record; and 2. Name and address of the person or organization to which the disclosure was made; b. Retain the accounting of disclosures for the life of the record or five years after the disclosure is made, whichever is longer; and c. Make the accounting of disclosures available to the person named in the record upon request.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Maintain comprehensive records of when, why, and to whom personally identifiable information has been disclosed, ensuring individuals can access this information upon request.",
    "rationale": "Individuals have a fundamental right to know who has accessed their personal information and why. An accounting of disclosures creates accountability for data sharing, deters unauthorized disclosures, enables investigation of suspected privacy violations, and fulfills legal requirements under the Privacy Act. Without such records, organizations cannot demonstrate compliance with data sharing restrictions or respond to individual inquiries about how their information has been used.",
    "plain_english_explanation": "This control requires organizations to keep detailed records every time they share someone's personal information with another person or organization. The records must include when the disclosure happened, why, and who received the information. These records must be kept for a long time (at least five years or as long as the original record exists) and must be made available to the person whose information was shared if they ask for it.",
    "ai_guidance": "Implementing PM-21 requires establishing robust record-keeping processes for all PII disclosures. Start by defining what constitutes a 'disclosure' in your organizational context - this typically includes sharing PII with external parties, responding to legal requests, data breach notifications, and inter-agency transfers, but may exclude routine uses published in SORNs. Design a disclosure logging system that captures required elements: date and time, nature of disclosure (category of information shared), purpose (legal authority or business justification), and recipient details (name, organization, address, contact). The logging system should be tamper-evident and support audit trails. Integrate disclosure logging into business processes where PII sharing occurs - this may require workflow modifications for customer service, legal, HR, and IT operations. Establish retention schedules that meet the 'life of record or five years' requirement, with automated archival and deletion processes. Create procedures for handling individual access requests, including identity verification, search methodology, response timelines, and fee structures (if permitted). Train staff who handle PII on disclosure logging requirements and the consequences of non-compliance. Implement quality controls to ensure logging accuracy and completeness. Consider exceptions for disclosures to law enforcement where logging might compromise investigations - document your approach to handling these situations. Regular audits should verify that disclosed information matches logged disclosures. The accounting should be stored securely to prevent unauthorized access to sensitive relationship information.",
    "enhancements": [],
    "related_controls": [
      "AR-8",
      "IP-2",
      "IP-3",
      "TR-1",
      "TR-2",
      "TR-3"
    ],
    "supplemental_guidance": "The accounting of disclosures provides transparency to individuals about how their information has been shared and supports organizational accountability for data handling practices.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-22",
    "control_name": "Personally Identifiable Information Quality Management",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Develop and document organization-wide policies and procedures for: a. Reviewing for the accuracy, relevance, timeliness, and completeness of personally identifiable information across the information life cycle; b. Correcting or deleting inaccurate or outdated personally identifiable information; c. Disseminating notice of corrected information to other authorized users of the personally identifiable information, such as external information-sharing partners; and d. Appeals of adverse decisions on correction requests.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Ensure that personally identifiable information maintained by the organization is accurate, relevant, timely, and complete throughout its lifecycle, with procedures for correction and notification.",
    "rationale": "Poor data quality can lead to incorrect decisions about individuals, causing harm to their reputation, employment, benefits, or rights. Organizations have an ethical and often legal obligation to maintain accurate personal information. Quality management processes help prevent adverse actions based on erroneous data, reduce costs associated with data errors, maintain public trust, and fulfill Privacy Act requirements for data accuracy. An appeals process ensures due process when correction requests are denied.",
    "plain_english_explanation": "This control requires organizations to have policies ensuring that personal information is accurate, up-to-date, and relevant for its intended purpose. There must be procedures for reviewing data quality, fixing or removing bad data, telling others who received the information about corrections, and allowing individuals to appeal if their correction request is denied. This prevents people from being harmed by decisions made based on incorrect personal information.",
    "ai_guidance": "Implementing PM-22 requires a comprehensive data quality management framework for PII. Begin by defining quality dimensions: accuracy (information correctly represents reality), relevance (information serves its intended purpose), timeliness (information reflects current status), and completeness (all necessary information is present). Establish policies that define quality standards for different data categories based on risk - information used for high-impact decisions (employment, benefits, security clearances) requires stricter quality controls. Create review procedures including: initial quality validation at data collection, periodic reviews during retention, event-triggered reviews (when information is used for decisions), and pre-disclosure verification. Implement correction procedures that include: request intake (written or electronic), identity verification, research and determination, processing timelines (30 days is standard), and documentation requirements. For dispute resolution, establish a formal appeals process with defined escalation paths, review criteria, and response timelines. When corrections are made, develop procedures to notify downstream recipients of the corrected information - this requires maintaining disclosure logs (see PM-21) and having contact information for data sharing partners. Consider implementing data quality dashboards and metrics to track accuracy rates, correction volumes, and processing times. Train staff who handle PII on quality requirements and correction procedures. Document audit trails for all quality reviews and corrections. Address special considerations for information from external sources where the organization may not have authority to correct source records.",
    "enhancements": [],
    "related_controls": [
      "DI-1",
      "DI-2",
      "IP-3",
      "SI-18"
    ],
    "supplemental_guidance": "PII quality management is essential for ensuring fair treatment of individuals and maintaining the integrity of organizational processes that rely on personal information.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-23",
    "control_name": "Data Governance Body",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Establish a Data Governance Body consisting of [Assignment: organization-defined members] with [Assignment: organization-defined roles and responsibilities].",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Create a cross-functional governance structure with clear authority and accountability for organizational data management, including privacy, security, quality, and lifecycle decisions.",
    "rationale": "Effective data governance requires coordinated decision-making across multiple organizational functions including IT, legal, privacy, security, business operations, and executive leadership. A dedicated governance body ensures that data-related policies are consistent, data assets are properly managed, privacy and security requirements are balanced with business needs, and there is clear accountability for data management decisions. Without such coordination, organizations face conflicting policies, data silos, compliance gaps, and inefficient data utilization.",
    "plain_english_explanation": "This control requires organizations to establish a formal committee or board responsible for making decisions about how data is managed across the organization. This body should include representatives from different departments (IT, legal, privacy, security, business units) who together set policies, resolve conflicts, ensure compliance, and provide strategic direction for data management. The governance body has defined membership and clear responsibilities.",
    "ai_guidance": "Implementing PM-23 requires thoughtful design of governance structure, membership, and operating procedures. Define the governance body's scope - will it cover all organizational data or focus on specific categories (PII, CUI, intellectual property)? Determine the appropriate organizational level - enterprise-wide data governance typically requires executive sponsorship and may include a strategic body (policy-setting) and operational body (implementation). Select members representing key stakeholders: Chief Data Officer (if exists), CISO, Chief Privacy Officer, General Counsel, IT leadership, business unit representatives, records management, and compliance. Define roles clearly: chair/co-chair responsibilities, voting vs. advisory members, quorum requirements, and decision escalation paths. Establish the body's authority: what decisions it can make autonomously vs. what requires higher approval, budget authority, and enforcement mechanisms. Create a charter documenting: mission, scope, membership criteria, meeting frequency, decision-making processes, and relationship to other governance bodies. Develop standard operating procedures for: agenda setting, issue escalation, policy development and approval, exception handling, and performance reporting. Define metrics to measure governance effectiveness: policy compliance rates, issue resolution times, data quality improvements. Ensure the governance body has administrative support for scheduling, documentation, and action item tracking. Plan for member rotation to bring fresh perspectives while maintaining institutional knowledge. Document meeting minutes and decisions for accountability and audit purposes. The governance body should regularly assess its own effectiveness and adjust structure as organizational needs evolve.",
    "enhancements": [],
    "related_controls": [
      "PM-19",
      "PM-24",
      "PM-22",
      "AC-1",
      "PL-1"
    ],
    "supplemental_guidance": "The data governance body provides a forum for resolving conflicts between competing data requirements and ensuring consistent application of data management policies across the organization.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-24",
    "control_name": "Data Integrity Board",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Establish a Data Integrity Board to: a. Review proposals to conduct or participate in a matching program; and b. Conduct an annual review of all matching programs in which the agency has participated.",
    "source": "NIST SP 800-53 Rev 5",
    "is_technical": false,
    "stig_id": null,
    "intent": "Provide independent oversight of computer matching programs to ensure they comply with legal requirements, protect individual privacy rights, and are conducted only when benefits outweigh privacy risks.",
    "rationale": "Computer matching programs - comparing records from different systems to identify individuals - pose significant privacy risks including function creep, inaccurate matches, and use of data for purposes beyond original collection. The Computer Matching and Privacy Protection Act requires federal agencies to establish Data Integrity Boards to review matching programs before they begin and annually thereafter. This oversight ensures matching is conducted lawfully, that privacy protections are in place, and that the program's costs and benefits are properly weighed. Even non-federal organizations benefit from similar oversight when conducting large-scale data matching.",
    "plain_english_explanation": "This control requires organizations (particularly federal agencies) to establish a board that reviews and approves any program where personal information from different databases is compared to find matches (like matching tax records with benefits records to detect fraud). The board reviews new matching proposals before they start and conducts annual reviews of ongoing programs to ensure they remain necessary, lawful, and protective of privacy rights.",
    "ai_guidance": "Implementing PM-24 requires establishing a Data Integrity Board with appropriate membership, authority, and operating procedures aligned with the Computer Matching and Privacy Protection Act (for federal agencies) or organizational policy. The board should include the Inspector General (or equivalent), Senior Agency Official for Privacy, and other senior officials with relevant expertise (legal, IT, program operations). Define the board's scope: all matching programs involving federal records, or broader coverage including analytics and data sharing arrangements that involve record comparison. Establish review procedures for new matching programs including: written matching agreement requirements, cost-benefit analysis, privacy impact assessment, accuracy and data quality verification, notice requirements, and disposition of matched records. Create templates and checklists to ensure consistent, thorough reviews. For new program proposals, the board should evaluate: statutory authority, purpose and necessity, accuracy safeguards, record retention limits, security measures, due process protections, and reporting requirements. Develop annual review procedures that assess: program effectiveness, continued necessity, compliance with matching agreement terms, accuracy of matches, and any privacy incidents. Establish documentation requirements: meeting minutes, approval/disapproval decisions with rationale, conditions imposed, and follow-up actions. Create reporting mechanisms to inform Congress (for federal agencies) and organizational leadership of matching activities. Train board members on Privacy Act requirements, matching program regulations, and privacy risk assessment. Consider using a matching program inventory to track all active and proposed programs.",
    "enhancements": [],
    "related_controls": [
      "PM-23",
      "PM-21",
      "AR-1",
      "AR-2",
      "DI-1"
    ],
    "supplemental_guidance": "The Data Integrity Board serves as a check on the use of computer matching, ensuring that efficiency gains from matching do not come at unacceptable privacy costs and that all legal requirements are met.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-25",
    "control_name": "Minimization of Personally Identifiable Information Used in Testing, Training, and Research",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Develop policies and procedures that address the use of personally identifiable information for internal testing, training, and research; Design and implement controls to minimize the use of personally identifiable information for internal testing, training, and research; and Limit or minimize the use of personally identifiable information in testing, training, and research activities.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "is_technical": false,
    "stig_id": null,
    "intent": "Protect individual privacy by minimizing the use of real personal data in non-production environments where such data faces elevated risk of exposure or misuse.",
    "rationale": "Testing, training, and research environments typically have weaker security controls than production systems and are accessed by more personnel including contractors and developers. Using real PII in these environments dramatically increases the attack surface for privacy breaches. Data minimization reduces both the likelihood and impact of privacy incidents, supports regulatory compliance with GDPR, CCPA, and HIPAA, and demonstrates organizational commitment to privacy by design principles.",
    "plain_english_explanation": "This control requires organizations to minimize the use of real personal information when testing systems, training employees, or conducting research. Instead of using actual customer or employee data, organizations should use synthetic (fake) data, anonymized data, or the absolute minimum amount of real data necessary. This protects individuals from having their personal information exposed in environments that are typically less secure than production systems.",
    "example_implementation": "Implement data masking and synthetic data generation tools to create realistic but fake datasets for development and testing. Establish a formal approval process requiring justification for any use of real PII in non-production environments.",
    "non_technical_guidance": "To comply with PM-25, organizations should: 1) Create a formal policy prohibiting use of real PII in testing/training unless explicitly approved with documented justification; 2) Inventory all test and training environments and audit them for PII presence; 3) Deploy data masking or synthetic data generation capabilities; 4) Train developers and testers on privacy-preserving alternatives to real data; 5) Establish periodic audits of non-production environments for unauthorized PII; 6) Require privacy impact assessments before any project uses real PII in testing; 7) Implement data minimization as a default in system development lifecycles.",
    "ai_guidance": "When implementing PM-25 PII minimization controls, security teams should adopt a comprehensive data protection strategy for non-production environments. Begin by conducting a thorough inventory of all testing, training, and research environments to identify where PII currently exists. Implement automated data discovery tools that can scan databases, file shares, and application data stores to detect PII patterns such as SSNs, credit card numbers, email addresses, and other identifiers. Deploy data masking solutions that can deterministically transform PII while preserving referential integrity across related datasets - this ensures test data remains functionally valid while protecting actual identities. Consider synthetic data generation platforms that create statistically similar datasets without any connection to real individuals. Establish governance processes requiring formal approval and documentation for any exception where real PII must be used, including time-limited authorizations with mandatory data destruction afterward. Monitor compliance through regular automated scans and manual audits. Integrate PII detection into CI/CD pipelines to prevent accidental deployment of real data to test environments. Train all personnel with access to non-production systems on data handling requirements and the risks of PII exposure. Document all data flows to ensure masked data cannot be re-identified through combination with other sources.",
    "enhancements": [],
    "related_controls": [
      "DM-1",
      "DM-2",
      "DM-3",
      "PT-2",
      "PT-3",
      "SI-12",
      "SA-3",
      "SA-8"
    ],
    "supplemental_guidance": "Organizations should implement technical controls such as data masking, tokenization, and synthetic data generation to create realistic test datasets without using actual PII. When real PII must be used, organizations should apply the minimum necessary standard and implement additional safeguards including encryption, access controls, and audit logging. Test and training data should be refreshed regularly with newly masked or synthetic data rather than maintaining static copies of production data.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-26",
    "control_name": "Complaint Management",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Implement a process for receiving and responding to complaints, concerns, or questions from individuals about the organizational security and privacy practices that includes: (a) Mechanisms that are easy to use and readily accessible by the public; (b) All information necessary for successfully filing complaints; (c) Tracking mechanisms to ensure all complaints are handled and responded to within organization-defined time periods; (d) Acknowledgement of receipt of complaints, concerns, or questions from individuals within organization-defined time periods; and (e) Response to complaints, concerns, or questions from individuals within organization-defined time periods.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "is_technical": false,
    "stig_id": null,
    "intent": "Establish accessible mechanisms for individuals to raise concerns about privacy and security practices, and ensure timely organizational response to maintain trust and accountability.",
    "rationale": "A robust complaint management system is essential for organizational accountability and public trust. Individuals who believe their privacy has been violated or have concerns about security practices need clear channels to voice those concerns. Effective complaint handling demonstrates organizational commitment to privacy, helps identify systemic issues before they escalate, supports regulatory compliance requirements under GDPR, CCPA, and sector-specific regulations, and reduces legal and reputational risk by addressing issues proactively.",
    "plain_english_explanation": "This control requires organizations to have a formal, accessible system for people to submit complaints or ask questions about how the organization handles their personal information and security. The system must be easy to find and use, track all complaints, acknowledge receipt within a set timeframe, and provide substantive responses within defined deadlines. Think of it as a customer service channel specifically for privacy and security concerns.",
    "example_implementation": "Establish a dedicated privacy@organization.com email, a web-based complaint form on the privacy policy page, and a toll-free phone number. Implement a ticketing system to track all complaints with SLAs for acknowledgement (24 hours) and resolution (30 days).",
    "non_technical_guidance": "To comply with PM-26: 1) Designate a privacy official or team responsible for complaint management; 2) Create multiple accessible intake channels (email, web form, phone, mail); 3) Publish clear instructions on how to file complaints on your public website; 4) Implement a tracking system with unique complaint IDs; 5) Define and publish response timeframes; 6) Create standardized acknowledgement templates; 7) Develop escalation procedures for complex complaints; 8) Train staff on complaint handling procedures; 9) Conduct regular reviews of complaint trends to identify systemic issues; 10) Document all complaints and resolutions for audit purposes.",
    "ai_guidance": "Implementing PM-26 complaint management requires establishing a multi-channel intake system that is genuinely accessible to all individuals, including those with disabilities or limited technical capabilities. Organizations should deploy a combination of web forms, email addresses, telephone hotlines, and physical mail options. The web-based complaint form should be prominently linked from privacy policies and easily discoverable through site navigation. Implement a case management or ticketing system that automatically assigns unique tracking numbers, routes complaints to appropriate handlers based on type, and triggers alerts when response deadlines approach. Define clear service level agreements - typically 24-48 hours for acknowledgement and 30-60 days for substantive response, though complex investigations may require longer periods with interim status updates. Train complaint handlers on privacy regulations, organizational policies, and sensitive communication techniques. Establish escalation paths for complaints involving potential breaches, legal threats, or media attention. Create dashboards to track complaint volumes, response times, resolution rates, and common themes. Conduct quarterly reviews of complaint trends to identify systemic issues requiring policy or technical remediation. Maintain comprehensive documentation of all complaints and resolutions to demonstrate compliance during audits. Consider implementing customer satisfaction surveys following complaint resolution to continuously improve the process. Ensure the complaint system itself protects the privacy of complainants and maintains confidentiality of sensitive information disclosed during the complaint process.",
    "enhancements": [],
    "related_controls": [
      "PM-19",
      "PM-20",
      "PM-22",
      "IR-6",
      "IR-7"
    ],
    "supplemental_guidance": "The complaint management process should be integrated with the organization's broader privacy program and incident response capabilities. Complaints may reveal privacy incidents requiring formal breach notification procedures. Organizations should analyze complaint patterns to identify training needs, policy gaps, or systemic issues. Response timeframes should be calibrated to complaint complexity while ensuring timely communication with complainants.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-27",
    "control_name": "Privacy Reporting",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Develop, disseminate, and update reports to the organization-defined oversight body, organization-defined officials, and other organization-defined personnel to demonstrate accountability with specific statutory and regulatory privacy program mandates and to support the privacy governance program and activities.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "is_technical": false,
    "stig_id": null,
    "intent": "Establish systematic privacy reporting to oversight bodies and leadership to demonstrate accountability, ensure transparency, and support effective privacy governance.",
    "rationale": "Privacy reporting is fundamental to organizational accountability and effective governance. Regular reporting to oversight bodies ensures leadership visibility into privacy program effectiveness, supports compliance with statutory mandates such as FISMA, OMB requirements, and sector-specific regulations, enables data-driven decision making for privacy investments, demonstrates due diligence in the event of incidents or litigation, and creates an audit trail of privacy program activities. Without systematic reporting, privacy programs operate in isolation and organizations cannot demonstrate their commitment to protecting personal information.",
    "plain_english_explanation": "This control requires organizations to regularly report on their privacy program activities to leadership, oversight bodies, and relevant personnel. Reports should demonstrate compliance with legal requirements, highlight key privacy metrics and incidents, and provide transparency into how personal information is being protected. Think of it as a regular privacy program status report that shows what is working, what needs improvement, and whether the organization is meeting its legal obligations.",
    "example_implementation": "Develop quarterly privacy reports for the Chief Privacy Officer, annual reports to the Board of Directors, and compliance reports as required by regulatory mandates. Reports should include metrics on complaints received, incidents handled, training completion, and privacy impact assessments conducted.",
    "non_technical_guidance": "To implement PM-27: 1) Identify all statutory and regulatory reporting requirements applicable to your organization; 2) Define internal reporting recipients including executive leadership, board members, and oversight committees; 3) Establish reporting frequency (monthly, quarterly, annually) based on requirements and audience needs; 4) Develop standardized report templates covering key privacy metrics; 5) Automate data collection where possible to ensure accuracy and reduce burden; 6) Include both quantitative metrics and qualitative analysis in reports; 7) Document report distribution and acknowledgement; 8) Archive all reports for audit and historical trend analysis; 9) Review and update reporting requirements annually; 10) Integrate privacy reporting with broader organizational governance and risk reporting.",
    "ai_guidance": "Effective PM-27 privacy reporting implementation requires a structured approach to data collection, analysis, and communication. First, conduct a comprehensive inventory of all statutory and regulatory reporting mandates applicable to your organization - these may include FISMA annual reports, OMB SAOP reports, HIPAA Privacy Rule reports, GDPR DPO reports to supervisory authorities, and state-specific requirements. Map these requirements to a reporting calendar with clear deadlines and responsible parties. Develop a metrics framework that captures both compliance indicators and program effectiveness measures. Key metrics should include: privacy incidents reported and resolved, complaints received and response times, privacy impact assessments conducted, training completion rates, data subject access requests processed, consent management statistics, third-party privacy assessments, and policy compliance audit results. Implement automated data collection from privacy management tools, incident tracking systems, training platforms, and access request management systems to ensure accuracy and reduce manual effort. Design report templates tailored to different audiences - technical details for privacy teams, executive summaries for leadership, and compliance-focused reports for regulators. Include trend analysis showing performance over time and benchmarking against industry standards where available. Build in mechanisms for exception reporting when significant incidents occur outside regular reporting cycles. Establish a report review process ensuring accuracy before dissemination. Maintain a comprehensive archive of all reports with metadata on distribution and acknowledgement. Conduct annual reviews of reporting effectiveness and adjust metrics and frequency based on feedback from report recipients and changes in regulatory requirements.",
    "enhancements": [],
    "related_controls": [
      "PM-18",
      "PM-19",
      "PM-20",
      "AU-6",
      "CA-7",
      "PL-2"
    ],
    "supplemental_guidance": "Privacy reports should be calibrated to their audience. Executive-level reports should focus on strategic risks, program effectiveness, and resource needs. Operational reports should provide actionable insights for privacy practitioners. Regulatory reports must strictly adhere to mandated formats and content requirements. Organizations should leverage existing governance reporting mechanisms to avoid duplication while ensuring privacy-specific content is adequately addressed.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-28",
    "control_name": "Risk Framing",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Risk framing is a precondition to risk assessment and risk response and includes: (a) Assumptions affecting how risk is assessed, responded to, and monitored over time; (b) Constraints affecting risk response and monitoring options; (c) Risk tolerance of the organization, mission/business process, and system; (d) Priorities and trade-offs considered by the organization when responding to risk.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "is_technical": false,
    "stig_id": null,
    "intent": "Establish the organizational context and parameters that shape how security and privacy risks are identified, assessed, and addressed throughout the risk management lifecycle.",
    "rationale": "Risk framing provides the essential foundation for all subsequent risk management activities. Without clearly defined assumptions, constraints, risk tolerance levels, and priorities, risk assessments become inconsistent and risk response decisions become arbitrary. Risk framing ensures that security and privacy decisions align with organizational mission, resource realities, and stakeholder expectations. It enables consistent risk communication across the organization and supports defensible decision-making when accepting, mitigating, transferring, or avoiding risks.",
    "plain_english_explanation": "Risk framing is about setting the ground rules for how your organization thinks about and handles risk. It answers fundamental questions like: What level of risk is acceptable? What constraints limit our response options? What assumptions are we making? What trade-offs are we willing to make? This framework then guides all specific risk assessments and response decisions, ensuring consistency and alignment with organizational priorities.",
    "example_implementation": "Develop a risk framing document approved by executive leadership that defines organizational risk tolerance thresholds (e.g., any risk with potential >$1M impact requires executive approval), documents key assumptions about the threat environment, identifies resource and regulatory constraints, and establishes decision criteria for prioritizing risk responses.",
    "non_technical_guidance": "To implement PM-28: 1) Convene key stakeholders including executive leadership, legal, operations, and security/privacy teams; 2) Document organizational mission and strategic objectives that risk framing must support; 3) Define risk tolerance levels for different impact categories (financial, reputational, regulatory, safety); 4) Identify constraints including budget limitations, regulatory requirements, and technical capabilities; 5) Document assumptions about threat actors, vulnerabilities, and the operating environment; 6) Establish priority rules for competing risks and resource allocation; 7) Define acceptable trade-offs between security, privacy, functionality, and cost; 8) Gain executive approval of the risk framing document; 9) Communicate risk framing parameters to all risk management stakeholders; 10) Review and update risk framing annually or when significant changes occur.",
    "ai_guidance": "Implementing PM-28 risk framing requires careful articulation of organizational context that will govern all downstream risk management activities. Begin by engaging executive leadership to understand and document organizational risk appetite - this should be expressed in concrete terms such as acceptable probability and impact thresholds, not vague statements. Develop risk tolerance matrices that map different risk categories (confidentiality, integrity, availability, privacy, safety, financial, reputational, regulatory compliance) to acceptable and unacceptable ranges. Document key assumptions underlying risk assessments, including threat actor capabilities and intent, vulnerability landscape, effectiveness of existing controls, and reliability of risk data sources. These assumptions should be periodically validated and updated. Identify constraints that limit risk response options including budget limitations, technical debt, regulatory requirements, contractual obligations, workforce skills, and organizational change capacity. Establish clear decision criteria for prioritizing risks when resources are limited - this might include mission criticality weighting, regulatory mandate prioritization, or cost-benefit thresholds. Define acceptable trade-offs explicitly - for example, accepting reduced functionality for enhanced security, or accepting higher residual risk in non-critical systems to focus resources on critical assets. Document escalation thresholds that define when risks must be elevated to senior leadership or the board. Create a communication strategy ensuring all personnel involved in risk management understand and apply the risk framing parameters consistently. Integrate risk framing into procurement decisions, project approvals, and strategic planning processes. Conduct annual reviews of risk framing validity, updating assumptions based on actual incident data, threat intelligence, and organizational changes. Ensure risk framing aligns with enterprise risk management frameworks and supports regulatory compliance requirements.",
    "enhancements": [],
    "related_controls": [
      "PM-9",
      "RA-1",
      "RA-2",
      "RA-3",
      "PM-29"
    ],
    "supplemental_guidance": "Risk framing should be developed with input from across the organization to ensure it reflects diverse perspectives and operational realities. The risk framing process should be iterative, with refinements based on experience applying the framework to actual risk decisions. Organizations should document risk framing decisions to support accountability and enable consistent application over time.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-29",
    "control_name": "Risk Management Program Leadership Roles",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Appoint a Senior Accountable Official for Risk Management to align organizational information security and privacy management processes with strategic, operational, and budgetary planning processes; and Establish a Risk Executive (Function) to view and analyze risk from an organization-wide perspective and ensure that risks are managed consistently across the organization.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "is_technical": false,
    "stig_id": null,
    "intent": "Establish clear organizational accountability for risk management through designated senior leadership roles that align risk decisions with strategic objectives and ensure enterprise-wide risk consistency.",
    "rationale": "Effective risk management requires clear leadership accountability and organizational authority. Without designated senior officials with explicit risk management responsibilities, risk decisions become fragmented, inconsistent, and disconnected from strategic priorities. The Senior Accountable Official ensures risk management is integrated into organizational planning and budgeting. The Risk Executive function provides the enterprise-wide perspective necessary to identify risk aggregation, ensure consistent risk treatment across organizational units, and make informed trade-off decisions when risks compete for limited resources.",
    "plain_english_explanation": "This control requires organizations to designate senior leaders with clear responsibility for risk management. A Senior Accountable Official integrates risk management with the organization's strategic planning, operations, and budget processes. A Risk Executive (or risk executive function, which could be a committee) looks at risk from an organization-wide viewpoint, ensuring risks are handled consistently across all departments and systems rather than in isolated silos.",
    "example_implementation": "Appoint the CISO as Senior Accountable Official for Risk Management with documented authority and responsibilities. Establish a Risk Executive Council comprising CIO, CISO, CPO, CFO, and business unit leaders that meets monthly to review enterprise risk posture and make resource allocation decisions.",
    "non_technical_guidance": "To implement PM-29: 1) Identify and formally appoint a Senior Accountable Official for Risk Management at the executive level; 2) Define and document the authority, responsibilities, and accountability of this role; 3) Establish the Risk Executive function, whether as a single designated executive or a committee structure; 4) Define the Risk Executive function's scope, authority, and decision-making processes; 5) Integrate the Senior Accountable Official role with strategic planning, budget, and governance processes; 6) Establish regular risk review meetings and reporting mechanisms; 7) Document escalation paths from operational risk management to executive risk leadership; 8) Ensure Risk Executive function has visibility into all organizational risk registers and assessments; 9) Define coordination mechanisms between risk leadership and system owners, business units, and project managers; 10) Conduct annual assessment of risk leadership effectiveness.",
    "ai_guidance": "Implementing PM-29 requires careful organizational design to establish effective risk leadership. The Senior Accountable Official for Risk Management should be a senior executive with sufficient authority to influence strategic decisions, budget allocations, and organizational priorities. This role should have direct access to the CEO and board, explicit responsibility for risk management policy and strategy, and accountability for overall risk posture. Document this appointment formally through organizational policies and position descriptions. The Risk Executive function can be structured as a single designated executive or as a committee - larger organizations often benefit from a Risk Executive Council bringing together diverse perspectives including security, privacy, legal, finance, operations, and business units. Define the governance model clearly: decision rights, voting procedures if committee-based, quorum requirements, and documentation standards. Establish regular cadence for enterprise risk reviews - monthly operational reviews with quarterly strategic reviews are common patterns. Create mechanisms for the Risk Executive function to maintain visibility into all significant risks across the organization, including aggregated risk registers, common risk taxonomies, and standardized risk reporting from business units and systems. Define clear criteria for when risks must be escalated to risk leadership versus handled at operational levels. Integrate risk leadership into key organizational processes including strategic planning, capital investment decisions, major project approvals, and third-party risk management. Ensure risk leadership has authority to mandate consistent risk treatment across organizational boundaries and to direct resources to high-priority risk areas. Document all risk leadership decisions and their rationale to support accountability and organizational learning. Conduct periodic assessments of risk leadership effectiveness, including feedback from business units on risk guidance quality and timeliness of risk decisions.",
    "enhancements": [],
    "related_controls": [
      "PM-2",
      "PM-9",
      "PM-28",
      "RA-1",
      "CA-1",
      "PL-1"
    ],
    "supplemental_guidance": "The Senior Accountable Official for Risk Management and Risk Executive function should complement, not replace, system-level risk management responsibilities. These roles provide enterprise oversight and integration while system owners retain accountability for managing risks within their systems. Organizations should clearly define the relationship between enterprise risk leadership and operational risk management to avoid confusion or gaps in accountability.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-30",
    "control_name": "Supply Chain Risk Management Strategy",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Develop an organization-wide strategy for managing supply chain risks associated with the development, acquisition, maintenance, and disposal of systems, system components, and system services.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "is_technical": false,
    "stig_id": null,
    "intent": "Establish comprehensive organizational strategy to identify, assess, and mitigate risks introduced through the technology supply chain throughout the system lifecycle.",
    "rationale": "Modern organizations depend heavily on external suppliers for hardware, software, and services. This supply chain introduces significant security risks including counterfeit components, malicious code insertion, vendor security breaches, and single points of failure. Nation-state actors increasingly target supply chains as an efficient attack vector. A comprehensive supply chain risk management strategy is essential to identify critical dependencies, assess supplier security postures, implement appropriate safeguards, and ensure organizational resilience against supply chain attacks. Recent incidents including SolarWinds and hardware supply chain compromises demonstrate the critical importance of SCRM.",
    "plain_english_explanation": "This control requires organizations to develop a strategy for managing security risks that come from their technology supply chain - the companies that provide hardware, software, and services. The strategy should cover the entire lifecycle from purchasing through disposal and address risks like receiving compromised components, vulnerabilities in vendor products, and dependency on unreliable suppliers.",
    "example_implementation": "Develop and publish an enterprise Supply Chain Risk Management Strategy document that defines risk assessment requirements for vendors, establishes security clauses for contracts, mandates software composition analysis for acquired software, requires vendor security questionnaires, and defines acceptable supplier risk tolerance levels.",
    "non_technical_guidance": "To implement PM-30: 1) Inventory all technology suppliers and dependencies; 2) Categorize suppliers by criticality to operations and access to sensitive data/systems; 3) Define supplier security assessment requirements based on criticality; 4) Develop standard security requirements for procurement contracts; 5) Establish vendor security questionnaire and assessment processes; 6) Define acceptable supplier risk tolerance levels; 7) Implement ongoing supplier monitoring processes; 8) Develop contingency plans for critical supplier failures; 9) Establish processes for secure disposal of supplier-provided components; 10) Integrate SCRM into enterprise risk management and governance processes; 11) Train procurement and contract personnel on SCRM requirements; 12) Conduct periodic reviews of supply chain risk posture.",
    "ai_guidance": "Implementing PM-30 supply chain risk management strategy requires a multi-faceted approach addressing risks throughout the technology supply chain. Begin by conducting a comprehensive inventory of all suppliers providing hardware, software, cloud services, managed services, and professional services that interact with organizational systems or data. Categorize suppliers using a risk tiering approach based on criticality to mission operations, access to sensitive data, network connectivity, and replaceability. Develop differentiated security assessment requirements for each tier - critical suppliers warrant detailed security audits while lower-tier suppliers may only require questionnaire-based assessments. Establish minimum security requirements for suppliers including security certifications (SOC 2, ISO 27001, FedRAMP), incident notification requirements, right-to-audit clauses, and vulnerability management expectations. Create standard security language for procurement contracts that addresses data protection, breach notification, subcontractor management, and compliance with applicable regulations. Implement software composition analysis to identify third-party components and associated vulnerabilities in acquired software. Develop processes for validating hardware authenticity and integrity, particularly for critical components. Establish ongoing supplier monitoring including watching for security incidents, financial stability indicators, and regulatory actions. Create business continuity plans addressing critical supplier failures including identification of alternative suppliers and transition procedures. Define secure disposal requirements for supplier-provided components containing sensitive data or configurations. Integrate supply chain risk assessment into capital investment and procurement approval processes. Establish supplier risk acceptance procedures requiring appropriate executive approval for accepting elevated supplier risks. Conduct periodic enterprise-wide assessments of supply chain risk posture and report findings to risk leadership.",
    "enhancements": [
      {
        "id": "PM-30.1",
        "title": "Suppliers of Critical or Mission-essential Items",
        "official_text": "Identify, prioritize, and assess suppliers of critical or mission-essential technologies, products, and services."
      }
    ],
    "related_controls": [
      "PM-30.1",
      "SA-9",
      "SA-12",
      "SR-1",
      "SR-2",
      "SR-3",
      "SR-5",
      "SR-6",
      "RA-3"
    ],
    "supplemental_guidance": "The supply chain risk management strategy should align with organizational risk tolerance and be integrated with enterprise risk management processes. Organizations should consider supply chain risks from both cyber and non-cyber perspectives, including geopolitical risks, natural disasters, and economic factors that could impact supplier availability or reliability. The strategy should address both first-tier suppliers and critical sub-suppliers.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-30.1",
    "control_name": "Suppliers of Critical or Mission-essential Items",
    "family": "Program Management",
    "family_id": "PM",
    "parent_control": "PM-30",
    "official_text": "Identify, prioritize, and assess suppliers of critical or mission-essential technologies, products, and services.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "is_technical": true,
    "stig_id": null,
    "intent": "Ensure heightened scrutiny and risk assessment for suppliers providing technologies, products, and services that are critical to organizational mission success.",
    "rationale": "Not all suppliers present equal risk - those providing mission-critical technologies, products, or services warrant enhanced risk management attention. Compromise of a critical supplier can directly impact organizational mission capability, potentially causing operational disruption, data breaches, or safety incidents. Identifying and prioritizing critical suppliers enables organizations to focus limited risk management resources where they matter most, implement enhanced security controls for critical dependencies, and develop targeted contingency plans. This enhancement operationalizes the broader SCRM strategy for the highest-risk supplier relationships.",
    "plain_english_explanation": "This enhancement requires organizations to specifically identify which suppliers provide mission-critical items, rank them by importance, and conduct thorough security assessments of those critical suppliers. A supplier of your core database software or cloud infrastructure provider requires more scrutiny than a supplier of office supplies. This ensures your most important vendor relationships receive appropriate risk management attention.",
    "example_implementation": "Implement a critical supplier identification and assessment program including: automated SBOM analysis for software dependencies, vendor security scorecards, third-party risk management platform integration, and quarterly critical supplier risk reviews with documented remediation tracking.",
    "non_technical_guidance": "To implement PM-30.1: 1) Develop criteria for identifying critical suppliers (mission impact, data access, system connectivity, replaceability); 2) Review all suppliers against criteria to identify critical/mission-essential suppliers; 3) Create and maintain a critical supplier registry; 4) Develop enhanced assessment procedures for critical suppliers including detailed security questionnaires, evidence review, and potentially on-site assessments; 5) Establish more frequent assessment cycles for critical suppliers; 6) Implement continuous monitoring of critical suppliers for security incidents, financial issues, or ownership changes; 7) Develop detailed contingency plans for each critical supplier; 8) Conduct tabletop exercises testing critical supplier failure scenarios; 9) Require executive approval for onboarding new critical suppliers; 10) Review critical supplier designations annually as mission priorities evolve.",
    "ai_guidance": "PM-30.1 implementation requires systematic identification, prioritization, and assessment of critical suppliers with technical controls supporting continuous monitoring and risk quantification. Develop formal criteria for critical supplier designation including: direct support of mission-essential functions, access to sensitive data or systems, limited alternative suppliers, significant switching costs, and potential for cascading failures. Apply these criteria across all supplier relationships to identify the subset warranting enhanced scrutiny. Implement Software Bill of Materials (SBOM) analysis to identify critical software dependencies that may not be visible through procurement records - a component deeply embedded in your technology stack may be as critical as a major vendor. Deploy third-party risk management platforms that aggregate vendor security data from questionnaires, external scanning, threat intelligence, and compliance certifications. Implement vendor security scoring methodologies that quantify supplier risk based on security posture indicators, enabling consistent prioritization and tracking over time. Establish integration with commercial threat intelligence services to receive alerts on supplier breaches, vulnerabilities, or indicators of compromise. Deploy automated monitoring for critical supplier security certificates, domain reputation, and exposed credentials. Implement software composition analysis in CI/CD pipelines to continuously track critical software dependencies and associated vulnerabilities. Create supplier risk dashboards providing visibility into critical supplier security posture, assessment status, and trend indicators. Establish automated alerting when critical supplier risk scores degrade or assessment deadlines approach. Maintain documented assessment records for each critical supplier including questionnaire responses, evidence artifacts, risk ratings, and accepted risks with approvals. Conduct periodic penetration testing or security assessments of critical supplier interfaces and integrations. Develop and test contingency plans through tabletop exercises simulating critical supplier security incidents or failures. Ensure critical supplier contracts include appropriate security requirements, incident notification provisions, right-to-audit clauses, and termination rights for security failures.",
    "enhancements": [],
    "related_controls": [
      "PM-30",
      "SA-9",
      "SA-12",
      "SR-2",
      "SR-3",
      "SR-5",
      "SR-6",
      "RA-3",
      "RA-5"
    ],
    "supplemental_guidance": "Organizations should leverage available sources of supplier security information including industry-specific information sharing organizations, government supply chain risk advisories, and commercial threat intelligence. Assessment depth should be proportionate to supplier criticality and risk exposure. Organizations should consider both direct suppliers and critical sub-suppliers in their assessments.",
    "implementation_scripts": {
      "linux": {
        "bash": "#!/bin/bash\n# PM-30.1: Critical Supplier Assessment and Monitoring Script\n# This script supports identification and assessment of critical suppliers\n\nLOG_FILE=\"/var/log/scrm/critical_supplier_assessment.log\"\nSUPPLIER_DB=\"/etc/scrm/critical_suppliers.json\"\nSBOM_DIR=\"/var/scrm/sbom\"\nREPORT_DIR=\"/var/scrm/reports\"\nALERT_EMAIL=\"security-team@organization.com\"\n\n# Ensure directories exist\nmkdir -p /var/log/scrm /etc/scrm /var/scrm/sbom /var/scrm/reports\n\nlog_message() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" >> \"$LOG_FILE\"\n}\n\n# Function to initialize critical supplier database\ninit_supplier_db() {\n    if [[ ! -f \"$SUPPLIER_DB\" ]]; then\n        cat > \"$SUPPLIER_DB\" << 'EOF'\n{\n  \"metadata\": {\n    \"version\": \"1.0\",\n    \"last_updated\": \"\",\n    \"organization\": \"Example Organization\"\n  },\n  \"criticality_criteria\": {\n    \"mission_essential\": 10,\n    \"data_access\": 8,\n    \"system_connectivity\": 7,\n    \"limited_alternatives\": 6,\n    \"switching_cost_high\": 5\n  },\n  \"suppliers\": []\n}\nEOF\n        log_message \"Initialized critical supplier database\"\n    fi\n}\n\n# Function to add a supplier to the critical supplier registry\nadd_critical_supplier() {\n    local name=\"$1\"\n    local product=\"$2\"\n    local criticality_score=\"$3\"\n    local assessment_date=\"$4\"\n    local risk_rating=\"$5\"\n    \n    log_message \"Adding critical supplier: $name (Score: $criticality_score)\"\n    \n    # Use jq to add supplier if available\n    if command -v jq &> /dev/null; then\n        local temp_file=$(mktemp)\n        jq --arg name \"$name\" \\\n           --arg product \"$product\" \\\n           --arg score \"$criticality_score\" \\\n           --arg date \"$assessment_date\" \\\n           --arg rating \"$risk_rating\" \\\n           '.suppliers += [{\"name\": $name, \"product\": $product, \"criticality_score\": ($score|tonumber), \"last_assessment\": $date, \"risk_rating\": $rating, \"status\": \"active\"}]' \\\n           \"$SUPPLIER_DB\" > \"$temp_file\" && mv \"$temp_file\" \"$SUPPLIER_DB\"\n        log_message \"Supplier added successfully: $name\"\n    else\n        log_message \"ERROR: jq not installed - cannot modify JSON database\"\n        echo \"Please install jq: apt-get install jq or yum install jq\"\n        return 1\n    fi\n}\n\n# Function to generate SBOM from installed packages\ngenerate_system_sbom() {\n    local output_file=\"$SBOM_DIR/system_sbom_$(date '+%Y%m%d').json\"\n    \n    log_message \"Generating system SBOM\"\n    \n    echo '{' > \"$output_file\"\n    echo '  \"sbom_version\": \"1.0\",' >> \"$output_file\"\n    echo '  \"generated\": \"'$(date -Iseconds)'\",' >> \"$output_file\"\n    echo '  \"system\": \"'$(hostname)'\",' >> \"$output_file\"\n    echo '  \"components\": [' >> \"$output_file\"\n    \n    # Detect package manager and list packages\n    if command -v dpkg &> /dev/null; then\n        dpkg-query -W -f='{\"name\": \"${Package}\", \"version\": \"${Version}\", \"source\": \"apt\"},\\n' 2>/dev/null | sed '$ s/,$//' >> \"$output_file\"\n    elif command -v rpm &> /dev/null; then\n        rpm -qa --queryformat '{\"name\": \"%{NAME}\", \"version\": \"%{VERSION}-%{RELEASE}\", \"source\": \"rpm\"},\\n' 2>/dev/null | sed '$ s/,$//' >> \"$output_file\"\n    fi\n    \n    echo '  ]' >> \"$output_file\"\n    echo '}' >> \"$output_file\"\n    \n    log_message \"SBOM generated: $output_file\"\n    echo \"$output_file\"\n}\n\n# Function to analyze SBOM for critical dependencies\nanalyze_sbom_criticality() {\n    local sbom_file=\"$1\"\n    local critical_packages=(\"openssl\" \"openssh\" \"kernel\" \"glibc\" \"systemd\" \"sudo\" \"pam\" \"coreutils\" \"bash\")\n    \n    log_message \"Analyzing SBOM for critical dependencies\"\n    \n    echo \"=== Critical Dependency Analysis ===\"\n    echo \"Date: $(date)\"\n    echo \"\"\n    \n    for pkg in \"${critical_packages[@]}\"; do\n        if grep -qi \"\\\"name\\\": \\\"$pkg\" \"$sbom_file\" 2>/dev/null; then\n            local version=$(grep -i \"\\\"name\\\": \\\"$pkg\" \"$sbom_file\" -A1 | grep version | head -1)\n            echo \"[CRITICAL] Found: $pkg - $version\"\n            log_message \"Critical package identified: $pkg\"\n        fi\n    done\n}\n\n# Function to check supplier assessment status\ncheck_assessment_status() {\n    log_message \"Checking supplier assessment status\"\n    \n    if command -v jq &> /dev/null && [[ -f \"$SUPPLIER_DB\" ]]; then\n        echo \"=== Critical Supplier Assessment Status ===\"\n        echo \"Generated: $(date)\"\n        echo \"\"\n        \n        local current_date=$(date '+%Y-%m-%d')\n        local ninety_days_ago=$(date -d \"-90 days\" '+%Y-%m-%d' 2>/dev/null || date -v-90d '+%Y-%m-%d' 2>/dev/null)\n        \n        jq -r '.suppliers[] | \"Supplier: \\(.name)\\n  Product: \\(.product)\\n  Criticality: \\(.criticality_score)\\n  Last Assessment: \\(.last_assessment)\\n  Risk Rating: \\(.risk_rating)\\n  Status: \\(.status)\\n\"' \"$SUPPLIER_DB\"\n        \n        # Check for overdue assessments\n        echo \"=== Assessment Alerts ===\"\n        jq -r --arg cutoff \"$ninety_days_ago\" '.suppliers[] | select(.last_assessment < $cutoff) | \"OVERDUE: \\(.name) - Last assessed: \\(.last_assessment)\"' \"$SUPPLIER_DB\"\n    else\n        log_message \"Cannot check status - jq not available or database missing\"\n    fi\n}\n\n# Function to generate supplier security scorecard\ngenerate_supplier_scorecard() {\n    local supplier_name=\"$1\"\n    local report_file=\"$REPORT_DIR/scorecard_${supplier_name// /_}_$(date '+%Y%m%d').txt\"\n    \n    log_message \"Generating scorecard for: $supplier_name\"\n    \n    cat > \"$report_file\" << EOF\n================================================================================\nSUPPLIER SECURITY SCORECARD\n================================================================================\nSupplier: $supplier_name\nAssessment Date: $(date '+%Y-%m-%d')\nAssessor: $(whoami)\n\n--------------------------------------------------------------------------------\nSECURITY ASSESSMENT CRITERIA\n--------------------------------------------------------------------------------\n\n1. SECURITY CERTIFICATIONS\n   [ ] SOC 2 Type II\n   [ ] ISO 27001\n   [ ] FedRAMP (if applicable)\n   [ ] PCI DSS (if applicable)\n   [ ] HIPAA (if applicable)\n\n2. SECURITY POLICIES\n   [ ] Information Security Policy\n   [ ] Incident Response Plan\n   [ ] Business Continuity Plan\n   [ ] Vulnerability Management Policy\n   [ ] Access Control Policy\n\n3. TECHNICAL CONTROLS\n   [ ] Encryption at rest\n   [ ] Encryption in transit\n   [ ] Multi-factor authentication\n   [ ] Regular penetration testing\n   [ ] Vulnerability scanning\n   [ ] Security monitoring/SIEM\n\n4. OPERATIONAL SECURITY\n   [ ] Background checks for employees\n   [ ] Security awareness training\n   [ ] Secure development practices\n   [ ] Change management process\n   [ ] Patch management process\n\n5. DATA PROTECTION\n   [ ] Data classification scheme\n   [ ] Data retention policy\n   [ ] Data disposal procedures\n   [ ] Privacy policy compliance\n   [ ] Subprocessor management\n\n6. INCIDENT MANAGEMENT\n   [ ] 24/7 security monitoring\n   [ ] Defined incident response process\n   [ ] Customer notification procedures\n   [ ] Post-incident review process\n   [ ] Evidence preservation capability\n\n--------------------------------------------------------------------------------\nRISK RATING CALCULATION\n--------------------------------------------------------------------------------\nTotal Items Checked: __ / 24\n\nRating Scale:\n  20-24: LOW RISK\n  15-19: MODERATE RISK  \n  10-14: HIGH RISK\n  0-9:   CRITICAL RISK\n\nFINAL RISK RATING: ________________\n\n--------------------------------------------------------------------------------\nFINDINGS AND RECOMMENDATIONS\n--------------------------------------------------------------------------------\n\n\n--------------------------------------------------------------------------------\nAPPROVALS\n--------------------------------------------------------------------------------\nAssessor Signature: _________________________ Date: ____________\nReviewer Signature: _________________________ Date: ____________\nRisk Acceptance:   _________________________ Date: ____________\n\n================================================================================\nEOF\n\n    log_message \"Scorecard generated: $report_file\"\n    echo \"Scorecard saved to: $report_file\"\n}\n\n# Function to monitor supplier security news\nmonitor_supplier_alerts() {\n    log_message \"Checking for supplier security alerts\"\n    \n    # Check common CVE databases for supplier-related vulnerabilities\n    echo \"=== Supplier Security Monitoring ===\"\n    echo \"Date: $(date)\"\n    echo \"\"\n    echo \"Recommended monitoring sources:\"\n    echo \"  - CISA KEV: https://www.cisa.gov/known-exploited-vulnerabilities-catalog\"\n    echo \"  - NVD: https://nvd.nist.gov/\"\n    echo \"  - Vendor Security Advisories\"\n    echo \"  - SecurityScorecard, BitSight, or similar TPRM platforms\"\n    echo \"\"\n    \n    # If suppliers are defined, list them for monitoring\n    if command -v jq &> /dev/null && [[ -f \"$SUPPLIER_DB\" ]]; then\n        echo \"Critical suppliers to monitor:\"\n        jq -r '.suppliers[] | \"  - \\(.name): \\(.product)\"' \"$SUPPLIER_DB\"\n    fi\n}\n\n# Function to generate comprehensive SCRM report\ngenerate_scrm_report() {\n    local report_file=\"$REPORT_DIR/scrm_report_$(date '+%Y%m%d').txt\"\n    \n    log_message \"Generating comprehensive SCRM report\"\n    \n    cat > \"$report_file\" << EOF\n================================================================================\nSUPPLY CHAIN RISK MANAGEMENT REPORT\n================================================================================\nReport Date: $(date '+%Y-%m-%d %H:%M:%S')\nGenerated By: $(whoami)@$(hostname)\n\n--------------------------------------------------------------------------------\n1. EXECUTIVE SUMMARY\n--------------------------------------------------------------------------------\nThis report provides an overview of the organization's supply chain risk \nmanagement posture for critical and mission-essential suppliers.\n\n--------------------------------------------------------------------------------\n2. CRITICAL SUPPLIER INVENTORY\n--------------------------------------------------------------------------------\nEOF\n\n    if command -v jq &> /dev/null && [[ -f \"$SUPPLIER_DB\" ]]; then\n        jq -r '.suppliers | length' \"$SUPPLIER_DB\" >> \"$report_file\"\n        echo \" critical suppliers registered\" >> \"$report_file\"\n        echo \"\" >> \"$report_file\"\n        jq -r '.suppliers[] | \"- \\(.name) (\\(.product)) - Risk: \\(.risk_rating)\"' \"$SUPPLIER_DB\" >> \"$report_file\"\n    else\n        echo \"No supplier database found or jq not installed\" >> \"$report_file\"\n    fi\n    \n    cat >> \"$report_file\" << EOF\n\n--------------------------------------------------------------------------------\n3. ASSESSMENT STATUS\n--------------------------------------------------------------------------------\nEOF\n    check_assessment_status >> \"$report_file\"\n    \n    cat >> \"$report_file\" << EOF\n\n--------------------------------------------------------------------------------\n4. SOFTWARE BILL OF MATERIALS SUMMARY\n--------------------------------------------------------------------------------\nEOF\n    ls -la \"$SBOM_DIR\"/*.json 2>/dev/null >> \"$report_file\" || echo \"No SBOM files found\" >> \"$report_file\"\n    \n    cat >> \"$report_file\" << EOF\n\n--------------------------------------------------------------------------------\n5. RECOMMENDATIONS\n--------------------------------------------------------------------------------\n- Review and update critical supplier assessments quarterly\n- Implement continuous monitoring for critical supplier security posture\n- Maintain current SBOMs for all critical systems\n- Conduct annual supplier risk tabletop exercises\n- Review supplier contracts for security clause adequacy\n\n================================================================================\nEND OF REPORT\n================================================================================\nEOF\n\n    log_message \"SCRM report generated: $report_file\"\n    echo \"Report saved to: $report_file\"\n}\n\n# Main menu\nmain() {\n    echo \"PM-30.1 Critical Supplier Assessment Tool\"\n    echo \"=========================================\"\n    echo \"1. Initialize supplier database\"\n    echo \"2. Add critical supplier\"\n    echo \"3. Check assessment status\"\n    echo \"4. Generate system SBOM\"\n    echo \"5. Analyze SBOM criticality\"\n    echo \"6. Generate supplier scorecard\"\n    echo \"7. Monitor supplier alerts\"\n    echo \"8. Generate SCRM report\"\n    echo \"9. Exit\"\n    echo \"\"\n    \n    read -p \"Select option: \" choice\n    \n    case $choice in\n        1) init_supplier_db ;;\n        2) \n           read -p \"Supplier name: \" name\n           read -p \"Product/Service: \" product\n           read -p \"Criticality score (1-10): \" score\n           read -p \"Risk rating (low/moderate/high/critical): \" rating\n           add_critical_supplier \"$name\" \"$product\" \"$score\" \"$(date '+%Y-%m-%d')\" \"$rating\"\n           ;;\n        3) check_assessment_status ;;\n        4) generate_system_sbom ;;\n        5) \n           read -p \"SBOM file path: \" sbom\n           analyze_sbom_criticality \"$sbom\"\n           ;;\n        6)\n           read -p \"Supplier name: \" supplier\n           generate_supplier_scorecard \"$supplier\"\n           ;;\n        7) monitor_supplier_alerts ;;\n        8) generate_scrm_report ;;\n        9) exit 0 ;;\n        *) echo \"Invalid option\" ;;\n    esac\n}\n\n# Run initialization and main\ninit_supplier_db\nmain",
        "ansible": "---\n# PM-30.1: Critical Supplier Assessment and Monitoring Playbook\n# Ansible playbook for supply chain risk management automation\n\n- name: PM-30.1 Critical Supplier Risk Management\n  hosts: all\n  become: yes\n  vars:\n    scrm_base_dir: /var/scrm\n    scrm_log_dir: /var/log/scrm\n    scrm_config_dir: /etc/scrm\n    sbom_retention_days: 365\n    assessment_frequency_days: 90\n    alert_email: \"security-team@organization.com\"\n    \n    # Define critical supplier assessment criteria\n    criticality_criteria:\n      mission_essential: 10\n      data_access: 8\n      system_connectivity: 7\n      limited_alternatives: 6\n      high_switching_cost: 5\n      \n    # Define critical package categories for SBOM analysis  \n    critical_packages:\n      - name: \"openssl\"\n        category: \"cryptography\"\n        criticality: \"high\"\n      - name: \"openssh\"\n        category: \"remote_access\"\n        criticality: \"high\"\n      - name: \"sudo\"\n        category: \"privilege_management\"\n        criticality: \"high\"\n      - name: \"pam\"\n        category: \"authentication\"\n        criticality: \"high\"\n      - name: \"systemd\"\n        category: \"system_init\"\n        criticality: \"high\"\n      - name: \"glibc\"\n        category: \"core_library\"\n        criticality: \"critical\"\n      - name: \"kernel\"\n        category: \"operating_system\"\n        criticality: \"critical\"\n\n  tasks:\n    - name: Create SCRM directory structure\n      file:\n        path: \"{{ item }}\"\n        state: directory\n        mode: '0750'\n        owner: root\n        group: root\n      loop:\n        - \"{{ scrm_base_dir }}\"\n        - \"{{ scrm_base_dir }}/sbom\"\n        - \"{{ scrm_base_dir }}/reports\"\n        - \"{{ scrm_base_dir }}/assessments\"\n        - \"{{ scrm_log_dir }}\"\n        - \"{{ scrm_config_dir }}\"\n      tags: [setup]\n\n    - name: Install required packages for SCRM tools\n      package:\n        name:\n          - jq\n          - python3\n          - python3-pip\n        state: present\n      tags: [setup]\n\n    - name: Create critical supplier database template\n      copy:\n        dest: \"{{ scrm_config_dir }}/critical_suppliers.json\"\n        content: |\n          {\n            \"metadata\": {\n              \"version\": \"1.0\",\n              \"organization\": \"{{ ansible_hostname }}\",\n              \"last_updated\": \"{{ ansible_date_time.iso8601 }}\",\n              \"assessment_frequency_days\": {{ assessment_frequency_days }}\n            },\n            \"criticality_criteria\": {{ criticality_criteria | to_json }},\n            \"suppliers\": []\n          }\n        mode: '0640'\n        force: no\n      tags: [setup]\n\n    - name: Generate Software Bill of Materials (SBOM)\n      block:\n        - name: Get installed packages (Debian/Ubuntu)\n          shell: |\n            dpkg-query -W -f='${Package},${Version},${Homepage}\\n' 2>/dev/null\n          register: debian_packages\n          when: ansible_os_family == \"Debian\"\n          changed_when: false\n          \n        - name: Get installed packages (RedHat/CentOS)\n          shell: |\n            rpm -qa --queryformat '%{NAME},%{VERSION}-%{RELEASE},%{URL}\\n' 2>/dev/null\n          register: redhat_packages  \n          when: ansible_os_family == \"RedHat\"\n          changed_when: false\n\n        - name: Create SBOM JSON file\n          copy:\n            dest: \"{{ scrm_base_dir }}/sbom/sbom_{{ ansible_hostname }}_{{ ansible_date_time.date }}.json\"\n            content: |\n              {\n                \"sbom_format\": \"CycloneDX\",\n                \"sbom_version\": \"1.4\",\n                \"generated\": \"{{ ansible_date_time.iso8601 }}\",\n                \"hostname\": \"{{ ansible_hostname }}\",\n                \"os_family\": \"{{ ansible_os_family }}\",\n                \"os_version\": \"{{ ansible_distribution_version }}\",\n                \"components\": [\n                  {% set packages = debian_packages.stdout_lines if ansible_os_family == 'Debian' else redhat_packages.stdout_lines %}\n                  {% for pkg in packages %}\n                  {% set parts = pkg.split(',') %}\n                  {\n                    \"type\": \"library\",\n                    \"name\": \"{{ parts[0] | default('unknown') }}\",\n                    \"version\": \"{{ parts[1] | default('unknown') }}\",\n                    \"purl\": \"pkg:{{ 'deb' if ansible_os_family == 'Debian' else 'rpm' }}/{{ parts[0] | default('unknown') }}@{{ parts[1] | default('unknown') }}\"\n                  }{% if not loop.last %},{% endif %}\n                  {% endfor %}\n                ]\n              }\n            mode: '0640'\n      tags: [sbom]\n\n    - name: Analyze SBOM for critical dependencies\n      shell: |\n        SBOM_FILE=$(ls -t {{ scrm_base_dir }}/sbom/sbom_*.json 2>/dev/null | head -1)\n        if [[ -f \"$SBOM_FILE\" ]]; then\n          echo \"=== Critical Dependency Analysis ===\"\n          echo \"SBOM File: $SBOM_FILE\"\n          echo \"Analysis Date: $(date)\"\n          echo \"\"\n          {% for pkg in critical_packages %}\n          if jq -e '.components[] | select(.name | test(\"{{ pkg.name }}\"; \"i\"))' \"$SBOM_FILE\" > /dev/null 2>&1; then\n            VERSION=$(jq -r '.components[] | select(.name | test(\"{{ pkg.name }}\"; \"i\")) | .version' \"$SBOM_FILE\" | head -1)\n            echo \"[{{ pkg.criticality | upper }}] {{ pkg.name }} v$VERSION ({{ pkg.category }})\"\n          fi\n          {% endfor %}\n        else\n          echo \"No SBOM file found. Run with tag 'sbom' first.\"\n        fi\n      register: sbom_analysis\n      changed_when: false\n      tags: [analyze]\n\n    - name: Display SBOM analysis results\n      debug:\n        var: sbom_analysis.stdout_lines\n      tags: [analyze]\n\n    - name: Create supplier assessment checklist template\n      copy:\n        dest: \"{{ scrm_base_dir }}/assessments/assessment_template.md\"\n        content: |\n          # Critical Supplier Security Assessment\n          \n          ## Supplier Information\n          - **Supplier Name**: \n          - **Product/Service**: \n          - **Assessment Date**: {{ ansible_date_time.date }}\n          - **Assessor**: \n          - **Criticality Score**: /10\n          \n          ## Security Certifications\n          - [ ] SOC 2 Type II (Expiration: )\n          - [ ] ISO 27001 (Expiration: )\n          - [ ] FedRAMP Authorization\n          - [ ] PCI DSS (if applicable)\n          - [ ] HIPAA BAA (if applicable)\n          \n          ## Security Controls Assessment\n          \n          ### Access Control\n          - [ ] Multi-factor authentication enforced\n          - [ ] Role-based access control implemented\n          - [ ] Privileged access management\n          - [ ] Regular access reviews conducted\n          \n          ### Data Protection\n          - [ ] Encryption at rest (Algorithm: )\n          - [ ] Encryption in transit (TLS version: )\n          - [ ] Data classification implemented\n          - [ ] Data retention policy defined\n          - [ ] Secure data disposal procedures\n          \n          ### Vulnerability Management\n          - [ ] Regular vulnerability scanning\n          - [ ] Penetration testing (Frequency: )\n          - [ ] Patch management process\n          - [ ] Known vulnerability response SLA\n          \n          ### Incident Response\n          - [ ] Documented incident response plan\n          - [ ] 24/7 security monitoring\n          - [ ] Customer notification procedures (SLA: hours)\n          - [ ] Post-incident review process\n          \n          ### Business Continuity\n          - [ ] Business continuity plan documented\n          - [ ] Disaster recovery capability\n          - [ ] Regular BC/DR testing\n          - [ ] Geographic redundancy\n          \n          ### Third-Party Management\n          - [ ] Subprocessor list maintained\n          - [ ] Subprocessor security requirements\n          - [ ] Right to audit subprocessors\n          \n          ## Risk Rating\n          \n          | Category | Score (1-5) | Weight | Weighted Score |\n          |----------|-------------|--------|----------------|\n          | Certifications | | 2 | |\n          | Access Control | | 2 | |\n          | Data Protection | | 3 | |\n          | Vulnerability Mgmt | | 2 | |\n          | Incident Response | | 2 | |\n          | Business Continuity | | 1 | |\n          | Third-Party Mgmt | | 1 | |\n          | **TOTAL** | | **13** | |\n          \n          **Risk Rating**: LOW / MODERATE / HIGH / CRITICAL\n          \n          ## Findings and Recommendations\n          \n          1. \n          2. \n          3. \n          \n          ## Approvals\n          \n          - **Assessor**: _________________ Date: _______\n          - **Reviewer**: _________________ Date: _______\n          - **Risk Owner**: _______________ Date: _______\n        mode: '0644'\n      tags: [setup, assessment]\n\n    - name: Check for overdue supplier assessments\n      shell: |\n        SUPPLIER_DB=\"{{ scrm_config_dir }}/critical_suppliers.json\"\n        if [[ -f \"$SUPPLIER_DB\" ]]; then\n          CUTOFF_DATE=$(date -d \"-{{ assessment_frequency_days }} days\" '+%Y-%m-%d' 2>/dev/null || date -v-{{ assessment_frequency_days }}d '+%Y-%m-%d' 2>/dev/null)\n          echo \"Checking for assessments older than: $CUTOFF_DATE\"\n          jq -r --arg cutoff \"$CUTOFF_DATE\" '\n            .suppliers[] | \n            select(.last_assessment < $cutoff) | \n            \"OVERDUE: \\(.name) - Last assessed: \\(.last_assessment) - Risk: \\(.risk_rating)\"\n          ' \"$SUPPLIER_DB\" 2>/dev/null || echo \"No suppliers in database\"\n        else\n          echo \"Supplier database not found\"\n        fi\n      register: overdue_assessments\n      changed_when: false\n      tags: [monitor]\n\n    - name: Display overdue assessments\n      debug:\n        var: overdue_assessments.stdout_lines\n      when: overdue_assessments.stdout_lines | length > 0\n      tags: [monitor]\n\n    - name: Generate SCRM compliance report\n      copy:\n        dest: \"{{ scrm_base_dir }}/reports/scrm_compliance_{{ ansible_date_time.date }}.txt\"\n        content: |\n          ================================================================================\n          SUPPLY CHAIN RISK MANAGEMENT COMPLIANCE REPORT\n          ================================================================================\n          Report Date: {{ ansible_date_time.iso8601 }}\n          Generated By: Ansible SCRM Playbook\n          Host: {{ ansible_hostname }}\n          \n          --------------------------------------------------------------------------------\n          1. CONTROL MAPPING\n          --------------------------------------------------------------------------------\n          NIST Control: PM-30.1 - Suppliers of Critical or Mission-essential Items\n          Status: IMPLEMENTED\n          \n          Implemented Capabilities:\n          - [x] Critical supplier registry maintained\n          - [x] SBOM generation automated\n          - [x] Assessment tracking implemented\n          - [x] Criticality scoring defined\n          - [x] Overdue assessment alerting\n          \n          --------------------------------------------------------------------------------\n          2. SBOM STATUS\n          --------------------------------------------------------------------------------\n          Latest SBOM: {{ scrm_base_dir }}/sbom/sbom_{{ ansible_hostname }}_{{ ansible_date_time.date }}.json\n          \n          Critical Dependencies Identified:\n          {{ sbom_analysis.stdout | default('Analysis not run') }}\n          \n          --------------------------------------------------------------------------------\n          3. ASSESSMENT STATUS\n          --------------------------------------------------------------------------------\n          {{ overdue_assessments.stdout | default('Status check not run') }}\n          \n          --------------------------------------------------------------------------------\n          4. RECOMMENDATIONS\n          --------------------------------------------------------------------------------\n          - Review and update critical supplier assessments every {{ assessment_frequency_days }} days\n          - Regenerate SBOMs after significant system changes\n          - Maintain documentation of all assessment decisions\n          - Conduct annual supplier risk tabletop exercises\n          \n          ================================================================================\n          END OF REPORT\n          ================================================================================\n        mode: '0640'\n      tags: [report]\n\n    - name: Clean up old SBOM files\n      find:\n        paths: \"{{ scrm_base_dir }}/sbom\"\n        patterns: \"sbom_*.json\"\n        age: \"{{ sbom_retention_days }}d\"\n      register: old_sboms\n      tags: [cleanup]\n\n    - name: Remove old SBOM files\n      file:\n        path: \"{{ item.path }}\"\n        state: absent\n      loop: \"{{ old_sboms.files }}\"\n      when: old_sboms.files | length > 0\n      tags: [cleanup]\n\n    - name: Display completion message\n      debug:\n        msg: |\n          PM-30.1 Supply Chain Risk Management tasks completed.\n          \n          Key files:\n          - Supplier Database: {{ scrm_config_dir }}/critical_suppliers.json\n          - SBOM Directory: {{ scrm_base_dir }}/sbom/\n          - Reports: {{ scrm_base_dir }}/reports/\n          - Assessment Template: {{ scrm_base_dir }}/assessments/assessment_template.md\n          \n          To add a supplier, edit the supplier database JSON file.\n          Run with specific tags: setup, sbom, analyze, monitor, report, cleanup\n      tags: [always]"
      },
      "windows": {
        "powershell": "# PM-30.1: Critical Supplier Assessment and Monitoring Script\n# PowerShell script for Windows supply chain risk management\n\n#Requires -Version 5.1\n\n[CmdletBinding()]\nparam(\n    [Parameter()]\n    [ValidateSet('Initialize', 'AddSupplier', 'CheckStatus', 'GenerateSBOM', 'AnalyzeSBOM', 'GenerateScorecard', 'GenerateReport')]\n    [string]$Action = 'CheckStatus',\n    \n    [Parameter()]\n    [string]$SupplierName,\n    \n    [Parameter()]\n    [string]$ProductService,\n    \n    [Parameter()]\n    [ValidateRange(1,10)]\n    [int]$CriticalityScore,\n    \n    [Parameter()]\n    [ValidateSet('Low', 'Moderate', 'High', 'Critical')]\n    [string]$RiskRating\n)\n\n# Configuration\n$SCRMBaseDir = \"$env:ProgramData\\SCRM\"\n$SCRMLogDir = \"$SCRMBaseDir\\Logs\"\n$SCRMConfigDir = \"$SCRMBaseDir\\Config\"\n$SCRMSBOMDir = \"$SCRMBaseDir\\SBOM\"\n$SCRMReportDir = \"$SCRMBaseDir\\Reports\"\n$SupplierDBPath = \"$SCRMConfigDir\\critical_suppliers.json\"\n$AssessmentFrequencyDays = 90\n\n# Ensure directories exist\nfunction Initialize-SCRMDirectories {\n    $directories = @($SCRMBaseDir, $SCRMLogDir, $SCRMConfigDir, $SCRMSBOMDir, $SCRMReportDir)\n    foreach ($dir in $directories) {\n        if (-not (Test-Path $dir)) {\n            New-Item -ItemType Directory -Path $dir -Force | Out-Null\n            Write-Host \"[INFO] Created directory: $dir\" -ForegroundColor Green\n        }\n    }\n}\n\n# Logging function\nfunction Write-SCRMLog {\n    param([string]$Message, [string]$Level = 'INFO')\n    $timestamp = Get-Date -Format 'yyyy-MM-dd HH:mm:ss'\n    $logEntry = \"$timestamp [$Level] $Message\"\n    $logFile = Join-Path $SCRMLogDir \"scrm_$(Get-Date -Format 'yyyyMMdd').log\"\n    Add-Content -Path $logFile -Value $logEntry\n    \n    switch ($Level) {\n        'ERROR' { Write-Host $logEntry -ForegroundColor Red }\n        'WARNING' { Write-Host $logEntry -ForegroundColor Yellow }\n        'SUCCESS' { Write-Host $logEntry -ForegroundColor Green }\n        default { Write-Host $logEntry }\n    }\n}\n\n# Initialize supplier database\nfunction Initialize-SupplierDatabase {\n    if (-not (Test-Path $SupplierDBPath)) {\n        $database = @{\n            metadata = @{\n                version = \"1.0\"\n                organization = $env:COMPUTERNAME\n                last_updated = (Get-Date -Format 'yyyy-MM-ddTHH:mm:ssZ')\n                assessment_frequency_days = $AssessmentFrequencyDays\n            }\n            criticality_criteria = @{\n                mission_essential = 10\n                data_access = 8\n                system_connectivity = 7\n                limited_alternatives = 6\n                high_switching_cost = 5\n            }\n            suppliers = @()\n        }\n        \n        $database | ConvertTo-Json -Depth 10 | Set-Content -Path $SupplierDBPath -Encoding UTF8\n        Write-SCRMLog \"Initialized supplier database at: $SupplierDBPath\" 'SUCCESS'\n    } else {\n        Write-SCRMLog \"Supplier database already exists: $SupplierDBPath\" 'INFO'\n    }\n}\n\n# Add critical supplier\nfunction Add-CriticalSupplier {\n    param(\n        [Parameter(Mandatory)][string]$Name,\n        [Parameter(Mandatory)][string]$Product,\n        [Parameter(Mandatory)][int]$Score,\n        [Parameter(Mandatory)][string]$Rating\n    )\n    \n    if (-not (Test-Path $SupplierDBPath)) {\n        Write-SCRMLog \"Supplier database not found. Initializing...\" 'WARNING'\n        Initialize-SupplierDatabase\n    }\n    \n    $database = Get-Content $SupplierDBPath -Raw | ConvertFrom-Json\n    \n    # Check for duplicate\n    $existing = $database.suppliers | Where-Object { $_.name -eq $Name }\n    if ($existing) {\n        Write-SCRMLog \"Supplier '$Name' already exists. Use update function to modify.\" 'WARNING'\n        return\n    }\n    \n    $newSupplier = @{\n        name = $Name\n        product = $Product\n        criticality_score = $Score\n        risk_rating = $Rating\n        last_assessment = (Get-Date -Format 'yyyy-MM-dd')\n        status = 'active'\n        created_date = (Get-Date -Format 'yyyy-MM-ddTHH:mm:ssZ')\n    }\n    \n    # PowerShell array handling\n    if ($database.suppliers -is [array]) {\n        $database.suppliers += $newSupplier\n    } else {\n        $database.suppliers = @($newSupplier)\n    }\n    \n    $database.metadata.last_updated = (Get-Date -Format 'yyyy-MM-ddTHH:mm:ssZ')\n    $database | ConvertTo-Json -Depth 10 | Set-Content -Path $SupplierDBPath -Encoding UTF8\n    \n    Write-SCRMLog \"Added critical supplier: $Name (Score: $Score, Risk: $Rating)\" 'SUCCESS'\n}\n\n# Check assessment status\nfunction Get-AssessmentStatus {\n    if (-not (Test-Path $SupplierDBPath)) {\n        Write-SCRMLog \"Supplier database not found. Run Initialize first.\" 'ERROR'\n        return\n    }\n    \n    $database = Get-Content $SupplierDBPath -Raw | ConvertFrom-Json\n    $cutoffDate = (Get-Date).AddDays(-$AssessmentFrequencyDays).ToString('yyyy-MM-dd')\n    \n    Write-Host \"`n=== Critical Supplier Assessment Status ===\" -ForegroundColor Cyan\n    Write-Host \"Generated: $(Get-Date -Format 'yyyy-MM-dd HH:mm:ss')\"\n    Write-Host \"Assessment Frequency: $AssessmentFrequencyDays days\"\n    Write-Host \"Overdue Threshold: $cutoffDate`n\"\n    \n    if ($database.suppliers.Count -eq 0) {\n        Write-Host \"No suppliers in database.\" -ForegroundColor Yellow\n        return\n    }\n    \n    $overdueCount = 0\n    foreach ($supplier in $database.suppliers) {\n        $isOverdue = $supplier.last_assessment -lt $cutoffDate\n        $statusColor = if ($isOverdue) { 'Red' } else { 'Green' }\n        $statusText = if ($isOverdue) { '[OVERDUE]' } else { '[CURRENT]' }\n        \n        Write-Host \"$statusText $($supplier.name)\" -ForegroundColor $statusColor\n        Write-Host \"  Product: $($supplier.product)\"\n        Write-Host \"  Criticality: $($supplier.criticality_score)/10\"\n        Write-Host \"  Risk Rating: $($supplier.risk_rating)\"\n        Write-Host \"  Last Assessment: $($supplier.last_assessment)\"\n        Write-Host \"\"\n        \n        if ($isOverdue) { $overdueCount++ }\n    }\n    \n    Write-Host \"=== Summary ===\" -ForegroundColor Cyan\n    Write-Host \"Total Suppliers: $($database.suppliers.Count)\"\n    Write-Host \"Overdue Assessments: $overdueCount\" -ForegroundColor $(if ($overdueCount -gt 0) { 'Red' } else { 'Green' })\n}\n\n# Generate Software Bill of Materials\nfunction New-SystemSBOM {\n    $sbomFile = Join-Path $SCRMSBOMDir \"sbom_$($env:COMPUTERNAME)_$(Get-Date -Format 'yyyyMMdd').json\"\n    \n    Write-SCRMLog \"Generating system SBOM...\" 'INFO'\n    \n    # Collect installed software\n    $software = @()\n    \n    # Get software from registry (64-bit)\n    $regPaths = @(\n        'HKLM:\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\*',\n        'HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\*',\n        'HKCU:\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\*'\n    )\n    \n    foreach ($path in $regPaths) {\n        if (Test-Path $path) {\n            Get-ItemProperty $path -ErrorAction SilentlyContinue | \n            Where-Object { $_.DisplayName } |\n            ForEach-Object {\n                $software += @{\n                    type = 'application'\n                    name = $_.DisplayName\n                    version = $_.DisplayVersion\n                    publisher = $_.Publisher\n                    install_date = $_.InstallDate\n                    source = 'registry'\n                }\n            }\n        }\n    }\n    \n    # Get Windows features\n    try {\n        Get-WindowsOptionalFeature -Online -ErrorAction SilentlyContinue | \n        Where-Object { $_.State -eq 'Enabled' } |\n        ForEach-Object {\n            $software += @{\n                type = 'feature'\n                name = $_.FeatureName\n                version = 'N/A'\n                publisher = 'Microsoft'\n                source = 'windows_feature'\n            }\n        }\n    } catch {\n        Write-SCRMLog \"Unable to enumerate Windows features (may require elevation)\" 'WARNING'\n    }\n    \n    # Create SBOM structure\n    $sbom = @{\n        sbom_format = 'CycloneDX'\n        sbom_version = '1.4'\n        generated = (Get-Date -Format 'yyyy-MM-ddTHH:mm:ssZ')\n        hostname = $env:COMPUTERNAME\n        os_version = [System.Environment]::OSVersion.VersionString\n        component_count = $software.Count\n        components = $software | Select-Object -Unique name, version, publisher, type, source\n    }\n    \n    $sbom | ConvertTo-Json -Depth 10 | Set-Content -Path $sbomFile -Encoding UTF8\n    Write-SCRMLog \"SBOM generated: $sbomFile (Components: $($software.Count))\" 'SUCCESS'\n    \n    return $sbomFile\n}\n\n# Analyze SBOM for critical dependencies\nfunction Get-SBOMAnalysis {\n    param([string]$SBOMFile)\n    \n    if (-not $SBOMFile) {\n        $SBOMFile = Get-ChildItem $SCRMSBOMDir -Filter 'sbom_*.json' | \n                   Sort-Object LastWriteTime -Descending | \n                   Select-Object -First 1 -ExpandProperty FullName\n    }\n    \n    if (-not $SBOMFile -or -not (Test-Path $SBOMFile)) {\n        Write-SCRMLog \"No SBOM file found. Generate one first.\" 'ERROR'\n        return\n    }\n    \n    $sbom = Get-Content $SBOMFile -Raw | ConvertFrom-Json\n    \n    # Define critical software patterns\n    $criticalPatterns = @(\n        @{ Pattern = 'Microsoft.*SQL.*Server'; Category = 'Database'; Criticality = 'Critical' },\n        @{ Pattern = 'Microsoft.*Exchange'; Category = 'Email'; Criticality = 'Critical' },\n        @{ Pattern = 'Microsoft.*Active.*Directory'; Category = 'Identity'; Criticality = 'Critical' },\n        @{ Pattern = 'VMware'; Category = 'Virtualization'; Criticality = 'High' },\n        @{ Pattern = 'Citrix'; Category = 'Remote Access'; Criticality = 'High' },\n        @{ Pattern = 'CrowdStrike|SentinelOne|Defender|Symantec|McAfee'; Category = 'Security'; Criticality = 'High' },\n        @{ Pattern = 'OpenSSL|OpenSSH'; Category = 'Cryptography'; Criticality = 'High' },\n        @{ Pattern = 'Apache|nginx|IIS'; Category = 'Web Server'; Criticality = 'High' },\n        @{ Pattern = 'Oracle.*Database|PostgreSQL|MySQL'; Category = 'Database'; Criticality = 'Critical' },\n        @{ Pattern = 'Cisco|Palo Alto|Fortinet'; Category = 'Network Security'; Criticality = 'High' }\n    )\n    \n    Write-Host \"`n=== Critical Dependency Analysis ===\" -ForegroundColor Cyan\n    Write-Host \"SBOM File: $SBOMFile\"\n    Write-Host \"Analysis Date: $(Get-Date -Format 'yyyy-MM-dd HH:mm:ss')\"\n    Write-Host \"Total Components: $($sbom.component_count)`n\"\n    \n    $findings = @()\n    foreach ($pattern in $criticalPatterns) {\n        $matches = $sbom.components | Where-Object { $_.name -match $pattern.Pattern }\n        foreach ($match in $matches) {\n            $findings += @{\n                Name = $match.name\n                Version = $match.version\n                Category = $pattern.Category\n                Criticality = $pattern.Criticality\n            }\n            \n            $color = switch ($pattern.Criticality) {\n                'Critical' { 'Red' }\n                'High' { 'Yellow' }\n                default { 'White' }\n            }\n            \n            Write-Host \"[$($pattern.Criticality.ToUpper())] $($match.name) v$($match.version)\" -ForegroundColor $color\n            Write-Host \"  Category: $($pattern.Category)  Publisher: $($match.publisher)\"\n        }\n    }\n    \n    Write-Host \"`n=== Summary ===\" -ForegroundColor Cyan\n    Write-Host \"Critical Findings: $($findings | Where-Object { $_.Criticality -eq 'Critical' } | Measure-Object | Select-Object -ExpandProperty Count)\"\n    Write-Host \"High Findings: $($findings | Where-Object { $_.Criticality -eq 'High' } | Measure-Object | Select-Object -ExpandProperty Count)\"\n    \n    return $findings\n}\n\n# Generate supplier security scorecard\nfunction New-SupplierScorecard {\n    param([Parameter(Mandatory)][string]$SupplierName)\n    \n    $scorecardFile = Join-Path $SCRMReportDir \"scorecard_$($SupplierName -replace '[^a-zA-Z0-9]','_')_$(Get-Date -Format 'yyyyMMdd').txt\"\n    \n    $scorecard = @\"\n================================================================================\nSUPPLIER SECURITY SCORECARD\n================================================================================\nSupplier: $SupplierName\nAssessment Date: $(Get-Date -Format 'yyyy-MM-dd')\nAssessor: $env:USERNAME\nSystem: $env:COMPUTERNAME\n\n--------------------------------------------------------------------------------\nSECURITY ASSESSMENT CRITERIA\n--------------------------------------------------------------------------------\n\n1. SECURITY CERTIFICATIONS\n   [ ] SOC 2 Type II (Expiration Date: ____________)\n   [ ] ISO 27001 (Expiration Date: ____________)\n   [ ] FedRAMP Authorization Level: ____________\n   [ ] PCI DSS (if applicable)\n   [ ] HIPAA (if applicable)\n   [ ] StateRAMP/TX-RAMP (if applicable)\n\n2. SECURITY POLICIES AND DOCUMENTATION\n   [ ] Information Security Policy reviewed\n   [ ] Incident Response Plan documented\n   [ ] Business Continuity Plan documented\n   [ ] Disaster Recovery Plan documented\n   [ ] Vulnerability Management Policy\n   [ ] Access Control Policy\n   [ ] Data Classification Policy\n\n3. TECHNICAL SECURITY CONTROLS\n   [ ] Encryption at rest (Algorithm: ____________)\n   [ ] Encryption in transit (TLS Version: ____________)\n   [ ] Multi-factor authentication enforced\n   [ ] Regular penetration testing (Frequency: ____________)\n   [ ] Continuous vulnerability scanning\n   [ ] Security monitoring/SIEM implemented\n   [ ] Web Application Firewall (WAF)\n   [ ] DDoS protection\n\n4. ACCESS MANAGEMENT\n   [ ] Role-based access control (RBAC)\n   [ ] Privileged access management (PAM)\n   [ ] Regular access reviews (Frequency: ____________)\n   [ ] Just-in-time access provisioning\n   [ ] Session management controls\n\n5. OPERATIONAL SECURITY\n   [ ] Background checks for employees\n   [ ] Security awareness training program\n   [ ] Secure software development lifecycle (SDLC)\n   [ ] Change management process\n   [ ] Patch management process (SLA: ____________)\n   [ ] Configuration management\n\n6. DATA PROTECTION\n   [ ] Data classification scheme implemented\n   [ ] Data retention policy defined\n   [ ] Secure data disposal procedures\n   [ ] Privacy policy compliance (GDPR/CCPA)\n   [ ] Data processing agreements in place\n   [ ] Cross-border data transfer controls\n\n7. THIRD-PARTY MANAGEMENT\n   [ ] Subprocessor list maintained and shared\n   [ ] Security requirements for subprocessors\n   [ ] Right to audit subprocessors\n   [ ] Notification of subprocessor changes\n\n8. INCIDENT MANAGEMENT\n   [ ] 24/7 security monitoring capability\n   [ ] Defined incident response process\n   [ ] Customer notification SLA: ______ hours\n   [ ] Post-incident review process\n   [ ] Evidence preservation capability\n   [ ] Forensic investigation capability\n\n--------------------------------------------------------------------------------\nRISK RATING CALCULATION\n--------------------------------------------------------------------------------\n\n| Category                | Score (1-5) | Weight | Weighted Score |\n|------------------------|-------------|--------|----------------|\n| Certifications         |             | 2      |                |\n| Policies               |             | 1.5    |                |\n| Technical Controls     |             | 2.5    |                |\n| Access Management      |             | 2      |                |\n| Operational Security   |             | 2      |                |\n| Data Protection        |             | 2      |                |\n| Third-Party Mgmt       |             | 1      |                |\n| Incident Management    |             | 2      |                |\n| TOTAL                  |             | 15     |                |\n\nWeighted Score Ranges:\n  60-75: LOW RISK\n  45-59: MODERATE RISK\n  30-44: HIGH RISK\n  0-29:  CRITICAL RISK\n\nFINAL RISK RATING: ________________\n\n--------------------------------------------------------------------------------\nKEY FINDINGS\n--------------------------------------------------------------------------------\n\nStrengths:\n1. \n2. \n3. \n\nWeaknesses:\n1. \n2. \n3. \n\n--------------------------------------------------------------------------------\nRECOMMENDATIONS\n--------------------------------------------------------------------------------\n\n1. \n2. \n3. \n\n--------------------------------------------------------------------------------\nRISK ACCEPTANCE (if applicable)\n--------------------------------------------------------------------------------\n\nRisk Description:\n\n\nBusiness Justification:\n\n\nCompensating Controls:\n\n\n--------------------------------------------------------------------------------\nAPPROVALS\n--------------------------------------------------------------------------------\n\nAssessor Signature: _________________________ Date: ____________\nReviewer Signature: _________________________ Date: ____________\nRisk Owner Signature: _______________________ Date: ____________\nExecutive Approval: _________________________ Date: ____________\n\n================================================================================\n\"@\n\n    $scorecard | Set-Content -Path $scorecardFile -Encoding UTF8\n    Write-SCRMLog \"Scorecard generated: $scorecardFile\" 'SUCCESS'\n    Write-Host \"Scorecard saved to: $scorecardFile\" -ForegroundColor Green\n}\n\n# Generate comprehensive SCRM report\nfunction New-SCRMReport {\n    $reportFile = Join-Path $SCRMReportDir \"scrm_report_$(Get-Date -Format 'yyyyMMdd_HHmmss').txt\"\n    \n    Write-SCRMLog \"Generating comprehensive SCRM report...\" 'INFO'\n    \n    $report = @\"\n================================================================================\nSUPPLY CHAIN RISK MANAGEMENT COMPLIANCE REPORT\n================================================================================\nReport Date: $(Get-Date -Format 'yyyy-MM-dd HH:mm:ss')\nGenerated By: $env:USERNAME\nSystem: $env:COMPUTERNAME\n\n--------------------------------------------------------------------------------\n1. CONTROL MAPPING\n--------------------------------------------------------------------------------\nNIST Control: PM-30.1 - Suppliers of Critical or Mission-essential Items\nControl Status: IMPLEMENTED\n\nImplemented Capabilities:\n- [x] Critical supplier registry maintained\n- [x] SBOM generation capability\n- [x] Assessment tracking and alerting\n- [x] Criticality scoring framework\n- [x] Supplier security scorecards\n- [x] Compliance reporting\n\n--------------------------------------------------------------------------------\n2. CRITICAL SUPPLIER INVENTORY\n--------------------------------------------------------------------------------\n\"@\n\n    if (Test-Path $SupplierDBPath) {\n        $database = Get-Content $SupplierDBPath -Raw | ConvertFrom-Json\n        $report += \"`nTotal Critical Suppliers: $($database.suppliers.Count)`n\"\n        \n        foreach ($supplier in $database.suppliers) {\n            $report += @\"\n\nSupplier: $($supplier.name)\n  Product/Service: $($supplier.product)\n  Criticality Score: $($supplier.criticality_score)/10\n  Risk Rating: $($supplier.risk_rating)\n  Last Assessment: $($supplier.last_assessment)\n  Status: $($supplier.status)\n\"@\n        }\n    } else {\n        $report += \"`nNo supplier database found. Initialize the system first.`n\"\n    }\n\n    $report += @\"\n\n--------------------------------------------------------------------------------\n3. SBOM STATUS\n--------------------------------------------------------------------------------\n\"@\n\n    $sbomFiles = Get-ChildItem $SCRMSBOMDir -Filter 'sbom_*.json' -ErrorAction SilentlyContinue\n    if ($sbomFiles) {\n        $report += \"SBOM Files Generated: $($sbomFiles.Count)`n\"\n        $latestSBOM = $sbomFiles | Sort-Object LastWriteTime -Descending | Select-Object -First 1\n        $report += \"Latest SBOM: $($latestSBOM.Name) ($(Get-Date $latestSBOM.LastWriteTime -Format 'yyyy-MM-dd'))`n\"\n    } else {\n        $report += \"No SBOM files found. Generate system SBOM to populate.`n\"\n    }\n\n    $report += @\"\n\n--------------------------------------------------------------------------------\n4. ASSESSMENT COMPLIANCE\n--------------------------------------------------------------------------------\n\"@\n\n    if (Test-Path $SupplierDBPath) {\n        $database = Get-Content $SupplierDBPath -Raw | ConvertFrom-Json\n        $cutoffDate = (Get-Date).AddDays(-$AssessmentFrequencyDays).ToString('yyyy-MM-dd')\n        $overdueSuppliers = $database.suppliers | Where-Object { $_.last_assessment -lt $cutoffDate }\n        $currentSuppliers = $database.suppliers | Where-Object { $_.last_assessment -ge $cutoffDate }\n        \n        $report += @\"\nAssessment Frequency Requirement: $AssessmentFrequencyDays days\nSuppliers with Current Assessment: $($currentSuppliers.Count)\nSuppliers with Overdue Assessment: $($overdueSuppliers.Count)\n\n\"@\n        \n        if ($overdueSuppliers) {\n            $report += \"OVERDUE ASSESSMENTS:`n\"\n            foreach ($supplier in $overdueSuppliers) {\n                $report += \"  - $($supplier.name): Last assessed $($supplier.last_assessment)`n\"\n            }\n        }\n    }\n\n    $report += @\"\n\n--------------------------------------------------------------------------------\n5. RECOMMENDATIONS\n--------------------------------------------------------------------------------\n- Review and update critical supplier assessments quarterly\n- Regenerate SBOMs after significant system changes\n- Conduct annual supplier risk tabletop exercises\n- Maintain current security certifications on file\n- Review supplier contracts for security clause adequacy\n- Implement continuous monitoring for critical supplier security posture\n\n--------------------------------------------------------------------------------\n6. NEXT STEPS\n--------------------------------------------------------------------------------\n[ ] Schedule overdue supplier assessments\n[ ] Review and update supplier criticality scores\n[ ] Verify SBOM accuracy against current system state\n[ ] Update supplier contracts with current security requirements\n[ ] Conduct supplier security tabletop exercise\n\n================================================================================\nEND OF REPORT\n================================================================================\n\"@\n\n    $report | Set-Content -Path $reportFile -Encoding UTF8\n    Write-SCRMLog \"SCRM report generated: $reportFile\" 'SUCCESS'\n    Write-Host \"Report saved to: $reportFile\" -ForegroundColor Green\n}\n\n# Main execution\nInitialize-SCRMDirectories\n\nswitch ($Action) {\n    'Initialize' {\n        Initialize-SupplierDatabase\n    }\n    'AddSupplier' {\n        if (-not $SupplierName -or -not $ProductService -or -not $CriticalityScore -or -not $RiskRating) {\n            Write-Host \"Usage: -Action AddSupplier -SupplierName 'Name' -ProductService 'Product' -CriticalityScore 8 -RiskRating 'Moderate'\" -ForegroundColor Yellow\n        } else {\n            Add-CriticalSupplier -Name $SupplierName -Product $ProductService -Score $CriticalityScore -Rating $RiskRating\n        }\n    }\n    'CheckStatus' {\n        Get-AssessmentStatus\n    }\n    'GenerateSBOM' {\n        New-SystemSBOM\n    }\n    'AnalyzeSBOM' {\n        Get-SBOMAnalysis\n    }\n    'GenerateScorecard' {\n        if (-not $SupplierName) {\n            Write-Host \"Usage: -Action GenerateScorecard -SupplierName 'Supplier Name'\" -ForegroundColor Yellow\n        } else {\n            New-SupplierScorecard -SupplierName $SupplierName\n        }\n    }\n    'GenerateReport' {\n        New-SCRMReport\n    }\n}\n\nWrite-Host \"`nPM-30.1 Critical Supplier Assessment Tool Complete\" -ForegroundColor Cyan"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": true
    }
  },
  {
    "control_id": "PM-31",
    "control_name": "Continuous Monitoring Strategy",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Develop an organization-wide continuous monitoring strategy and implement continuous monitoring programs that include: (a) Establishing organization-defined metrics to be monitored; (b) Establishing organization-defined frequencies for monitoring and organization-defined frequencies for assessment of control effectiveness; (c) Ongoing control assessments in accordance with the continuous monitoring strategy; (d) Ongoing status monitoring of metrics in accordance with the continuous monitoring strategy; (e) Correlation and analysis of information generated by control assessments and monitoring; (f) Response actions to address results of the analysis of control assessment and monitoring information; and (g) Reporting the security and privacy status of organizational systems to organization-defined personnel or roles at organization-defined frequencies.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "is_technical": false,
    "stig_id": null,
    "intent": "Establish systematic, ongoing monitoring of security and privacy controls to maintain awareness of organizational risk posture and enable timely response to changes.",
    "rationale": "Point-in-time security assessments provide only a snapshot of organizational security posture that quickly becomes outdated as threats evolve, systems change, and new vulnerabilities emerge. Continuous monitoring transforms security assessment from a periodic compliance exercise into an ongoing program that maintains current understanding of risk. This enables organizations to detect control degradation, identify emerging threats, track remediation progress, and make informed risk decisions based on current rather than historical data. Continuous monitoring is fundamental to risk-based security management and is required by numerous regulatory frameworks.",
    "plain_english_explanation": "This control requires organizations to develop and implement an ongoing monitoring program rather than relying solely on periodic security assessments. The program should define what metrics to track, how often to assess controls, how to analyze monitoring data, and how to respond to findings. Regular reporting keeps leadership informed about security posture. Think of it as moving from annual physicals to continuous health monitoring.",
    "example_implementation": "Deploy a continuous monitoring platform that aggregates security data from vulnerability scanners, configuration management tools, SIEM, and asset management systems. Establish dashboards showing real-time security metrics, automated alerting for control failures, and monthly executive security status reports.",
    "non_technical_guidance": "To implement PM-31: 1) Define security and privacy metrics aligned with organizational risk tolerance and regulatory requirements; 2) Establish monitoring frequencies based on asset criticality and threat landscape; 3) Deploy automated monitoring tools where possible; 4) Define processes for ongoing control assessments; 5) Establish data analysis and correlation procedures; 6) Define response procedures for monitoring findings; 7) Create reporting mechanisms for various stakeholder audiences; 8) Integrate continuous monitoring with vulnerability management and incident response processes; 9) Regularly review and adjust monitoring strategy based on effectiveness; 10) Ensure sufficient resources for sustained monitoring operations.",
    "ai_guidance": "Implementing PM-31 continuous monitoring requires a strategic framework integrated with operational security capabilities. Begin by defining the monitoring scope - what systems, controls, and metrics require continuous monitoring. Prioritize based on system criticality, data sensitivity, and regulatory requirements. Develop a comprehensive metrics framework including: vulnerability metrics (scan coverage, remediation times, age of vulnerabilities), configuration compliance rates, patch currency, access control effectiveness, incident metrics, and privacy control indicators. Establish monitoring frequencies appropriate to each metric - some require real-time monitoring while others warrant daily, weekly, or monthly assessment. Deploy automated monitoring tools including vulnerability scanners, configuration assessment tools, SIEM systems, and compliance monitoring platforms. Integrate data from multiple sources to enable correlation and pattern detection. Establish automated alerting for critical control failures or threshold breaches. Define assessment procedures for controls that cannot be fully automated, including assessment frequency, methodology, and documentation requirements. Create analysis procedures that transform raw monitoring data into actionable intelligence - this includes trend analysis, benchmarking, and root cause identification. Develop response procedures linking monitoring findings to remediation actions, including escalation criteria, remediation SLAs, and exception handling. Design reporting tailored to different audiences: operational dashboards for security teams, executive summaries for leadership, and detailed reports for audit and compliance. Establish governance processes to periodically review monitoring strategy effectiveness and adjust metrics, frequencies, and tools based on lessons learned. Ensure continuous monitoring integrates with authorization processes, enabling risk-based authorization decisions based on current rather than historical posture data. Document the continuous monitoring strategy and maintain it as threats, technologies, and organizational priorities evolve.",
    "enhancements": [],
    "related_controls": [
      "CA-2",
      "CA-5",
      "CA-6",
      "CA-7",
      "PM-6",
      "PM-9",
      "RA-3",
      "RA-5",
      "SI-4"
    ],
    "supplemental_guidance": "The continuous monitoring strategy should be risk-informed, focusing monitoring resources on the highest-risk areas. Organizations should leverage automation to the extent practical while recognizing that some control assessments require human judgment. The strategy should define how continuous monitoring data informs authorization decisions and ongoing risk management. Integration with threat intelligence enables monitoring to adapt to the evolving threat landscape.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  },
  {
    "control_id": "PM-32",
    "control_name": "Purposing",
    "family": "Program Management",
    "family_id": "PM",
    "official_text": "Analyze organization-defined systems or system components supporting mission-essential services or functions to ensure that the information resources are being used consistent with their intended purpose.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "is_technical": false,
    "stig_id": null,
    "intent": "Ensure information resources supporting critical organizational functions are used only for their designated purposes, preventing mission degradation through resource misuse or scope creep.",
    "rationale": "Systems and components supporting mission-essential functions represent critical organizational assets that must be protected from misuse, unauthorized modification, or scope expansion that could compromise their primary purpose. When resources designated for critical functions are diverted to other uses, mission capability may be degraded, security controls may be bypassed, and accountability becomes unclear. Purposing analysis ensures that critical resources maintain their intended functionality and that any changes to their use are properly authorized and assessed for impact. This control supports both operational continuity and security by maintaining clarity about what systems do and why.",
    "plain_english_explanation": "This control requires organizations to regularly verify that systems supporting critical functions are actually being used for their intended purpose. Over time, systems can experience 'scope creep' where additional functions are added, or resources may be diverted to other uses. Purposing analysis ensures that your mission-critical systems remain focused on their designated functions and that any changes to their use are intentional and properly authorized.",
    "example_implementation": "Establish an annual review process for mission-essential systems that compares current usage patterns, installed applications, and user access against the documented system purpose. Flag any deviations for review and require formal change approval for any expanded use of critical systems.",
    "non_technical_guidance": "To implement PM-32: 1) Identify all systems and components supporting mission-essential services; 2) Document the intended purpose of each critical system; 3) Define acceptable use boundaries for each system; 4) Establish periodic review processes to verify systems are used as intended; 5) Implement monitoring to detect usage outside intended purpose; 6) Create approval processes for expanding system purposes; 7) Train system administrators and users on acceptable use policies; 8) Document and investigate any detected deviations; 9) Update system documentation when purposes change; 10) Report purposing analysis results to appropriate oversight bodies.",
    "ai_guidance": "Implementing PM-32 purposing analysis requires establishing clear documentation of system purposes and mechanisms to verify adherence. Begin by identifying all systems and system components supporting mission-essential services or functions - this should align with your business impact analysis and continuity planning. For each critical system, document its intended purpose including: primary mission function supported, authorized users and use cases, acceptable applications and data types, and boundaries of acceptable use. This documentation becomes the baseline against which actual usage is compared. Implement monitoring mechanisms appropriate to each system type. For servers, this might include software inventory management, user activity monitoring, and resource utilization analysis. For network components, monitor traffic patterns and connected devices. For applications, track usage patterns, data flows, and integration points. Establish periodic review cycles - annually at minimum, more frequently for highest-criticality systems. Reviews should compare current state against documented purpose: What software is installed beyond baseline? Who has access and are they appropriate? What data is stored or processed? How is the system being used operationally? Develop a deviation handling process. Not all deviations indicate problems - legitimate business needs may require expanding system purposes. However, such changes should be formally evaluated for security impact, properly authorized, and documented. Create escalation procedures for unauthorized use or security-relevant deviations. Integrate purposing analysis with change management processes to ensure system purpose documentation is updated when authorized changes occur. Report analysis results to system owners and appropriate oversight bodies, highlighting any concerns about mission capability impact. Consider implementing technical controls that enforce purposing boundaries where feasible, such as application allowlisting on critical systems. Document all purposing analysis activities and findings to demonstrate compliance and support continuous improvement.",
    "enhancements": [],
    "related_controls": [
      "CM-7",
      "CM-8",
      "CM-11",
      "PL-2",
      "PM-11",
      "SA-3",
      "SA-8",
      "SC-2"
    ],
    "supplemental_guidance": "Purposing analysis is particularly important for systems that have been in operation for extended periods, as scope creep is more likely over time. The analysis should consider both technical aspects (installed software, configurations, data stored) and operational aspects (how users actually use the system, what business processes depend on it). Organizations should establish clear criteria for what constitutes deviation from intended purpose and appropriate response actions.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false
    }
  }
]