[
  {
    "control_id": "CP-1",
    "control_name": "Policy and Procedures",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "is_technical": false,
    "official_text": "a. Develop, document, and disseminate to [organization-defined personnel or roles]:\n  1. [Selection (one or more): organization-level; mission/business process-level; system-level] contingency planning policy that:\n    (a) Addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and\n    (b) Is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and\n  2. Procedures to facilitate the implementation of the contingency planning policy and the associated contingency planning controls;\nb. Designate an [organization-defined official] to manage the development, documentation, and dissemination of the contingency planning policy and procedures; and\nc. Review and update the current contingency planning:\n  1. Policy [organization-defined frequency] and following [organization-defined events]; and\n  2. Procedures [organization-defined frequency] and following [organization-defined events].",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": true,
      "moderate": true,
      "high": true
    },
    "plain_english_explanation": "CP-1 requires organizations to create, maintain, and distribute formal contingency planning policies and procedures. The policy must define the purpose, scope, roles, responsibilities, and how the organization will coordinate contingency planning activities. An official must be designated to oversee these documents, and both the policy and procedures must be reviewed and updated on a regular schedule and whenever significant changes occur (such as after security incidents, audits, or regulatory changes).",
    "intent": "To ensure organizations have documented contingency planning policies and procedures that guide the implementation of all other contingency planning controls (CP family), establishing clear accountability and ensuring consistent practices across the organization.",
    "ai_guidance": "For AI/ML systems implementing CP-1: Document policies addressing AI system backup strategies, model versioning and recovery procedures, training data preservation, and failover mechanisms for AI inference services. Include procedures for gracefully degrading AI capabilities during contingency events, such as switching from complex models to simpler fallback systems. Define recovery time objectives (RTOs) and recovery point objectives (RPOs) specific to AI workloads, considering the time required to restore models, retrain if necessary, and validate model integrity post-recovery. Address policies for maintaining AI ethics compliance during degraded operations.",
    "example_implementation": "Organizations should develop a comprehensive contingency planning policy document that: (1) defines contingency planning objectives aligned with business continuity requirements; (2) establishes roles such as Contingency Planning Coordinator, Business Impact Analyst, and Recovery Team Lead; (3) mandates annual policy reviews or reviews after major incidents; (4) requires documented procedures for backup, recovery, and failover operations; and (5) ensures coordination with related plans such as disaster recovery, incident response, and business continuity plans.",
    "non_technical_guidance": "To comply with CP-1:\n\n1. POLICY DEVELOPMENT:\n   - Draft a formal contingency planning policy statement signed by senior leadership\n   - Define the scope (which systems, processes, and locations are covered)\n   - Assign clear roles: Who develops plans? Who approves them? Who executes them?\n   - Ensure alignment with applicable regulations (FISMA, HIPAA, PCI-DSS, etc.)\n\n2. PROCEDURE DOCUMENTATION:\n   - Create step-by-step procedures for backup operations\n   - Document recovery procedures for each critical system\n   - Establish communication protocols for contingency events\n   - Define escalation paths and decision-making authority\n\n3. GOVERNANCE:\n   - Designate a Contingency Planning Official (typically CISO or IT Director)\n   - Establish a review schedule (at minimum annually)\n   - Define triggers for out-of-cycle reviews (incidents, audits, organizational changes)\n   - Maintain version control and distribution records\n\n4. COORDINATION:\n   - Integrate with disaster recovery planning\n   - Align with incident response procedures\n   - Coordinate with physical security and facilities management\n   - Engage with external service providers as needed",
    "enhancements": [],
    "related_controls": [
      "PM-9",
      "PS-8",
      "SI-12",
      "CP-2",
      "CP-3",
      "CP-4",
      "IR-1",
      "PL-1"
    ],
    "supplemental_guidance": "Contingency planning policy and procedures address the controls in the CP family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of contingency planning policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to contingency planning policy and procedures include assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "audit_procedures": {
      "interview_questions": [
        "Who is the designated official responsible for contingency planning policy and procedures?",
        "When was the contingency planning policy last reviewed and updated?",
        "What events trigger a review of the contingency planning policy?",
        "How are personnel made aware of their contingency planning responsibilities?",
        "How do you ensure contingency planning procedures remain current and aligned with the policy?"
      ],
      "document_requests": [
        "Current contingency planning policy document with approval signatures",
        "Contingency planning procedures documentation",
        "Evidence of policy distribution to required personnel",
        "Records of policy and procedure reviews (dates, reviewers, changes made)",
        "Designation letter or memo for the contingency planning official"
      ],
      "evidence_artifacts": [
        "Signed and dated contingency planning policy",
        "Version-controlled procedure documents",
        "Distribution acknowledgment records",
        "Review meeting minutes or sign-off sheets",
        "Policy exception and deviation logs"
      ]
    },
    "references": [
      "NIST SP 800-34 Rev 1: Contingency Planning Guide for Federal Information Systems",
      "NIST SP 800-12 Rev 1: An Introduction to Information Security",
      "NIST SP 800-53A Rev 5: Assessing Security and Privacy Controls",
      "FIPS 199: Standards for Security Categorization",
      "OMB Circular A-130: Managing Information as a Strategic Resource"
    ],
    "metadata": {
      "status": "enhanced",
      "last_updated": "2025-11-22T00:00:00.000Z",
      "has_scripts": false,
      "qa_verified": true,
      "qa_agent": "LOVELESS",
      "enhancement_notes": "Enhanced with comprehensive official text, detailed guidance, audit procedures, and AI-specific considerations per NIST SP 800-53 Rev 5"
    },
    "cac_metadata": {
      "implementation_type": "organizational",
      "last_analyzed": "2025-11-22T00:00:00.000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "CP-1 is an organizational/policy control requiring documented policies and procedures. No technical automation is applicable - compliance is demonstrated through policy documentation, designated officials, and evidence of regular reviews."
    },
    "rationale": "Without documented policies, staff won't know what's expected during emergencies. Clear rules ensure everyone responds consistently when systems fail."
  },
  {
    "control_id": "CP-2",
    "control_name": "Contingency Plan",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "official_text": "a. Develop a contingency plan for the system that: 1. Identifies essential mission and business functions and associated contingency requirements; 2. Provides recovery objectives, restoration priorities, and metrics; 3. Addresses contingency roles, responsibilities, assigned individuals with contact information; 4. Addresses maintaining essential mission and business functions despite a system disruption, compromise, or failure; 5. Addresses eventual, full system restoration without deterioration of the controls originally planned and implemented; 6. Addresses the sharing of contingency information; and 7. Is reviewed and approved by organization-defined personnel or roles; b. Distribute copies of the contingency plan to organization-defined key contingency personnel and organizational elements; c. Coordinate contingency planning activities with incident handling activities; d. Review the contingency plan for the system at organization-defined frequency; e. Update the contingency plan to address changes to the organization, system, or environment of operation and problems encountered during contingency plan implementation, execution, or testing; f. Communicate contingency plan changes to organization-defined key contingency personnel and organizational elements; g. Incorporate lessons learned from contingency plan testing, training, or actual contingency activities into contingency testing and training; and h. Protect the contingency plan from unauthorized disclosure and modification.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": true,
      "moderate": true,
      "high": true
    },
    "is_technical": false,
    "intent": "Ensure organizational resilience by establishing documented procedures for system recovery and continuity of operations during disruptions, disasters, or security incidents.",
    "plain_english_explanation": "Organizations must create and maintain a comprehensive contingency plan that outlines how to keep critical business functions running when systems fail or are compromised. This plan identifies who is responsible for what during an emergency, sets recovery time objectives, and ensures the organization can eventually restore full operations without weakening security controls. The plan must be regularly reviewed, tested, and updated based on lessons learned.",
    "ai_guidance": "AI systems implementing contingency planning should focus on automated backup verification, real-time system health monitoring, and predictive failure analysis. Implement machine learning models to identify patterns that precede system failures and trigger proactive responses. AI can assist in dynamically adjusting recovery priorities based on current business context and threat landscape. Ensure AI-driven recovery processes maintain audit trails and can explain decisions made during contingency operations for post-incident review.",
    "example_implementation": "1. Document all critical systems and their dependencies in a Configuration Management Database (CMDB). 2. Establish Recovery Time Objectives (RTO) and Recovery Point Objectives (RPO) for each critical system. 3. Create runbooks for each recovery scenario. 4. Implement automated backup verification scripts. 5. Establish communication trees and escalation procedures. 6. Conduct tabletop exercises quarterly and full-scale tests annually.",
    "non_technical_guidance": "To comply with CP-2: 1. Identify all essential business functions and the systems that support them. 2. Document recovery priorities - which systems must be restored first. 3. Assign specific individuals to contingency roles with clear responsibilities. 4. Establish communication procedures for emergencies. 5. Store contingency plan copies in secure, accessible locations. 6. Review the plan annually or after significant changes. 7. Train all personnel on their contingency responsibilities.",
    "enhancements": [
      {
        "id": "CP-2.1",
        "title": "Coordinate with Related Plans",
        "official_text": "Coordinate contingency plan development with organizational elements responsible for related plans."
      },
      {
        "id": "CP-2.2",
        "title": "Capacity Planning",
        "official_text": "Conduct capacity planning so that necessary capacity for information processing, telecommunications, and environmental support exists during contingency operations."
      },
      {
        "id": "CP-2.3",
        "title": "Resume Mission and Business Functions",
        "official_text": "Plan for the resumption of essential mission and business functions within organization-defined time period of contingency plan activation."
      },
      {
        "id": "CP-2.4",
        "title": "Resume All Mission and Business Functions",
        "official_text": "Plan for the resumption of all mission and business functions within organization-defined time period of contingency plan activation."
      },
      {
        "id": "CP-2.5",
        "title": "Continue Mission and Business Functions",
        "official_text": "Plan for the continuance of essential mission and business functions with minimal or no loss of operational continuity and sustain that continuity until full system restoration at primary processing and/or storage sites."
      },
      {
        "id": "CP-2.6",
        "title": "Alternate Processing and Storage Sites",
        "official_text": "Plan for the transfer of essential mission and business functions to alternate processing and/or storage sites with minimal or no loss of operational continuity and sustain that continuity through system restoration to primary processing and/or storage sites."
      },
      {
        "id": "CP-2.7",
        "title": "Coordinate with External Service Providers",
        "official_text": "Coordinate the contingency plan with the contingency plans of external service providers to ensure that contingency requirements can be satisfied."
      },
      {
        "id": "CP-2.8",
        "title": "Identify Critical Assets",
        "official_text": "Identify critical system assets supporting essential mission and business functions."
      }
    ],
    "related_controls": [
      "CP-3",
      "CP-4",
      "CP-6",
      "CP-7",
      "CP-8",
      "CP-9",
      "CP-10",
      "CP-11",
      "IR-4",
      "IR-6",
      "IR-8",
      "PM-8",
      "PM-11"
    ],
    "supplemental_guidance": "Contingency planning for systems is part of an overall program for achieving continuity of operations for organizational mission and business functions. Contingency planning addresses system restoration and implementation of alternative mission or business processes when systems are compromised or breached.",
    "implementation_scripts": {
      "linux": {
        "bash": "#!/bin/bash\n# CP-2: Contingency Plan Verification Script\n# Verifies backup systems and documents contingency readiness\n\nLOG_FILE=\"/var/log/contingency_plan_check.log\"\nDATE=$(date '+%Y-%m-%d %H:%M:%S')\n\necho \"[$DATE] Starting CP-2 Contingency Plan Verification\" | tee -a \"$LOG_FILE\"\n\n# Check backup service status\necho \"Checking backup services...\" | tee -a \"$LOG_FILE\"\nfor service in rsync cron; do\n    if systemctl is-active --quiet $service 2>/dev/null; then\n        echo \"[PASS] $service is running\" | tee -a \"$LOG_FILE\"\n    else\n        echo \"[WARN] $service is not running\" | tee -a \"$LOG_FILE\"\n    fi\ndone\n\n# Verify backup directories exist\nBACKUP_DIRS=(\"/backup\" \"/var/backup\" \"/opt/backup\")\nfor dir in \"${BACKUP_DIRS[@]}\"; do\n    if [ -d \"$dir\" ]; then\n        BACKUP_SIZE=$(du -sh \"$dir\" 2>/dev/null | cut -f1)\n        echo \"[INFO] Backup directory $dir exists (Size: $BACKUP_SIZE)\" | tee -a \"$LOG_FILE\"\n    fi\ndone\n\n# Check for contingency plan documentation\nDOC_LOCATIONS=(\"/etc/contingency\" \"/opt/docs/contingency\" \"/var/lib/contingency\")\nfor loc in \"${DOC_LOCATIONS[@]}\"; do\n    if [ -d \"$loc\" ]; then\n        DOC_COUNT=$(find \"$loc\" -type f -name \"*.md\" -o -name \"*.pdf\" -o -name \"*.doc*\" 2>/dev/null | wc -l)\n        echo \"[INFO] Found $DOC_COUNT contingency documents in $loc\" | tee -a \"$LOG_FILE\"\n    fi\ndone\n\n# Check last backup timestamp\nif [ -f \"/var/log/backup.log\" ]; then\n    LAST_BACKUP=$(tail -1 /var/log/backup.log 2>/dev/null)\n    echo \"[INFO] Last backup entry: $LAST_BACKUP\" | tee -a \"$LOG_FILE\"\nfi\n\necho \"[$DATE] CP-2 Verification Complete\" | tee -a \"$LOG_FILE\"",
        "ansible": "---\n# CP-2: Contingency Plan Implementation Playbook\n- name: CP-2 Contingency Plan Setup and Verification\n  hosts: all\n  become: yes\n  vars:\n    backup_dir: /var/backup\n    contingency_doc_dir: /etc/contingency\n    log_file: /var/log/contingency_plan.log\n\n  tasks:\n    - name: Create contingency documentation directory\n      file:\n        path: \"{{ contingency_doc_dir }}\"\n        state: directory\n        mode: '0750'\n        owner: root\n        group: root\n\n    - name: Create backup directory structure\n      file:\n        path: \"{{ backup_dir }}\"\n        state: directory\n        mode: '0700'\n        owner: root\n        group: root\n\n    - name: Ensure rsync is installed for backups\n      package:\n        name: rsync\n        state: present\n\n    - name: Ensure cron service is running\n      service:\n        name: cron\n        state: started\n        enabled: yes\n      ignore_errors: yes\n\n    - name: Ensure crond service is running (RHEL/CentOS)\n      service:\n        name: crond\n        state: started\n        enabled: yes\n      ignore_errors: yes\n\n    - name: Create contingency plan template\n      copy:\n        dest: \"{{ contingency_doc_dir }}/contingency_plan_template.md\"\n        content: |\n          # System Contingency Plan\n          \n          ## Document Control\n          - Version: 1.0\n          - Last Updated: {{ ansible_date_time.date }}\n          - Next Review: [ANNUAL REVIEW REQUIRED]\n          \n          ## 1. Essential Mission Functions\n          [Document critical business functions here]\n          \n          ## 2. Recovery Objectives\n          - RTO: [Define Recovery Time Objective]\n          - RPO: [Define Recovery Point Objective]\n          \n          ## 3. Contingency Roles\n          [List personnel and responsibilities]\n          \n          ## 4. Contact Information\n          [Emergency contacts]\n          \n          ## 5. Recovery Procedures\n          [Step-by-step recovery procedures]\n          \n          ## 6. Communication Plan\n          [Stakeholder notification procedures]\n        mode: '0640'\n        owner: root\n        group: root\n\n    - name: Log contingency plan verification\n      lineinfile:\n        path: \"{{ log_file }}\"\n        line: \"{{ ansible_date_time.iso8601 }} - CP-2 contingency plan infrastructure verified\"\n        create: yes\n        mode: '0640'"
      },
      "windows": {
        "powershell": "# CP-2: Contingency Plan Verification Script for Windows\n# Verifies backup systems and documents contingency readiness\n\n$LogFile = \"C:\\Windows\\Logs\\ContingencyPlanCheck.log\"\n$Date = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n\nfunction Write-Log {\n    param([string]$Message)\n    $LogEntry = \"[$Date] $Message\"\n    Add-Content -Path $LogFile -Value $LogEntry\n    Write-Host $LogEntry\n}\n\nWrite-Log \"Starting CP-2 Contingency Plan Verification\"\n\n# Check Windows Backup Service\n$BackupService = Get-Service -Name \"wbengine\" -ErrorAction SilentlyContinue\nif ($BackupService) {\n    if ($BackupService.Status -eq \"Running\") {\n        Write-Log \"[PASS] Windows Backup Engine is running\"\n    } else {\n        Write-Log \"[WARN] Windows Backup Engine is not running (Status: $($BackupService.Status))\"\n    }\n} else {\n    Write-Log \"[INFO] Windows Backup Engine service not found\"\n}\n\n# Check Volume Shadow Copy Service\n$VSSService = Get-Service -Name \"VSS\" -ErrorAction SilentlyContinue\nif ($VSSService.Status -eq \"Running\" -or $VSSService.Status -eq \"Stopped\") {\n    Write-Log \"[PASS] Volume Shadow Copy Service available (Status: $($VSSService.Status))\"\n}\n\n# Check for backup locations\n$BackupPaths = @(\"D:\\Backup\", \"E:\\Backup\", \"C:\\Backup\", \"\\\\backup-server\\backups\")\nforeach ($Path in $BackupPaths) {\n    if (Test-Path $Path) {\n        $Size = (Get-ChildItem $Path -Recurse -ErrorAction SilentlyContinue | Measure-Object -Property Length -Sum).Sum / 1GB\n        Write-Log \"[INFO] Backup location found: $Path (Size: $([math]::Round($Size,2)) GB)\"\n    }\n}\n\n# Check Windows Server Backup feature\n$WSBFeature = Get-WindowsFeature -Name Windows-Server-Backup -ErrorAction SilentlyContinue\nif ($WSBFeature -and $WSBFeature.Installed) {\n    Write-Log \"[PASS] Windows Server Backup feature is installed\"\n    \n    # Check last backup status\n    try {\n        $LastBackup = Get-WBSummary -ErrorAction SilentlyContinue\n        if ($LastBackup) {\n            Write-Log \"[INFO] Last successful backup: $($LastBackup.LastSuccessfulBackupTime)\"\n        }\n    } catch {\n        Write-Log \"[INFO] Unable to retrieve backup summary\"\n    }\n}\n\n# Check for contingency documentation\n$DocPaths = @(\"C:\\Contingency\", \"C:\\IT\\Contingency\", \"D:\\Documentation\\Contingency\")\nforeach ($Path in $DocPaths) {\n    if (Test-Path $Path) {\n        $DocCount = (Get-ChildItem $Path -Recurse -Include *.docx,*.pdf,*.md -ErrorAction SilentlyContinue).Count\n        Write-Log \"[INFO] Found $DocCount contingency documents in $Path\"\n    }\n}\n\nWrite-Log \"CP-2 Verification Complete\"",
        "ansible": "---\n# CP-2: Contingency Plan Implementation Playbook for Windows\n- name: CP-2 Contingency Plan Setup and Verification for Windows\n  hosts: windows\n  gather_facts: yes\n  vars:\n    backup_dir: C:\\Backup\n    contingency_doc_dir: C:\\Contingency\n    log_file: C:\\Windows\\Logs\\ContingencyPlan.log\n\n  tasks:\n    - name: Create contingency documentation directory\n      win_file:\n        path: \"{{ contingency_doc_dir }}\"\n        state: directory\n\n    - name: Create backup directory\n      win_file:\n        path: \"{{ backup_dir }}\"\n        state: directory\n\n    - name: Ensure Windows Backup feature is installed\n      win_feature:\n        name: Windows-Server-Backup\n        state: present\n      register: backup_feature\n      ignore_errors: yes\n\n    - name: Check Volume Shadow Copy service\n      win_service:\n        name: VSS\n        start_mode: manual\n      register: vss_service\n\n    - name: Create contingency plan template document\n      win_copy:\n        dest: \"{{ contingency_doc_dir }}\\\\ContingencyPlanTemplate.txt\"\n        content: |\n          SYSTEM CONTINGENCY PLAN\n          =======================\n          \n          Document Control\n          ----------------\n          Version: 1.0\n          Last Updated: {{ ansible_date_time.date }}\n          Next Review: [ANNUAL REVIEW REQUIRED]\n          \n          1. ESSENTIAL MISSION FUNCTIONS\n          [Document critical business functions]\n          \n          2. RECOVERY OBJECTIVES\n          - RTO: [Define Recovery Time Objective]\n          - RPO: [Define Recovery Point Objective]\n          \n          3. CONTINGENCY ROLES AND RESPONSIBILITIES\n          [List personnel and responsibilities]\n          \n          4. EMERGENCY CONTACT INFORMATION\n          [Key contacts for emergencies]\n          \n          5. RECOVERY PROCEDURES\n          [Step-by-step recovery instructions]\n          \n          6. COMMUNICATION PLAN\n          [Stakeholder notification procedures]\n\n    - name: Log contingency plan verification\n      win_lineinfile:\n        path: \"{{ log_file }}\"\n        line: \"{{ ansible_date_time.iso8601 }} - CP-2 contingency plan infrastructure verified\"\n        create: yes"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true
    },
    "cac_metadata": {
      "implementation_type": "hybrid",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "CP-2 is primarily an organizational control requiring documented contingency plans. Technical components include backup system configuration, recovery procedure automation, and contingency plan documentation management."
    },
    "rationale": "A written plan ensures you know exactly what to do when disaster strikes. Without it, recovery becomes chaotic and takes longer."
  },
  {
    "control_id": "CP-2.1",
    "control_name": "Coordinate with Related Plans",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "parent_control": "CP-2",
    "official_text": "Coordinate contingency plan development with organizational elements responsible for related plans.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": true,
      "high": true
    },
    "is_technical": false,
    "intent": "Ensure contingency planning efforts are synchronized with other organizational plans such as business continuity plans, disaster recovery plans, incident response plans, and occupant emergency plans to avoid conflicts and gaps.",
    "plain_english_explanation": "Your contingency plan should not exist in isolation. Coordinate with teams responsible for other plans like business continuity, disaster recovery, communications, and facility emergency plans. This ensures all plans work together without conflicts and that resources are not double-allocated during emergencies.",
    "ai_guidance": "AI systems can assist in plan coordination by analyzing multiple plan documents for conflicts, overlapping resource allocations, or gaps in coverage. Natural language processing can identify inconsistencies between plans and flag potential coordination issues. Implement automated workflows to notify relevant stakeholders when contingency plans are updated, ensuring related plans are reviewed for alignment. AI can also model emergency scenarios to test how well different plans integrate during simulated events.",
    "example_implementation": "1. Establish a cross-functional planning committee with representatives from IT, facilities, HR, communications, and business units. 2. Create a master planning calendar showing review dates for all related plans. 3. Use a common template structure across all plans to facilitate comparison. 4. Implement change management processes that trigger plan reviews when related plans are updated.",
    "non_technical_guidance": "To comply with CP-2.1: 1. Identify all related plans in your organization (business continuity, disaster recovery, incident response, COOP, facility emergency). 2. Meet regularly with owners of these plans to discuss dependencies. 3. Ensure your contingency plan references related plans and does not conflict with them. 4. When updating your plan, notify owners of related plans. 5. Participate in joint exercises that test multiple plans together.",
    "enhancements": [],
    "related_controls": [
      "CP-2",
      "CP-4",
      "IR-8",
      "PM-8",
      "PM-11"
    ],
    "supplemental_guidance": "Related plans include Business Continuity Plans, Disaster Recovery Plans, Critical Infrastructure Plans, Continuity of Operations Plans, Crisis Communications Plans, and Occupant Emergency Plans.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": false,
      "qa_verified": true
    },
    "cac_metadata": {
      "implementation_type": "organizational",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "This control is organizational in nature requiring coordination between planning teams. No technical automation available - requires documented coordination procedures and regular stakeholder meetings."
    },
    "rationale": "Your contingency plan must align with other plans (incident response, disaster recovery) to avoid conflicting actions during a crisis."
  },
  {
    "control_id": "CP-2.2",
    "control_name": "Capacity Planning",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "parent_control": "CP-2",
    "official_text": "Conduct capacity planning so that necessary capacity for information processing, telecommunications, and environmental support exists during contingency operations.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": true
    },
    "is_technical": true,
    "intent": "Ensure that alternate processing sites, backup systems, and recovery infrastructure have sufficient capacity to support essential operations during a contingency event.",
    "plain_english_explanation": "When your primary systems fail, your backup and recovery systems need enough capacity to handle the workload. This means planning for adequate processing power, network bandwidth, storage, and physical infrastructure like power and cooling at alternate sites. Without proper capacity planning, your contingency site might be overwhelmed when you need it most.",
    "ai_guidance": "AI systems can significantly enhance capacity planning through predictive analytics that forecast resource requirements based on historical patterns and growth trends. Implement machine learning models to analyze peak usage periods and ensure contingency infrastructure can handle worst-case scenarios. AI can continuously monitor current utilization against contingency capacity thresholds and alert when gaps emerge. Use simulation models to stress-test contingency infrastructure before actual emergencies occur.",
    "example_implementation": "1. Document current production workloads including CPU, memory, storage, and network utilization. 2. Size alternate site infrastructure to handle at least 100% of essential workloads. 3. Implement automated scaling capabilities at contingency sites. 4. Conduct quarterly capacity reviews comparing production growth to contingency capacity. 5. Test failover scenarios under realistic load conditions.",
    "non_technical_guidance": "To comply with CP-2.2: 1. Inventory all essential systems and their resource requirements. 2. Document minimum capacity needed to sustain critical operations. 3. Ensure alternate sites have sufficient infrastructure. 4. Consider telecommunications bandwidth to alternate sites. 5. Plan for environmental needs (power, cooling, physical space). 6. Review capacity requirements annually as workloads grow.",
    "enhancements": [],
    "related_controls": [
      "CP-2",
      "CP-7",
      "CP-8",
      "PE-11",
      "SC-5"
    ],
    "supplemental_guidance": "Capacity planning for contingency operations addresses the need to ensure that sufficient capacity exists to support critical missions and business functions during contingency operations.",
    "implementation_scripts": {
      "linux": {
        "bash": "#!/bin/bash\n# CP-2.2: Capacity Planning Assessment Script\n# Documents current system capacity for contingency planning\n\nOUTPUT_FILE=\"/var/log/capacity_assessment_$(date +%Y%m%d).log\"\necho \"=== CP-2.2 Capacity Assessment Report ===\"  | tee \"$OUTPUT_FILE\"\necho \"Generated: $(date)\" | tee -a \"$OUTPUT_FILE\"\necho \"\" | tee -a \"$OUTPUT_FILE\"\n\n# CPU Capacity\necho \"=== CPU CAPACITY ===\" | tee -a \"$OUTPUT_FILE\"\nCPU_CORES=$(nproc)\nCPU_MODEL=$(grep 'model name' /proc/cpuinfo | head -1 | cut -d':' -f2 | xargs)\nCPU_LOAD=$(uptime | awk -F'load average:' '{print $2}')\necho \"CPU Cores: $CPU_CORES\" | tee -a \"$OUTPUT_FILE\"\necho \"CPU Model: $CPU_MODEL\" | tee -a \"$OUTPUT_FILE\"\necho \"Current Load Average: $CPU_LOAD\" | tee -a \"$OUTPUT_FILE\"\necho \"\" | tee -a \"$OUTPUT_FILE\"\n\n# Memory Capacity\necho \"=== MEMORY CAPACITY ===\" | tee -a \"$OUTPUT_FILE\"\nfree -h | tee -a \"$OUTPUT_FILE\"\necho \"\" | tee -a \"$OUTPUT_FILE\"\n\n# Storage Capacity\necho \"=== STORAGE CAPACITY ===\" | tee -a \"$OUTPUT_FILE\"\ndf -h | grep -E '^/dev/' | tee -a \"$OUTPUT_FILE\"\necho \"\" | tee -a \"$OUTPUT_FILE\"\n\n# Network Capacity\necho \"=== NETWORK INTERFACES ===\" | tee -a \"$OUTPUT_FILE\"\nip -br addr show | tee -a \"$OUTPUT_FILE\"\necho \"\" | tee -a \"$OUTPUT_FILE\"\n\n# Running Services\necho \"=== CRITICAL SERVICES ===\" | tee -a \"$OUTPUT_FILE\"\nfor svc in sshd httpd nginx postgresql mysql docker; do\n    if systemctl is-active --quiet $svc 2>/dev/null; then\n        MEM=$(systemctl show $svc --property=MemoryCurrent 2>/dev/null | cut -d'=' -f2)\n        echo \"[ACTIVE] $svc (Memory: $MEM)\" | tee -a \"$OUTPUT_FILE\"\n    fi\ndone\n\necho \"\" | tee -a \"$OUTPUT_FILE\"\necho \"=== CAPACITY SUMMARY FOR CONTINGENCY PLANNING ===\" | tee -a \"$OUTPUT_FILE\"\necho \"Minimum contingency site requirements:\" | tee -a \"$OUTPUT_FILE\"\necho \"  - CPU: $CPU_CORES cores or equivalent\" | tee -a \"$OUTPUT_FILE\"\nMEM_TOTAL=$(free -g | awk '/Mem:/{print $2}')\necho \"  - Memory: ${MEM_TOTAL}GB minimum\" | tee -a \"$OUTPUT_FILE\"\nDISK_TOTAL=$(df -BG / | awk 'NR==2{print $2}')\necho \"  - Storage: $DISK_TOTAL minimum\" | tee -a \"$OUTPUT_FILE\"\n\necho \"\" | tee -a \"$OUTPUT_FILE\"\necho \"Assessment complete. Review $OUTPUT_FILE for contingency capacity requirements.\"",
        "ansible": "---\n# CP-2.2: Capacity Planning Assessment Playbook\n- name: CP-2.2 Capacity Planning Assessment\n  hosts: all\n  become: yes\n  vars:\n    report_dir: /var/log/capacity_reports\n\n  tasks:\n    - name: Create report directory\n      file:\n        path: \"{{ report_dir }}\"\n        state: directory\n        mode: '0750'\n\n    - name: Gather system facts\n      setup:\n        gather_subset:\n          - hardware\n          - network\n          - virtual\n\n    - name: Document CPU capacity\n      set_fact:\n        cpu_capacity:\n          cores: \"{{ ansible_processor_vcpus }}\"\n          architecture: \"{{ ansible_architecture }}\"\n          model: \"{{ ansible_processor[2] | default('Unknown') }}\"\n\n    - name: Document memory capacity\n      set_fact:\n        memory_capacity:\n          total_mb: \"{{ ansible_memtotal_mb }}\"\n          free_mb: \"{{ ansible_memfree_mb }}\"\n\n    - name: Get disk capacity\n      shell: df -BG --output=size,used,avail,pcent,target | grep -E '^[0-9]'\n      register: disk_info\n      changed_when: false\n\n    - name: Generate capacity report\n      copy:\n        dest: \"{{ report_dir }}/capacity_{{ ansible_hostname }}_{{ ansible_date_time.date }}.txt\"\n        content: |\n          CP-2.2 CAPACITY PLANNING REPORT\n          ================================\n          Host: {{ ansible_hostname }}\n          Date: {{ ansible_date_time.iso8601 }}\n          \n          CPU CAPACITY\n          ------------\n          Cores: {{ cpu_capacity.cores }}\n          Architecture: {{ cpu_capacity.architecture }}\n          Model: {{ cpu_capacity.model }}\n          \n          MEMORY CAPACITY\n          ---------------\n          Total: {{ memory_capacity.total_mb }} MB\n          Free: {{ memory_capacity.free_mb }} MB\n          \n          STORAGE CAPACITY\n          ----------------\n          {{ disk_info.stdout }}\n          \n          CONTINGENCY SITE REQUIREMENTS\n          -----------------------------\n          Minimum CPU: {{ cpu_capacity.cores }} cores\n          Minimum RAM: {{ memory_capacity.total_mb }} MB\n          \n          This report should be used for contingency site capacity planning.\n        mode: '0640'\n\n    - name: Display capacity summary\n      debug:\n        msg: \"Capacity report generated for {{ ansible_hostname }}: CPU={{ cpu_capacity.cores }} cores, RAM={{ memory_capacity.total_mb }}MB\""
      },
      "windows": {
        "powershell": "# CP-2.2: Capacity Planning Assessment Script for Windows\n# Documents current system capacity for contingency planning\n\n$ReportPath = \"C:\\Windows\\Logs\\CapacityAssessment_$(Get-Date -Format 'yyyyMMdd').txt\"\n$Report = @()\n\n$Report += \"=== CP-2.2 CAPACITY PLANNING ASSESSMENT ===\"\n$Report += \"Generated: $(Get-Date)\"\n$Report += \"Computer: $env:COMPUTERNAME\"\n$Report += \"\"\n\n# CPU Capacity\n$Report += \"=== CPU CAPACITY ===\"\n$CPU = Get-WmiObject Win32_Processor\n$Report += \"Processor: $($CPU.Name)\"\n$Report += \"Cores: $($CPU.NumberOfCores)\"\n$Report += \"Logical Processors: $($CPU.NumberOfLogicalProcessors)\"\n$Report += \"Max Clock Speed: $($CPU.MaxClockSpeed) MHz\"\n$Report += \"Current Load: $($CPU.LoadPercentage)%\"\n$Report += \"\"\n\n# Memory Capacity\n$Report += \"=== MEMORY CAPACITY ===\"\n$Memory = Get-WmiObject Win32_ComputerSystem\n$MemoryGB = [math]::Round($Memory.TotalPhysicalMemory / 1GB, 2)\n$Report += \"Total Physical Memory: $MemoryGB GB\"\n\n$FreeMemory = Get-WmiObject Win32_OperatingSystem\n$FreeMemoryGB = [math]::Round($FreeMemory.FreePhysicalMemory / 1MB, 2)\n$Report += \"Free Physical Memory: $FreeMemoryGB GB\"\n$Report += \"\"\n\n# Storage Capacity\n$Report += \"=== STORAGE CAPACITY ===\"\n$Disks = Get-WmiObject Win32_LogicalDisk -Filter \"DriveType=3\"\nforeach ($Disk in $Disks) {\n    $TotalGB = [math]::Round($Disk.Size / 1GB, 2)\n    $FreeGB = [math]::Round($Disk.FreeSpace / 1GB, 2)\n    $UsedPercent = [math]::Round((($Disk.Size - $Disk.FreeSpace) / $Disk.Size) * 100, 1)\n    $Report += \"Drive $($Disk.DeviceID): Total=$TotalGB GB, Free=$FreeGB GB, Used=$UsedPercent%\"\n}\n$Report += \"\"\n\n# Network Capacity\n$Report += \"=== NETWORK ADAPTERS ===\"\n$Adapters = Get-NetAdapter | Where-Object { $_.Status -eq 'Up' }\nforeach ($Adapter in $Adapters) {\n    $Speed = $Adapter.LinkSpeed\n    $Report += \"$($Adapter.Name): $Speed\"\n}\n$Report += \"\"\n\n# Critical Services\n$Report += \"=== CRITICAL SERVICES ===\"\n$CriticalServices = @('W32Time', 'Dnscache', 'LanmanServer', 'LanmanWorkstation', 'EventLog', 'Winmgmt')\nforeach ($SvcName in $CriticalServices) {\n    $Svc = Get-Service -Name $SvcName -ErrorAction SilentlyContinue\n    if ($Svc) {\n        $Report += \"[$($Svc.Status)] $($Svc.DisplayName)\"\n    }\n}\n$Report += \"\"\n\n# Contingency Requirements Summary\n$Report += \"=== CONTINGENCY SITE REQUIREMENTS ===\"\n$Report += \"Based on current system capacity:\"\n$Report += \"  - Minimum CPU: $($CPU.NumberOfCores) cores\"\n$Report += \"  - Minimum RAM: $MemoryGB GB\"\n$TotalStorageGB = ($Disks | Measure-Object -Property Size -Sum).Sum / 1GB\n$Report += \"  - Minimum Storage: $([math]::Round($TotalStorageGB, 0)) GB\"\n$Report += \"\"\n$Report += \"Use this report for contingency site capacity planning.\"\n\n# Write report\n$Report | Out-File -FilePath $ReportPath -Encoding UTF8\nWrite-Host \"Capacity assessment report saved to: $ReportPath\"\nWrite-Host \"\"\n$Report | ForEach-Object { Write-Host $_ }",
        "ansible": "---\n# CP-2.2: Capacity Planning Assessment Playbook for Windows\n- name: CP-2.2 Capacity Planning Assessment for Windows\n  hosts: windows\n  gather_facts: yes\n  vars:\n    report_dir: C:\\Logs\\CapacityReports\n\n  tasks:\n    - name: Create report directory\n      win_file:\n        path: \"{{ report_dir }}\"\n        state: directory\n\n    - name: Get CPU information\n      win_shell: |\n        $cpu = Get-WmiObject Win32_Processor\n        @{\n          Name = $cpu.Name\n          Cores = $cpu.NumberOfCores\n          LogicalProcessors = $cpu.NumberOfLogicalProcessors\n        } | ConvertTo-Json\n      register: cpu_info\n\n    - name: Get memory information\n      win_shell: |\n        $mem = Get-WmiObject Win32_ComputerSystem\n        @{\n          TotalGB = [math]::Round($mem.TotalPhysicalMemory / 1GB, 2)\n        } | ConvertTo-Json\n      register: mem_info\n\n    - name: Get disk information\n      win_shell: |\n        Get-WmiObject Win32_LogicalDisk -Filter \"DriveType=3\" | ForEach-Object {\n          @{\n            Drive = $_.DeviceID\n            TotalGB = [math]::Round($_.Size / 1GB, 2)\n            FreeGB = [math]::Round($_.FreeSpace / 1GB, 2)\n          }\n        } | ConvertTo-Json\n      register: disk_info\n\n    - name: Generate capacity report\n      win_copy:\n        dest: \"{{ report_dir }}\\\\Capacity_{{ ansible_hostname }}_{{ ansible_date_time.date }}.txt\"\n        content: |\n          CP-2.2 CAPACITY PLANNING REPORT\n          ================================\n          Host: {{ ansible_hostname }}\n          Date: {{ ansible_date_time.iso8601 }}\n          \n          CPU: {{ cpu_info.stdout | from_json | json_query('Cores') }} cores\n          Memory: {{ mem_info.stdout | from_json | json_query('TotalGB') }} GB\n          \n          Use for contingency site planning."
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true
    },
    "cac_metadata": {
      "implementation_type": "hybrid",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Capacity planning requires both organizational planning and technical assessment. Scripts can automate capacity documentation but planning decisions require human judgment."
    },
    "rationale": "If you don't plan for capacity needs during recovery, your backup systems may be overwhelmed when everyone tries to use them at once."
  },
  {
    "control_id": "CP-2.3",
    "control_name": "Resume Mission and Business Functions",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "parent_control": "CP-2",
    "official_text": "Plan for the resumption of essential mission and business functions within organization-defined time period of contingency plan activation.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": true,
      "high": true
    },
    "is_technical": true,
    "intent": "Define specific recovery time objectives for essential functions and ensure the contingency plan can achieve those objectives.",
    "plain_english_explanation": "Your contingency plan must specify how quickly essential business functions will be restored after an incident. This is your Recovery Time Objective (RTO). For example, email might need to be restored within 4 hours, while financial systems might need to be back within 2 hours. The plan must include procedures that can actually meet these timeframes.",
    "ai_guidance": "AI can optimize recovery sequencing by analyzing dependencies between systems and business functions, ensuring the most critical functions are restored first within defined RTOs. Machine learning models can predict realistic recovery times based on historical incident data and current system states. Implement AI-driven runbook automation that can execute recovery procedures with minimal human intervention, reducing recovery time. AI monitoring should continuously validate that recovery procedures remain capable of meeting defined RTOs.",
    "example_implementation": "1. Conduct Business Impact Analysis (BIA) to determine RTOs for each essential function. 2. Document recovery procedures with estimated completion times. 3. Implement automated recovery scripts where possible. 4. Conduct recovery exercises and measure actual recovery times. 5. Refine procedures to meet or exceed RTOs. 6. Report recovery time metrics to management.",
    "non_technical_guidance": "To comply with CP-2.3: 1. Define which mission functions are essential (cannot wait for normal restoration). 2. Assign specific time objectives for resuming each essential function. 3. Document step-by-step procedures to achieve those timeframes. 4. Identify resources required for rapid recovery. 5. Test regularly to verify you can meet the objectives. 6. Adjust plans if testing shows objectives cannot be met.",
    "enhancements": [],
    "related_controls": [
      "CP-2",
      "CP-4",
      "CP-7",
      "CP-10"
    ],
    "supplemental_guidance": "Organizations may define different time periods for resuming different mission and business functions. Essential mission and business functions are those that are the core of the organization's mission.",
    "implementation_scripts": {
      "linux": {
        "bash": "#!/bin/bash\n# CP-2.3: Essential Function Recovery Time Tracking\n# Tracks and reports on recovery objectives for essential services\n\nLOG_FILE=\"/var/log/recovery_tracking.log\"\nRTO_CONFIG=\"/etc/contingency/rto_objectives.conf\"\nDATE=$(date '+%Y-%m-%d %H:%M:%S')\n\n# Sample RTO configuration (in minutes)\ndeclare -A RTO_TARGETS\nRTO_TARGETS[\"database\"]=60\nRTO_TARGETS[\"webserver\"]=30\nRTO_TARGETS[\"fileserver\"]=120\nRTO_TARGETS[\"email\"]=240\n\necho \"[$DATE] CP-2.3 Recovery Objective Assessment\" | tee \"$LOG_FILE\"\necho \"=========================================\" | tee -a \"$LOG_FILE\"\n\n# Check essential services and their recovery readiness\nfor service in database webserver fileserver email; do\n    RTO=${RTO_TARGETS[$service]}\n    \n    case $service in\n        database)\n            SVC_NAME=\"postgresql mysql mariadb\"\n            ;;\n        webserver)\n            SVC_NAME=\"httpd nginx apache2\"\n            ;;\n        fileserver)\n            SVC_NAME=\"nfs-server smbd\"\n            ;;\n        email)\n            SVC_NAME=\"postfix dovecot\"\n            ;;\n    esac\n    \n    RUNNING=false\n    for svc in $SVC_NAME; do\n        if systemctl is-active --quiet $svc 2>/dev/null; then\n            RUNNING=true\n            echo \"[INFO] $service ($svc): RUNNING - RTO Target: ${RTO} minutes\" | tee -a \"$LOG_FILE\"\n            break\n        fi\n    done\n    \n    if [ \"$RUNNING\" = false ]; then\n        echo \"[WARN] $service: NOT RUNNING - RTO Target: ${RTO} minutes - Recovery may be needed\" | tee -a \"$LOG_FILE\"\n    fi\ndone\n\necho \"\" | tee -a \"$LOG_FILE\"\necho \"Recovery Time Objectives Summary:\" | tee -a \"$LOG_FILE\"\nfor service in \"${!RTO_TARGETS[@]}\"; do\n    echo \"  - $service: ${RTO_TARGETS[$service]} minutes\" | tee -a \"$LOG_FILE\"\ndone\n\necho \"\" | tee -a \"$LOG_FILE\"\necho \"[$DATE] Assessment complete. Review RTOs and ensure recovery procedures can meet objectives.\" | tee -a \"$LOG_FILE\"",
        "ansible": "---\n# CP-2.3: Recovery Time Objective Management Playbook\n- name: CP-2.3 Recovery Time Objective Assessment\n  hosts: all\n  become: yes\n  vars:\n    rto_objectives:\n      - name: database\n        services:\n          - postgresql\n          - mysql\n          - mariadb\n        rto_minutes: 60\n        priority: 1\n      - name: webserver\n        services:\n          - httpd\n          - nginx\n          - apache2\n        rto_minutes: 30\n        priority: 2\n      - name: application\n        services:\n          - tomcat\n          - nodejs\n        rto_minutes: 45\n        priority: 3\n    report_file: /var/log/rto_assessment.log\n\n  tasks:\n    - name: Create RTO configuration directory\n      file:\n        path: /etc/contingency\n        state: directory\n        mode: '0750'\n\n    - name: Check service status for each RTO objective\n      shell: \"systemctl is-active {{ item.1 }} 2>/dev/null || echo 'inactive'\"\n      register: service_status\n      loop: \"{{ rto_objectives | subelements('services') }}\"\n      changed_when: false\n      ignore_errors: yes\n\n    - name: Document RTO objectives\n      copy:\n        dest: /etc/contingency/rto_objectives.yml\n        content: |\n          # CP-2.3 Recovery Time Objectives\n          # Generated: {{ ansible_date_time.iso8601 }}\n          \n          recovery_objectives:\n          {% for obj in rto_objectives %}\n            - function: {{ obj.name }}\n              rto_minutes: {{ obj.rto_minutes }}\n              priority: {{ obj.priority }}\n              services: {{ obj.services | to_yaml }}\n          {% endfor %}\n          \n          # Review these objectives regularly\n          # Test recovery procedures to ensure RTOs can be met\n        mode: '0640'\n\n    - name: Generate RTO assessment report\n      lineinfile:\n        path: \"{{ report_file }}\"\n        line: \"{{ ansible_date_time.iso8601 }} - CP-2.3 RTO objectives documented for {{ ansible_hostname }}\"\n        create: yes"
      },
      "windows": {
        "powershell": "# CP-2.3: Essential Function Recovery Time Tracking for Windows\n# Tracks and reports on recovery objectives for essential services\n\n$LogFile = \"C:\\Windows\\Logs\\RecoveryTracking.log\"\n$Date = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n\n# Define RTO targets (in minutes)\n$RTOTargets = @{\n    'Database' = @{ RTO = 60; Services = @('MSSQLSERVER', 'SQLSERVERAGENT', 'MySQL') }\n    'WebServer' = @{ RTO = 30; Services = @('W3SVC', 'WAS') }\n    'FileServer' = @{ RTO = 120; Services = @('LanmanServer') }\n    'DomainController' = @{ RTO = 15; Services = @('NTDS', 'DNS', 'Netlogon') }\n    'Exchange' = @{ RTO = 240; Services = @('MSExchangeIS', 'MSExchangeTransport') }\n}\n\n$Report = @()\n$Report += \"[$Date] CP-2.3 Recovery Objective Assessment\"\n$Report += \"===========================================\"\n$Report += \"\"\n\nforeach ($Function in $RTOTargets.Keys) {\n    $Config = $RTOTargets[$Function]\n    $RTO = $Config.RTO\n    $Services = $Config.Services\n    $Running = $false\n    $ActiveService = \"\"\n    \n    foreach ($SvcName in $Services) {\n        $Svc = Get-Service -Name $SvcName -ErrorAction SilentlyContinue\n        if ($Svc -and $Svc.Status -eq 'Running') {\n            $Running = $true\n            $ActiveService = $SvcName\n            break\n        }\n    }\n    \n    if ($Running) {\n        $Report += \"[PASS] $Function ($ActiveService): RUNNING - RTO Target: $RTO minutes\"\n    } else {\n        $Report += \"[INFO] $Function: Not detected or not running - RTO Target: $RTO minutes\"\n    }\n}\n\n$Report += \"\"\n$Report += \"Recovery Time Objectives Summary:\"\n$Report += \"---------------------------------\"\nforeach ($Function in $RTOTargets.Keys | Sort-Object { $RTOTargets[$_].RTO }) {\n    $RTO = $RTOTargets[$Function].RTO\n    $Report += \"  Priority restore $Function within $RTO minutes\"\n}\n\n$Report += \"\"\n$Report += \"[$Date] Assessment complete.\"\n$Report += \"Ensure recovery procedures can meet these objectives.\"\n\n# Output and log\n$Report | Out-File -FilePath $LogFile -Encoding UTF8\n$Report | ForEach-Object { Write-Host $_ }\n\nWrite-Host \"\"\nWrite-Host \"Report saved to: $LogFile\"",
        "ansible": "---\n# CP-2.3: Recovery Time Objective Management for Windows\n- name: CP-2.3 RTO Assessment for Windows\n  hosts: windows\n  vars:\n    rto_objectives:\n      - function: Database\n        rto_minutes: 60\n        services:\n          - MSSQLSERVER\n          - MySQL\n      - function: WebServer\n        rto_minutes: 30\n        services:\n          - W3SVC\n      - function: DomainController\n        rto_minutes: 15\n        services:\n          - NTDS\n          - DNS\n\n  tasks:\n    - name: Check service status for RTO functions\n      win_shell: |\n        $Results = @()\n        {% for obj in rto_objectives %}\n        $Function = '{{ obj.function }}'\n        $RTO = {{ obj.rto_minutes }}\n        $Running = $false\n        {% for svc in obj.services %}\n        $s = Get-Service -Name '{{ svc }}' -ErrorAction SilentlyContinue\n        if ($s -and $s.Status -eq 'Running') { $Running = $true }\n        {% endfor %}\n        $Results += @{ Function = $Function; RTO = $RTO; Running = $Running }\n        {% endfor %}\n        $Results | ConvertTo-Json\n      register: rto_status\n\n    - name: Create RTO documentation\n      win_copy:\n        dest: C:\\Contingency\\RTO_Objectives.txt\n        content: |\n          CP-2.3 Recovery Time Objectives\n          ================================\n          Generated: {{ ansible_date_time.iso8601 }}\n          \n          {% for obj in rto_objectives %}\n          {{ obj.function }}: {{ obj.rto_minutes }} minutes\n          {% endfor %}"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true
    },
    "cac_metadata": {
      "implementation_type": "hybrid",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Requires organizational definition of RTOs combined with technical implementation of recovery procedures that can meet those objectives."
    },
    "rationale": "Some business functions are more critical than others. This ensures you restore the most important ones first."
  },
  {
    "control_id": "CP-2.4",
    "control_name": "Resume All Mission and Business Functions",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "parent_control": "CP-2",
    "official_text": "Plan for the resumption of all mission and business functions within organization-defined time period of contingency plan activation.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "is_technical": true,
    "intent": "Extend recovery planning beyond essential functions to include ALL mission and business functions, ensuring complete organizational recovery within defined timeframes.",
    "plain_english_explanation": "While CP-2.3 focuses on essential functions, this enhancement requires planning for the complete restoration of ALL business functions - not just the critical ones. This ensures the organization can return to full normal operations within a defined timeframe, not just minimal survivable operations.",
    "ai_guidance": "AI systems can create comprehensive recovery orchestration that sequences the restoration of all functions based on dependency analysis. Machine learning can optimize recovery order to minimize overall downtime while respecting function interdependencies. Implement AI-driven progress tracking that predicts total recovery completion time and identifies bottlenecks. Use natural language processing to maintain recovery status communications to stakeholders automatically.",
    "example_implementation": "1. Extend Business Impact Analysis to cover all functions, not just essential ones. 2. Define recovery tiers (Tier 1: Essential in hours, Tier 2: Important in days, Tier 3: Normal in weeks). 3. Document complete recovery procedures for each tier. 4. Test full recovery scenarios annually. 5. Ensure adequate resources for complete restoration.",
    "non_technical_guidance": "To comply with CP-2.4: 1. Identify ALL mission and business functions (beyond just essential ones). 2. Categorize functions by recovery priority. 3. Define recovery time objectives for complete restoration. 4. Plan resources needed for full recovery. 5. Document procedures for restoring non-essential functions after critical systems are restored. 6. Test complete recovery at least annually.",
    "enhancements": [],
    "related_controls": [
      "CP-2",
      "CP-2.3",
      "CP-4",
      "CP-10"
    ],
    "supplemental_guidance": "This enhancement differs from CP-2.3 in scope - CP-2.3 addresses essential functions while CP-2.4 addresses all functions. Organizations with this enhancement have more comprehensive recovery requirements.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": false,
      "qa_verified": true
    },
    "cac_metadata": {
      "implementation_type": "organizational",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "This enhancement extends CP-2.3 to all functions. Primary implementation is organizational planning. Technical scripts from CP-2.3 can be extended to cover additional non-essential functions."
    },
    "rationale": "After restoring critical functions, you need a plan to bring back everything else in an organized way."
  },
  {
    "control_id": "CP-2.5",
    "control_name": "Continue Mission and Business Functions",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "parent_control": "CP-2",
    "official_text": "Plan for the continuance of essential mission and business functions with minimal or no loss of operational continuity and sustain that continuity until full system restoration at primary processing and/or storage sites.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": true
    },
    "is_technical": true,
    "intent": "Ensure essential operations continue without interruption during contingency events through high-availability configurations, failover systems, and continuous operations capabilities.",
    "plain_english_explanation": "This enhancement goes beyond recovery - it requires CONTINUOUS operations. Essential functions should experience minimal or no downtime during incidents. This typically requires real-time failover capabilities, redundant systems, and high-availability architectures that allow operations to continue seamlessly while issues are resolved.",
    "ai_guidance": "AI systems are critical for achieving zero-downtime continuity through predictive failure detection that triggers failover before service degradation occurs. Implement machine learning models that continuously analyze system health indicators and automatically route workloads to healthy infrastructure. AI can manage complex failover orchestration across multiple systems while maintaining data consistency. Use AI monitoring to detect subtle performance degradation that might indicate impending failures.",
    "example_implementation": "1. Implement high-availability clusters for all essential systems. 2. Configure automatic failover with sub-minute recovery. 3. Deploy active-active configurations where possible. 4. Implement real-time data replication to standby systems. 5. Use load balancers with health checks for automatic traffic rerouting. 6. Test failover monthly without service interruption.",
    "non_technical_guidance": "To comply with CP-2.5: 1. Identify functions that cannot tolerate any downtime. 2. Implement redundant systems for these functions. 3. Configure automatic failover capabilities. 4. Ensure backup systems can handle full production load. 5. Test failover regularly during maintenance windows. 6. Monitor failover readiness continuously.",
    "enhancements": [],
    "related_controls": [
      "CP-2",
      "CP-6",
      "CP-7",
      "CP-8",
      "CP-9",
      "SC-36"
    ],
    "supplemental_guidance": "Continuance of mission and business functions requires sophisticated high-availability architectures and real-time or near-real-time data replication.",
    "implementation_scripts": {
      "linux": {
        "bash": "#!/bin/bash\n# CP-2.5: High Availability Status Check\n# Monitors systems configured for continuous operations\n\nLOG_FILE=\"/var/log/ha_status_check.log\"\nDATE=$(date '+%Y-%m-%d %H:%M:%S')\n\necho \"[$DATE] CP-2.5 High Availability Status Check\" | tee \"$LOG_FILE\"\necho \"=============================================\" | tee -a \"$LOG_FILE\"\n\n# Check Pacemaker cluster status (if installed)\nif command -v pcs &> /dev/null; then\n    echo \"\" | tee -a \"$LOG_FILE\"\n    echo \"=== Pacemaker Cluster Status ===\" | tee -a \"$LOG_FILE\"\n    pcs status --brief 2>/dev/null | tee -a \"$LOG_FILE\" || echo \"Pacemaker not configured\" | tee -a \"$LOG_FILE\"\nfi\n\n# Check Keepalived (VRRP) status\nif systemctl is-active --quiet keepalived 2>/dev/null; then\n    echo \"\" | tee -a \"$LOG_FILE\"\n    echo \"=== Keepalived Status ===\" | tee -a \"$LOG_FILE\"\n    echo \"[PASS] Keepalived is running\" | tee -a \"$LOG_FILE\"\n    ip addr show | grep -E 'inet.*secondary' | tee -a \"$LOG_FILE\"\nfi\n\n# Check HAProxy status\nif systemctl is-active --quiet haproxy 2>/dev/null; then\n    echo \"\" | tee -a \"$LOG_FILE\"\n    echo \"=== HAProxy Load Balancer ===\" | tee -a \"$LOG_FILE\"\n    echo \"[PASS] HAProxy is running\" | tee -a \"$LOG_FILE\"\n    if [ -S /var/run/haproxy/admin.sock ]; then\n        echo \"show stat\" | socat stdio /var/run/haproxy/admin.sock 2>/dev/null | head -5 | tee -a \"$LOG_FILE\"\n    fi\nfi\n\n# Check DRBD replication status (if installed)\nif command -v drbdadm &> /dev/null; then\n    echo \"\" | tee -a \"$LOG_FILE\"\n    echo \"=== DRBD Replication Status ===\" | tee -a \"$LOG_FILE\"\n    drbdadm status 2>/dev/null | tee -a \"$LOG_FILE\" || echo \"DRBD not configured\" | tee -a \"$LOG_FILE\"\nfi\n\n# Check database replication\necho \"\" | tee -a \"$LOG_FILE\"\necho \"=== Database Replication ===\" | tee -a \"$LOG_FILE\"\n\n# PostgreSQL replication\nif systemctl is-active --quiet postgresql 2>/dev/null; then\n    sudo -u postgres psql -c \"SELECT pg_is_in_recovery();\" 2>/dev/null | tee -a \"$LOG_FILE\"\nfi\n\n# MySQL/MariaDB replication\nif systemctl is-active --quiet mysql 2>/dev/null || systemctl is-active --quiet mariadb 2>/dev/null; then\n    mysql -e \"SHOW SLAVE STATUS\\G\" 2>/dev/null | grep -E 'Slave_IO_Running|Slave_SQL_Running' | tee -a \"$LOG_FILE\"\nfi\n\necho \"\" | tee -a \"$LOG_FILE\"\necho \"[$DATE] HA Status check complete\" | tee -a \"$LOG_FILE\"",
        "ansible": "---\n# CP-2.5: High Availability Verification Playbook\n- name: CP-2.5 High Availability Status Verification\n  hosts: all\n  become: yes\n  vars:\n    ha_report_file: /var/log/ha_verification.log\n\n  tasks:\n    - name: Check for Pacemaker cluster\n      shell: pcs status --brief 2>/dev/null || echo 'Not configured'\n      register: pacemaker_status\n      changed_when: false\n      ignore_errors: yes\n\n    - name: Check Keepalived service\n      service_facts:\n      register: services_state\n\n    - name: Check HAProxy service\n      set_fact:\n        haproxy_running: \"{{ 'haproxy.service' in services_state.ansible_facts.services and services_state.ansible_facts.services['haproxy.service'].state == 'running' }}\"\n\n    - name: Check for DRBD replication\n      shell: drbdadm status 2>/dev/null || echo 'Not configured'\n      register: drbd_status\n      changed_when: false\n      ignore_errors: yes\n\n    - name: Generate HA status report\n      copy:\n        dest: \"{{ ha_report_file }}\"\n        content: |\n          CP-2.5 HIGH AVAILABILITY STATUS REPORT\n          =======================================\n          Host: {{ ansible_hostname }}\n          Date: {{ ansible_date_time.iso8601 }}\n          \n          Pacemaker Cluster:\n          {{ pacemaker_status.stdout }}\n          \n          HAProxy Running: {{ haproxy_running }}\n          \n          DRBD Status:\n          {{ drbd_status.stdout }}\n          \n          Recommendation: Verify all HA components are properly\n          configured for continuous operations.\n        mode: '0640'"
      },
      "windows": {
        "powershell": "# CP-2.5: High Availability Status Check for Windows\n# Monitors Windows Failover Clustering and HA configurations\n\n$LogFile = \"C:\\Windows\\Logs\\HA_StatusCheck.log\"\n$Date = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n$Report = @()\n\n$Report += \"[$Date] CP-2.5 High Availability Status Check\"\n$Report += \"=============================================\"\n$Report += \"\"\n\n# Check Windows Failover Clustering\n$Report += \"=== Windows Failover Cluster ===\"\ntry {\n    $Cluster = Get-Cluster -ErrorAction Stop\n    $Report += \"[PASS] Cluster Name: $($Cluster.Name)\"\n    \n    # Get cluster nodes\n    $Nodes = Get-ClusterNode -ErrorAction SilentlyContinue\n    foreach ($Node in $Nodes) {\n        $Report += \"  Node: $($Node.Name) - State: $($Node.State)\"\n    }\n    \n    # Get cluster resources\n    $Resources = Get-ClusterResource -ErrorAction SilentlyContinue\n    $Report += \"\"\n    $Report += \"Cluster Resources:\"\n    foreach ($Res in $Resources | Select-Object -First 10) {\n        $Report += \"  $($Res.Name): $($Res.State)\"\n    }\n} catch {\n    $Report += \"[INFO] Windows Failover Clustering not configured or not accessible\"\n}\n\n$Report += \"\"\n\n# Check Hyper-V Replica status\n$Report += \"=== Hyper-V Replica ===\"\ntry {\n    $VMs = Get-VM -ErrorAction SilentlyContinue\n    if ($VMs) {\n        foreach ($VM in $VMs) {\n            $Replication = Get-VMReplication -VMName $VM.Name -ErrorAction SilentlyContinue\n            if ($Replication) {\n                $Report += \"  $($VM.Name): Replication State = $($Replication.State)\"\n            }\n        }\n    } else {\n        $Report += \"[INFO] No Hyper-V VMs found\"\n    }\n} catch {\n    $Report += \"[INFO] Hyper-V not installed or not accessible\"\n}\n\n$Report += \"\"\n\n# Check SQL Server AlwaysOn (if applicable)\n$Report += \"=== SQL Server AlwaysOn ===\"\ntry {\n    $SQLService = Get-Service -Name 'MSSQLSERVER' -ErrorAction SilentlyContinue\n    if ($SQLService -and $SQLService.Status -eq 'Running') {\n        $AGQuery = @\"\nSELECT ag.name AS ag_name, ars.role_desc, ars.synchronization_health_desc\nFROM sys.dm_hadr_availability_replica_states ars\nJOIN sys.availability_groups ag ON ars.group_id = ag.group_id\nWHERE ars.is_local = 1\n\"@\n        # Note: Actual query would require sqlcmd or Invoke-Sqlcmd\n        $Report += \"[INFO] SQL Server running - check AlwaysOn AG status manually\"\n    } else {\n        $Report += \"[INFO] SQL Server not running\"\n    }\n} catch {\n    $Report += \"[INFO] Unable to check SQL Server status\"\n}\n\n$Report += \"\"\n$Report += \"[$Date] HA Status check complete\"\n\n$Report | Out-File -FilePath $LogFile -Encoding UTF8\n$Report | ForEach-Object { Write-Host $_ }",
        "ansible": "---\n# CP-2.5: High Availability Verification for Windows\n- name: CP-2.5 HA Status for Windows\n  hosts: windows\n  tasks:\n    - name: Check Failover Cluster status\n      win_shell: |\n        try {\n          $Cluster = Get-Cluster\n          $Nodes = Get-ClusterNode | Select Name, State\n          @{ ClusterName = $Cluster.Name; Nodes = $Nodes } | ConvertTo-Json\n        } catch {\n          @{ ClusterName = 'Not Configured' } | ConvertTo-Json\n        }\n      register: cluster_status\n\n    - name: Generate HA report\n      win_copy:\n        dest: C:\\Logs\\HA_Status.txt\n        content: |\n          CP-2.5 High Availability Status\n          ================================\n          Host: {{ ansible_hostname }}\n          Date: {{ ansible_date_time.iso8601 }}\n          \n          Cluster Status: {{ cluster_status.stdout }}"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true
    },
    "cac_metadata": {
      "implementation_type": "technical",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "This control requires technical implementation of high-availability architectures including clustering, replication, and automatic failover capabilities."
    },
    "rationale": "Some operations can't stop, even briefly. This ensures continuous operation of the most essential functions."
  },
  {
    "control_id": "CP-2.6",
    "control_name": "Alternate Processing and Storage Sites",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "parent_control": "CP-2",
    "official_text": "Plan for the transfer of essential mission and business functions to alternate processing and/or storage sites with minimal or no loss of operational continuity and sustain that continuity through system restoration to primary processing and/or storage sites.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "is_technical": true,
    "intent": "Ensure operations can seamlessly transfer to geographically separate alternate sites and continue without significant interruption until primary sites are restored.",
    "plain_english_explanation": "When your primary data center or office cannot be used, you need the ability to seamlessly shift operations to a backup location. This requires pre-configured alternate sites with replicated data, tested failover procedures, and the ability to operate indefinitely from the alternate location until the primary site is restored.",
    "ai_guidance": "AI can optimize workload distribution between primary and alternate sites based on real-time conditions, network latency, and resource availability. Implement machine learning models that predict the optimal timing for site failover based on degradation patterns. AI systems should continuously verify data synchronization between sites and alert on replication lag. Use AI to automate complex multi-site failover orchestration while maintaining transaction integrity.",
    "example_implementation": "1. Establish alternate processing site with equivalent capabilities. 2. Implement real-time or near-real-time data replication. 3. Configure network failover (DNS, BGP, load balancers). 4. Document site transfer procedures. 5. Conduct annual failover exercises to alternate site. 6. Maintain alternate site readiness monitoring.",
    "non_technical_guidance": "To comply with CP-2.6: 1. Identify or establish alternate processing and storage sites. 2. Ensure alternate sites have sufficient capacity. 3. Implement data replication to alternate sites. 4. Pre-position necessary equipment and supplies. 5. Train staff on alternate site operations. 6. Test site transfer procedures regularly. 7. Maintain agreements with alternate site providers.",
    "enhancements": [],
    "related_controls": [
      "CP-2",
      "CP-6",
      "CP-7",
      "CP-8",
      "CP-9"
    ],
    "supplemental_guidance": "Organizations may use alternate sites for processing and storage that are collocated or geographically dispersed. The extent of the operational continuity capability depends on the information and system components available at the alternate site.",
    "implementation_scripts": {
      "linux": {
        "bash": "#!/bin/bash\n# CP-2.6: Alternate Site Replication Status Check\n# Monitors data replication to alternate processing/storage sites\n\nLOG_FILE=\"/var/log/alternate_site_status.log\"\nDATE=$(date '+%Y-%m-%d %H:%M:%S')\n\necho \"[$DATE] CP-2.6 Alternate Site Status Check\" | tee \"$LOG_FILE\"\necho \"==========================================\" | tee -a \"$LOG_FILE\"\n\n# Check rsync replication jobs\necho \"\" | tee -a \"$LOG_FILE\"\necho \"=== Rsync Replication Status ===\" | tee -a \"$LOG_FILE\"\nif [ -f /var/log/rsync_replication.log ]; then\n    LAST_SYNC=$(tail -1 /var/log/rsync_replication.log 2>/dev/null)\n    echo \"Last rsync: $LAST_SYNC\" | tee -a \"$LOG_FILE\"\nelse\n    echo \"[INFO] No rsync replication log found\" | tee -a \"$LOG_FILE\"\nfi\n\n# Check for common replication tools\necho \"\" | tee -a \"$LOG_FILE\"\necho \"=== Replication Tools Status ===\" | tee -a \"$LOG_FILE\"\n\nfor tool in lsyncd csync2 unison; do\n    if command -v $tool &> /dev/null; then\n        if pgrep -x $tool > /dev/null; then\n            echo \"[PASS] $tool is running\" | tee -a \"$LOG_FILE\"\n        else\n            echo \"[WARN] $tool installed but not running\" | tee -a \"$LOG_FILE\"\n        fi\n    fi\ndone\n\n# Check cloud storage sync (AWS S3, Azure, GCP)\necho \"\" | tee -a \"$LOG_FILE\"\necho \"=== Cloud Replication ===\" | tee -a \"$LOG_FILE\"\n\n# Check AWS CLI\nif command -v aws &> /dev/null; then\n    echo \"[INFO] AWS CLI available - can replicate to S3\" | tee -a \"$LOG_FILE\"\nfi\n\n# Check Azure CLI\nif command -v az &> /dev/null; then\n    echo \"[INFO] Azure CLI available - can replicate to Azure Blob\" | tee -a \"$LOG_FILE\"\nfi\n\n# Check network connectivity to alternate site\necho \"\" | tee -a \"$LOG_FILE\"\necho \"=== Alternate Site Connectivity ===\" | tee -a \"$LOG_FILE\"\nALT_SITES=(\"backup.example.com\" \"dr-site.example.com\")\nfor site in \"${ALT_SITES[@]}\"; do\n    if ping -c 1 -W 2 $site &> /dev/null; then\n        echo \"[PASS] $site is reachable\" | tee -a \"$LOG_FILE\"\n    else\n        echo \"[INFO] $site - configure actual alternate site address\" | tee -a \"$LOG_FILE\"\n    fi\ndone\n\necho \"\" | tee -a \"$LOG_FILE\"\necho \"[$DATE] Alternate site check complete\" | tee -a \"$LOG_FILE\"",
        "ansible": "---\n# CP-2.6: Alternate Site Configuration Playbook\n- name: CP-2.6 Alternate Site Replication Setup\n  hosts: all\n  become: yes\n  vars:\n    alternate_site: \"dr-site.example.com\"\n    replication_user: \"replication\"\n    critical_data_paths:\n      - /var/lib/data\n      - /opt/application\n      - /etc/application\n\n  tasks:\n    - name: Ensure rsync is installed\n      package:\n        name: rsync\n        state: present\n\n    - name: Create replication script\n      copy:\n        dest: /usr/local/bin/replicate_to_alternate.sh\n        content: |\n          #!/bin/bash\n          # CP-2.6 Alternate Site Replication\n          LOG=\"/var/log/alternate_site_replication.log\"\n          DATE=$(date '+%Y-%m-%d %H:%M:%S')\n          echo \"[$DATE] Starting replication to {{ alternate_site }}\" >> $LOG\n          \n          {% for path in critical_data_paths %}\n          rsync -avz --delete {{ path }} {{ replication_user }}@{{ alternate_site }}:{{ path }} >> $LOG 2>&1\n          {% endfor %}\n          \n          echo \"[$DATE] Replication complete\" >> $LOG\n        mode: '0750'\n\n    - name: Create replication cron job\n      cron:\n        name: \"CP-2.6 Alternate Site Replication\"\n        minute: \"0\"\n        hour: \"*/4\"\n        job: \"/usr/local/bin/replicate_to_alternate.sh\"\n\n    - name: Document alternate site configuration\n      copy:\n        dest: /etc/contingency/alternate_site.conf\n        content: |\n          # CP-2.6 Alternate Site Configuration\n          ALTERNATE_SITE={{ alternate_site }}\n          REPLICATION_FREQUENCY=every_4_hours\n          CRITICAL_PATHS={{ critical_data_paths | join(',') }}\n        mode: '0640'"
      },
      "windows": {
        "powershell": "# CP-2.6: Alternate Site Replication Status for Windows\n\n$LogFile = \"C:\\Windows\\Logs\\AlternateSiteStatus.log\"\n$Date = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n$Report = @()\n\n$Report += \"[$Date] CP-2.6 Alternate Site Status Check\"\n$Report += \"==========================================\"\n$Report += \"\"\n\n# Check DFS Replication\n$Report += \"=== DFS Replication ===\"\ntry {\n    $DFSRGroups = Get-DfsReplicationGroup -ErrorAction Stop\n    foreach ($Group in $DFSRGroups) {\n        $Report += \"Replication Group: $($Group.GroupName)\"\n        $Connections = Get-DfsrConnection -GroupName $Group.GroupName -ErrorAction SilentlyContinue\n        foreach ($Conn in $Connections) {\n            $Report += \"  $($Conn.SourceComputerName) -> $($Conn.DestinationComputerName): Enabled=$($Conn.Enabled)\"\n        }\n    }\n} catch {\n    $Report += \"[INFO] DFS-R not configured or not accessible\"\n}\n\n$Report += \"\"\n\n# Check Storage Replica (Windows Server)\n$Report += \"=== Storage Replica ===\"\ntry {\n    $SRPartnership = Get-SRPartnership -ErrorAction Stop\n    foreach ($Partner in $SRPartnership) {\n        $Report += \"Partnership: $($Partner.SourceComputerName) <-> $($Partner.DestinationComputerName)\"\n    }\n} catch {\n    $Report += \"[INFO] Storage Replica not configured\"\n}\n\n$Report += \"\"\n\n# Check Azure Site Recovery Agent\n$Report += \"=== Azure Site Recovery ===\"\n$ASRService = Get-Service -Name 'MARS' -ErrorAction SilentlyContinue\nif ($ASRService) {\n    $Report += \"Azure Recovery Services Agent: $($ASRService.Status)\"\n} else {\n    $Report += \"[INFO] Azure Recovery Services Agent not installed\"\n}\n\n$Report += \"\"\n\n# Check Robocopy scheduled tasks for replication\n$Report += \"=== Scheduled Replication Tasks ===\"\n$Tasks = Get-ScheduledTask | Where-Object { $_.TaskName -match 'backup|replication|sync' }\nforeach ($Task in $Tasks) {\n    $Report += \"Task: $($Task.TaskName) - State: $($Task.State)\"\n}\n\n$Report += \"\"\n$Report += \"[$Date] Alternate site check complete\"\n\n$Report | Out-File -FilePath $LogFile -Encoding UTF8\n$Report | ForEach-Object { Write-Host $_ }",
        "ansible": "---\n# CP-2.6: Alternate Site Configuration for Windows\n- name: CP-2.6 Alternate Site Setup for Windows\n  hosts: windows\n  vars:\n    alternate_site: \"dr-site.example.com\"\n    replication_paths:\n      - C:\\Data\n      - C:\\Application\n\n  tasks:\n    - name: Check DFS-R status\n      win_shell: |\n        try {\n          Get-DfsReplicationGroup | Select GroupName | ConvertTo-Json\n        } catch {\n          @{ Status = 'Not Configured' } | ConvertTo-Json\n        }\n      register: dfsr_status\n\n    - name: Create replication script\n      win_copy:\n        dest: C:\\Scripts\\ReplicateToAlternate.ps1\n        content: |\n          # CP-2.6 Alternate Site Replication\n          $Log = \"C:\\Logs\\AlternateReplication.log\"\n          $Date = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n          Add-Content $Log \"[$Date] Starting replication to {{ alternate_site }}\"\n          \n          {% for path in replication_paths %}\n          robocopy \"{{ path }}\" \"\\\\{{ alternate_site }}\\{{ path | win_basename }}\" /MIR /R:3 /W:5 /LOG+:$Log\n          {% endfor %}\n          \n          Add-Content $Log \"[$Date] Replication complete\""
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true
    },
    "cac_metadata": {
      "implementation_type": "hybrid",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Requires both organizational planning for alternate sites and technical implementation of replication and failover mechanisms."
    },
    "rationale": "If your main site is destroyed, you need a backup location ready to go. This ensures you've planned for that scenario."
  },
  {
    "control_id": "CP-2.7",
    "control_name": "Coordinate with External Service Providers",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "parent_control": "CP-2",
    "official_text": "Coordinate the contingency plan with the contingency plans of external service providers to ensure that contingency requirements can be satisfied.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "is_technical": false,
    "intent": "Ensure that contingency plans account for dependencies on external service providers and that provider contingency capabilities align with organizational requirements.",
    "plain_english_explanation": "Your organization likely depends on external providers for cloud services, telecommunications, power, or other critical infrastructure. Your contingency plan must coordinate with these providers to ensure their disaster recovery capabilities meet your needs. If your cloud provider has a 24-hour recovery time but you need 4 hours, you have a gap that must be addressed.",
    "ai_guidance": "AI can analyze service provider SLAs and contingency documentation to identify misalignments with organizational requirements. Implement natural language processing to continuously monitor provider status pages and communications for early warning of potential issues. AI systems can model cascading failures across provider dependencies and recommend mitigation strategies. Use machine learning to predict provider reliability based on historical incident data.",
    "example_implementation": "1. Inventory all external service providers and their criticality. 2. Obtain and review provider contingency plans and SLAs. 3. Document provider RTOs and RPOs and compare to your requirements. 4. Establish communication protocols with providers for emergencies. 5. Include provider failover testing in your contingency exercises. 6. Review provider contingency capabilities annually.",
    "non_technical_guidance": "To comply with CP-2.7: 1. List all external service providers your organization depends on. 2. Request contingency plan summaries from critical providers. 3. Verify provider recovery capabilities meet your requirements. 4. Establish emergency contact procedures with providers. 5. Include provider dependencies in your contingency plan. 6. Participate in joint exercises with critical providers. 7. Review provider capabilities during contract renewals.",
    "enhancements": [],
    "related_controls": [
      "CP-2",
      "SA-9",
      "SR-1",
      "SR-2"
    ],
    "supplemental_guidance": "External service providers include telecommunications providers, cloud service providers, infrastructure as a service providers, managed security service providers, and other organizations that support the mission and business functions of the organization.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": false,
      "qa_verified": true
    },
    "cac_metadata": {
      "implementation_type": "organizational",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "This control is organizational in nature requiring coordination with external providers. No technical automation available - requires documented coordination procedures, SLA reviews, and regular communication with providers."
    },
    "rationale": "Your vendors and cloud providers need to be part of your recovery plan. Their failures can cause your failures."
  },
  {
    "control_id": "CP-2.8",
    "control_name": "Identify Critical Assets",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "parent_control": "CP-2",
    "official_text": "Identify critical system assets supporting essential mission and business functions.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": true,
      "high": true
    },
    "is_technical": true,
    "intent": "Maintain an accurate inventory of critical assets that support essential functions to ensure proper protection, recovery prioritization, and resource allocation during contingency operations.",
    "plain_english_explanation": "You need to know exactly which systems, applications, data, and infrastructure components are critical to your essential business functions. This asset identification ensures you protect the right things, recover the right things first, and allocate resources appropriately during emergencies. Without this inventory, you might recover non-essential systems while critical ones remain offline.",
    "ai_guidance": "AI can automate critical asset discovery by analyzing network traffic, system dependencies, and application usage patterns to identify which assets actually support essential functions. Machine learning models can classify assets by criticality based on operational impact analysis. Implement AI-driven dependency mapping that automatically updates as infrastructure changes. Use natural language processing to correlate business function documentation with technical asset inventories.",
    "example_implementation": "1. Conduct Business Impact Analysis to identify essential functions. 2. Map each essential function to supporting technology assets. 3. Document asset criticality ratings in CMDB or asset inventory. 4. Identify asset dependencies and interdependencies. 5. Review and update critical asset inventory quarterly. 6. Use asset inventory to prioritize recovery and protection efforts.",
    "non_technical_guidance": "To comply with CP-2.8: 1. List all essential mission and business functions. 2. For each function, identify supporting systems, applications, and data. 3. Document the criticality of each asset. 4. Map dependencies between assets. 5. Maintain asset inventory with designated owners. 6. Review asset criticality when business functions change. 7. Use this inventory to guide contingency planning priorities.",
    "enhancements": [],
    "related_controls": [
      "CP-2",
      "CM-8",
      "PM-5",
      "RA-2",
      "SA-20"
    ],
    "supplemental_guidance": "Critical system assets include hardware, software, data, and supporting infrastructure. Organizations may use Business Impact Analyses to help identify critical system assets.",
    "implementation_scripts": {
      "linux": {
        "bash": "#!/bin/bash\n# CP-2.8: Critical Asset Inventory Script\n# Documents critical system assets for contingency planning\n\nOUTPUT_FILE=\"/var/log/critical_asset_inventory_$(date +%Y%m%d).json\"\nDATE=$(date -Iseconds)\n\necho \"{\" > \"$OUTPUT_FILE\"\necho \"  \\\"inventory_date\\\": \\\"$DATE\\\",\" >> \"$OUTPUT_FILE\"\necho \"  \\\"hostname\\\": \\\"$(hostname)\\\",\" >> \"$OUTPUT_FILE\"\necho \"  \\\"control\\\": \\\"CP-2.8 Critical Asset Identification\\\",\" >> \"$OUTPUT_FILE\"\n\n# System Information\necho \"  \\\"system_info\\\": {\" >> \"$OUTPUT_FILE\"\necho \"    \\\"os\\\": \\\"$(cat /etc/os-release | grep PRETTY_NAME | cut -d'=' -f2 | tr -d '\"')\\\",\" >> \"$OUTPUT_FILE\"\necho \"    \\\"kernel\\\": \\\"$(uname -r)\\\",\" >> \"$OUTPUT_FILE\"\necho \"    \\\"architecture\\\": \\\"$(uname -m)\\\"\" >> \"$OUTPUT_FILE\"\necho \"  },\" >> \"$OUTPUT_FILE\"\n\n# Critical Services\necho \"  \\\"critical_services\\\": [\" >> \"$OUTPUT_FILE\"\nCRITICAL_SVCS=(sshd httpd nginx postgresql mysql docker kubelet)\nFIRST=true\nfor svc in \"${CRITICAL_SVCS[@]}\"; do\n    if systemctl is-active --quiet $svc 2>/dev/null; then\n        if [ \"$FIRST\" = true ]; then\n            FIRST=false\n        else\n            echo \",\" >> \"$OUTPUT_FILE\"\n        fi\n        STATUS=$(systemctl is-active $svc)\n        echo -n \"    {\\\"name\\\": \\\"$svc\\\", \\\"status\\\": \\\"$STATUS\\\", \\\"criticality\\\": \\\"high\\\"}\" >> \"$OUTPUT_FILE\"\n    fi\ndone\necho \"\" >> \"$OUTPUT_FILE\"\necho \"  ],\" >> \"$OUTPUT_FILE\"\n\n# Critical Data Paths\necho \"  \\\"critical_data_paths\\\": [\" >> \"$OUTPUT_FILE\"\nDATA_PATHS=(\"/var/lib/postgresql\" \"/var/lib/mysql\" \"/var/lib/docker\" \"/home\" \"/opt\")\nFIRST=true\nfor path in \"${DATA_PATHS[@]}\"; do\n    if [ -d \"$path\" ]; then\n        if [ \"$FIRST\" = true ]; then\n            FIRST=false\n        else\n            echo \",\" >> \"$OUTPUT_FILE\"\n        fi\n        SIZE=$(du -sh \"$path\" 2>/dev/null | cut -f1)\n        echo -n \"    {\\\"path\\\": \\\"$path\\\", \\\"size\\\": \\\"$SIZE\\\"}\" >> \"$OUTPUT_FILE\"\n    fi\ndone\necho \"\" >> \"$OUTPUT_FILE\"\necho \"  ],\" >> \"$OUTPUT_FILE\"\n\n# Network Configuration\necho \"  \\\"network_assets\\\": [\" >> \"$OUTPUT_FILE\"\nip -j addr show 2>/dev/null | python3 -c \"\nimport sys, json\ndata = json.load(sys.stdin)\nfor iface in data:\n    if iface.get('operstate') == 'UP':\n        addrs = [a['local'] for a in iface.get('addr_info', []) if a.get('family') == 'inet']\n        if addrs:\n            print(f'    {{\\\"interface\\\": \\\"{iface[\\\"ifname\\\"]}\\\", \\\"addresses\\\": {json.dumps(addrs)}}},')\n\" 2>/dev/null >> \"$OUTPUT_FILE\" || echo \"    {\\\"note\\\": \\\"network inventory requires python3\\\"}\" >> \"$OUTPUT_FILE\"\necho \"    {\\\"note\\\": \\\"Review and classify network assets by criticality\\\"}\" >> \"$OUTPUT_FILE\"\necho \"  ]\" >> \"$OUTPUT_FILE\"\n\necho \"}\" >> \"$OUTPUT_FILE\"\n\necho \"Critical asset inventory saved to: $OUTPUT_FILE\"\ncat \"$OUTPUT_FILE\"",
        "ansible": "---\n# CP-2.8: Critical Asset Inventory Playbook\n- name: CP-2.8 Critical Asset Identification\n  hosts: all\n  become: yes\n  vars:\n    inventory_dir: /var/lib/asset_inventory\n    critical_service_list:\n      - name: sshd\n        function: \"Remote Administration\"\n        criticality: high\n      - name: httpd\n        function: \"Web Services\"\n        criticality: high\n      - name: nginx\n        function: \"Web Services\"\n        criticality: high\n      - name: postgresql\n        function: \"Database\"\n        criticality: critical\n      - name: mysql\n        function: \"Database\"\n        criticality: critical\n      - name: docker\n        function: \"Container Platform\"\n        criticality: high\n\n  tasks:\n    - name: Create asset inventory directory\n      file:\n        path: \"{{ inventory_dir }}\"\n        state: directory\n        mode: '0750'\n\n    - name: Gather system facts\n      setup:\n        gather_subset:\n          - hardware\n          - network\n          - virtual\n\n    - name: Check critical service status\n      shell: \"systemctl is-active {{ item.name }} 2>/dev/null || echo 'inactive'\"\n      register: service_status\n      loop: \"{{ critical_service_list }}\"\n      changed_when: false\n      ignore_errors: yes\n\n    - name: Get disk information\n      shell: \"lsblk -J -o NAME,SIZE,TYPE,MOUNTPOINT\"\n      register: disk_info\n      changed_when: false\n\n    - name: Generate critical asset inventory\n      copy:\n        dest: \"{{ inventory_dir }}/critical_assets_{{ ansible_hostname }}.yml\"\n        content: |\n          ---\n          # CP-2.8 Critical Asset Inventory\n          # Generated: {{ ansible_date_time.iso8601 }}\n          \n          host_info:\n            hostname: {{ ansible_hostname }}\n            fqdn: {{ ansible_fqdn }}\n            os: {{ ansible_distribution }} {{ ansible_distribution_version }}\n            kernel: {{ ansible_kernel }}\n            architecture: {{ ansible_architecture }}\n            \n          hardware_assets:\n            cpu_cores: {{ ansible_processor_vcpus }}\n            memory_mb: {{ ansible_memtotal_mb }}\n            \n          critical_services:\n          {% for result in service_status.results %}\n            - name: {{ result.item.name }}\n              function: {{ result.item.function }}\n              criticality: {{ result.item.criticality }}\n              status: {{ result.stdout }}\n          {% endfor %}\n          \n          network_interfaces:\n          {% for iface in ansible_interfaces %}\n          {% if hostvars[inventory_hostname]['ansible_' + iface] is defined %}\n            - name: {{ iface }}\n              ipv4: {{ hostvars[inventory_hostname]['ansible_' + iface].ipv4.address | default('N/A') }}\n          {% endif %}\n          {% endfor %}\n          \n          # Review this inventory and update criticality ratings\n          # based on Business Impact Analysis\n        mode: '0640'\n\n    - name: Display inventory location\n      debug:\n        msg: \"Critical asset inventory saved to {{ inventory_dir }}/critical_assets_{{ ansible_hostname }}.yml\""
      },
      "windows": {
        "powershell": "# CP-2.8: Critical Asset Inventory Script for Windows\n# Documents critical system assets for contingency planning\n\n$OutputFile = \"C:\\Windows\\Logs\\CriticalAssetInventory_$(Get-Date -Format 'yyyyMMdd').json\"\n$Date = Get-Date -Format \"o\"\n\n$Inventory = @{\n    inventory_date = $Date\n    hostname = $env:COMPUTERNAME\n    control = \"CP-2.8 Critical Asset Identification\"\n    \n    system_info = @{\n        os = (Get-WmiObject Win32_OperatingSystem).Caption\n        version = (Get-WmiObject Win32_OperatingSystem).Version\n        architecture = $env:PROCESSOR_ARCHITECTURE\n        domain = $env:USERDOMAIN\n    }\n    \n    critical_services = @()\n    critical_applications = @()\n    critical_data_locations = @()\n    network_assets = @()\n}\n\n# Critical Windows Services\n$CriticalServices = @(\n    @{ Name = 'W3SVC'; Function = 'Web Services'; Criticality = 'High' },\n    @{ Name = 'MSSQLSERVER'; Function = 'Database'; Criticality = 'Critical' },\n    @{ Name = 'DNS'; Function = 'Name Resolution'; Criticality = 'Critical' },\n    @{ Name = 'NTDS'; Function = 'Directory Services'; Criticality = 'Critical' },\n    @{ Name = 'Dnscache'; Function = 'DNS Client'; Criticality = 'Medium' },\n    @{ Name = 'LanmanServer'; Function = 'File Sharing'; Criticality = 'High' },\n    @{ Name = 'EventLog'; Function = 'Audit Logging'; Criticality = 'High' }\n)\n\nforeach ($SvcDef in $CriticalServices) {\n    $Svc = Get-Service -Name $SvcDef.Name -ErrorAction SilentlyContinue\n    if ($Svc) {\n        $Inventory.critical_services += @{\n            name = $SvcDef.Name\n            display_name = $Svc.DisplayName\n            status = $Svc.Status.ToString()\n            function = $SvcDef.Function\n            criticality = $SvcDef.Criticality\n        }\n    }\n}\n\n# Critical Data Locations\n$DataLocations = @(\n    \"C:\\inetpub\\wwwroot\",\n    \"C:\\Program Files\\Microsoft SQL Server\",\n    \"C:\\Windows\\NTDS\",\n    \"C:\\Data\",\n    \"D:\\Shares\"\n)\n\nforeach ($Path in $DataLocations) {\n    if (Test-Path $Path) {\n        $Size = (Get-ChildItem $Path -Recurse -ErrorAction SilentlyContinue | Measure-Object -Property Length -Sum).Sum / 1GB\n        $Inventory.critical_data_locations += @{\n            path = $Path\n            size_gb = [math]::Round($Size, 2)\n            exists = $true\n        }\n    }\n}\n\n# Network Assets\n$Adapters = Get-NetAdapter | Where-Object { $_.Status -eq 'Up' }\nforeach ($Adapter in $Adapters) {\n    $IPs = Get-NetIPAddress -InterfaceIndex $Adapter.InterfaceIndex -AddressFamily IPv4 -ErrorAction SilentlyContinue\n    $Inventory.network_assets += @{\n        name = $Adapter.Name\n        interface_description = $Adapter.InterfaceDescription\n        mac_address = $Adapter.MacAddress\n        ip_addresses = @($IPs.IPAddress)\n        link_speed = $Adapter.LinkSpeed\n    }\n}\n\n# Installed Roles and Features (Server only)\ntry {\n    $Features = Get-WindowsFeature | Where-Object { $_.Installed -eq $true } | Select-Object -First 20\n    $Inventory.installed_features = @($Features.Name)\n} catch {\n    $Inventory.installed_features = @(\"Feature enumeration not available\")\n}\n\n# Convert to JSON and save\n$Inventory | ConvertTo-Json -Depth 4 | Out-File -FilePath $OutputFile -Encoding UTF8\n\nWrite-Host \"Critical Asset Inventory saved to: $OutputFile\"\nWrite-Host \"\"\nWrite-Host \"Summary:\"\nWrite-Host \"  Critical Services Found: $($Inventory.critical_services.Count)\"\nWrite-Host \"  Data Locations Found: $($Inventory.critical_data_locations.Count)\"\nWrite-Host \"  Network Interfaces: $($Inventory.network_assets.Count)\"\nWrite-Host \"\"\nWrite-Host \"Review inventory and update criticality ratings based on Business Impact Analysis.\"",
        "ansible": "---\n# CP-2.8: Critical Asset Inventory for Windows\n- name: CP-2.8 Critical Asset Identification for Windows\n  hosts: windows\n  vars:\n    inventory_dir: C:\\AssetInventory\n    critical_services:\n      - name: W3SVC\n        function: Web Services\n        criticality: high\n      - name: MSSQLSERVER\n        function: Database\n        criticality: critical\n      - name: DNS\n        function: Name Resolution\n        criticality: critical\n\n  tasks:\n    - name: Create inventory directory\n      win_file:\n        path: \"{{ inventory_dir }}\"\n        state: directory\n\n    - name: Check critical service status\n      win_shell: |\n        $svc = Get-Service -Name '{{ item.name }}' -ErrorAction SilentlyContinue\n        if ($svc) {\n          @{ Name = $svc.Name; Status = $svc.Status.ToString() } | ConvertTo-Json\n        } else {\n          @{ Name = '{{ item.name }}'; Status = 'NotFound' } | ConvertTo-Json\n        }\n      register: svc_status\n      loop: \"{{ critical_services }}\"\n\n    - name: Get disk information\n      win_shell: |\n        Get-WmiObject Win32_LogicalDisk -Filter \"DriveType=3\" | \n        Select DeviceID, @{N='SizeGB';E={[math]::Round($_.Size/1GB,2)}}, \n               @{N='FreeGB';E={[math]::Round($_.FreeSpace/1GB,2)}} |\n        ConvertTo-Json\n      register: disk_info\n\n    - name: Generate asset inventory\n      win_copy:\n        dest: \"{{ inventory_dir }}\\\\CriticalAssets_{{ ansible_hostname }}.txt\"\n        content: |\n          CP-2.8 CRITICAL ASSET INVENTORY\n          ================================\n          Host: {{ ansible_hostname }}\n          Date: {{ ansible_date_time.iso8601 }}\n          \n          CRITICAL SERVICES:\n          {% for result in svc_status.results %}\n          - {{ result.item.name }}: {{ result.stdout | from_json | json_query('Status') }}\n          {% endfor %}\n          \n          Review and update criticality ratings."
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true
    },
    "cac_metadata": {
      "implementation_type": "hybrid",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Critical asset identification requires organizational Business Impact Analysis combined with technical inventory automation. Scripts automate discovery while humans determine criticality ratings."
    },
    "rationale": "You can't protect everything equally. This ensures you've identified what's most critical to your mission."
  },
  {
    "control_id": "CP-3",
    "control_name": "Contingency Training",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "official_text": "a. Provide contingency training to system users consistent with assigned roles and responsibilities: 1. Within [Assignment: organization-defined time period] of assuming a contingency role or responsibility; 2. When required by system changes; and 3. [Assignment: organization-defined frequency] thereafter; and b. Review and update contingency training content [Assignment: organization-defined frequency] and following [Assignment: organization-defined events].",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": true,
      "moderate": true,
      "high": true
    },
    "intent": "Ensure personnel with contingency roles and responsibilities are adequately trained to execute contingency plans effectively during disruptions, maintaining organizational resilience and continuity of operations.",
    "plain_english_explanation": "Organizations must train employees on contingency procedures so they know how to respond when systems fail or disasters occur. Training must happen within a defined timeframe of taking on contingency responsibilities, whenever systems change significantly, and on a regular schedule. The training content itself must be reviewed and updated periodically and after significant events to ensure it remains current and effective.",
    "ai_guidance": "When implementing CP-3 Contingency Training, organizations should establish a comprehensive training program that covers: disaster recovery procedures, business continuity protocols, communication chains during emergencies, system restoration priorities, and individual role-specific responsibilities. Training should include both theoretical knowledge and practical exercises. Consider using Learning Management Systems (LMS) to track training completion, schedule refresher courses, and maintain training records for audit purposes. Integration with HR onboarding processes ensures new personnel receive timely training. Automated reminders and compliance dashboards help maintain training currency across the organization.",
    "example_implementation": "Establish a contingency training program using an LMS that tracks completion rates, schedules annual refresher training, and integrates with HR systems to trigger training assignments when employees assume contingency roles.",
    "non_technical_guidance": "To comply with CP-3 Contingency Training:\n1. Develop a contingency training program that covers all aspects of your contingency plan including roles, responsibilities, and procedures.\n2. Identify all personnel with contingency roles and ensure they receive initial training within your defined timeframe of assuming those roles.\n3. Schedule recurring training sessions at your defined frequency (annually is common for moderate/high impact systems).\n4. Update training materials when systems change or after contingency plan updates.\n5. Maintain training records documenting who was trained, when, and on what topics.\n6. Conduct periodic reviews of training effectiveness through assessments or tabletop exercises.\n7. Coordinate with HR to integrate contingency training into onboarding for relevant positions.",
    "is_technical": false,
    "enhancements": [
      {
        "id": "CP-3.1",
        "title": "Simulated Events",
        "official_text": "Incorporate simulated events into contingency training to facilitate effective response by personnel in crisis situations."
      },
      {
        "id": "CP-3.2",
        "title": "Mechanisms Used in Training Environments",
        "official_text": "Employ mechanisms used in operations to provide a more thorough and realistic contingency training environment."
      }
    ],
    "related_controls": [
      "AT-2",
      "AT-3",
      "AT-4",
      "CP-2",
      "CP-4",
      "CP-8",
      "IR-2",
      "IR-4",
      "IR-8"
    ],
    "supplemental_guidance": "Contingency training provided by organizations is linked to the assigned roles and responsibilities of organizational personnel to ensure that the appropriate content and level of detail is included in such training. For example, some individuals may only need to know when and where to report during contingency operations and if normal duties are affected; system administrators may require additional training on how to establish systems at alternate processing and storage sites; and organizational officials may receive more specific training on how to conduct mission-essential functions in designated off-site locations and how to establish communications with other governmental entities for purposes of coordination on contingency-related activities. Training for contingency roles or responsibilities reflects the specific continuity requirements in the contingency plan. Events that may precipitate an update to contingency training content include, but are not limited to, contingency plan testing or an actual contingency, changes in missions, roles, or responsibilities, or a change in the contingency plan content.",
    "implementation_scripts": {
      "linux": {
        "bash": "# training_tracker\n#!/bin/bash\n# CP-3: Contingency Training Tracker\n# Generates training compliance report from LMS exports\n\nTRAINING_LOG=\"/var/log/contingency_training.log\"\nREPORT_DIR=\"/var/reports/compliance\"\n\necho \"=== CP-3 Contingency Training Compliance Report ===\"\necho \"Generated: $(date)\"\necho \"\"\n\n# Check for training records\nif [ -f \"$TRAINING_LOG\" ]; then\n    echo \"Training Records Found:\"\n    grep -c \"COMPLETED\" \"$TRAINING_LOG\" | xargs -I {} echo \"  Completed: {} personnel\"\n    grep -c \"OVERDUE\" \"$TRAINING_LOG\" | xargs -I {} echo \"  Overdue: {} personnel\"\nelse\n    echo \"WARNING: Training log not found at $TRAINING_LOG\"\n    echo \"Ensure LMS integration is configured\"\nfi"
      },
      "windows": {
        "powershell": "# training_tracker\n# CP-3: Contingency Training Compliance Check\n# PowerShell script to query training status from Active Directory or LMS\n\n$TrainingGroup = \"Contingency-Trained-Personnel\"\n$ReportPath = \"C:\\Reports\\CP3_Training_Compliance.csv\"\n\nWrite-Host \"=== CP-3 Contingency Training Compliance Report ===\"\nWrite-Host \"Generated: $(Get-Date)\"\nWrite-Host \"\"\n\n# Query AD group membership for trained personnel\ntry {\n    $TrainedUsers = Get-ADGroupMember -Identity $TrainingGroup -ErrorAction Stop\n    Write-Host \"Personnel with current contingency training: $($TrainedUsers.Count)\"\n    \n    # Export to report\n    $TrainedUsers | Select-Object Name, SamAccountName | Export-Csv -Path $ReportPath -NoTypeInformation\n    Write-Host \"Report exported to: $ReportPath\"\n} catch {\n    Write-Warning \"Unable to query training group. Ensure AD module is available.\"\n    Write-Warning \"Error: $_\"\n}"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true,
      "qa_agent": "loveless"
    },
    "cac_metadata": {
      "implementation_type": "organizational",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "This control is primarily organizational/procedural. Technical automation supports tracking and reporting but the core requirement is human training delivery and documentation."
    },
    "rationale": "Staff who haven't practiced emergency procedures will panic or make mistakes during real incidents. Training builds muscle memory."
  },
  {
    "control_id": "CP-3.1",
    "control_name": "Simulated Events",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "official_text": "Incorporate simulated events into contingency training to facilitate effective response by personnel in crisis situations.",
    "parent_control": "CP-3",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": true
    },
    "intent": "Enhance contingency training effectiveness by exposing personnel to realistic simulated crisis scenarios, improving their ability to respond appropriately under pressure during actual contingency events.",
    "plain_english_explanation": "Beyond standard contingency training, organizations should incorporate realistic simulations of disaster scenarios into their training program. These simulated events help personnel practice their response in conditions that approximate real crises, building muscle memory and confidence. Simulations can range from tabletop exercises to full-scale drills involving system failovers and communication exercises.",
    "ai_guidance": "Implementing CP-3.1 Simulated Events requires developing scenario-based training exercises that test personnel responses to realistic contingency situations. Organizations should create a library of simulation scenarios covering various threat types: natural disasters, cyberattacks, infrastructure failures, and pandemic situations. Tabletop exercises are cost-effective for initial training, while functional exercises test actual procedures. Full-scale exercises should be conducted periodically for high-impact systems. Use simulation platforms or chaos engineering tools to create controlled failure scenarios in test environments. Document lessons learned from each simulation and incorporate improvements into training materials and contingency plans.",
    "example_implementation": "Conduct quarterly tabletop exercises simulating different disaster scenarios, annual functional exercises testing backup site activation, and integrate chaos engineering practices to simulate system failures in non-production environments.",
    "non_technical_guidance": "To comply with CP-3.1 Simulated Events:\n1. Develop a simulation exercise calendar with varying scenario types and complexity levels.\n2. Create realistic scenarios based on your organization's threat landscape and risk assessments.\n3. Conduct tabletop exercises where participants discuss responses to presented scenarios.\n4. Execute functional exercises that test specific contingency procedures without full operational impact.\n5. Periodically conduct full-scale exercises that test complete contingency activation.\n6. Include stress-inducing elements like time pressure or incomplete information to simulate real crisis conditions.\n7. Conduct after-action reviews following each simulation to capture lessons learned.\n8. Update contingency plans and training based on simulation outcomes.",
    "is_technical": false,
    "enhancements": [],
    "related_controls": [
      "CP-2",
      "CP-3",
      "CP-4",
      "IR-2",
      "IR-3"
    ],
    "supplemental_guidance": "Simulated events include, for example, tabletop exercises, functional exercises, and full-scale exercises. Simulations enhance contingency training by requiring personnel to demonstrate their responses under realistic conditions and in a timeframe that is consistent with actual contingency situations.",
    "implementation_scripts": {
      "linux": {
        "bash": "# simulation_scheduler\n#!/bin/bash\n# CP-3.1: Simulation Exercise Scheduler\n# Tracks and schedules contingency simulation exercises\n\nSIM_LOG=\"/var/log/contingency_simulations.log\"\nSCHEDULE_FILE=\"/etc/contingency/simulation_schedule.conf\"\n\necho \"=== CP-3.1 Simulation Exercise Status ===\"\necho \"Generated: $(date)\"\n\n# Check last simulation date\nif [ -f \"$SIM_LOG\" ]; then\n    LAST_SIM=$(tail -1 \"$SIM_LOG\" | cut -d'|' -f1)\n    echo \"Last simulation conducted: $LAST_SIM\"\n    \n    # Calculate days since last simulation\n    LAST_EPOCH=$(date -d \"$LAST_SIM\" +%s 2>/dev/null)\n    NOW_EPOCH=$(date +%s)\n    DAYS_SINCE=$(( (NOW_EPOCH - LAST_EPOCH) / 86400 ))\n    echo \"Days since last simulation: $DAYS_SINCE\"\n    \n    if [ $DAYS_SINCE -gt 90 ]; then\n        echo \"WARNING: Simulation exercise overdue (>90 days)\"\n    fi\nelse\n    echo \"WARNING: No simulation records found\"\nfi"
      },
      "windows": {
        "powershell": "# simulation_scheduler\n# CP-3.1: Simulation Exercise Tracker\n# PowerShell script to track contingency simulation exercises\n\n$SimulationLog = \"C:\\ProgramData\\Contingency\\simulation_log.csv\"\n$MaxDaysBetweenSims = 90\n\nWrite-Host \"=== CP-3.1 Simulation Exercise Status ===\"\nWrite-Host \"Generated: $(Get-Date)\"\nWrite-Host \"\"\n\nif (Test-Path $SimulationLog) {\n    $Simulations = Import-Csv $SimulationLog\n    $LastSim = $Simulations | Sort-Object Date -Descending | Select-Object -First 1\n    \n    Write-Host \"Last simulation: $($LastSim.Date) - $($LastSim.Type)\"\n    \n    $DaysSince = (New-TimeSpan -Start ([datetime]$LastSim.Date) -End (Get-Date)).Days\n    Write-Host \"Days since last simulation: $DaysSince\"\n    \n    if ($DaysSince -gt $MaxDaysBetweenSims) {\n        Write-Warning \"Simulation exercise overdue (>$MaxDaysBetweenSims days)\"\n    }\n} else {\n    Write-Warning \"No simulation log found at $SimulationLog\"\n}"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true,
      "qa_agent": "loveless"
    },
    "cac_metadata": {
      "implementation_type": "organizational",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "This enhancement is organizational, requiring scenario development and exercise execution. Technical scripts support scheduling and tracking simulation exercises."
    },
    "rationale": "Tabletop exercises and simulations reveal gaps in your plan before a real disaster does."
  },
  {
    "control_id": "CP-3.2",
    "control_name": "Mechanisms Used in Training Environments",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "official_text": "Employ mechanisms used in operations to provide a more thorough and realistic contingency training environment.",
    "parent_control": "CP-3",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "intent": "Ensure contingency training uses the same tools, systems, and mechanisms that personnel will use during actual contingency operations, reducing the gap between training and real-world execution.",
    "plain_english_explanation": "Training environments should use the same systems, tools, and procedures that staff will use during actual emergencies. If personnel train on different systems than they will use in a real contingency, they may struggle to execute procedures correctly under pressure. This enhancement ensures training fidelity by requiring organizations to replicate operational mechanisms in training contexts.",
    "ai_guidance": "Implementing CP-3.2 requires creating training environments that mirror production systems and operational tools. Organizations should establish dedicated training instances of critical systems, including backup and recovery tools, communication systems, and alternate processing site access. Container technologies and infrastructure-as-code enable rapid provisioning of production-like training environments. Consider maintaining a training lab that replicates key operational systems. For cloud environments, use separate accounts or subscriptions configured identically to production. Ensure personnel practice with actual recovery tools, not simulated interfaces. Document any differences between training and production environments and account for them in training materials.",
    "example_implementation": "Maintain a training environment that mirrors production infrastructure using infrastructure-as-code. Personnel practice contingency procedures using the same backup tools, communication systems, and alternate site access methods they would use in actual emergencies.",
    "non_technical_guidance": "To comply with CP-3.2 Mechanisms Used in Training Environments:\n1. Inventory all systems, tools, and mechanisms used during contingency operations.\n2. Create or designate training environments that replicate these operational mechanisms.\n3. Ensure backup and recovery tools used in training are identical to production tools.\n4. Provide access to alternate processing sites for training purposes where feasible.\n5. Configure training communication systems to match operational emergency communication capabilities.\n6. Maintain training environment currency with production system updates.\n7. Document any unavoidable differences between training and operational environments.\n8. Periodically validate that training mechanisms remain aligned with operational systems.",
    "is_technical": false,
    "enhancements": [],
    "related_controls": [
      "CP-2",
      "CP-3",
      "CP-3.1",
      "CP-4",
      "CP-7",
      "CP-8"
    ],
    "supplemental_guidance": "Mechanisms used in contingency operations may include, for example, communications equipment, backup power sources, alternate processing and storage sites, and recovery software. Using such mechanisms in training provides a more thorough and realistic experience for personnel.",
    "implementation_scripts": {
      "linux": {
        "bash": "# environment_validator\n#!/bin/bash\n# CP-3.2: Training Environment Validation\n# Compares training environment to production for parity\n\nPROD_CONFIG=\"/etc/contingency/prod_baseline.conf\"\nTRAIN_CONFIG=\"/etc/contingency/training_baseline.conf\"\n\necho \"=== CP-3.2 Training Environment Validation ===\"\necho \"Generated: $(date)\"\n\nif [ -f \"$PROD_CONFIG\" ] && [ -f \"$TRAIN_CONFIG\" ]; then\n    echo \"Comparing production and training configurations...\"\n    DIFF_COUNT=$(diff \"$PROD_CONFIG\" \"$TRAIN_CONFIG\" | grep -c '^[<>]')\n    \n    if [ $DIFF_COUNT -eq 0 ]; then\n        echo \"PASS: Training environment matches production baseline\"\n    else\n        echo \"WARNING: $DIFF_COUNT configuration differences detected\"\n        echo \"Review differences to ensure training fidelity\"\n        diff \"$PROD_CONFIG\" \"$TRAIN_CONFIG\"\n    fi\nelse\n    echo \"ERROR: Baseline configuration files not found\"\nfi"
      },
      "windows": {
        "powershell": "# environment_validator\n# CP-3.2: Training Environment Validation\n# PowerShell script to validate training environment parity\n\n$ProdBaseline = \"C:\\ProgramData\\Contingency\\prod_baseline.json\"\n$TrainBaseline = \"C:\\ProgramData\\Contingency\\training_baseline.json\"\n\nWrite-Host \"=== CP-3.2 Training Environment Validation ===\"\nWrite-Host \"Generated: $(Get-Date)\"\nWrite-Host \"\"\n\nif ((Test-Path $ProdBaseline) -and (Test-Path $TrainBaseline)) {\n    $Prod = Get-Content $ProdBaseline | ConvertFrom-Json\n    $Train = Get-Content $TrainBaseline | ConvertFrom-Json\n    \n    $Differences = Compare-Object -ReferenceObject $Prod.PSObject.Properties -DifferenceObject $Train.PSObject.Properties\n    \n    if ($Differences.Count -eq 0) {\n        Write-Host \"PASS: Training environment matches production baseline\" -ForegroundColor Green\n    } else {\n        Write-Warning \"$($Differences.Count) configuration differences detected\"\n        $Differences | ForEach-Object { Write-Host \"  - $($_.InputObject.Name): $($_.SideIndicator)\" }\n    }\n} else {\n    Write-Error \"Baseline configuration files not found\"\n}"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true,
      "qa_agent": "loveless"
    },
    "cac_metadata": {
      "implementation_type": "hybrid",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "This enhancement requires maintaining training environments with production-equivalent tools. Technical scripts validate environment parity between training and production systems."
    },
    "rationale": "Training environments should mirror production so staff practice with realistic tools and scenarios."
  },
  {
    "control_id": "CP-4",
    "control_name": "Contingency Plan Testing",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "official_text": "a. Test the contingency plan for the system [Assignment: organization-defined frequency] using the following tests to determine the effectiveness of the plan and the readiness to execute the plan: [Assignment: organization-defined tests]; b. Review the contingency plan test results; and c. Initiate corrective actions, if needed.",
    "parent_control": null,
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": true,
      "moderate": true,
      "high": true
    },
    "plain_english_explanation": "Organizations must regularly test their contingency plans to verify that backup systems, recovery procedures, and disaster response protocols actually work when needed. This involves conducting scheduled exercises such as tabletop walkthroughs, functional tests, or full-scale simulations to validate that critical systems can be restored within required timeframes. Test results must be documented and any identified gaps addressed through corrective actions to continuously improve organizational resilience.",
    "intent": "Ensure that contingency plans are effective and that personnel are prepared to execute recovery operations during actual disruptions or disasters.",
    "is_technical": false,
    "ai_guidance": "When implementing CP-4 Contingency Plan Testing, organizations should establish a comprehensive testing program that includes multiple testing methodologies. Begin with tabletop exercises for low-risk validation, progress to functional tests that verify specific recovery procedures, and conduct full-scale tests annually for high-impact systems. Document test scenarios, expected outcomes, actual results, and lessons learned. Integrate testing with change management to ensure plans remain current as systems evolve. Consider automation for backup verification and recovery time objective (RTO) measurement. Coordinate tests across organizational boundaries to validate interdependencies.",
    "example_implementation": "Conduct quarterly tabletop exercises with IT and business stakeholders, annual functional recovery tests of critical systems, and document all test results with corrective action plans.",
    "non_technical_guidance": "To comply with CP-4, organizations should: 1) Establish a testing schedule based on system criticality and risk assessment. 2) Define test objectives and success criteria before each exercise. 3) Involve key personnel from IT operations, security, and business units. 4) Document test procedures, participants, and outcomes. 5) Track corrective actions to closure. 6) Update contingency plans based on lessons learned.",
    "enhancements": [
      {
        "id": "CP-4.1",
        "title": "Coordinate with Related Plans",
        "official_text": "Coordinate contingency plan testing with organizational elements responsible for related plans."
      },
      {
        "id": "CP-4.2",
        "title": "Alternate Processing Site",
        "official_text": "Test the contingency plan at the alternate processing site: (a) To familiarize contingency personnel with the facility and available resources; and (b) To evaluate the capabilities of the alternate processing site to support contingency operations."
      },
      {
        "id": "CP-4.3",
        "title": "Automated Testing",
        "official_text": "Test the contingency plan using [Assignment: organization-defined automated mechanisms]."
      },
      {
        "id": "CP-4.4",
        "title": "Full Recovery and Reconstitution",
        "official_text": "Include a full recovery and reconstitution of the system to a known state as part of contingency plan testing."
      },
      {
        "id": "CP-4.5",
        "title": "Self-Challenge",
        "official_text": "Employ [Assignment: organization-defined mechanisms] to [Assignment: organization-defined system or system component] to disrupt and adversely affect the system or system component."
      }
    ],
    "related_controls": [
      "CP-2",
      "CP-3",
      "CP-6",
      "CP-7",
      "CP-8",
      "CP-9",
      "IR-3",
      "IR-4",
      "PM-14"
    ],
    "supplemental_guidance": "Methods for testing contingency plans include checklists, walk-throughs, tabletop exercises, simulations (parallel or full interrupt), and comprehensive exercises. Organizations conduct testing based on the criticality of the functions that systems support and the overall continuity of operations requirements. Testing can be scenario-based, focused on a specific event, or general. Testing also includes determination of effects on organizational operations and assets and on individuals arising from contingency operations.",
    "implementation_scripts": {
      "linux": {
        "bash": "# backup_verification\n#!/bin/bash\n# CP-4: Backup Verification Test Script\n# Verifies backup integrity and recovery capability\n\nset -euo pipefail\n\nLOG_FILE=\"/var/log/contingency-test-$(date +%Y%m%d).log\"\nBACKUP_DIR=\"/backup\"\nTEST_RESTORE_DIR=\"/tmp/restore-test\"\n\nlog_message() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" | tee -a \"$LOG_FILE\"\n}\n\nlog_message \"Starting CP-4 Contingency Plan Test\"\n\n# Test 1: Verify backup files exist and are recent\nlog_message \"Test 1: Checking backup file existence and age\"\nfind \"$BACKUP_DIR\" -name \"*.tar.gz\" -mtime -1 | head -5\nif [ $? -eq 0 ]; then\n    log_message \"PASS: Recent backups found\"\nelse\n    log_message \"FAIL: No recent backups found\"\n    exit 1\nfi\n\n# Test 2: Verify backup integrity\nlog_message \"Test 2: Verifying backup integrity\"\nfor backup in $(find \"$BACKUP_DIR\" -name \"*.tar.gz\" -mtime -1 | head -3); do\n    if gzip -t \"$backup\" 2>/dev/null; then\n        log_message \"PASS: $backup integrity verified\"\n    else\n        log_message \"FAIL: $backup is corrupted\"\n        exit 1\n    fi\ndone\n\n# Test 3: Test restore capability\nlog_message \"Test 3: Testing restore capability\"\nmkdir -p \"$TEST_RESTORE_DIR\"\nLATEST_BACKUP=$(find \"$BACKUP_DIR\" -name \"*.tar.gz\" -mtime -1 | head -1)\nif tar -tzf \"$LATEST_BACKUP\" > /dev/null 2>&1; then\n    log_message \"PASS: Restore test successful\"\nelse\n    log_message \"FAIL: Restore test failed\"\n    exit 1\nfi\nrm -rf \"$TEST_RESTORE_DIR\"\n\nlog_message \"CP-4 Contingency Plan Test Complete - All tests passed\"\nexit 0\n\n# dr_validation\n#!/bin/bash\n# CP-4: Disaster Recovery Validation Script\n# Validates DR site connectivity and readiness\n\nset -euo pipefail\n\nDR_SITE=\"dr-site.example.com\"\nCRITICAL_SERVICES=(\"database\" \"webserver\" \"fileserver\")\nLOG_FILE=\"/var/log/dr-validation-$(date +%Y%m%d).log\"\n\nlog_message() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" | tee -a \"$LOG_FILE\"\n}\n\nlog_message \"Starting DR Site Validation\"\n\n# Test 1: DR site connectivity\nlog_message \"Test 1: Checking DR site connectivity\"\nif ping -c 3 \"$DR_SITE\" > /dev/null 2>&1; then\n    log_message \"PASS: DR site is reachable\"\nelse\n    log_message \"FAIL: DR site is unreachable\"\n    exit 1\nfi\n\n# Test 2: Check critical services on DR site\nlog_message \"Test 2: Validating critical services\"\nfor service in \"${CRITICAL_SERVICES[@]}\"; do\n    if ssh \"$DR_SITE\" \"systemctl is-active $service\" 2>/dev/null; then\n        log_message \"PASS: $service is active on DR site\"\n    else\n        log_message \"WARN: $service status unknown on DR site\"\n    fi\ndone\n\n# Test 3: Verify data synchronization\nlog_message \"Test 3: Checking data synchronization status\"\nif ssh \"$DR_SITE\" \"test -f /var/dr-sync/last-sync && find /var/dr-sync/last-sync -mmin -60\" 2>/dev/null; then\n    log_message \"PASS: Data synchronization is current\"\nelse\n    log_message \"WARN: Data synchronization may be stale\"\nfi\n\nlog_message \"DR Site Validation Complete\"\nexit 0"
      },
      "windows": {
        "powershell": "# backup_verification\n# CP-4: Backup Verification Test Script for Windows\n# Verifies backup integrity and recovery capability\n\n$ErrorActionPreference = \"Stop\"\n$LogFile = \"C:\\Logs\\contingency-test-$(Get-Date -Format 'yyyyMMdd').log\"\n$BackupDir = \"D:\\Backups\"\n$TestRestoreDir = \"C:\\Temp\\RestoreTest\"\n\nfunction Write-Log {\n    param([string]$Message)\n    $timestamp = Get-Date -Format 'yyyy-MM-dd HH:mm:ss'\n    \"$timestamp - $Message\" | Tee-Object -FilePath $LogFile -Append\n}\n\nWrite-Log \"Starting CP-4 Contingency Plan Test\"\n\n# Test 1: Verify backup files exist and are recent\nWrite-Log \"Test 1: Checking backup file existence and age\"\n$recentBackups = Get-ChildItem -Path $BackupDir -Filter \"*.bak\" -Recurse | Where-Object { $_.LastWriteTime -gt (Get-Date).AddDays(-1) }\nif ($recentBackups.Count -gt 0) {\n    Write-Log \"PASS: Found $($recentBackups.Count) recent backup(s)\"\n    $recentBackups | ForEach-Object { Write-Log \"  - $($_.FullName)\" }\n} else {\n    Write-Log \"FAIL: No recent backups found\"\n    exit 1\n}\n\n# Test 2: Verify Windows Backup status\nWrite-Log \"Test 2: Checking Windows Backup service status\"\n$wbadmin = Get-Command wbadmin -ErrorAction SilentlyContinue\nif ($wbadmin) {\n    $backupStatus = wbadmin get status 2>&1\n    Write-Log \"Backup Status: $backupStatus\"\n    Write-Log \"PASS: Backup service accessible\"\n} else {\n    Write-Log \"WARN: wbadmin not available\"\n}\n\n# Test 3: Verify Volume Shadow Copy\nWrite-Log \"Test 3: Checking Volume Shadow Copies\"\n$shadows = Get-WmiObject Win32_ShadowCopy\nif ($shadows.Count -gt 0) {\n    Write-Log \"PASS: $($shadows.Count) shadow copies available\"\n} else {\n    Write-Log \"WARN: No shadow copies found\"\n}\n\nWrite-Log \"CP-4 Contingency Plan Test Complete\"\nexit 0\n\n# dr_validation\n# CP-4: Disaster Recovery Validation Script for Windows\n# Validates DR site connectivity and readiness\n\n$ErrorActionPreference = \"Stop\"\n$DRSite = \"dr-site.example.com\"\n$CriticalServices = @(\"MSSQLSERVER\", \"W3SVC\", \"WinRM\")\n$LogFile = \"C:\\Logs\\dr-validation-$(Get-Date -Format 'yyyyMMdd').log\"\n\nfunction Write-Log {\n    param([string]$Message)\n    $timestamp = Get-Date -Format 'yyyy-MM-dd HH:mm:ss'\n    \"$timestamp - $Message\" | Tee-Object -FilePath $LogFile -Append\n}\n\nWrite-Log \"Starting DR Site Validation\"\n\n# Test 1: DR site connectivity\nWrite-Log \"Test 1: Checking DR site connectivity\"\nif (Test-Connection -ComputerName $DRSite -Count 3 -Quiet) {\n    Write-Log \"PASS: DR site is reachable\"\n} else {\n    Write-Log \"FAIL: DR site is unreachable\"\n    exit 1\n}\n\n# Test 2: Check critical services on DR site\nWrite-Log \"Test 2: Validating critical services on DR site\"\nforeach ($service in $CriticalServices) {\n    try {\n        $svc = Get-Service -ComputerName $DRSite -Name $service -ErrorAction SilentlyContinue\n        if ($svc.Status -eq 'Running') {\n            Write-Log \"PASS: $service is running on DR site\"\n        } else {\n            Write-Log \"WARN: $service is $($svc.Status) on DR site\"\n        }\n    } catch {\n        Write-Log \"WARN: Could not check $service status\"\n    }\n}\n\n# Test 3: Verify network path to DR storage\nWrite-Log \"Test 3: Checking DR storage accessibility\"\n$drPath = \"\\\\$DRSite\\DRStorage\"\nif (Test-Path $drPath -ErrorAction SilentlyContinue) {\n    Write-Log \"PASS: DR storage is accessible\"\n} else {\n    Write-Log \"WARN: DR storage path not accessible\"\n}\n\nWrite-Log \"DR Site Validation Complete\"\nexit 0"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true
    },
    "cac_metadata": {
      "implementation_type": "hybrid",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "CP-4 requires a combination of organizational procedures and technical validation. Automated scripts can verify backup integrity and DR site readiness, but tabletop exercises and coordination require manual implementation."
    },
    "rationale": "An untested plan is just a guess. Regular testing proves your recovery procedures actually work."
  },
  {
    "control_id": "CP-4.1",
    "control_name": "Coordinate with Related Plans",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "official_text": "Coordinate contingency plan testing with organizational elements responsible for related plans.",
    "parent_control": "CP-4",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": true,
      "high": true
    },
    "plain_english_explanation": "When testing your contingency plan, coordinate with other teams who maintain related plans such as business continuity, disaster recovery, incident response, communications, and occupant emergency plans. This ensures that all organizational elements work together effectively during an actual emergency and identifies potential conflicts or gaps between different plans.",
    "intent": "Ensure comprehensive and integrated testing of contingency capabilities across all organizational elements with related emergency and continuity plans.",
    "is_technical": false,
    "ai_guidance": "Implementing CP-4.1 requires establishing formal coordination mechanisms between contingency plan owners and related plan stakeholders. Create a coordination matrix identifying all related plans (COOP, BCP, DRP, IRP, OEP, CMP) and their owners. Schedule joint testing exercises at least annually that involve multiple plan domains. Document interdependencies between plans and validate them during testing. Establish communication protocols for notifying stakeholders of test schedules and results. Consider using integrated exercise scenarios that activate multiple plans simultaneously to validate coordination procedures.",
    "example_implementation": "Establish a cross-functional contingency planning committee with representatives from IT, facilities, HR, communications, and business units. Schedule annual integrated exercises that test multiple plans together.",
    "non_technical_guidance": "To comply with CP-4.1: 1) Identify all related plans within the organization (continuity, disaster recovery, incident response, communications). 2) Create a stakeholder matrix with plan owners and testing contacts. 3) Establish a coordination schedule for joint testing activities. 4) Develop integrated test scenarios that involve multiple organizational elements. 5) Document coordination activities and lessons learned. 6) Share test results across all stakeholder groups.",
    "enhancements": [],
    "related_controls": [
      "CP-2",
      "CP-4",
      "IR-8",
      "PM-8",
      "PM-11"
    ],
    "supplemental_guidance": "Related plans include business continuity plans, disaster recovery plans, continuity of operations plans, crisis management plans, critical infrastructure protection plans, cyber incident response plans, and occupant emergency plans.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": false
    },
    "cac_metadata": {
      "implementation_type": "organizational",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "This enhancement requires organizational coordination and cannot be fully automated. Focus on establishing governance structures, communication channels, and integrated exercise schedules."
    },
    "rationale": "Test results should feed back into improving all related plans, not just the contingency plan."
  },
  {
    "control_id": "CP-4.2",
    "control_name": "Alternate Processing Site",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "official_text": "Test the contingency plan at the alternate processing site: (a) To familiarize contingency personnel with the facility and available resources; and (b) To evaluate the capabilities of the alternate processing site to support contingency operations.",
    "parent_control": "CP-4",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": true
    },
    "plain_english_explanation": "Conduct contingency plan tests at your designated alternate processing site (disaster recovery location) to ensure personnel are familiar with the facility and to verify that the site has adequate resources and capabilities to support critical operations. This includes validating network connectivity, system access, data availability, and environmental controls at the alternate location.",
    "intent": "Validate the readiness and capability of the alternate processing site to support contingency operations and ensure personnel familiarity with the alternate environment.",
    "is_technical": true,
    "ai_guidance": "When implementing CP-4.2, organizations should conduct annual failover tests to the alternate processing site. Test scenarios should include: network connectivity validation, application functionality verification, data synchronization confirmation, user access testing, and environmental systems checks. Document RTO (Recovery Time Objective) and RPO (Recovery Point Objective) achievement during tests. Train personnel on alternate site procedures including physical access, system login, and communication channels. Consider conducting surprise failover tests to validate true readiness. Automate connectivity and service monitoring between primary and alternate sites.",
    "example_implementation": "Conduct quarterly connectivity tests and annual full failover exercises at the DR site. Document personnel familiarity training and validate all critical systems can operate from the alternate location.",
    "non_technical_guidance": "To comply with CP-4.2: 1) Schedule regular visits to the alternate site for contingency personnel. 2) Conduct hands-on exercises at the alternate location. 3) Verify all necessary credentials and access are provisioned for the alternate site. 4) Test communication systems from the alternate location. 5) Validate that documentation and procedures are available at the alternate site. 6) Assess any capability gaps and develop remediation plans.",
    "enhancements": [],
    "related_controls": [
      "CP-6",
      "CP-7",
      "CP-4"
    ],
    "supplemental_guidance": "Alternate processing site testing provides confidence that the organization can actually recover operations at the designated site. Testing should include verification of telecommunications, power, environmental controls, and physical security at the alternate site.",
    "implementation_scripts": {
      "linux": {
        "bash": "# alternate_site_test\n#!/bin/bash\n# CP-4.2: Alternate Processing Site Connectivity Test\n# Validates DR site readiness and connectivity\n\nset -euo pipefail\n\nDR_SITE=\"dr-site.example.com\"\nDR_DB_SERVER=\"dr-db.example.com\"\nDR_APP_SERVERS=(\"dr-app1.example.com\" \"dr-app2.example.com\")\nLOG_FILE=\"/var/log/alternate-site-test-$(date +%Y%m%d).log\"\nRESULTS_FILE=\"/var/log/cp42-test-results.json\"\n\nlog_message() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" | tee -a \"$LOG_FILE\"\n}\n\nlog_message \"=== CP-4.2 Alternate Processing Site Test ===\"\nlog_message \"Testing alternate site: $DR_SITE\"\n\nTEST_RESULTS='{}'\nPASS_COUNT=0\nFAIL_COUNT=0\n\n# Test 1: Primary connectivity to DR site\nlog_message \"Test 1: DR Site Connectivity\"\nif ping -c 5 \"$DR_SITE\" > /dev/null 2>&1; then\n    log_message \"PASS: DR site is reachable\"\n    ((PASS_COUNT++))\nelse\n    log_message \"FAIL: DR site is unreachable\"\n    ((FAIL_COUNT++))\nfi\n\n# Test 2: Database server connectivity\nlog_message \"Test 2: DR Database Server Connectivity\"\nif nc -z -w5 \"$DR_DB_SERVER\" 5432 2>/dev/null; then\n    log_message \"PASS: DR database server port accessible\"\n    ((PASS_COUNT++))\nelse\n    log_message \"FAIL: DR database server not accessible\"\n    ((FAIL_COUNT++))\nfi\n\n# Test 3: Application servers connectivity\nlog_message \"Test 3: DR Application Servers\"\nfor server in \"${DR_APP_SERVERS[@]}\"; do\n    if nc -z -w5 \"$server\" 443 2>/dev/null; then\n        log_message \"PASS: $server HTTPS port accessible\"\n        ((PASS_COUNT++))\n    else\n        log_message \"FAIL: $server HTTPS port not accessible\"\n        ((FAIL_COUNT++))\n    fi\ndone\n\n# Test 4: SSH access to DR site\nlog_message \"Test 4: SSH Access Validation\"\nif ssh -o ConnectTimeout=10 -o BatchMode=yes \"$DR_SITE\" 'echo connected' 2>/dev/null; then\n    log_message \"PASS: SSH access to DR site confirmed\"\n    ((PASS_COUNT++))\nelse\n    log_message \"WARN: SSH access test inconclusive\"\nfi\n\n# Test 5: Check disk space at DR site\nlog_message \"Test 5: DR Site Resource Availability\"\nif ssh -o ConnectTimeout=10 \"$DR_SITE\" 'df -h / | tail -1' 2>/dev/null; then\n    log_message \"PASS: DR site resource check complete\"\n    ((PASS_COUNT++))\nelse\n    log_message \"WARN: Could not verify DR site resources\"\nfi\n\n# Summary\nlog_message \"=== Test Summary ===\"\nlog_message \"Tests Passed: $PASS_COUNT\"\nlog_message \"Tests Failed: $FAIL_COUNT\"\n\nif [ \"$FAIL_COUNT\" -eq 0 ]; then\n    log_message \"OVERALL: PASS - Alternate site is ready\"\n    exit 0\nelse\n    log_message \"OVERALL: FAIL - Alternate site has issues\"\n    exit 1\nfi"
      },
      "windows": {
        "powershell": "# alternate_site_test\n# CP-4.2: Alternate Processing Site Connectivity Test for Windows\n# Validates DR site readiness and connectivity\n\n$ErrorActionPreference = \"Stop\"\n$DRSite = \"dr-site.example.com\"\n$DRDBServer = \"dr-db.example.com\"\n$DRAppServers = @(\"dr-app1.example.com\", \"dr-app2.example.com\")\n$LogFile = \"C:\\Logs\\alternate-site-test-$(Get-Date -Format 'yyyyMMdd').log\"\n\n$PassCount = 0\n$FailCount = 0\n\nfunction Write-Log {\n    param([string]$Message)\n    $timestamp = Get-Date -Format 'yyyy-MM-dd HH:mm:ss'\n    \"$timestamp - $Message\" | Tee-Object -FilePath $LogFile -Append\n}\n\nWrite-Log \"=== CP-4.2 Alternate Processing Site Test ===\"\nWrite-Log \"Testing alternate site: $DRSite\"\n\n# Test 1: Primary connectivity to DR site\nWrite-Log \"Test 1: DR Site Connectivity\"\nif (Test-Connection -ComputerName $DRSite -Count 5 -Quiet) {\n    Write-Log \"PASS: DR site is reachable\"\n    $PassCount++\n} else {\n    Write-Log \"FAIL: DR site is unreachable\"\n    $FailCount++\n}\n\n# Test 2: Database server connectivity (SQL Server default port)\nWrite-Log \"Test 2: DR Database Server Connectivity\"\ntry {\n    $tcpClient = New-Object System.Net.Sockets.TcpClient\n    $tcpClient.Connect($DRDBServer, 1433)\n    $tcpClient.Close()\n    Write-Log \"PASS: DR database server port accessible\"\n    $PassCount++\n} catch {\n    Write-Log \"FAIL: DR database server not accessible\"\n    $FailCount++\n}\n\n# Test 3: Application servers connectivity (HTTPS)\nWrite-Log \"Test 3: DR Application Servers\"\nforeach ($server in $DRAppServers) {\n    try {\n        $tcpClient = New-Object System.Net.Sockets.TcpClient\n        $tcpClient.Connect($server, 443)\n        $tcpClient.Close()\n        Write-Log \"PASS: $server HTTPS port accessible\"\n        $PassCount++\n    } catch {\n        Write-Log \"FAIL: $server HTTPS port not accessible\"\n        $FailCount++\n    }\n}\n\n# Test 4: WinRM access to DR site\nWrite-Log \"Test 4: WinRM Access Validation\"\ntry {\n    Test-WSMan -ComputerName $DRSite -ErrorAction Stop | Out-Null\n    Write-Log \"PASS: WinRM access to DR site confirmed\"\n    $PassCount++\n} catch {\n    Write-Log \"WARN: WinRM access test inconclusive\"\n}\n\n# Test 5: Check disk space at DR site\nWrite-Log \"Test 5: DR Site Resource Availability\"\ntry {\n    $diskInfo = Invoke-Command -ComputerName $DRSite -ScriptBlock { Get-PSDrive C } -ErrorAction Stop\n    Write-Log \"PASS: DR site has $([math]::Round($diskInfo.Free/1GB, 2)) GB free\"\n    $PassCount++\n} catch {\n    Write-Log \"WARN: Could not verify DR site resources\"\n}\n\n# Summary\nWrite-Log \"=== Test Summary ===\"\nWrite-Log \"Tests Passed: $PassCount\"\nWrite-Log \"Tests Failed: $FailCount\"\n\nif ($FailCount -eq 0) {\n    Write-Log \"OVERALL: PASS - Alternate site is ready\"\n    exit 0\n} else {\n    Write-Log \"OVERALL: FAIL - Alternate site has issues\"\n    exit 1\n}"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true
    },
    "cac_metadata": {
      "implementation_type": "hybrid",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "CP-4.2 requires both technical validation (connectivity, services, resources) and organizational activities (personnel familiarization, capability evaluation). Automated scripts can validate technical readiness."
    },
    "rationale": "Your backup site needs regular testing to ensure it can actually take over when needed."
  },
  {
    "control_id": "CP-4.3",
    "control_name": "Automated Testing",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "official_text": "Test the contingency plan using [Assignment: organization-defined automated mechanisms].",
    "parent_control": "CP-4",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "plain_english_explanation": "Use automated tools and mechanisms to test contingency plan components without requiring manual intervention. This includes automated backup verification, recovery testing, failover validation, and monitoring system health checks. Automation improves test frequency, consistency, and reduces human error in validating disaster recovery capabilities.",
    "intent": "Enable more thorough, frequent, and reliable contingency plan testing through automation, reducing reliance on manual testing procedures.",
    "is_technical": true,
    "ai_guidance": "CP-4.3 focuses on automating contingency plan testing for improved reliability and frequency. Implement automated mechanisms including: scheduled backup integrity verification using checksums and test restores, automated failover testing during maintenance windows, synthetic transaction monitoring to validate application recovery, infrastructure-as-code for consistent DR environment provisioning, and automated RTO/RPO measurement and reporting. Consider chaos engineering practices to continuously validate resilience. Integrate automated testing into CI/CD pipelines for systems that support it. Use orchestration tools like Ansible, Terraform, or cloud-native DR services for automated recovery testing.",
    "example_implementation": "Implement automated nightly backup verification scripts, weekly automated failover tests to DR site, and continuous monitoring of replication lag. Use infrastructure automation to provision test recovery environments.",
    "non_technical_guidance": "To comply with CP-4.3: 1) Identify components of the contingency plan suitable for automation. 2) Select appropriate automation tools and platforms. 3) Develop automated test scripts for backup, recovery, and failover scenarios. 4) Schedule automated tests at appropriate frequencies. 5) Configure alerting for automated test failures. 6) Review automated test results and maintain automation scripts.",
    "enhancements": [],
    "related_controls": [
      "CP-4",
      "CP-9",
      "SI-6",
      "SI-7"
    ],
    "supplemental_guidance": "Automated testing provides a more thorough and effective testing capability and allows for testing to occur more frequently. Automated mechanisms include synthetic transactions, simulation testing, and anomaly detection.",
    "implementation_scripts": {
      "linux": {
        "bash": "# automated_contingency_test\n#!/bin/bash\n# CP-4.3: Automated Contingency Plan Testing Suite\n# Comprehensive automated testing of backup and recovery capabilities\n\nset -euo pipefail\n\nCONFIG_FILE=\"/etc/contingency-test/config.conf\"\nLOG_DIR=\"/var/log/contingency-tests\"\nLOG_FILE=\"$LOG_DIR/automated-test-$(date +%Y%m%d-%H%M%S).log\"\nRESULTS_DIR=\"$LOG_DIR/results\"\nALERT_EMAIL=\"security@example.com\"\n\nmkdir -p \"$LOG_DIR\" \"$RESULTS_DIR\"\n\nlog_message() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" | tee -a \"$LOG_FILE\"\n}\n\nsend_alert() {\n    local subject=\"$1\"\n    local body=\"$2\"\n    echo \"$body\" | mail -s \"$subject\" \"$ALERT_EMAIL\" 2>/dev/null || true\n}\n\n# Initialize test results\nTEST_START=$(date +%s)\nPASS_COUNT=0\nFAIL_COUNT=0\nWARN_COUNT=0\n\nlog_message \"========================================\"\nlog_message \"CP-4.3 Automated Contingency Plan Test\"\nlog_message \"========================================\"\n\n# Test Suite 1: Backup Integrity Verification\nlog_message \"\\n=== Test Suite 1: Backup Integrity ===\"\n\n# 1.1 Check backup schedule execution\nlog_message \"Test 1.1: Backup Schedule Verification\"\nif systemctl is-active --quiet backup.timer 2>/dev/null || crontab -l 2>/dev/null | grep -q backup; then\n    log_message \"PASS: Backup scheduling is active\"\n    ((PASS_COUNT++))\nelse\n    log_message \"FAIL: No backup scheduling detected\"\n    ((FAIL_COUNT++))\nfi\n\n# 1.2 Verify recent backup existence\nlog_message \"Test 1.2: Recent Backup Existence\"\nBACKUP_DIRS=(\"/backup\" \"/var/backup\" \"/mnt/backup\")\nBACKUP_FOUND=false\nfor dir in \"${BACKUP_DIRS[@]}\"; do\n    if [ -d \"$dir\" ]; then\n        recent=$(find \"$dir\" -type f -mtime -1 -name \"*.tar.gz\" -o -name \"*.bak\" -o -name \"*.sql\" 2>/dev/null | head -1)\n        if [ -n \"$recent\" ]; then\n            log_message \"PASS: Recent backup found: $recent\"\n            ((PASS_COUNT++))\n            BACKUP_FOUND=true\n            break\n        fi\n    fi\ndone\nif [ \"$BACKUP_FOUND\" = false ]; then\n    log_message \"FAIL: No recent backups found in standard locations\"\n    ((FAIL_COUNT++))\nfi\n\n# 1.3 Checksum verification\nlog_message \"Test 1.3: Backup Checksum Verification\"\nif [ -f \"/backup/checksums.sha256\" ]; then\n    cd /backup && sha256sum -c checksums.sha256 --quiet 2>/dev/null\n    if [ $? -eq 0 ]; then\n        log_message \"PASS: Backup checksums verified\"\n        ((PASS_COUNT++))\n    else\n        log_message \"FAIL: Backup checksum mismatch\"\n        ((FAIL_COUNT++))\n    fi\nelse\n    log_message \"WARN: No checksum file found for verification\"\n    ((WARN_COUNT++))\nfi\n\n# Test Suite 2: Recovery Capability\nlog_message \"\\n=== Test Suite 2: Recovery Capability ===\"\n\n# 2.1 Test archive extraction\nlog_message \"Test 2.1: Archive Extraction Test\"\nTEST_DIR=\"/tmp/recovery-test-$$\"\nmkdir -p \"$TEST_DIR\"\nLATEST_BACKUP=$(find /backup -name \"*.tar.gz\" -type f -mtime -7 2>/dev/null | head -1)\nif [ -n \"$LATEST_BACKUP\" ]; then\n    if tar -tzf \"$LATEST_BACKUP\" > /dev/null 2>&1; then\n        log_message \"PASS: Archive can be extracted: $LATEST_BACKUP\"\n        ((PASS_COUNT++))\n    else\n        log_message \"FAIL: Archive extraction failed\"\n        ((FAIL_COUNT++))\n    fi\nelse\n    log_message \"WARN: No recent archive found for extraction test\"\n    ((WARN_COUNT++))\nfi\nrm -rf \"$TEST_DIR\"\n\n# 2.2 Database recovery test (if applicable)\nlog_message \"Test 2.2: Database Recovery Capability\"\nif command -v mysql &> /dev/null; then\n    if mysql -e \"SELECT 1\" &>/dev/null; then\n        log_message \"PASS: Database connectivity verified\"\n        ((PASS_COUNT++))\n    else\n        log_message \"FAIL: Database connectivity failed\"\n        ((FAIL_COUNT++))\n    fi\nelif command -v psql &> /dev/null; then\n    if psql -c \"SELECT 1\" &>/dev/null; then\n        log_message \"PASS: PostgreSQL connectivity verified\"\n        ((PASS_COUNT++))\n    else\n        log_message \"FAIL: PostgreSQL connectivity failed\"\n        ((FAIL_COUNT++))\n    fi\nelse\n    log_message \"INFO: No database detected for recovery test\"\nfi\n\n# Test Suite 3: Service Recovery\nlog_message \"\\n=== Test Suite 3: Service Recovery ===\"\n\n# 3.1 Critical services check\nlog_message \"Test 3.1: Critical Services Status\"\nCRITICAL_SERVICES=(\"sshd\" \"nginx\" \"httpd\" \"docker\")\nfor svc in \"${CRITICAL_SERVICES[@]}\"; do\n    if systemctl is-active --quiet \"$svc\" 2>/dev/null; then\n        log_message \"PASS: Service $svc is running\"\n        ((PASS_COUNT++))\n    elif systemctl list-unit-files | grep -q \"$svc\"; then\n        log_message \"WARN: Service $svc is installed but not running\"\n        ((WARN_COUNT++))\n    fi\ndone\n\n# 3.2 Service restart capability\nlog_message \"Test 3.2: Service Restart Capability (dry-run)\"\nif systemctl list-units --type=service --state=running | head -5 > /dev/null; then\n    log_message \"PASS: Service management operational\"\n    ((PASS_COUNT++))\nelse\n    log_message \"FAIL: Service management not operational\"\n    ((FAIL_COUNT++))\nfi\n\n# Test Suite 4: Network Recovery\nlog_message \"\\n=== Test Suite 4: Network Recovery ===\"\n\n# 4.1 DNS resolution\nlog_message \"Test 4.1: DNS Resolution\"\nif host google.com > /dev/null 2>&1; then\n    log_message \"PASS: DNS resolution working\"\n    ((PASS_COUNT++))\nelse\n    log_message \"FAIL: DNS resolution failed\"\n    ((FAIL_COUNT++))\nfi\n\n# 4.2 External connectivity\nlog_message \"Test 4.2: External Connectivity\"\nif curl -s --connect-timeout 10 https://www.google.com > /dev/null 2>&1; then\n    log_message \"PASS: External connectivity verified\"\n    ((PASS_COUNT++))\nelse\n    log_message \"FAIL: External connectivity failed\"\n    ((FAIL_COUNT++))\nfi\n\n# Calculate test duration\nTEST_END=$(date +%s)\nDURATION=$((TEST_END - TEST_START))\n\n# Generate summary\nlog_message \"\\n========================================\"\nlog_message \"Test Summary\"\nlog_message \"========================================\"\nlog_message \"Tests Passed:  $PASS_COUNT\"\nlog_message \"Tests Failed:  $FAIL_COUNT\"\nlog_message \"Warnings:      $WARN_COUNT\"\nlog_message \"Duration:      ${DURATION}s\"\nlog_message \"========================================\"\n\n# Generate JSON results\ncat > \"$RESULTS_DIR/test-results-$(date +%Y%m%d).json\" << EOF\n{\n  \"timestamp\": \"$(date -Iseconds)\",\n  \"control\": \"CP-4.3\",\n  \"tests_passed\": $PASS_COUNT,\n  \"tests_failed\": $FAIL_COUNT,\n  \"warnings\": $WARN_COUNT,\n  \"duration_seconds\": $DURATION,\n  \"overall_status\": \"$([ $FAIL_COUNT -eq 0 ] && echo 'PASS' || echo 'FAIL')\"\n}\nEOF\n\n# Send alert if failures detected\nif [ \"$FAIL_COUNT\" -gt 0 ]; then\n    log_message \"OVERALL: FAIL - Contingency plan test identified issues\"\n    send_alert \"[ALERT] CP-4.3 Automated Test Failed\" \"$FAIL_COUNT tests failed. Review log: $LOG_FILE\"\n    exit 1\nelse\n    log_message \"OVERALL: PASS - Contingency plan automated testing successful\"\n    exit 0\nfi"
      },
      "windows": {
        "powershell": "# automated_contingency_test\n# CP-4.3: Automated Contingency Plan Testing Suite for Windows\n# Comprehensive automated testing of backup and recovery capabilities\n\n$ErrorActionPreference = \"Stop\"\n$LogDir = \"C:\\Logs\\ContingencyTests\"\n$LogFile = Join-Path $LogDir \"automated-test-$(Get-Date -Format 'yyyyMMdd-HHmmss').log\"\n$ResultsDir = Join-Path $LogDir \"Results\"\n$AlertEmail = \"security@example.com\"\n\nNew-Item -ItemType Directory -Path $LogDir, $ResultsDir -Force | Out-Null\n\n$TestStart = Get-Date\n$PassCount = 0\n$FailCount = 0\n$WarnCount = 0\n\nfunction Write-Log {\n    param([string]$Message)\n    $timestamp = Get-Date -Format 'yyyy-MM-dd HH:mm:ss'\n    \"$timestamp - $Message\" | Tee-Object -FilePath $LogFile -Append\n}\n\nfunction Send-Alert {\n    param([string]$Subject, [string]$Body)\n    try {\n        Send-MailMessage -To $AlertEmail -Subject $Subject -Body $Body -SmtpServer \"smtp.example.com\" -ErrorAction SilentlyContinue\n    } catch {\n        Write-Log \"WARN: Could not send alert email\"\n    }\n}\n\nWrite-Log \"========================================\"\nWrite-Log \"CP-4.3 Automated Contingency Plan Test\"\nWrite-Log \"========================================\"\n\n# Test Suite 1: Backup Integrity Verification\nWrite-Log \"`n=== Test Suite 1: Backup Integrity ===\"\n\n# 1.1 Check Windows Backup status\nWrite-Log \"Test 1.1: Windows Backup Service Status\"\n$wbService = Get-Service -Name wbengine -ErrorAction SilentlyContinue\nif ($wbService -and $wbService.Status -eq 'Running') {\n    Write-Log \"PASS: Windows Backup Engine is running\"\n    $PassCount++\n} else {\n    Write-Log \"WARN: Windows Backup Engine not running\"\n    $WarnCount++\n}\n\n# 1.2 Check recent backup files\nWrite-Log \"Test 1.2: Recent Backup Existence\"\n$BackupDirs = @(\"D:\\Backups\", \"E:\\Backups\", \"\\\\backupserver\\backups\")\n$BackupFound = $false\nforeach ($dir in $BackupDirs) {\n    if (Test-Path $dir) {\n        $recentBackups = Get-ChildItem -Path $dir -Recurse -Include \"*.bak\",\"*.vhdx\",\"*.zip\" -ErrorAction SilentlyContinue | \n            Where-Object { $_.LastWriteTime -gt (Get-Date).AddDays(-1) } | \n            Select-Object -First 1\n        if ($recentBackups) {\n            Write-Log \"PASS: Recent backup found: $($recentBackups.FullName)\"\n            $PassCount++\n            $BackupFound = $true\n            break\n        }\n    }\n}\nif (-not $BackupFound) {\n    Write-Log \"FAIL: No recent backups found in standard locations\"\n    $FailCount++\n}\n\n# 1.3 Volume Shadow Copy check\nWrite-Log \"Test 1.3: Volume Shadow Copy Verification\"\n$shadows = Get-WmiObject Win32_ShadowCopy -ErrorAction SilentlyContinue\nif ($shadows -and $shadows.Count -gt 0) {\n    $recentShadow = $shadows | Sort-Object InstallDate -Descending | Select-Object -First 1\n    Write-Log \"PASS: $($shadows.Count) shadow copies available\"\n    $PassCount++\n} else {\n    Write-Log \"WARN: No shadow copies found\"\n    $WarnCount++\n}\n\n# Test Suite 2: Recovery Capability\nWrite-Log \"`n=== Test Suite 2: Recovery Capability ===\"\n\n# 2.1 SQL Server backup verification (if applicable)\nWrite-Log \"Test 2.1: SQL Server Recovery Capability\"\n$sqlService = Get-Service -Name MSSQLSERVER -ErrorAction SilentlyContinue\nif ($sqlService -and $sqlService.Status -eq 'Running') {\n    try {\n        $result = Invoke-Sqlcmd -Query \"SELECT name, state_desc FROM sys.databases\" -ErrorAction Stop\n        Write-Log \"PASS: SQL Server accessible, $($result.Count) databases found\"\n        $PassCount++\n    } catch {\n        Write-Log \"FAIL: SQL Server query failed\"\n        $FailCount++\n    }\n} else {\n    Write-Log \"INFO: SQL Server not installed or not running\"\n}\n\n# 2.2 Test archive extraction\nWrite-Log \"Test 2.2: Archive Extraction Capability\"\n$testArchive = Get-ChildItem -Path \"D:\\Backups\" -Filter \"*.zip\" -ErrorAction SilentlyContinue | Select-Object -First 1\nif ($testArchive) {\n    try {\n        $testDir = \"C:\\Temp\\RecoveryTest\"\n        Expand-Archive -Path $testArchive.FullName -DestinationPath $testDir -Force -ErrorAction Stop\n        Write-Log \"PASS: Archive extraction successful\"\n        $PassCount++\n        Remove-Item -Path $testDir -Recurse -Force -ErrorAction SilentlyContinue\n    } catch {\n        Write-Log \"FAIL: Archive extraction failed\"\n        $FailCount++\n    }\n} else {\n    Write-Log \"WARN: No test archive found\"\n    $WarnCount++\n}\n\n# Test Suite 3: Service Recovery\nWrite-Log \"`n=== Test Suite 3: Service Recovery ===\"\n\n# 3.1 Critical services check\nWrite-Log \"Test 3.1: Critical Services Status\"\n$CriticalServices = @(\"W3SVC\", \"WinRM\", \"Spooler\", \"Schedule\")\nforeach ($svc in $CriticalServices) {\n    $service = Get-Service -Name $svc -ErrorAction SilentlyContinue\n    if ($service -and $service.Status -eq 'Running') {\n        Write-Log \"PASS: Service $svc is running\"\n        $PassCount++\n    } elseif ($service) {\n        Write-Log \"WARN: Service $svc is $($service.Status)\"\n        $WarnCount++\n    }\n}\n\n# 3.2 Event Log check\nWrite-Log \"Test 3.2: Event Logging Operational\"\n$eventLog = Get-EventLog -LogName System -Newest 1 -ErrorAction SilentlyContinue\nif ($eventLog) {\n    Write-Log \"PASS: Event logging operational\"\n    $PassCount++\n} else {\n    Write-Log \"FAIL: Event logging not operational\"\n    $FailCount++\n}\n\n# Test Suite 4: Network Recovery\nWrite-Log \"`n=== Test Suite 4: Network Recovery ===\"\n\n# 4.1 DNS resolution\nWrite-Log \"Test 4.1: DNS Resolution\"\ntry {\n    $dns = Resolve-DnsName google.com -ErrorAction Stop\n    Write-Log \"PASS: DNS resolution working\"\n    $PassCount++\n} catch {\n    Write-Log \"FAIL: DNS resolution failed\"\n    $FailCount++\n}\n\n# 4.2 External connectivity\nWrite-Log \"Test 4.2: External Connectivity\"\ntry {\n    $response = Invoke-WebRequest -Uri \"https://www.google.com\" -TimeoutSec 10 -UseBasicParsing -ErrorAction Stop\n    Write-Log \"PASS: External connectivity verified\"\n    $PassCount++\n} catch {\n    Write-Log \"FAIL: External connectivity failed\"\n    $FailCount++\n}\n\n# Calculate test duration\n$TestEnd = Get-Date\n$Duration = ($TestEnd - $TestStart).TotalSeconds\n\n# Generate summary\nWrite-Log \"`n========================================\"\nWrite-Log \"Test Summary\"\nWrite-Log \"========================================\"\nWrite-Log \"Tests Passed:  $PassCount\"\nWrite-Log \"Tests Failed:  $FailCount\"\nWrite-Log \"Warnings:      $WarnCount\"\nWrite-Log \"Duration:      $([math]::Round($Duration, 2))s\"\nWrite-Log \"========================================\"\n\n# Generate JSON results\n$results = @{\n    timestamp = (Get-Date -Format 'o')\n    control = 'CP-4.3'\n    tests_passed = $PassCount\n    tests_failed = $FailCount\n    warnings = $WarnCount\n    duration_seconds = [math]::Round($Duration, 2)\n    overall_status = if ($FailCount -eq 0) { 'PASS' } else { 'FAIL' }\n}\n$results | ConvertTo-Json | Out-File \"$ResultsDir\\test-results-$(Get-Date -Format 'yyyyMMdd').json\"\n\n# Final result\nif ($FailCount -gt 0) {\n    Write-Log \"OVERALL: FAIL - Contingency plan test identified issues\"\n    Send-Alert \"[ALERT] CP-4.3 Automated Test Failed\" \"$FailCount tests failed. Review log: $LogFile\"\n    exit 1\n} else {\n    Write-Log \"OVERALL: PASS - Contingency plan automated testing successful\"\n    exit 0\n}"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true
    },
    "cac_metadata": {
      "implementation_type": "technical",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "CP-4.3 is a technical control requiring automated mechanisms for contingency testing. Implementation involves scheduling automated backup verification, recovery testing, and failover validation scripts."
    },
    "rationale": "Automated testing catches problems faster and more consistently than manual testing alone."
  },
  {
    "control_id": "CP-4.4",
    "control_name": "Full Recovery and Reconstitution",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "official_text": "Include a full recovery and reconstitution of the system to a known state as part of contingency plan testing.",
    "parent_control": "CP-4",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "plain_english_explanation": "Conduct comprehensive testing that includes completely recovering and rebuilding the system to a known good state. This goes beyond basic backup verification to actually restore the full system from scratch, validating that all components, configurations, data, and integrations can be successfully reconstructed and verified as operational.",
    "intent": "Verify that systems can be completely restored to a known operational state from backups and recovery procedures, validating end-to-end recovery capability.",
    "is_technical": true,
    "ai_guidance": "CP-4.4 requires organizations to validate complete system recovery, not just backup restoration. Implementation should include: documented baseline configurations for all system components, tested procedures for complete system rebuild from bare metal or VM template, verification that restored systems match baseline configurations, validation of all integrations and dependencies after recovery, security control validation on reconstituted systems, and documented recovery time measurements against RTO requirements. Consider using infrastructure-as-code to enable consistent, repeatable full system recovery. Test reconstitution in isolated environments to avoid production impact.",
    "example_implementation": "Conduct annual full system recovery exercises where production systems are completely rebuilt from backups in an isolated environment. Validate all functions and compare against baseline documentation.",
    "non_technical_guidance": "To comply with CP-4.4: 1) Document complete system baseline configurations. 2) Develop detailed recovery procedures for full system restoration. 3) Schedule annual full recovery exercises. 4) Restore systems to isolated test environments. 5) Validate all system functions against baseline. 6) Document recovery time and any issues encountered. 7) Update procedures based on lessons learned.",
    "enhancements": [],
    "related_controls": [
      "CP-4",
      "CP-9",
      "CP-10",
      "SC-24"
    ],
    "supplemental_guidance": "Recovery is executing contingency plan activities to restore organizational missions and business functions. Reconstitution takes place following recovery and includes activities for returning systems to fully operational states. Full recovery and reconstitution testing provides the most rigorous form of contingency plan testing.",
    "implementation_scripts": {
      "linux": {
        "bash": "# full_recovery_test\n#!/bin/bash\n# CP-4.4: Full Recovery and Reconstitution Test Script\n# Validates complete system recovery capability\n\nset -euo pipefail\n\nLOG_FILE=\"/var/log/full-recovery-test-$(date +%Y%m%d).log\"\nBASELINE_DIR=\"/etc/baseline\"\nRECOVERY_CHECKLIST=()\nPASS_COUNT=0\nFAIL_COUNT=0\n\nlog_message() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" | tee -a \"$LOG_FILE\"\n}\n\nlog_message \"==================================================\"\nlog_message \"CP-4.4 Full Recovery and Reconstitution Test\"\nlog_message \"==================================================\"\n\n# Phase 1: Pre-Recovery Baseline Capture\nlog_message \"\\n=== Phase 1: Baseline Capture ===\"\n\n# 1.1 Capture current system state\nlog_message \"Capturing current system baseline...\"\nmkdir -p \"$BASELINE_DIR/current\"\n\n# Package list\ndpkg -l 2>/dev/null > \"$BASELINE_DIR/current/packages.txt\" || rpm -qa > \"$BASELINE_DIR/current/packages.txt\"\nlog_message \"Captured installed packages\"\n\n# Running services\nsystemctl list-units --type=service --state=running > \"$BASELINE_DIR/current/services.txt\"\nlog_message \"Captured running services\"\n\n# Network configuration\nip addr > \"$BASELINE_DIR/current/network.txt\"\nlog_message \"Captured network configuration\"\n\n# Firewall rules\niptables -L -n > \"$BASELINE_DIR/current/firewall.txt\" 2>/dev/null || true\nlog_message \"Captured firewall rules\"\n\n# User accounts\ncat /etc/passwd > \"$BASELINE_DIR/current/users.txt\"\nlog_message \"Captured user accounts\"\n\nlog_message \"PASS: Baseline capture complete\"\n((PASS_COUNT++))\n\n# Phase 2: Backup Validation\nlog_message \"\\n=== Phase 2: Backup Validation ===\"\n\n# 2.1 Verify backup completeness\nlog_message \"Test 2.1: Backup Completeness Check\"\nBACKUP_MANIFEST=\"/backup/manifest.txt\"\nif [ -f \"$BACKUP_MANIFEST\" ]; then\n    log_message \"PASS: Backup manifest found\"\n    ((PASS_COUNT++))\nelse\n    log_message \"FAIL: No backup manifest - cannot validate completeness\"\n    ((FAIL_COUNT++))\nfi\n\n# 2.2 Verify critical data backed up\nlog_message \"Test 2.2: Critical Data Backup Verification\"\nCRITICAL_PATHS=(\"/etc\" \"/home\" \"/var/lib\" \"/opt\")\nfor path in \"${CRITICAL_PATHS[@]}\"; do\n    if find /backup -name \"*$(basename $path)*\" -type f 2>/dev/null | head -1 | grep -q .; then\n        log_message \"PASS: $path appears in backup\"\n        ((PASS_COUNT++))\n    else\n        log_message \"WARN: $path may not be backed up\"\n    fi\ndone\n\n# Phase 3: Recovery Capability Validation\nlog_message \"\\n=== Phase 3: Recovery Capability Validation ===\"\n\n# 3.1 Verify recovery tools available\nlog_message \"Test 3.1: Recovery Tools Availability\"\nRECOVERY_TOOLS=(\"tar\" \"gzip\" \"rsync\" \"ssh\")\nfor tool in \"${RECOVERY_TOOLS[@]}\"; do\n    if command -v \"$tool\" &> /dev/null; then\n        log_message \"PASS: $tool is available\"\n        ((PASS_COUNT++))\n    else\n        log_message \"FAIL: $tool is missing\"\n        ((FAIL_COUNT++))\n    fi\ndone\n\n# 3.2 Verify recovery documentation exists\nlog_message \"Test 3.2: Recovery Documentation\"\nDOC_PATHS=(\"/etc/contingency/recovery-procedures.md\" \"/opt/recovery/runbook.md\")\nDOC_FOUND=false\nfor doc in \"${DOC_PATHS[@]}\"; do\n    if [ -f \"$doc\" ]; then\n        log_message \"PASS: Recovery documentation found: $doc\"\n        ((PASS_COUNT++))\n        DOC_FOUND=true\n        break\n    fi\ndone\nif [ \"$DOC_FOUND\" = false ]; then\n    log_message \"WARN: No recovery documentation found in standard locations\"\nfi\n\n# Phase 4: Reconstitution Readiness\nlog_message \"\\n=== Phase 4: Reconstitution Readiness ===\"\n\n# 4.1 Configuration management\nlog_message \"Test 4.1: Configuration Management\"\nif [ -d \"/etc/ansible\" ] || [ -d \"/etc/puppet\" ] || [ -f \"/.terraform\" ]; then\n    log_message \"PASS: Configuration management tools detected\"\n    ((PASS_COUNT++))\nelse\n    log_message \"WARN: No configuration management detected\"\nfi\n\n# 4.2 Security baseline availability\nlog_message \"Test 4.2: Security Baseline Availability\"\nif [ -f \"$BASELINE_DIR/security-baseline.conf\" ]; then\n    log_message \"PASS: Security baseline configuration available\"\n    ((PASS_COUNT++))\nelse\n    log_message \"WARN: No security baseline configuration found\"\nfi\n\n# 4.3 Post-recovery validation script\nlog_message \"Test 4.3: Post-Recovery Validation Script\"\nif [ -f \"/opt/recovery/validate-recovery.sh\" ]; then\n    log_message \"PASS: Post-recovery validation script exists\"\n    ((PASS_COUNT++))\nelse\n    log_message \"WARN: No post-recovery validation script found\"\nfi\n\n# Summary\nlog_message \"\\n==================================================\"\nlog_message \"Full Recovery and Reconstitution Test Summary\"\nlog_message \"==================================================\"\nlog_message \"Tests Passed: $PASS_COUNT\"\nlog_message \"Tests Failed: $FAIL_COUNT\"\nlog_message \"==================================================\"\n\nif [ \"$FAIL_COUNT\" -eq 0 ]; then\n    log_message \"OVERALL: PASS - System is prepared for full recovery\"\n    exit 0\nelse\n    log_message \"OVERALL: FAIL - Recovery readiness issues detected\"\n    exit 1\nfi"
      },
      "windows": {
        "powershell": "# full_recovery_test\n# CP-4.4: Full Recovery and Reconstitution Test Script for Windows\n# Validates complete system recovery capability\n\n$ErrorActionPreference = \"Stop\"\n$LogFile = \"C:\\Logs\\full-recovery-test-$(Get-Date -Format 'yyyyMMdd').log\"\n$BaselineDir = \"C:\\Baseline\"\n$PassCount = 0\n$FailCount = 0\n\nNew-Item -ItemType Directory -Path $BaselineDir, \"$BaselineDir\\current\" -Force | Out-Null\n\nfunction Write-Log {\n    param([string]$Message)\n    $timestamp = Get-Date -Format 'yyyy-MM-dd HH:mm:ss'\n    \"$timestamp - $Message\" | Tee-Object -FilePath $LogFile -Append\n}\n\nWrite-Log \"==================================================\"\nWrite-Log \"CP-4.4 Full Recovery and Reconstitution Test\"\nWrite-Log \"==================================================\"\n\n# Phase 1: Pre-Recovery Baseline Capture\nWrite-Log \"`n=== Phase 1: Baseline Capture ===\"\n\n# 1.1 Capture current system state\nWrite-Log \"Capturing current system baseline...\"\n\n# Installed programs\nGet-ItemProperty HKLM:\\Software\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\* | \n    Select-Object DisplayName, DisplayVersion | \n    Export-Csv \"$BaselineDir\\current\\programs.csv\" -NoTypeInformation\nWrite-Log \"Captured installed programs\"\n\n# Running services\nGet-Service | Where-Object { $_.Status -eq 'Running' } | \n    Export-Csv \"$BaselineDir\\current\\services.csv\" -NoTypeInformation\nWrite-Log \"Captured running services\"\n\n# Network configuration\nGet-NetAdapter | Get-NetIPAddress | \n    Export-Csv \"$BaselineDir\\current\\network.csv\" -NoTypeInformation\nWrite-Log \"Captured network configuration\"\n\n# Firewall rules\nGet-NetFirewallRule -Enabled True | \n    Export-Csv \"$BaselineDir\\current\\firewall.csv\" -NoTypeInformation\nWrite-Log \"Captured firewall rules\"\n\n# Local users\nGet-LocalUser | Export-Csv \"$BaselineDir\\current\\users.csv\" -NoTypeInformation\nWrite-Log \"Captured local users\"\n\nWrite-Log \"PASS: Baseline capture complete\"\n$PassCount++\n\n# Phase 2: Backup Validation\nWrite-Log \"`n=== Phase 2: Backup Validation ===\"\n\n# 2.1 Windows Backup status\nWrite-Log \"Test 2.1: Windows Backup Status\"\ntry {\n    $backup = Get-WBSummary -ErrorAction SilentlyContinue\n    if ($backup) {\n        Write-Log \"PASS: Last successful backup: $($backup.LastSuccessfulBackupTime)\"\n        $PassCount++\n    } else {\n        Write-Log \"WARN: Cannot retrieve Windows Backup summary\"\n    }\n} catch {\n    Write-Log \"WARN: Windows Backup feature not available\"\n}\n\n# 2.2 Verify backup files exist\nWrite-Log \"Test 2.2: Backup Files Verification\"\n$BackupLocations = @(\"D:\\Backups\", \"E:\\WindowsImageBackup\")\nforeach ($loc in $BackupLocations) {\n    if (Test-Path $loc) {\n        $files = Get-ChildItem -Path $loc -Recurse -ErrorAction SilentlyContinue | Measure-Object\n        if ($files.Count -gt 0) {\n            Write-Log \"PASS: Backup location $loc contains $($files.Count) items\"\n            $PassCount++\n            break\n        }\n    }\n}\n\n# Phase 3: Recovery Capability Validation\nWrite-Log \"`n=== Phase 3: Recovery Capability Validation ===\"\n\n# 3.1 System Restore availability\nWrite-Log \"Test 3.1: System Restore Availability\"\n$restorePoints = Get-ComputerRestorePoint -ErrorAction SilentlyContinue\nif ($restorePoints -and $restorePoints.Count -gt 0) {\n    Write-Log \"PASS: $($restorePoints.Count) restore points available\"\n    Write-Log \"  Latest: $($restorePoints[-1].Description) - $($restorePoints[-1].CreationTime)\"\n    $PassCount++\n} else {\n    Write-Log \"WARN: No system restore points found\"\n}\n\n# 3.2 Recovery partition check\nWrite-Log \"Test 3.2: Recovery Partition Check\"\n$recoveryPartition = Get-Partition | Where-Object { $_.Type -eq 'Recovery' }\nif ($recoveryPartition) {\n    Write-Log \"PASS: Recovery partition exists\"\n    $PassCount++\n} else {\n    Write-Log \"WARN: No recovery partition detected\"\n}\n\n# 3.3 Windows Recovery Environment\nWrite-Log \"Test 3.3: Windows Recovery Environment\"\ntry {\n    $winRE = reagentc /info 2>&1\n    if ($winRE -match 'Enabled') {\n        Write-Log \"PASS: Windows RE is enabled\"\n        $PassCount++\n    } else {\n        Write-Log \"WARN: Windows RE may not be enabled\"\n    }\n} catch {\n    Write-Log \"WARN: Could not check Windows RE status\"\n}\n\n# Phase 4: Reconstitution Readiness\nWrite-Log \"`n=== Phase 4: Reconstitution Readiness ===\"\n\n# 4.1 Domain connectivity (if applicable)\nWrite-Log \"Test 4.1: Domain Connectivity\"\ntry {\n    $domain = Get-ADDomain -ErrorAction SilentlyContinue\n    if ($domain) {\n        Write-Log \"PASS: Domain connectivity verified: $($domain.DNSRoot)\"\n        $PassCount++\n    }\n} catch {\n    Write-Log \"INFO: Not domain-joined or AD module not available\"\n}\n\n# 4.2 Group Policy availability\nWrite-Log \"Test 4.2: Group Policy Baseline\"\nif (Test-Path \"C:\\Windows\\System32\\GroupPolicy\") {\n    Write-Log \"PASS: Group Policy configuration present\"\n    $PassCount++\n} else {\n    Write-Log \"WARN: Group Policy configuration not found\"\n}\n\n# 4.3 Recovery documentation\nWrite-Log \"Test 4.3: Recovery Documentation\"\n$DocPaths = @(\"C:\\Recovery\\runbook.md\", \"C:\\IT\\DisasterRecovery\\procedures.docx\")\nforeach ($doc in $DocPaths) {\n    if (Test-Path $doc) {\n        Write-Log \"PASS: Recovery documentation found: $doc\"\n        $PassCount++\n        break\n    }\n}\n\n# Summary\nWrite-Log \"`n==================================================\"\nWrite-Log \"Full Recovery and Reconstitution Test Summary\"\nWrite-Log \"==================================================\"\nWrite-Log \"Tests Passed: $PassCount\"\nWrite-Log \"Tests Failed: $FailCount\"\nWrite-Log \"==================================================\"\n\nif ($FailCount -eq 0) {\n    Write-Log \"OVERALL: PASS - System is prepared for full recovery\"\n    exit 0\n} else {\n    Write-Log \"OVERALL: FAIL - Recovery readiness issues detected\"\n    exit 1\n}"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true
    },
    "cac_metadata": {
      "implementation_type": "hybrid",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "CP-4.4 requires testing complete system recovery to a known state. This involves both technical validation scripts and organizational procedures for full-scale recovery exercises."
    },
    "rationale": "Partial tests aren't enough. You need to verify you can fully recover and reconstitute operations."
  },
  {
    "control_id": "CP-4.5",
    "control_name": "Self-Challenge",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "official_text": "Employ [Assignment: organization-defined mechanisms] to [Assignment: organization-defined system or system component] to disrupt and adversely affect the system or system component.",
    "parent_control": "CP-4",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "plain_english_explanation": "Proactively introduce controlled failures, disruptions, or adverse conditions to test system resilience and validate contingency response capabilities. This includes chaos engineering practices where intentional faults are injected to verify that systems degrade gracefully and recovery procedures work as designed under realistic failure conditions.",
    "intent": "Validate system resilience and contingency response capabilities by deliberately introducing controlled disruptions to verify that systems can withstand and recover from adverse conditions.",
    "is_technical": true,
    "ai_guidance": "CP-4.5 implements chaos engineering principles for contingency validation. Organizations should develop controlled disruption scenarios including: network latency injection, service termination, resource exhaustion simulations, dependency failures, and data corruption scenarios. Implement these tests in isolated environments before production. Use tools like Chaos Monkey, Gremlin, LitmusChaos, or custom fault injection scripts. Establish clear rollback procedures and monitoring before initiating disruption tests. Document expected behavior during disruptions and compare against actual results. Start with simple failure scenarios and progressively increase complexity. Always conduct tests during low-impact periods with appropriate approvals.",
    "example_implementation": "Implement monthly chaos engineering exercises using fault injection tools. Test scenarios include random service termination, network partition simulation, and database failover triggers. Document system behavior and recovery times.",
    "non_technical_guidance": "To comply with CP-4.5: 1) Identify critical systems suitable for self-challenge testing. 2) Define controlled disruption scenarios appropriate for each system. 3) Establish safety controls and rollback procedures. 4) Obtain management approval for disruption testing. 5) Conduct tests in isolated environments first. 6) Document system behavior during disruptions. 7) Validate recovery procedures are effective. 8) Use lessons learned to improve resilience.",
    "enhancements": [],
    "related_controls": [
      "CP-4",
      "CA-8",
      "SI-6",
      "SI-7"
    ],
    "supplemental_guidance": "Self-challenge provides a more rigorous test of contingency plans than traditional testing because it involves intentionally disrupting systems to test response and recovery. Organizations can employ mechanisms such as simulated attacks, insider threat scenarios, supply chain disruptions, or environmental failures.",
    "implementation_scripts": {
      "linux": {
        "bash": "# chaos_test_framework\n#!/bin/bash\n# CP-4.5: Self-Challenge Chaos Testing Framework\n# Controlled disruption testing for contingency validation\n# WARNING: Use only in approved test environments\n\nset -euo pipefail\n\nLOG_FILE=\"/var/log/chaos-test-$(date +%Y%m%d-%H%M%S).log\"\nSAFE_MODE=true  # Set to false only in approved test environments\nTEST_DURATION=60  # seconds\n\nlog_message() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" | tee -a \"$LOG_FILE\"\n}\n\nlog_message \"==================================================\"\nlog_message \"CP-4.5 Self-Challenge Chaos Testing Framework\"\nlog_message \"==================================================\"\nlog_message \"SAFE_MODE: $SAFE_MODE\"\nlog_message \"WARNING: This framework introduces controlled failures\"\nlog_message \"==================================================\"\n\n# Safety check\nif [ \"$SAFE_MODE\" = true ]; then\n    log_message \"SAFE MODE ENABLED - Running simulation only\"\nfi\n\n# Test 1: Network Latency Injection (Simulation)\ntest_network_latency() {\n    log_message \"\\n=== Test 1: Network Latency Injection ===\"\n    if [ \"$SAFE_MODE\" = true ]; then\n        log_message \"SIMULATED: Would add 100ms latency to eth0\"\n        log_message \"Command: tc qdisc add dev eth0 root netem delay 100ms\"\n        log_message \"PASS: Network latency test simulated\"\n    else\n        # Actual implementation - use with extreme caution\n        log_message \"Adding 100ms network latency...\"\n        tc qdisc add dev eth0 root netem delay 100ms 2>/dev/null || true\n        sleep \"$TEST_DURATION\"\n        tc qdisc del dev eth0 root 2>/dev/null || true\n        log_message \"Latency removed\"\n    fi\n}\n\n# Test 2: CPU Stress Test\ntest_cpu_stress() {\n    log_message \"\\n=== Test 2: CPU Stress Test ===\"\n    if [ \"$SAFE_MODE\" = true ]; then\n        log_message \"SIMULATED: Would stress all CPU cores for ${TEST_DURATION}s\"\n        log_message \"Command: stress-ng --cpu 0 --timeout ${TEST_DURATION}s\"\n        log_message \"PASS: CPU stress test simulated\"\n    else\n        if command -v stress-ng &> /dev/null; then\n            log_message \"Starting CPU stress test...\"\n            stress-ng --cpu 0 --timeout \"${TEST_DURATION}s\" &\n            STRESS_PID=$!\n            wait $STRESS_PID\n            log_message \"CPU stress test completed\"\n        else\n            log_message \"SKIP: stress-ng not installed\"\n        fi\n    fi\n}\n\n# Test 3: Memory Pressure Test\ntest_memory_pressure() {\n    log_message \"\\n=== Test 3: Memory Pressure Test ===\"\n    if [ \"$SAFE_MODE\" = true ]; then\n        log_message \"SIMULATED: Would consume 50% of available memory\"\n        log_message \"Command: stress-ng --vm 1 --vm-bytes 50% --timeout ${TEST_DURATION}s\"\n        log_message \"PASS: Memory pressure test simulated\"\n    else\n        if command -v stress-ng &> /dev/null; then\n            log_message \"Starting memory pressure test...\"\n            stress-ng --vm 1 --vm-bytes 50% --timeout \"${TEST_DURATION}s\" &\n            STRESS_PID=$!\n            wait $STRESS_PID\n            log_message \"Memory pressure test completed\"\n        else\n            log_message \"SKIP: stress-ng not installed\"\n        fi\n    fi\n}\n\n# Test 4: Disk I/O Stress\ntest_disk_stress() {\n    log_message \"\\n=== Test 4: Disk I/O Stress Test ===\"\n    if [ \"$SAFE_MODE\" = true ]; then\n        log_message \"SIMULATED: Would stress disk I/O for ${TEST_DURATION}s\"\n        log_message \"Command: stress-ng --hdd 1 --timeout ${TEST_DURATION}s\"\n        log_message \"PASS: Disk I/O stress test simulated\"\n    else\n        if command -v stress-ng &> /dev/null; then\n            log_message \"Starting disk I/O stress test...\"\n            stress-ng --hdd 1 --timeout \"${TEST_DURATION}s\" &\n            STRESS_PID=$!\n            wait $STRESS_PID\n            log_message \"Disk I/O stress test completed\"\n        else\n            log_message \"SKIP: stress-ng not installed\"\n        fi\n    fi\n}\n\n# Test 5: Service Termination Simulation\ntest_service_termination() {\n    log_message \"\\n=== Test 5: Service Termination Simulation ===\"\n    local test_service=\"nginx\"\n    if [ \"$SAFE_MODE\" = true ]; then\n        log_message \"SIMULATED: Would stop and restart $test_service\"\n        log_message \"Commands:\"\n        log_message \"  systemctl stop $test_service\"\n        log_message \"  sleep 30\"\n        log_message \"  systemctl start $test_service\"\n        log_message \"PASS: Service termination test simulated\"\n    else\n        if systemctl is-active --quiet \"$test_service\"; then\n            log_message \"Stopping $test_service...\"\n            systemctl stop \"$test_service\"\n            sleep 30\n            log_message \"Restarting $test_service...\"\n            systemctl start \"$test_service\"\n            log_message \"Service termination test completed\"\n        else\n            log_message \"SKIP: $test_service not running\"\n        fi\n    fi\n}\n\n# Test 6: DNS Resolution Failure Simulation\ntest_dns_failure() {\n    log_message \"\\n=== Test 6: DNS Resolution Failure Simulation ===\"\n    if [ \"$SAFE_MODE\" = true ]; then\n        log_message \"SIMULATED: Would temporarily break DNS resolution\"\n        log_message \"Command: mv /etc/resolv.conf /etc/resolv.conf.bak\"\n        log_message \"PASS: DNS failure test simulated\"\n    else\n        log_message \"SKIP: DNS failure test requires manual approval\"\n    fi\n}\n\n# Run all tests\nlog_message \"\\n=== Executing Chaos Test Suite ===\"\n\ntest_network_latency\ntest_cpu_stress\ntest_memory_pressure\ntest_disk_stress\ntest_service_termination\ntest_dns_failure\n\n# Summary\nlog_message \"\\n==================================================\"\nlog_message \"Chaos Test Suite Complete\"\nlog_message \"==================================================\"\nlog_message \"Mode: $([ \"$SAFE_MODE\" = true ] && echo 'SIMULATION' || echo 'LIVE')\"\nlog_message \"Log file: $LOG_FILE\"\nlog_message \"==================================================\"\nlog_message \"Review results and update contingency procedures as needed\"\n\nexit 0"
      },
      "windows": {
        "powershell": "# chaos_test_framework\n# CP-4.5: Self-Challenge Chaos Testing Framework for Windows\n# Controlled disruption testing for contingency validation\n# WARNING: Use only in approved test environments\n\n$ErrorActionPreference = \"Stop\"\n$LogFile = \"C:\\Logs\\chaos-test-$(Get-Date -Format 'yyyyMMdd-HHmmss').log\"\n$SafeMode = $true  # Set to $false only in approved test environments\n$TestDuration = 60  # seconds\n\nfunction Write-Log {\n    param([string]$Message)\n    $timestamp = Get-Date -Format 'yyyy-MM-dd HH:mm:ss'\n    \"$timestamp - $Message\" | Tee-Object -FilePath $LogFile -Append\n}\n\nWrite-Log \"==================================================\"\nWrite-Log \"CP-4.5 Self-Challenge Chaos Testing Framework\"\nWrite-Log \"==================================================\"\nWrite-Log \"SAFE_MODE: $SafeMode\"\nWrite-Log \"WARNING: This framework introduces controlled failures\"\nWrite-Log \"==================================================\"\n\nif ($SafeMode) {\n    Write-Log \"SAFE MODE ENABLED - Running simulation only\"\n}\n\n# Test 1: CPU Stress Test\nfunction Test-CPUStress {\n    Write-Log \"`n=== Test 1: CPU Stress Test ===\"\n    if ($SafeMode) {\n        Write-Log \"SIMULATED: Would stress all CPU cores for ${TestDuration}s\"\n        Write-Log \"Would spawn CPU-intensive processes on all cores\"\n        Write-Log \"PASS: CPU stress test simulated\"\n    } else {\n        Write-Log \"Starting CPU stress test...\"\n        $cpuCount = (Get-WmiObject -Class Win32_ComputerSystem).NumberOfLogicalProcessors\n        $jobs = 1..$cpuCount | ForEach-Object {\n            Start-Job -ScriptBlock {\n                $end = (Get-Date).AddSeconds($using:TestDuration)\n                while ((Get-Date) -lt $end) {\n                    [Math]::Sqrt([Math]::PI) | Out-Null\n                }\n            }\n        }\n        $jobs | Wait-Job\n        $jobs | Remove-Job\n        Write-Log \"CPU stress test completed\"\n    }\n}\n\n# Test 2: Memory Pressure Test\nfunction Test-MemoryPressure {\n    Write-Log \"`n=== Test 2: Memory Pressure Test ===\"\n    if ($SafeMode) {\n        Write-Log \"SIMULATED: Would consume significant memory\"\n        Write-Log \"Would allocate large byte arrays\"\n        Write-Log \"PASS: Memory pressure test simulated\"\n    } else {\n        Write-Log \"SKIP: Memory pressure test requires manual approval\"\n    }\n}\n\n# Test 3: Disk I/O Stress\nfunction Test-DiskStress {\n    Write-Log \"`n=== Test 3: Disk I/O Stress Test ===\"\n    if ($SafeMode) {\n        Write-Log \"SIMULATED: Would stress disk I/O for ${TestDuration}s\"\n        Write-Log \"Would write and delete large temporary files\"\n        Write-Log \"PASS: Disk I/O stress test simulated\"\n    } else {\n        Write-Log \"Starting disk I/O stress test...\"\n        $testFile = \"C:\\Temp\\chaos-disk-test.dat\"\n        $endTime = (Get-Date).AddSeconds($TestDuration)\n        while ((Get-Date) -lt $endTime) {\n            [byte[]]$data = New-Object byte[] 10MB\n            [IO.File]::WriteAllBytes($testFile, $data)\n            Remove-Item $testFile -Force -ErrorAction SilentlyContinue\n        }\n        Write-Log \"Disk I/O stress test completed\"\n    }\n}\n\n# Test 4: Service Termination Simulation\nfunction Test-ServiceTermination {\n    Write-Log \"`n=== Test 4: Service Termination Simulation ===\"\n    $testService = \"Spooler\"  # Print Spooler - safe to restart\n    if ($SafeMode) {\n        Write-Log \"SIMULATED: Would stop and restart $testService\"\n        Write-Log \"Commands:\"\n        Write-Log \"  Stop-Service -Name $testService\"\n        Write-Log \"  Start-Sleep -Seconds 30\"\n        Write-Log \"  Start-Service -Name $testService\"\n        Write-Log \"PASS: Service termination test simulated\"\n    } else {\n        $svc = Get-Service -Name $testService -ErrorAction SilentlyContinue\n        if ($svc -and $svc.Status -eq 'Running') {\n            Write-Log \"Stopping $testService...\"\n            Stop-Service -Name $testService -Force\n            Start-Sleep -Seconds 30\n            Write-Log \"Restarting $testService...\"\n            Start-Service -Name $testService\n            Write-Log \"Service termination test completed\"\n        } else {\n            Write-Log \"SKIP: $testService not running\"\n        }\n    }\n}\n\n# Test 5: Network Disruption Simulation\nfunction Test-NetworkDisruption {\n    Write-Log \"`n=== Test 5: Network Disruption Simulation ===\"\n    if ($SafeMode) {\n        Write-Log \"SIMULATED: Would disable/enable network adapter\"\n        Write-Log \"Command: Disable-NetAdapter -Name 'Ethernet'\"\n        Write-Log \"PASS: Network disruption test simulated\"\n    } else {\n        Write-Log \"SKIP: Network disruption test requires manual approval\"\n    }\n}\n\n# Test 6: Process Termination Simulation\nfunction Test-ProcessTermination {\n    Write-Log \"`n=== Test 6: Process Termination Simulation ===\"\n    if ($SafeMode) {\n        Write-Log \"SIMULATED: Would terminate non-critical process\"\n        Write-Log \"Would test automatic process restart/recovery\"\n        Write-Log \"PASS: Process termination test simulated\"\n    } else {\n        Write-Log \"SKIP: Process termination requires specific target\"\n    }\n}\n\n# Run all tests\nWrite-Log \"`n=== Executing Chaos Test Suite ===\"\n\nTest-CPUStress\nTest-MemoryPressure\nTest-DiskStress\nTest-ServiceTermination\nTest-NetworkDisruption\nTest-ProcessTermination\n\n# Summary\nWrite-Log \"`n==================================================\"\nWrite-Log \"Chaos Test Suite Complete\"\nWrite-Log \"==================================================\"\nWrite-Log \"Mode: $(if ($SafeMode) { 'SIMULATION' } else { 'LIVE' })\"\nWrite-Log \"Log file: $LogFile\"\nWrite-Log \"==================================================\"\nWrite-Log \"Review results and update contingency procedures as needed\"\n\nexit 0"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true
    },
    "cac_metadata": {
      "implementation_type": "technical",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "CP-4.5 implements chaos engineering principles. Automated fault injection scripts can be used, but require careful planning, approval, and safety controls. Start with simulations before live testing."
    },
    "rationale": "Self-imposed challenges (like chaos engineering) find weaknesses before attackers or disasters do."
  },
  {
    "control_id": "CP-5",
    "control_name": "Contingency Plan Update [WITHDRAWN]",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "official_text": "CONTROL WITHDRAWN: CP-5 was withdrawn in NIST SP 800-53 Revision 5 and its requirements were incorporated into CP-2 (Contingency Plan). Organizations should implement the update requirements within CP-2 instead of maintaining CP-5 as a separate control. The CP-2 control now requires organizations to update the contingency plan to address changes to the organization, information system, or environment of operation and problems encountered during contingency plan implementation, execution, or testing.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "plain_english_explanation": "This control was removed from NIST SP 800-53 Revision 5 and consolidated into CP-2 (Contingency Plan). The requirement to regularly review and update contingency plans is now embedded within the parent CP-2 control rather than being a separate control. Organizations should refer to CP-2 for all contingency plan development, maintenance, and update requirements. The consolidation reflects that contingency plan updates are an integral part of maintaining an effective contingency plan, not a separate activity.",
    "intent": "The original intent of CP-5 was to ensure organizations maintained current, accurate, and effective contingency plans by establishing formal review and update processes triggered by organizational changes, system modifications, or lessons learned from plan testing or actual incidents. This intent is now fully addressed within CP-2, which establishes a comprehensive contingency planning lifecycle that includes development, distribution, review, update, and testing of the plan.",
    "ai_guidance": "CRITICAL: CP-5 (Contingency Plan Update) does not exist as a separate control in NIST SP 800-53 Rev 5. This control was withdrawn and consolidated into CP-2 (Contingency Plan). When processing user requests or compliance assessments for CP-5, inform stakeholders that this control has been withdrawn and direct them to implement the update requirements within CP-2 instead. CP-2 now explicitly requires organizations to: (a) develop and maintain a contingency plan that addresses essential mission and business functions; (b) distribute copies to designated personnel; (c) coordinate contingency planning activities with incident handling; (d) review the contingency plan at an organization-defined frequency; (e) update the contingency plan to address changes to the organization, system, or environment; (f) communicate changes to personnel; and (g) incorporate lessons learned from testing and actual incidents. The update cadence (formerly specified in CP-5) is now an organization-defined parameter within CP-2. Typical update frequencies include annually, after significant system changes, after contingency events, or after testing reveals deficiencies. This is a procedural/organizational control with opportunities for automation through calendar reminders, version control systems, and document management workflows.",
    "example_implementation": "See CP-2 (Contingency Plan) for implementation guidance. Specifically, organizations should establish: (1) a defined review schedule (e.g., annually or after major changes); (2) version control for the contingency plan document; (3) change tracking procedures; (4) distribution lists for updated plans; and (5) acknowledgment processes for plan recipients.",
    "non_technical_guidance": "CP-5 no longer exists as a separate control in NIST SP 800-53 Revision 5. The contingency plan update requirements have been consolidated into CP-2, which provides comprehensive guidance on maintaining effective contingency plans. Organizations should implement the following update practices as part of their CP-2 compliance: (1) Establish a formal review schedule (commonly annually or after significant events); (2) Define triggers for out-of-cycle reviews such as organizational restructuring, major system changes, personnel changes affecting key contingency roles, lessons learned from tests or actual incidents, and changes in recovery time objectives; (3) Maintain version control and change history for all plan revisions; (4) Ensure updated plans are distributed to all designated personnel and stakeholders; (5) Require acknowledgment of receipt for updated plans; (6) Integrate plan updates with related plans such as incident response, business continuity, and disaster recovery; (7) Archive previous versions for audit and reference purposes.",
    "implementation_guidance": "Organizations previously implementing CP-5 as a separate control should transition their update processes into their CP-2 implementation. Key activities include: (1) Incorporate update frequency requirements into the CP-2 policy documentation; (2) Document triggers that require contingency plan updates; (3) Establish workflows for review and approval of plan changes; (4) Implement version control using document management systems or GRC platforms; (5) Configure automated reminders for scheduled reviews; (6) Maintain distribution lists synchronized with personnel changes; (7) Track acknowledgments and training completion for updated plans.",
    "is_technical": false,
    "enhancements": [],
    "related_controls": [
      "CP-2",
      "CP-3",
      "CP-4",
      "IR-8",
      "PM-8"
    ],
    "supplemental_guidance": "Organizations implementing NIST SP 800-53 Rev 5 should implement contingency plan update requirements as part of CP-2 rather than as a separate CP-5 control. The consolidation reflects the reality that contingency plan updates are an integral maintenance activity rather than a standalone requirement. CP-2 now includes explicit language requiring organizations to update the contingency plan to address changes to the organization, information system, or environment of operation and problems encountered during contingency plan implementation, execution, or testing. The update frequency is an organization-defined parameter that should reflect the organization's risk tolerance, rate of change, and regulatory requirements. Related controls include CP-3 (Contingency Training) which may need updates when plans change, CP-4 (Contingency Plan Testing) which may reveal update needs, and IR-8 (Incident Response Plan) which should be coordinated with contingency plan updates.",
    "implementation_scripts": {
      "linux": {
        "contingency_plan_review_reminder": {
          "description": "Cron job to send contingency plan review reminders",
          "script": "#!/bin/bash\n# Contingency Plan Review Reminder Script\n# Schedule via cron: 0 9 1 1,4,7,10 * /path/to/script.sh\n\nRECIPIENTS=\"isso@organization.gov,contingency-team@organization.gov\"\nSUBJECT=\"[ACTION REQUIRED] Quarterly Contingency Plan Review Due\"\n\necho \"Quarterly contingency plan review is now due per CP-2 requirements.\" | \\\n  mail -s \"$SUBJECT\" $RECIPIENTS\n\nlogger \"Contingency plan review reminder sent to $RECIPIENTS\""
        },
        "contingency_plan_version_check": {
          "description": "Check contingency plan document version and age",
          "script": "#!/bin/bash\n# Contingency Plan Version Check\n# Alerts if plan is older than 365 days\n\nPLAN_PATH=\"/var/docs/contingency-plan.pdf\"\nMAX_AGE_DAYS=365\n\nif [ -f \"$PLAN_PATH\" ]; then\n  FILE_AGE=$(( ($(date +%s) - $(stat -c %Y \"$PLAN_PATH\")) / 86400 ))\n  if [ $FILE_AGE -gt $MAX_AGE_DAYS ]; then\n    echo \"WARNING: Contingency plan is $FILE_AGE days old (exceeds $MAX_AGE_DAYS day threshold)\"\n    exit 1\n  else\n    echo \"OK: Contingency plan last modified $FILE_AGE days ago\"\n    exit 0\n  fi\nelse\n  echo \"ERROR: Contingency plan not found at $PLAN_PATH\"\n  exit 2\nfi"
        }
      },
      "windows": {
        "contingency_plan_review_reminder": {
          "description": "PowerShell script to send contingency plan review reminders",
          "script": "# Contingency Plan Review Reminder\n# Schedule via Task Scheduler for quarterly execution\n\n$SmtpServer = \"smtp.organization.gov\"\n$From = \"compliance-system@organization.gov\"\n$To = @(\"isso@organization.gov\", \"contingency-team@organization.gov\")\n$Subject = \"[ACTION REQUIRED] Quarterly Contingency Plan Review Due\"\n$Body = @\"\nThis is an automated reminder that the quarterly contingency plan review is now due.\n\nPer CP-2 requirements, the contingency plan must be reviewed and updated to address:\n- Changes to the organization\n- Changes to information systems\n- Changes to the operating environment\n- Lessons learned from testing or actual incidents\n\nPlease complete your review within 30 days.\n\nCompliance Automation System\n\"@\n\nSend-MailMessage -SmtpServer $SmtpServer -From $From -To $To -Subject $Subject -Body $Body\nWrite-EventLog -LogName Application -Source \"ComplianceAutomation\" -EventId 1001 -Message \"Contingency plan review reminder sent\""
        },
        "contingency_plan_version_audit": {
          "description": "PowerShell script to audit contingency plan version and modification date",
          "script": "# Contingency Plan Version Audit\n# Checks plan age and alerts if overdue for review\n\n$PlanPath = \"C:\\Compliance\\Documents\\Contingency-Plan.docx\"\n$MaxAgeDays = 365\n\nif (Test-Path $PlanPath) {\n    $FileInfo = Get-Item $PlanPath\n    $FileAge = (Get-Date) - $FileInfo.LastWriteTime\n    $DaysOld = [math]::Floor($FileAge.TotalDays)\n    \n    $Result = @{\n        FilePath = $PlanPath\n        LastModified = $FileInfo.LastWriteTime\n        DaysOld = $DaysOld\n        Status = if ($DaysOld -gt $MaxAgeDays) { \"OVERDUE\" } else { \"CURRENT\" }\n        Threshold = $MaxAgeDays\n    }\n    \n    $Result | ConvertTo-Json\n    \n    if ($DaysOld -gt $MaxAgeDays) {\n        Write-Warning \"Contingency plan is overdue for review ($DaysOld days old)\"\n        exit 1\n    }\n} else {\n    Write-Error \"Contingency plan not found at $PlanPath\"\n    exit 2\n}"
        }
      }
    },
    "metadata": {
      "status": "withdrawn",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "withdrawal_notice": "This control was withdrawn in NIST SP 800-53 Revision 5. Requirements incorporated into CP-2 (Contingency Plan).",
      "enhanced_by": "loveless_qa"
    },
    "cac_metadata": {
      "implementation_type": "withdrawn",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "NIST SP 800-53 Rev 5",
      "implementation_guidance": "This control was withdrawn in NIST SP 800-53 Revision 5 and consolidated into CP-2. Contingency plan update requirements should be implemented as part of CP-2 compliance activities.",
      "cac_status": "withdrawn",
      "cac_planned": false
    },
    "withdrawal_info": {
      "withdrawn_in_revision": "5",
      "incorporated_into": "CP-2",
      "incorporated_into_family": "Contingency Planning",
      "migration_guidance": "Organizations previously implementing CP-5 as a separate control should transition their update processes into their CP-2 implementation. The CP-2 control in Rev 5 explicitly includes requirements to update the contingency plan to address organizational changes, system changes, environmental changes, and lessons learned from testing or incidents. Establish organization-defined update frequencies, triggers for out-of-cycle updates, version control procedures, and distribution processes as part of the CP-2 implementation. Automated reminder systems and document management workflows can support these requirements."
    },
    "rationale": "Plans become outdated as systems change. Regular reviews ensure your plan reflects current reality. (Note: Incorporated into CP-2 in Rev 5)"
  },
  {
    "control_id": "CP-6",
    "control_name": "Alternate Storage Site",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "official_text": "a. Establish an alternate storage site, including necessary agreements to permit the storage and retrieval of system backup information; and b. Ensure that the alternate storage site provides controls equivalent to that of the primary site.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": true,
      "high": true
    },
    "intent": "Ensure organizational resilience by maintaining backup data at a geographically separate location that provides equivalent security protections, enabling recovery of critical information systems and data following a disaster, disruption, or system failure at the primary site.",
    "plain_english_explanation": "Your organization must establish a secondary location to store backup copies of critical system data and information. This alternate storage site must have formal agreements in place that allow you to store and retrieve backup data when needed. The security controls at this backup location must be just as strong as those at your primary data center, ensuring that sensitive information remains protected regardless of where it is stored.",
    "ai_guidance": "When implementing CP-6, organizations should first conduct a comprehensive risk assessment to identify threats that could simultaneously affect both primary and alternate sites. Consider cloud-based storage solutions such as AWS S3, Azure Blob Storage, or Google Cloud Storage as alternate storage sites, ensuring cross-region replication is enabled. For on-premises solutions, select a site at least 100 miles from the primary location to mitigate regional disasters. Implement automated backup replication using tools like rsync, rclone, or enterprise solutions such as Veeam or Commvault. Establish service level agreements (SLAs) with storage providers that guarantee availability and recovery time objectives. Regular testing of backup restoration from the alternate site is critical - schedule quarterly restoration drills. Document the physical and logical access controls at both sites and ensure parity. Consider implementing immutable backups to protect against ransomware. Monitor replication lag and alert on failures using tools like Prometheus, Nagios, or cloud-native monitoring services.",
    "example_implementation": "Implement automated daily backup replication to a geographically distant cloud storage region using encrypted transfer protocols. Configure monitoring to verify successful replication and alert on failures.",
    "non_technical_guidance": "To comply with CP-6 (Alternate Storage Site), follow these steps:\n1. Conduct a risk assessment to identify potential threats to your primary storage location.\n2. Select an alternate storage site that is geographically separate from your primary site.\n3. Establish formal agreements with the alternate site provider covering storage, retrieval, and security requirements.\n4. Document the security controls at both sites and verify equivalency.\n5. Implement regular backup replication to the alternate site.\n6. Test backup retrieval from the alternate site at least quarterly.\n7. Maintain documentation of all agreements, procedures, and test results.\n8. Review and update the alternate storage site arrangements annually.",
    "is_technical": true,
    "enhancements": [
      {
        "id": "CP-6.1",
        "title": "Separation from Primary Site",
        "official_text": "Identify an alternate storage site that is sufficiently separated from the primary storage site to reduce susceptibility to the same threats."
      },
      {
        "id": "CP-6.2",
        "title": "Recovery Time and Recovery Point Objectives",
        "official_text": "Configure the alternate storage site to facilitate recovery operations in accordance with recovery time and recovery point objectives."
      },
      {
        "id": "CP-6.3",
        "title": "Accessibility",
        "official_text": "Identify potential accessibility problems to the alternate storage site in the event of an area-wide disruption or disaster and outline explicit mitigation actions."
      }
    ],
    "related_controls": [
      "CP-2",
      "CP-7",
      "CP-8",
      "CP-9",
      "CP-10",
      "MP-4",
      "MP-5",
      "SC-36"
    ],
    "supplemental_guidance": "Alternate storage sites are geographically distinct from primary storage sites and maintain duplicate copies of information and data if the primary storage site is not available. Items covered by alternate storage site agreements include environmental conditions at the alternate sites, access rules for systems and facilities, physical and environmental protection requirements, and coordination of delivery and retrieval of backup media. Alternate storage sites reflect the requirements in contingency plans so that organizations can maintain essential mission and business functions despite compromise, failure, or disruption in organizational systems.",
    "implementation_scripts": {
      "linux": {
        "bash": "# backup_replication_rsync\n#!/bin/bash\n# CP-6: Alternate Storage Site - Backup Replication Script\n# Replicates critical data to alternate storage site using rsync over SSH\n\nset -euo pipefail\n\n# Configuration\nPRIMARY_BACKUP_DIR=\"/var/backups/critical-data\"\nALTERNATE_SITE_HOST=\"backup.alternate-site.example.com\"\nALTERNATE_SITE_USER=\"backup-admin\"\nALTERNATE_SITE_DIR=\"/storage/replicated-backups\"\nSSH_KEY=\"/root/.ssh/backup_replication_key\"\nLOG_FILE=\"/var/log/backup-replication.log\"\nALERT_EMAIL=\"security-team@example.com\"\n\nlog_message() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" | tee -a \"$LOG_FILE\"\n}\n\nlog_message \"Starting backup replication to alternate storage site\"\n\n# Verify source directory exists\nif [ ! -d \"$PRIMARY_BACKUP_DIR\" ]; then\n    log_message \"ERROR: Primary backup directory does not exist: $PRIMARY_BACKUP_DIR\"\n    echo \"CP-6 Backup Replication Failed: Source directory missing\" | mail -s \"ALERT: Backup Replication Failure\" \"$ALERT_EMAIL\"\n    exit 1\nfi\n\n# Test connectivity to alternate site\nif ! ssh -i \"$SSH_KEY\" -o ConnectTimeout=30 -o BatchMode=yes \"${ALTERNATE_SITE_USER}@${ALTERNATE_SITE_HOST}\" \"echo 'Connection test successful'\" >> \"$LOG_FILE\" 2>&1; then\n    log_message \"ERROR: Cannot connect to alternate storage site\"\n    echo \"CP-6 Backup Replication Failed: Cannot connect to alternate site\" | mail -s \"ALERT: Backup Replication Failure\" \"$ALERT_EMAIL\"\n    exit 1\nfi\n\n# Perform rsync replication with encryption\nlog_message \"Beginning rsync transfer to alternate site\"\nif rsync -avz --delete --progress \\\n    -e \"ssh -i $SSH_KEY -o StrictHostKeyChecking=yes\" \\\n    \"$PRIMARY_BACKUP_DIR/\" \\\n    \"${ALTERNATE_SITE_USER}@${ALTERNATE_SITE_HOST}:${ALTERNATE_SITE_DIR}/\" >> \"$LOG_FILE\" 2>&1; then\n    log_message \"SUCCESS: Backup replication completed successfully\"\n    \n    # Generate verification checksum\n    CHECKSUM=$(find \"$PRIMARY_BACKUP_DIR\" -type f -exec md5sum {} \\; | md5sum | cut -d' ' -f1)\n    log_message \"Local checksum: $CHECKSUM\"\n    \n    # Verify remote checksum\n    REMOTE_CHECKSUM=$(ssh -i \"$SSH_KEY\" \"${ALTERNATE_SITE_USER}@${ALTERNATE_SITE_HOST}\" \\\n        \"find ${ALTERNATE_SITE_DIR} -type f -exec md5sum {} \\; | md5sum | cut -d' ' -f1\")\n    log_message \"Remote checksum: $REMOTE_CHECKSUM\"\n    \n    if [ \"$CHECKSUM\" = \"$REMOTE_CHECKSUM\" ]; then\n        log_message \"VERIFIED: Checksums match - replication integrity confirmed\"\n    else\n        log_message \"WARNING: Checksum mismatch - investigation required\"\n    fi\nelse\n    log_message \"ERROR: Rsync replication failed\"\n    echo \"CP-6 Backup Replication Failed: Rsync error\" | mail -s \"ALERT: Backup Replication Failure\" \"$ALERT_EMAIL\"\n    exit 1\nfi\n\nlog_message \"CP-6 alternate storage site replication completed\"\n\n# verify_alternate_site\n#!/bin/bash\n# CP-6: Verify Alternate Storage Site Accessibility and Contents\n\nset -euo pipefail\n\nALTERNATE_SITE_HOST=\"backup.alternate-site.example.com\"\nALTERNATE_SITE_USER=\"backup-admin\"\nALTERNATE_SITE_DIR=\"/storage/replicated-backups\"\nSSH_KEY=\"/root/.ssh/backup_replication_key\"\nLOG_FILE=\"/var/log/alternate-site-verification.log\"\n\nlog_message() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" | tee -a \"$LOG_FILE\"\n}\n\nlog_message \"=== CP-6 Alternate Storage Site Verification ===\"\n\n# Test SSH connectivity\nlog_message \"Testing SSH connectivity to alternate site...\"\nif ssh -i \"$SSH_KEY\" -o ConnectTimeout=30 -o BatchMode=yes \"${ALTERNATE_SITE_USER}@${ALTERNATE_SITE_HOST}\" \"echo 'SSH connection successful'\" >> \"$LOG_FILE\" 2>&1; then\n    log_message \"PASS: SSH connectivity verified\"\nelse\n    log_message \"FAIL: Cannot establish SSH connection to alternate site\"\n    exit 1\nfi\n\n# Verify storage directory exists and is accessible\nlog_message \"Verifying storage directory accessibility...\"\nif ssh -i \"$SSH_KEY\" \"${ALTERNATE_SITE_USER}@${ALTERNATE_SITE_HOST}\" \"[ -d '$ALTERNATE_SITE_DIR' ] && [ -r '$ALTERNATE_SITE_DIR' ] && [ -w '$ALTERNATE_SITE_DIR' ]\"; then\n    log_message \"PASS: Storage directory exists and is read/write accessible\"\nelse\n    log_message \"FAIL: Storage directory not accessible\"\n    exit 1\nfi\n\n# Get storage statistics\nlog_message \"Retrieving storage statistics...\"\nSTORAGE_STATS=$(ssh -i \"$SSH_KEY\" \"${ALTERNATE_SITE_USER}@${ALTERNATE_SITE_HOST}\" \"\n    echo 'Directory: $ALTERNATE_SITE_DIR'\n    echo 'Total Size:' \\$(du -sh '$ALTERNATE_SITE_DIR' 2>/dev/null | cut -f1)\n    echo 'File Count:' \\$(find '$ALTERNATE_SITE_DIR' -type f 2>/dev/null | wc -l)\n    echo 'Last Modified:' \\$(stat -c '%y' '$ALTERNATE_SITE_DIR' 2>/dev/null | cut -d'.' -f1)\n    echo 'Disk Space Available:' \\$(df -h '$ALTERNATE_SITE_DIR' | tail -1 | awk '{print \\$4}')\n\")\nlog_message \"Storage Statistics:\\n$STORAGE_STATS\"\n\n# Verify backup age (should be recent)\nlog_message \"Checking backup freshness...\"\nLAST_BACKUP_AGE=$(ssh -i \"$SSH_KEY\" \"${ALTERNATE_SITE_USER}@${ALTERNATE_SITE_HOST}\" \"\n    find '$ALTERNATE_SITE_DIR' -type f -mtime -1 | wc -l\n\")\nif [ \"$LAST_BACKUP_AGE\" -gt 0 ]; then\n    log_message \"PASS: Recent backups found (modified within 24 hours)\"\nelse\n    log_message \"WARNING: No recent backups found - replication may be stale\"\nfi\n\nlog_message \"=== CP-6 Verification Complete ===\"\n\n# geographic_redundancy_check\n#!/bin/bash\n# CP-6: Geographic Redundancy Verification\n# Verifies alternate site is geographically separated from primary\n\nset -euo pipefail\n\n# Configuration - set your site coordinates\nPRIMARY_SITE_LAT=\"40.7128\"\nPRIMARY_SITE_LON=\"-74.0060\"\nALTERNATE_SITE_LAT=\"37.7749\"\nALTERNATE_SITE_LON=\"-122.4194\"\nMIN_DISTANCE_MILES=100\n\nLOG_FILE=\"/var/log/geographic-redundancy-check.log\"\n\nlog_message() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" | tee -a \"$LOG_FILE\"\n}\n\n# Calculate distance using Haversine formula\ncalculate_distance() {\n    python3 << EOF\nimport math\n\nlat1 = math.radians($PRIMARY_SITE_LAT)\nlat2 = math.radians($ALTERNATE_SITE_LAT)\nlon1 = math.radians($PRIMARY_SITE_LON)\nlon2 = math.radians($ALTERNATE_SITE_LON)\n\ndlat = lat2 - lat1\ndlon = lon2 - lon1\n\na = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\nc = 2 * math.asin(math.sqrt(a))\n\n# Earth's radius in miles\nradius = 3956\n\ndistance = radius * c\nprint(f\"{distance:.2f}\")\nEOF\n}\n\nlog_message \"=== CP-6 Geographic Redundancy Check ===\"\nlog_message \"Primary Site: ($PRIMARY_SITE_LAT, $PRIMARY_SITE_LON)\"\nlog_message \"Alternate Site: ($ALTERNATE_SITE_LAT, $ALTERNATE_SITE_LON)\"\n\nDISTANCE=$(calculate_distance)\nlog_message \"Calculated Distance: $DISTANCE miles\"\n\nif (( $(echo \"$DISTANCE >= $MIN_DISTANCE_MILES\" | bc -l) )); then\n    log_message \"PASS: Alternate site is sufficiently separated ($DISTANCE miles >= $MIN_DISTANCE_MILES miles minimum)\"\n    echo \"COMPLIANT: Geographic separation requirement met\"\n    exit 0\nelse\n    log_message \"FAIL: Alternate site is NOT sufficiently separated ($DISTANCE miles < $MIN_DISTANCE_MILES miles minimum)\"\n    echo \"NON-COMPLIANT: Geographic separation requirement NOT met\"\n    exit 1\nfi"
      },
      "windows": {
        "powershell": "# backup_replication_robocopy\n# CP-6: Alternate Storage Site - Backup Replication Script (Windows)\n# Replicates critical data to alternate storage site using Robocopy\n\nparam(\n    [string]$PrimaryBackupPath = \"C:\\Backups\\CriticalData\",\n    [string]$AlternateSiteUNC = \"\\\\alternate-site.example.com\\ReplicatedBackups\",\n    [string]$LogPath = \"C:\\Logs\\BackupReplication\",\n    [string]$AlertEmail = \"security-team@example.com\"\n)\n\n$ErrorActionPreference = \"Stop\"\n$timestamp = Get-Date -Format \"yyyy-MM-dd_HH-mm-ss\"\n$logFile = Join-Path $LogPath \"replication_$timestamp.log\"\n\nif (-not (Test-Path $LogPath)) {\n    New-Item -ItemType Directory -Path $LogPath -Force | Out-Null\n}\n\nfunction Write-Log {\n    param([string]$Message)\n    $entry = \"$(Get-Date -Format 'yyyy-MM-dd HH:mm:ss') - $Message\"\n    Write-Host $entry\n    Add-Content -Path $logFile -Value $entry\n}\n\nfunction Send-Alert {\n    param([string]$Subject, [string]$Body)\n    try {\n        Send-MailMessage -To $AlertEmail -Subject $Subject -Body $Body -SmtpServer \"smtp.example.com\" -From \"backup-monitor@example.com\"\n    } catch {\n        Write-Log \"WARNING: Could not send alert email: $_\"\n    }\n}\n\nWrite-Log \"=== CP-6 Alternate Storage Site Replication Starting ===\"\n\n# Verify source directory exists\nif (-not (Test-Path $PrimaryBackupPath)) {\n    Write-Log \"ERROR: Primary backup directory does not exist: $PrimaryBackupPath\"\n    Send-Alert -Subject \"ALERT: CP-6 Backup Replication Failed\" -Body \"Source directory missing: $PrimaryBackupPath\"\n    exit 1\n}\n\n# Test connectivity to alternate site\nWrite-Log \"Testing connectivity to alternate storage site...\"\ntry {\n    if (-not (Test-Path $AlternateSiteUNC)) {\n        throw \"Cannot access alternate site UNC path\"\n    }\n    Write-Log \"SUCCESS: Alternate site is accessible\"\n} catch {\n    Write-Log \"ERROR: Cannot connect to alternate storage site: $_\"\n    Send-Alert -Subject \"ALERT: CP-6 Backup Replication Failed\" -Body \"Cannot connect to alternate site: $AlternateSiteUNC\"\n    exit 1\n}\n\n# Perform Robocopy replication\nWrite-Log \"Beginning Robocopy replication to alternate site...\"\n$robocopyArgs = @(\n    $PrimaryBackupPath,\n    $AlternateSiteUNC,\n    \"/MIR\",           # Mirror directory tree\n    \"/Z\",             # Restartable mode\n    \"/MT:8\",          # Multi-threaded (8 threads)\n    \"/R:3\",           # Retry 3 times\n    \"/W:10\",          # Wait 10 seconds between retries\n    \"/NP\",            # No progress percentage\n    \"/LOG+:$logFile\", # Append to log\n    \"/TEE\"            # Output to console and log\n)\n\n$result = Start-Process -FilePath \"robocopy.exe\" -ArgumentList $robocopyArgs -Wait -PassThru -NoNewWindow\n\n# Robocopy exit codes: 0-7 are success, 8+ are errors\nif ($result.ExitCode -lt 8) {\n    Write-Log \"SUCCESS: Robocopy replication completed (Exit Code: $($result.ExitCode))\"\n    \n    # Generate file count verification\n    $sourceCount = (Get-ChildItem -Path $PrimaryBackupPath -Recurse -File).Count\n    $destCount = (Get-ChildItem -Path $AlternateSiteUNC -Recurse -File).Count\n    \n    Write-Log \"Source file count: $sourceCount\"\n    Write-Log \"Destination file count: $destCount\"\n    \n    if ($sourceCount -eq $destCount) {\n        Write-Log \"VERIFIED: File counts match - replication integrity confirmed\"\n    } else {\n        Write-Log \"WARNING: File count mismatch - investigation required\"\n    }\n} else {\n    Write-Log \"ERROR: Robocopy replication failed (Exit Code: $($result.ExitCode))\"\n    Send-Alert -Subject \"ALERT: CP-6 Backup Replication Failed\" -Body \"Robocopy error. Exit code: $($result.ExitCode). See log: $logFile\"\n    exit 1\n}\n\nWrite-Log \"=== CP-6 Alternate Storage Site Replication Complete ===\"\n\n# verify_alternate_site\n# CP-6: Verify Alternate Storage Site Accessibility (Windows)\n\nparam(\n    [string]$AlternateSiteUNC = \"\\\\alternate-site.example.com\\ReplicatedBackups\",\n    [string]$LogPath = \"C:\\Logs\\AlternateSiteVerification\"\n)\n\n$ErrorActionPreference = \"Stop\"\n$timestamp = Get-Date -Format \"yyyy-MM-dd_HH-mm-ss\"\n$logFile = Join-Path $LogPath \"verification_$timestamp.log\"\n\nif (-not (Test-Path $LogPath)) {\n    New-Item -ItemType Directory -Path $LogPath -Force | Out-Null\n}\n\nfunction Write-Log {\n    param([string]$Message)\n    $entry = \"$(Get-Date -Format 'yyyy-MM-dd HH:mm:ss') - $Message\"\n    Write-Host $entry\n    Add-Content -Path $logFile -Value $entry\n}\n\nWrite-Log \"=== CP-6 Alternate Storage Site Verification ===\"\n\n# Test UNC path accessibility\nWrite-Log \"Testing accessibility to alternate site...\"\ntry {\n    if (Test-Path $AlternateSiteUNC) {\n        Write-Log \"PASS: Alternate site UNC path is accessible\"\n    } else {\n        Write-Log \"FAIL: Cannot access alternate site UNC path\"\n        exit 1\n    }\n} catch {\n    Write-Log \"FAIL: Error accessing alternate site: $_\"\n    exit 1\n}\n\n# Check read/write permissions\nWrite-Log \"Testing read/write permissions...\"\ntry {\n    $testFile = Join-Path $AlternateSiteUNC \"_cp6_permission_test_$(Get-Random).tmp\"\n    \"Permission Test\" | Out-File -FilePath $testFile\n    $content = Get-Content -Path $testFile\n    Remove-Item -Path $testFile -Force\n    Write-Log \"PASS: Read/write permissions verified\"\n} catch {\n    Write-Log \"FAIL: Insufficient permissions on alternate site: $_\"\n    exit 1\n}\n\n# Get storage statistics\nWrite-Log \"Retrieving storage statistics...\"\ntry {\n    $items = Get-ChildItem -Path $AlternateSiteUNC -Recurse -File -ErrorAction SilentlyContinue\n    $totalSize = ($items | Measure-Object -Property Length -Sum).Sum\n    $fileCount = $items.Count\n    $lastModified = ($items | Sort-Object LastWriteTime -Descending | Select-Object -First 1).LastWriteTime\n    \n    Write-Log \"Directory: $AlternateSiteUNC\"\n    Write-Log \"Total Size: $([math]::Round($totalSize / 1GB, 2)) GB\"\n    Write-Log \"File Count: $fileCount\"\n    Write-Log \"Last Modified: $lastModified\"\n} catch {\n    Write-Log \"WARNING: Could not retrieve complete storage statistics: $_\"\n}\n\n# Check backup freshness\nWrite-Log \"Checking backup freshness...\"\n$recentFiles = Get-ChildItem -Path $AlternateSiteUNC -Recurse -File | Where-Object { $_.LastWriteTime -gt (Get-Date).AddDays(-1) }\nif ($recentFiles.Count -gt 0) {\n    Write-Log \"PASS: $($recentFiles.Count) files modified within last 24 hours\"\n} else {\n    Write-Log \"WARNING: No files modified within last 24 hours - backups may be stale\"\n}\n\nWrite-Log \"=== CP-6 Verification Complete ===\""
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": true,
      "qa_validated": true
    },
    "cac_metadata": {
      "implementation_type": "hybrid",
      "last_analyzed": "2025-11-22T00:00:00Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "This control requires both organizational policies for site selection and agreements, plus technical implementation for backup replication and verification. Scripts provided for automated backup synchronization and site verification."
    },
    "rationale": "If your data is only in one place, a single disaster can destroy it all. Alternate storage is your insurance policy."
  },
  {
    "control_id": "CP-6.1",
    "control_name": "Separation from Primary Site",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "official_text": "Identify an alternate storage site that is sufficiently separated from the primary storage site to reduce susceptibility to the same threats.",
    "parent_control": "CP-6",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": true,
      "high": true
    },
    "intent": "Ensure that the alternate storage site is located far enough from the primary site that a single disaster event (such as a hurricane, earthquake, flood, or large-scale power outage) cannot affect both sites simultaneously, thereby protecting backup data from regional catastrophes.",
    "plain_english_explanation": "Your backup storage location must be far enough away from your main data center that a single disaster cannot take out both. For example, if your primary site is in a flood zone, your alternate site should be on higher ground or in a different geographic region entirely. The goal is to ensure that natural disasters, regional power outages, or other area-wide events cannot destroy both your primary data and your backups at the same time.",
    "ai_guidance": "When implementing CP-6.1, conduct a thorough threat assessment to identify all hazards that could affect the primary site, including natural disasters (earthquakes, hurricanes, floods, tornadoes, wildfires), infrastructure failures (power grid outages, telecommunications failures), and man-made threats (civil unrest, terrorism). The alternate site should be outside the impact radius of these threats. Industry best practice recommends a minimum of 100 miles separation for general purposes, though specific requirements may vary based on threat analysis. For cloud deployments, ensure cross-region replication is enabled and regions are in different geographic areas (e.g., AWS us-east-1 and us-west-2). Document the rationale for site selection including threat analysis, distance calculations, and infrastructure independence verification. Consider factors such as different power grids, telecommunications providers, and natural disaster zones. Implement automated geographic separation verification scripts that can validate distance requirements are maintained.",
    "example_implementation": "Primary data center in New York (us-east-1) with alternate storage in Oregon (us-west-2), providing 2,800+ miles separation across different seismic zones, hurricane paths, and power grids.",
    "non_technical_guidance": "To comply with CP-6.1:\n1. Conduct a threat assessment for your primary storage site.\n2. Identify all potential regional disasters (floods, earthquakes, hurricanes, etc.).\n3. Determine the geographic scope of each identified threat.\n4. Select an alternate site outside the threat radius of all identified risks.\n5. Verify the alternate site uses different infrastructure (power grid, internet backbone).\n6. Document the separation distance and rationale.\n7. Review annually to ensure threats have not changed.",
    "is_technical": true,
    "enhancements": [],
    "related_controls": [
      "CP-6",
      "CP-7.1",
      "PE-18"
    ],
    "supplemental_guidance": "Threats that affect alternate storage sites are typically defined in organizational risk assessments and include natural disasters or structural failures. Organizations determine what is considered a sufficient degree of separation between primary and alternate storage sites based on the types of threats that are of concern. For one particular type of threat (i.e., hostile combatant or attack on the primary site), the alternate storage site can be closer to the primary site, but for others (such as natural disasters like hurricanes or floods), the site needs to be farther away.",
    "implementation_scripts": {
      "linux": {
        "bash": "# geographic_separation_audit\n#!/bin/bash\n# CP-6.1: Geographic Separation Verification Script\n\nset -euo pipefail\n\n# Site configurations - UPDATE THESE VALUES\nPRIMARY_SITE_NAME=\"Primary Data Center - NYC\"\nPRIMARY_LAT=\"40.7128\"\nPRIMARY_LON=\"-74.0060\"\nPRIMARY_REGION=\"us-east-1\"\n\nALTERNATE_SITE_NAME=\"Alternate Storage - Oregon\"\nALTERNATE_LAT=\"45.5152\"\nALTERNATE_LON=\"-122.6784\"\nALTERNATE_REGION=\"us-west-2\"\n\nMIN_DISTANCE_MILES=100\nRECOMMENDED_DISTANCE_MILES=500\n\nLOG_FILE=\"/var/log/cp6-separation-audit.log\"\nREPORT_FILE=\"/var/reports/cp6-separation-report-$(date +%Y%m%d).txt\"\n\nmkdir -p /var/reports\n\nlog_message() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" | tee -a \"$LOG_FILE\"\n}\n\n# Calculate Haversine distance\ncalculate_distance() {\n    python3 << EOF\nimport math\n\nlat1, lon1 = math.radians($PRIMARY_LAT), math.radians($PRIMARY_LON)\nlat2, lon2 = math.radians($ALTERNATE_LAT), math.radians($ALTERNATE_LON)\n\ndlat, dlon = lat2 - lat1, lon2 - lon1\na = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\ndistance = 3956 * 2 * math.asin(math.sqrt(a))  # Earth radius in miles\n\nprint(f\"{distance:.2f}\")\nEOF\n}\n\nlog_message \"=== CP-6.1 Geographic Separation Audit ===\"\n\n# Generate report\n{\n    echo \"===============================================\"\n    echo \"CP-6.1 GEOGRAPHIC SEPARATION COMPLIANCE REPORT\"\n    echo \"Generated: $(date)\"\n    echo \"===============================================\"\n    echo \"\"\n    echo \"PRIMARY SITE:\"\n    echo \"  Name: $PRIMARY_SITE_NAME\"\n    echo \"  Coordinates: ($PRIMARY_LAT, $PRIMARY_LON)\"\n    echo \"  Cloud Region: $PRIMARY_REGION\"\n    echo \"\"\n    echo \"ALTERNATE SITE:\"\n    echo \"  Name: $ALTERNATE_SITE_NAME\"\n    echo \"  Coordinates: ($ALTERNATE_LAT, $ALTERNATE_LON)\"\n    echo \"  Cloud Region: $ALTERNATE_REGION\"\n    echo \"\"\n    \n    DISTANCE=$(calculate_distance)\n    echo \"SEPARATION DISTANCE: $DISTANCE miles\"\n    echo \"\"\n    echo \"REQUIREMENTS:\"\n    echo \"  Minimum Required: $MIN_DISTANCE_MILES miles\"\n    echo \"  Recommended: $RECOMMENDED_DISTANCE_MILES miles\"\n    echo \"\"\n    \n    if (( $(echo \"$DISTANCE >= $RECOMMENDED_DISTANCE_MILES\" | bc -l) )); then\n        echo \"STATUS: FULLY COMPLIANT\"\n        echo \"  Sites exceed recommended separation distance.\"\n    elif (( $(echo \"$DISTANCE >= $MIN_DISTANCE_MILES\" | bc -l) )); then\n        echo \"STATUS: COMPLIANT (MINIMUM)\"\n        echo \"  Sites meet minimum requirements but do not exceed recommended distance.\"\n    else\n        echo \"STATUS: NON-COMPLIANT\"\n        echo \"  Sites do not meet minimum separation requirements.\"\n    fi\n    echo \"\"\n    echo \"THREAT ZONE ANALYSIS:\"\n    echo \"  - Hurricane zone separation: $(if (( $(echo \"$DISTANCE >= 200\" | bc -l) )); then echo \"ADEQUATE\"; else echo \"INSUFFICIENT\"; fi)\"\n    echo \"  - Earthquake zone separation: $(if [ \"$PRIMARY_REGION\" != \"$ALTERNATE_REGION\" ]; then echo \"DIFFERENT ZONES\"; else echo \"SAME ZONE\"; fi)\"\n    echo \"  - Power grid independence: $(if [ \"$PRIMARY_REGION\" != \"$ALTERNATE_REGION\" ]; then echo \"LIKELY INDEPENDENT\"; else echo \"VERIFY MANUALLY\"; fi)\"\n    echo \"\"\n    echo \"===============================================\"\n} | tee \"$REPORT_FILE\"\n\nlog_message \"Report generated: $REPORT_FILE\"\nlog_message \"=== CP-6.1 Audit Complete ===\""
      },
      "windows": {
        "powershell": "# geographic_separation_audit\n# CP-6.1: Geographic Separation Verification Script (Windows)\n\nparam(\n    [string]$PrimarySiteName = \"Primary Data Center - NYC\",\n    [double]$PrimaryLat = 40.7128,\n    [double]$PrimaryLon = -74.0060,\n    [string]$PrimaryRegion = \"us-east-1\",\n    \n    [string]$AlternateSiteName = \"Alternate Storage - Oregon\",\n    [double]$AlternateLat = 45.5152,\n    [double]$AlternateLon = -122.6784,\n    [string]$AlternateRegion = \"us-west-2\",\n    \n    [int]$MinDistanceMiles = 100,\n    [int]$RecommendedDistanceMiles = 500,\n    \n    [string]$ReportPath = \"C:\\Reports\\CP6-Separation\"\n)\n\n$ErrorActionPreference = \"Stop\"\n\nif (-not (Test-Path $ReportPath)) {\n    New-Item -ItemType Directory -Path $ReportPath -Force | Out-Null\n}\n\n$reportFile = Join-Path $ReportPath \"CP6-Separation-Report-$(Get-Date -Format 'yyyyMMdd-HHmmss').txt\"\n\n# Haversine formula for distance calculation\nfunction Get-HaversineDistance {\n    param(\n        [double]$Lat1, [double]$Lon1,\n        [double]$Lat2, [double]$Lon2\n    )\n    \n    $R = 3956  # Earth's radius in miles\n    \n    $lat1Rad = $Lat1 * [Math]::PI / 180\n    $lat2Rad = $Lat2 * [Math]::PI / 180\n    $dLat = ($Lat2 - $Lat1) * [Math]::PI / 180\n    $dLon = ($Lon2 - $Lon1) * [Math]::PI / 180\n    \n    $a = [Math]::Sin($dLat/2) * [Math]::Sin($dLat/2) +\n         [Math]::Cos($lat1Rad) * [Math]::Cos($lat2Rad) *\n         [Math]::Sin($dLon/2) * [Math]::Sin($dLon/2)\n    \n    $c = 2 * [Math]::Asin([Math]::Sqrt($a))\n    \n    return [Math]::Round($R * $c, 2)\n}\n\n$distance = Get-HaversineDistance -Lat1 $PrimaryLat -Lon1 $PrimaryLon -Lat2 $AlternateLat -Lon2 $AlternateLon\n\n# Determine compliance status\nif ($distance -ge $RecommendedDistanceMiles) {\n    $status = \"FULLY COMPLIANT\"\n    $statusDetail = \"Sites exceed recommended separation distance.\"\n} elseif ($distance -ge $MinDistanceMiles) {\n    $status = \"COMPLIANT (MINIMUM)\"\n    $statusDetail = \"Sites meet minimum requirements but do not exceed recommended distance.\"\n} else {\n    $status = \"NON-COMPLIANT\"\n    $statusDetail = \"Sites do not meet minimum separation requirements.\"\n}\n\n# Generate report\n$report = @\"\n===============================================\nCP-6.1 GEOGRAPHIC SEPARATION COMPLIANCE REPORT\nGenerated: $(Get-Date)\n===============================================\n\nPRIMARY SITE:\n  Name: $PrimarySiteName\n  Coordinates: ($PrimaryLat, $PrimaryLon)\n  Cloud Region: $PrimaryRegion\n\nALTERNATE SITE:\n  Name: $AlternateSiteName\n  Coordinates: ($AlternateLat, $AlternateLon)\n  Cloud Region: $AlternateRegion\n\nSEPARATION DISTANCE: $distance miles\n\nREQUIREMENTS:\n  Minimum Required: $MinDistanceMiles miles\n  Recommended: $RecommendedDistanceMiles miles\n\nSTATUS: $status\n  $statusDetail\n\nTHREAT ZONE ANALYSIS:\n  - Hurricane zone separation: $(if ($distance -ge 200) { \"ADEQUATE\" } else { \"INSUFFICIENT\" })\n  - Earthquake zone separation: $(if ($PrimaryRegion -ne $AlternateRegion) { \"DIFFERENT ZONES\" } else { \"SAME ZONE - VERIFY\" })\n  - Power grid independence: $(if ($PrimaryRegion -ne $AlternateRegion) { \"LIKELY INDEPENDENT\" } else { \"VERIFY MANUALLY\" })\n\n===============================================\n\"@\n\n$report | Out-File -FilePath $reportFile\nWrite-Host $report\nWrite-Host \"`nReport saved to: $reportFile\""
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": true,
      "qa_validated": true
    },
    "cac_metadata": {
      "implementation_type": "hybrid",
      "last_analyzed": "2025-11-22T00:00:00Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Requires organizational site selection decisions combined with technical verification scripts to validate geographic separation requirements are met."
    },
    "rationale": "Your backup storage must be far enough away that the same disaster can't hit both locations."
  },
  {
    "control_id": "CP-6.2",
    "control_name": "Recovery Time and Recovery Point Objectives",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "official_text": "Configure the alternate storage site to facilitate recovery operations in accordance with recovery time and recovery point objectives.",
    "parent_control": "CP-6",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": true
    },
    "intent": "Ensure that the alternate storage site is configured with sufficient bandwidth, storage capacity, and replication frequency to meet the organization's defined Recovery Time Objective (RTO) and Recovery Point Objective (RPO), enabling timely restoration of operations with minimal data loss.",
    "plain_english_explanation": "Your backup storage site must be set up to meet your organization's recovery goals. The Recovery Time Objective (RTO) defines how quickly you need to restore operations after a disaster - if your RTO is 4 hours, your alternate site must be capable of bringing systems back online within that timeframe. The Recovery Point Objective (RPO) defines how much data loss is acceptable - if your RPO is 1 hour, you cannot lose more than 1 hour of data, meaning backups must occur at least hourly. Your alternate site's configuration, bandwidth, and replication schedule must be designed to meet both of these objectives.",
    "ai_guidance": "When implementing CP-6.2, first establish formal RTO and RPO requirements for each system tier (e.g., Tier 1 critical systems: RTO 4 hours, RPO 15 minutes). Configure replication frequency to match RPO requirements - for 15-minute RPO, implement synchronous or near-synchronous replication. For RTO compliance, ensure sufficient bandwidth exists between sites to transfer required data volumes within the recovery window. Calculate bandwidth requirements: (Data Change Rate x RPO) / Available Bandwidth. Implement continuous data replication using technologies like AWS Cross-Region Replication, Azure Site Recovery, or database-native replication (PostgreSQL streaming replication, MySQL binlog replication). Deploy monitoring to track replication lag and alert when lag approaches RPO thresholds. Conduct regular recovery drills to validate RTO can be achieved. Document current replication lag, bandwidth utilization, and recovery test results. Consider implementing tiered storage with different RTO/RPO configurations based on data criticality. Use automated scripts to verify replication status and calculate current recovery capabilities against defined objectives.",
    "example_implementation": "Configure AWS S3 Cross-Region Replication with RTC (Replication Time Control) guaranteeing 99.99% of objects replicated within 15 minutes. Implement CloudWatch alarms for replication lag exceeding RPO threshold.",
    "non_technical_guidance": "To comply with CP-6.2:\n1. Define RTO (Recovery Time Objective) for each critical system.\n2. Define RPO (Recovery Point Objective) for each critical system.\n3. Document these objectives in the Business Continuity Plan.\n4. Configure backup replication frequency to meet RPO requirements.\n5. Ensure network bandwidth supports required replication volume.\n6. Verify alternate site storage capacity meets growth projections.\n7. Conduct quarterly recovery drills to validate RTO achievement.\n8. Monitor and report on replication lag continuously.\n9. Review and update RTO/RPO requirements annually.",
    "is_technical": true,
    "enhancements": [],
    "related_controls": [
      "CP-6",
      "CP-7.3",
      "CP-9",
      "CP-10"
    ],
    "supplemental_guidance": "Configuring alternate storage sites to facilitate recovery operations includes ensuring that the alternate site has the necessary computing and communication resources to support recovery operations. Organizations also determine the time and resource allocation to alternate storage sites during contingency operations. This control enhancement also applies to cloud computing, grid computing, and hybrid computing environments where recovery of and access to data may be distributed across multiple systems and geographic locations.",
    "implementation_scripts": {
      "linux": {
        "bash": "# rto_rpo_verification\n#!/bin/bash\n# CP-6.2: RTO/RPO Compliance Verification Script\n\nset -euo pipefail\n\n# Configuration - UPDATE THESE VALUES\nRPO_MINUTES=15              # Recovery Point Objective in minutes\nRTO_HOURS=4                 # Recovery Time Objective in hours\nREPLICATION_LOG=\"/var/log/replication-status.log\"\nALTERNATE_SITE_HOST=\"backup.alternate-site.example.com\"\nSSH_KEY=\"/root/.ssh/backup_replication_key\"\nALERT_EMAIL=\"it-operations@example.com\"\nREPORT_DIR=\"/var/reports/rto-rpo\"\n\nmkdir -p \"$REPORT_DIR\"\nLOG_FILE=\"/var/log/rto-rpo-verification.log\"\nREPORT_FILE=\"$REPORT_DIR/rto-rpo-report-$(date +%Y%m%d-%H%M%S).txt\"\n\nlog_message() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" | tee -a \"$LOG_FILE\"\n}\n\nalert_violation() {\n    echo \"$1\" | mail -s \"ALERT: CP-6.2 RTO/RPO Violation\" \"$ALERT_EMAIL\"\n}\n\nlog_message \"=== CP-6.2 RTO/RPO Compliance Verification ===\"\n\n# Calculate current replication lag\nget_replication_lag() {\n    # Get last local backup timestamp\n    local_last_backup=$(stat -c %Y /var/backups/critical-data 2>/dev/null || echo 0)\n    \n    # Get last remote backup timestamp\n    remote_last_backup=$(ssh -i \"$SSH_KEY\" -o ConnectTimeout=10 \\\n        \"backup-admin@${ALTERNATE_SITE_HOST}\" \\\n        \"stat -c %Y /storage/replicated-backups 2>/dev/null || echo 0\" 2>/dev/null || echo 0)\n    \n    if [ \"$local_last_backup\" -gt 0 ] && [ \"$remote_last_backup\" -gt 0 ]; then\n        lag_seconds=$((local_last_backup - remote_last_backup))\n        if [ $lag_seconds -lt 0 ]; then lag_seconds=0; fi\n        echo $((lag_seconds / 60))\n    else\n        echo \"-1\"\n    fi\n}\n\n# Estimate recovery time based on data volume and bandwidth\nestimate_recovery_time() {\n    # Get data volume at alternate site (in MB)\n    data_volume_mb=$(ssh -i \"$SSH_KEY\" -o ConnectTimeout=10 \\\n        \"backup-admin@${ALTERNATE_SITE_HOST}\" \\\n        \"du -sm /storage/replicated-backups | cut -f1\" 2>/dev/null || echo \"0\")\n    \n    # Assume 100 Mbps effective restore bandwidth (conservative)\n    bandwidth_mbps=100\n    \n    # Calculate restore time: (data_mb * 8) / bandwidth_mbps / 60 = hours\n    if [ \"$data_volume_mb\" -gt 0 ]; then\n        restore_time_hours=$(echo \"scale=2; ($data_volume_mb * 8) / ($bandwidth_mbps * 60 * 60)\" | bc)\n        echo \"$restore_time_hours\"\n    else\n        echo \"-1\"\n    fi\n}\n\n# Generate compliance report\n{\n    echo \"===============================================\"\n    echo \"CP-6.2 RTO/RPO COMPLIANCE REPORT\"\n    echo \"Generated: $(date)\"\n    echo \"===============================================\"\n    echo \"\"\n    echo \"DEFINED OBJECTIVES:\"\n    echo \"  Recovery Point Objective (RPO): $RPO_MINUTES minutes\"\n    echo \"  Recovery Time Objective (RTO): $RTO_HOURS hours\"\n    echo \"\"\n    \n    # Check RPO compliance\n    CURRENT_LAG=$(get_replication_lag)\n    echo \"RPO ANALYSIS:\"\n    echo \"  Current Replication Lag: ${CURRENT_LAG} minutes\"\n    \n    if [ \"$CURRENT_LAG\" -eq -1 ]; then\n        echo \"  RPO Status: UNKNOWN - Cannot determine replication lag\"\n        RPO_STATUS=\"UNKNOWN\"\n    elif [ \"$CURRENT_LAG\" -le \"$RPO_MINUTES\" ]; then\n        echo \"  RPO Status: COMPLIANT (lag <= RPO)\"\n        RPO_STATUS=\"COMPLIANT\"\n    else\n        echo \"  RPO Status: NON-COMPLIANT (lag > RPO)\"\n        RPO_STATUS=\"NON-COMPLIANT\"\n        alert_violation \"RPO Violation: Current lag ($CURRENT_LAG min) exceeds RPO ($RPO_MINUTES min)\"\n    fi\n    echo \"\"\n    \n    # Check RTO capability\n    ESTIMATED_RTO=$(estimate_recovery_time)\n    echo \"RTO ANALYSIS:\"\n    echo \"  Estimated Recovery Time: ${ESTIMATED_RTO} hours\"\n    \n    if [ \"$ESTIMATED_RTO\" = \"-1\" ]; then\n        echo \"  RTO Status: UNKNOWN - Cannot estimate recovery time\"\n        RTO_STATUS=\"UNKNOWN\"\n    elif (( $(echo \"$ESTIMATED_RTO <= $RTO_HOURS\" | bc -l) )); then\n        echo \"  RTO Status: ACHIEVABLE (estimated <= RTO)\"\n        RTO_STATUS=\"COMPLIANT\"\n    else\n        echo \"  RTO Status: AT RISK (estimated > RTO)\"\n        RTO_STATUS=\"AT RISK\"\n        alert_violation \"RTO Risk: Estimated recovery ($ESTIMATED_RTO hrs) may exceed RTO ($RTO_HOURS hrs)\"\n    fi\n    echo \"\"\n    \n    # Overall compliance\n    echo \"OVERALL COMPLIANCE:\"\n    if [ \"$RPO_STATUS\" = \"COMPLIANT\" ] && [ \"$RTO_STATUS\" = \"COMPLIANT\" ]; then\n        echo \"  Status: FULLY COMPLIANT\"\n    elif [ \"$RPO_STATUS\" = \"NON-COMPLIANT\" ] || [ \"$RTO_STATUS\" = \"AT RISK\" ]; then\n        echo \"  Status: NON-COMPLIANT - Immediate action required\"\n    else\n        echo \"  Status: PARTIALLY COMPLIANT - Review recommended\"\n    fi\n    echo \"\"\n    echo \"RECOMMENDATIONS:\"\n    if [ \"$RPO_STATUS\" = \"NON-COMPLIANT\" ]; then\n        echo \"  - Increase replication frequency to meet RPO\"\n        echo \"  - Verify network bandwidth to alternate site\"\n    fi\n    if [ \"$RTO_STATUS\" = \"AT RISK\" ]; then\n        echo \"  - Increase bandwidth for faster recovery\"\n        echo \"  - Consider implementing hot standby systems\"\n        echo \"  - Reduce data volume through archival policies\"\n    fi\n    echo \"\"\n    echo \"===============================================\"\n} | tee \"$REPORT_FILE\"\n\nlog_message \"Report generated: $REPORT_FILE\"\nlog_message \"=== CP-6.2 Verification Complete ===\"\n\n# monitor_replication_lag\n#!/bin/bash\n# CP-6.2: Continuous Replication Lag Monitoring\n# Run via cron every 5 minutes\n\nset -euo pipefail\n\nRPO_MINUTES=15\nWARNING_THRESHOLD_PERCENT=80  # Alert at 80% of RPO\nMETRICS_FILE=\"/var/metrics/replication-lag.prom\"\nALERT_EMAIL=\"it-operations@example.com\"\n\nmkdir -p /var/metrics\n\n# Calculate current lag (simplified - adjust for your environment)\nLAST_LOCAL_UPDATE=$(stat -c %Y /var/backups/critical-data/.last-sync 2>/dev/null || echo 0)\nCURRENT_TIME=$(date +%s)\n\nif [ \"$LAST_LOCAL_UPDATE\" -gt 0 ]; then\n    LAG_SECONDS=$((CURRENT_TIME - LAST_LOCAL_UPDATE))\n    LAG_MINUTES=$((LAG_SECONDS / 60))\nelse\n    LAG_MINUTES=-1\nfi\n\n# Write Prometheus metrics\ncat > \"$METRICS_FILE\" << EOF\n# HELP replication_lag_minutes Current replication lag in minutes\n# TYPE replication_lag_minutes gauge\nreplication_lag_minutes $LAG_MINUTES\n\n# HELP rpo_target_minutes Configured RPO target in minutes\n# TYPE rpo_target_minutes gauge\nrpo_target_minutes $RPO_MINUTES\n\n# HELP rpo_compliance Whether RPO is being met (1=compliant, 0=violation)\n# TYPE rpo_compliance gauge\nrpo_compliance $(if [ \"$LAG_MINUTES\" -le \"$RPO_MINUTES\" ] && [ \"$LAG_MINUTES\" -ge 0 ]; then echo 1; else echo 0; fi)\nEOF\n\n# Alert if approaching or exceeding RPO\nWARNING_THRESHOLD=$((RPO_MINUTES * WARNING_THRESHOLD_PERCENT / 100))\n\nif [ \"$LAG_MINUTES\" -ge \"$RPO_MINUTES\" ]; then\n    echo \"CRITICAL: Replication lag ($LAG_MINUTES min) exceeds RPO ($RPO_MINUTES min)\" | \\\n        mail -s \"CRITICAL: CP-6.2 RPO Violation\" \"$ALERT_EMAIL\"\nelif [ \"$LAG_MINUTES\" -ge \"$WARNING_THRESHOLD\" ]; then\n    echo \"WARNING: Replication lag ($LAG_MINUTES min) approaching RPO ($RPO_MINUTES min)\" | \\\n        mail -s \"WARNING: CP-6.2 RPO Threshold\" \"$ALERT_EMAIL\"\nfi"
      },
      "windows": {
        "powershell": "# rto_rpo_verification\n# CP-6.2: RTO/RPO Compliance Verification Script (Windows)\n\nparam(\n    [int]$RPOMinutes = 15,\n    [int]$RTOHours = 4,\n    [string]$LocalBackupPath = \"C:\\Backups\\CriticalData\",\n    [string]$RemoteBackupPath = \"\\\\alternate-site.example.com\\ReplicatedBackups\",\n    [string]$ReportPath = \"C:\\Reports\\RTO-RPO\",\n    [string]$AlertEmail = \"it-operations@example.com\"\n)\n\n$ErrorActionPreference = \"Stop\"\n\nif (-not (Test-Path $ReportPath)) {\n    New-Item -ItemType Directory -Path $ReportPath -Force | Out-Null\n}\n\n$reportFile = Join-Path $ReportPath \"RTO-RPO-Report-$(Get-Date -Format 'yyyyMMdd-HHmmss').txt\"\n\nfunction Send-Alert {\n    param([string]$Subject, [string]$Body)\n    try {\n        Send-MailMessage -To $AlertEmail -Subject $Subject -Body $Body `\n            -SmtpServer \"smtp.example.com\" -From \"cp6-monitor@example.com\"\n    } catch {\n        Write-Warning \"Could not send alert: $_\"\n    }\n}\n\n# Calculate replication lag\nfunction Get-ReplicationLag {\n    try {\n        $localLastWrite = (Get-Item $LocalBackupPath -ErrorAction Stop).LastWriteTime\n        $remoteLastWrite = (Get-Item $RemoteBackupPath -ErrorAction Stop).LastWriteTime\n        \n        $lag = ($localLastWrite - $remoteLastWrite).TotalMinutes\n        if ($lag -lt 0) { $lag = 0 }\n        return [math]::Round($lag, 2)\n    } catch {\n        return -1\n    }\n}\n\n# Estimate recovery time\nfunction Get-EstimatedRecoveryTime {\n    try {\n        $dataVolumeMB = [math]::Round((Get-ChildItem $RemoteBackupPath -Recurse | \n            Measure-Object -Property Length -Sum).Sum / 1MB, 2)\n        \n        # Assume 100 Mbps effective bandwidth\n        $bandwidthMbps = 100\n        $recoveryHours = ($dataVolumeMB * 8) / ($bandwidthMbps * 60 * 60)\n        \n        return [math]::Round($recoveryHours, 2)\n    } catch {\n        return -1\n    }\n}\n\n$currentLag = Get-ReplicationLag\n$estimatedRTO = Get-EstimatedRecoveryTime\n\n# Determine compliance status\n$rpoStatus = if ($currentLag -eq -1) { \"UNKNOWN\" }\n             elseif ($currentLag -le $RPOMinutes) { \"COMPLIANT\" }\n             else { \"NON-COMPLIANT\" }\n\n$rtoStatus = if ($estimatedRTO -eq -1) { \"UNKNOWN\" }\n             elseif ($estimatedRTO -le $RTOHours) { \"COMPLIANT\" }\n             else { \"AT RISK\" }\n\n# Generate report\n$report = @\"\n===============================================\nCP-6.2 RTO/RPO COMPLIANCE REPORT\nGenerated: $(Get-Date)\n===============================================\n\nDEFINED OBJECTIVES:\n  Recovery Point Objective (RPO): $RPOMinutes minutes\n  Recovery Time Objective (RTO): $RTOHours hours\n\nRPO ANALYSIS:\n  Current Replication Lag: $currentLag minutes\n  RPO Status: $rpoStatus\n\nRTO ANALYSIS:\n  Estimated Recovery Time: $estimatedRTO hours\n  RTO Status: $rtoStatus\n\nOVERALL COMPLIANCE:\n  Status: $(if ($rpoStatus -eq \"COMPLIANT\" -and $rtoStatus -eq \"COMPLIANT\") { \"FULLY COMPLIANT\" } elseif ($rpoStatus -eq \"NON-COMPLIANT\" -or $rtoStatus -eq \"AT RISK\") { \"NON-COMPLIANT\" } else { \"PARTIALLY COMPLIANT\" })\n\n===============================================\n\"@\n\n$report | Out-File -FilePath $reportFile\nWrite-Host $report\n\n# Send alerts if non-compliant\nif ($rpoStatus -eq \"NON-COMPLIANT\") {\n    Send-Alert -Subject \"ALERT: CP-6.2 RPO Violation\" `\n               -Body \"Replication lag ($currentLag min) exceeds RPO ($RPOMinutes min)\"\n}\n\nif ($rtoStatus -eq \"AT RISK\") {\n    Send-Alert -Subject \"WARNING: CP-6.2 RTO Risk\" `\n               -Body \"Estimated recovery time ($estimatedRTO hrs) may exceed RTO ($RTOHours hrs)\"\n}\n\nWrite-Host \"`nReport saved to: $reportFile\""
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": true,
      "qa_validated": true
    },
    "cac_metadata": {
      "implementation_type": "hybrid",
      "last_analyzed": "2025-11-22T00:00:00Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Requires definition of RTO/RPO objectives by business stakeholders, followed by technical implementation of replication and monitoring systems to meet those objectives."
    },
    "rationale": "Knowing your RTO (Recovery Time Objective) and RPO (Recovery Point Objective) ensures backups meet business needs."
  },
  {
    "control_id": "CP-6.3",
    "control_name": "Accessibility",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "official_text": "Identify potential accessibility problems to the alternate storage site in the event of an area-wide disruption or disaster and outline explicit mitigation actions.",
    "parent_control": "CP-6",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": true,
      "high": true
    },
    "intent": "Ensure that the organization proactively identifies potential barriers to accessing the alternate storage site during a regional disaster and develops documented mitigation strategies to overcome these barriers, guaranteeing data availability when it is most critically needed.",
    "plain_english_explanation": "You must identify all the things that could prevent you from accessing your backup storage site during a widespread disaster, and create plans to work around each problem. For example, if roads might be flooded, plan for helicopter access or ensure you can restore data remotely. If the internet might be down, have backup communication links. If key personnel might be unavailable, cross-train others and document procedures clearly. The goal is to ensure you can always get to your backup data, even in the worst-case scenario.",
    "ai_guidance": "When implementing CP-6.3, conduct a comprehensive accessibility risk assessment that identifies all potential barriers to alternate site access during various disaster scenarios. Consider physical accessibility issues: road closures, bridge failures, flooding, building damage, restricted areas. Address personnel availability: key staff incapacity, travel restrictions, shelter-in-place orders. Evaluate network connectivity: ISP failures, DNS outages, peering issues, last-mile connectivity. Plan for authentication systems: directory service outages, MFA system failures, certificate authority unavailability. Document mitigation strategies for each identified risk. Implement redundant network paths (multiple ISPs, VPN failover, dedicated circuits). Establish out-of-band management capabilities (cellular backup, satellite links). Pre-position credentials and access keys in secure offline storage. Cross-train personnel and document all recovery procedures. Test accessibility from multiple locations and under degraded conditions. Implement automated health checks that verify alternate site accessibility continuously. Create runbooks for each mitigation action with clear escalation paths.",
    "example_implementation": "Maintain redundant network connectivity (primary ISP + cellular backup + satellite link). Pre-position emergency access credentials in fireproof safe. Document manual recovery procedures that do not depend on primary site infrastructure.",
    "non_technical_guidance": "To comply with CP-6.3:\n1. Identify all methods of accessing the alternate storage site (network, physical).\n2. List potential disasters that could affect each access method.\n3. Document specific barriers for each disaster scenario.\n4. Develop mitigation strategies for each identified barrier.\n5. Establish redundant access paths (multiple network providers, alternate routes).\n6. Pre-position emergency access credentials securely.\n7. Cross-train personnel on alternate site access procedures.\n8. Document all procedures in an accessible disaster recovery runbook.\n9. Test accessibility under simulated disaster conditions annually.\n10. Review and update accessibility plans after any actual incidents.",
    "is_technical": true,
    "enhancements": [],
    "related_controls": [
      "CP-6",
      "CP-7.2",
      "CP-8",
      "PE-18"
    ],
    "supplemental_guidance": "Area-wide disruptions refer to those types of disruptions that are broad in geographic scope with such determinations made by organizations based on organizational assessments of risk. Explicit mitigation actions include establishing additional alternate storage sites, maintaining multiple network connections to alternate sites, or establishing alternative site access methods such as out-of-band communication channels.",
    "implementation_scripts": {
      "linux": {
        "bash": "# accessibility_check\n#!/bin/bash\n# CP-6.3: Alternate Site Accessibility Verification\n# Tests multiple access paths to alternate storage site\n\nset -euo pipefail\n\n# Configuration\nALTERNATE_SITE_PRIMARY=\"backup.alternate-site.example.com\"\nALTERNATE_SITE_VPN=\"10.100.50.10\"\nALTERNATE_SITE_BACKUP_ISP=\"backup-isp.alternate-site.example.com\"\nSSH_KEY=\"/root/.ssh/backup_replication_key\"\nSSH_USER=\"backup-admin\"\nSSH_PORT=22\n\nREPORT_DIR=\"/var/reports/accessibility\"\nLOG_FILE=\"/var/log/cp6-accessibility-check.log\"\nALERT_EMAIL=\"it-operations@example.com\"\n\nmkdir -p \"$REPORT_DIR\"\n\nlog_message() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" | tee -a \"$LOG_FILE\"\n}\n\ntest_connectivity() {\n    local host=$1\n    local description=$2\n    local port=${3:-22}\n    \n    log_message \"Testing: $description ($host:$port)\"\n    \n    # Test ICMP\n    if ping -c 3 -W 5 \"$host\" &>/dev/null; then\n        icmp_status=\"PASS\"\n    else\n        icmp_status=\"FAIL\"\n    fi\n    \n    # Test TCP port\n    if timeout 10 bash -c \"echo >/dev/tcp/$host/$port\" 2>/dev/null; then\n        tcp_status=\"PASS\"\n    else\n        tcp_status=\"FAIL\"\n    fi\n    \n    # Test SSH if port 22\n    if [ \"$port\" -eq 22 ]; then\n        if ssh -i \"$SSH_KEY\" -o ConnectTimeout=10 -o BatchMode=yes \\\n            \"${SSH_USER}@${host}\" \"echo 'SSH OK'\" &>/dev/null; then\n            ssh_status=\"PASS\"\n        else\n            ssh_status=\"FAIL\"\n        fi\n    else\n        ssh_status=\"N/A\"\n    fi\n    \n    echo \"$description|$host|$icmp_status|$tcp_status|$ssh_status\"\n}\n\nlog_message \"=== CP-6.3 Accessibility Verification Starting ===\"\n\n# Test all access paths\nRESULTS=$(mktemp)\n\ntest_connectivity \"$ALTERNATE_SITE_PRIMARY\" \"Primary Network Path\" >> \"$RESULTS\"\ntest_connectivity \"$ALTERNATE_SITE_VPN\" \"VPN Tunnel Path\" >> \"$RESULTS\"\ntest_connectivity \"$ALTERNATE_SITE_BACKUP_ISP\" \"Backup ISP Path\" >> \"$RESULTS\"\n\n# Generate report\nREPORT_FILE=\"$REPORT_DIR/accessibility-report-$(date +%Y%m%d-%H%M%S).txt\"\n\n{\n    echo \"===============================================\"\n    echo \"CP-6.3 ALTERNATE SITE ACCESSIBILITY REPORT\"\n    echo \"Generated: $(date)\"\n    echo \"===============================================\"\n    echo \"\"\n    echo \"ACCESS PATH TEST RESULTS:\"\n    echo \"-----------------------------------------\"\n    printf \"%-25s | %-8s | %-8s | %-8s\\n\" \"Path\" \"ICMP\" \"TCP\" \"SSH\"\n    echo \"-----------------------------------------\"\n    \n    TOTAL_PATHS=0\n    WORKING_PATHS=0\n    \n    while IFS='|' read -r desc host icmp tcp ssh; do\n        printf \"%-25s | %-8s | %-8s | %-8s\\n\" \"$desc\" \"$icmp\" \"$tcp\" \"$ssh\"\n        TOTAL_PATHS=$((TOTAL_PATHS + 1))\n        if [ \"$tcp\" = \"PASS\" ]; then\n            WORKING_PATHS=$((WORKING_PATHS + 1))\n        fi\n    done < \"$RESULTS\"\n    \n    echo \"-----------------------------------------\"\n    echo \"\"\n    echo \"SUMMARY:\"\n    echo \"  Total Access Paths Tested: $TOTAL_PATHS\"\n    echo \"  Working Access Paths: $WORKING_PATHS\"\n    echo \"  Redundancy Level: $(echo \"scale=0; $WORKING_PATHS * 100 / $TOTAL_PATHS\" | bc)%\"\n    echo \"\"\n    \n    if [ \"$WORKING_PATHS\" -eq 0 ]; then\n        echo \"STATUS: CRITICAL - No access paths available!\"\n        echo \"COMPLIANCE: NON-COMPLIANT\"\n    elif [ \"$WORKING_PATHS\" -lt \"$TOTAL_PATHS\" ]; then\n        echo \"STATUS: DEGRADED - Some access paths unavailable\"\n        echo \"COMPLIANCE: PARTIAL - Remediation recommended\"\n    else\n        echo \"STATUS: HEALTHY - All access paths operational\"\n        echo \"COMPLIANCE: COMPLIANT\"\n    fi\n    echo \"\"\n    \n    # DNS resolution check\n    echo \"DNS RESOLUTION CHECK:\"\n    for host in \"$ALTERNATE_SITE_PRIMARY\" \"$ALTERNATE_SITE_BACKUP_ISP\"; do\n        if host \"$host\" &>/dev/null; then\n            echo \"  $host: RESOLVES\"\n        else\n            echo \"  $host: FAILS\"\n        fi\n    done\n    echo \"\"\n    \n    # Latency measurements\n    echo \"LATENCY MEASUREMENTS:\"\n    for host in \"$ALTERNATE_SITE_PRIMARY\" \"$ALTERNATE_SITE_VPN\"; do\n        latency=$(ping -c 3 -W 5 \"$host\" 2>/dev/null | grep 'avg' | awk -F'/' '{print $5}' || echo \"N/A\")\n        echo \"  $host: ${latency}ms\"\n    done\n    echo \"\"\n    echo \"===============================================\"\n} | tee \"$REPORT_FILE\"\n\nrm -f \"$RESULTS\"\n\n# Alert if critical\nif [ \"$WORKING_PATHS\" -eq 0 ]; then\n    echo \"CRITICAL: All access paths to alternate site are down!\" | \\\n        mail -s \"CRITICAL: CP-6.3 Accessibility Failure\" \"$ALERT_EMAIL\"\nelif [ \"$WORKING_PATHS\" -lt \"$TOTAL_PATHS\" ]; then\n    echo \"WARNING: Some access paths to alternate site are unavailable\" | \\\n        mail -s \"WARNING: CP-6.3 Accessibility Degraded\" \"$ALERT_EMAIL\"\nfi\n\nlog_message \"Report generated: $REPORT_FILE\"\nlog_message \"=== CP-6.3 Verification Complete ===\"\n\n# mitigation_runbook\n#!/bin/bash\n# CP-6.3: Accessibility Mitigation Runbook\n# Documents and tests mitigation actions for accessibility issues\n\ncat << 'EOF'\n===============================================\nCP-6.3 ACCESSIBILITY MITIGATION RUNBOOK\n===============================================\n\nSCENARIO 1: Primary Network Path Failure\n-----------------------------------------\nSymptoms: Cannot reach alternate site via primary ISP\nMitigation Steps:\n  1. Verify primary ISP outage: ping gateway, check ISP status page\n  2. Activate backup ISP connection:\n     - ip route del default\n     - ip route add default via <backup-gateway>\n  3. Update DNS if needed: echo \"nameserver <backup-dns>\" > /etc/resolv.conf\n  4. Verify connectivity: ping backup.alternate-site.example.com\n  5. Notify operations team of failover\n\nSCENARIO 2: VPN Tunnel Failure\n-----------------------------------------\nSymptoms: VPN tunnel down, cannot reach 10.100.50.x\nMitigation Steps:\n  1. Check VPN service: systemctl status openvpn@alternate-site\n  2. Restart VPN: systemctl restart openvpn@alternate-site\n  3. If VPN server unreachable, use alternate VPN endpoint:\n     - Edit /etc/openvpn/alternate-site.conf\n     - Change 'remote' to backup VPN server IP\n     - Restart VPN service\n  4. If all VPN fails, use SSH tunnel:\n     - ssh -L 8022:10.100.50.10:22 jump-host.example.com\n     - Connect via localhost:8022\n\nSCENARIO 3: DNS Resolution Failure\n-----------------------------------------\nSymptoms: Cannot resolve alternate site hostnames\nMitigation Steps:\n  1. Test alternate DNS servers\n  2. Add static /etc/hosts entries:\n     - 203.0.113.50 backup.alternate-site.example.com\n     - 203.0.113.51 backup-isp.alternate-site.example.com\n  3. Use IP addresses directly in scripts temporarily\n\nSCENARIO 4: SSH Key Authentication Failure\n-----------------------------------------\nSymptoms: SSH key rejected at alternate site\nMitigation Steps:\n  1. Verify key permissions: chmod 600 /root/.ssh/backup_replication_key\n  2. Use emergency password (stored in secure vault)\n  3. Contact alternate site admin to re-add public key\n  4. As last resort, physical access to alternate site\n\nSCENARIO 5: Area-Wide Internet Outage\n-----------------------------------------\nSymptoms: No internet connectivity from primary site\nMitigation Steps:\n  1. Activate cellular backup modem\n  2. Use satellite backup link if available\n  3. Contact alternate site via out-of-band phone\n  4. If extended outage, dispatch personnel to alternate site\n  5. Pre-positioned USB drives contain offline recovery data\n\nEMERGENCY CONTACTS:\n  - Alternate Site NOC: +1-555-123-4567\n  - Primary ISP Support: +1-555-234-5678\n  - Backup ISP Support: +1-555-345-6789\n  - On-Call Engineer: +1-555-456-7890\n\nPRE-POSITIONED RESOURCES:\n  - Emergency credentials: Fireproof safe, Primary Site Server Room\n  - Offline recovery USB: IT Manager's secure cabinet\n  - Satellite phone: Emergency supplies cabinet\n  - Paper runbooks: Disaster recovery binder, all IT offices\n\n===============================================\nEOF"
      },
      "windows": {
        "powershell": "# accessibility_check\n# CP-6.3: Alternate Site Accessibility Verification (Windows)\n\nparam(\n    [string]$PrimarySiteHost = \"backup.alternate-site.example.com\",\n    [string]$VPNSiteIP = \"10.100.50.10\",\n    [string]$BackupISPHost = \"backup-isp.alternate-site.example.com\",\n    [string]$ReportPath = \"C:\\Reports\\Accessibility\",\n    [string]$AlertEmail = \"it-operations@example.com\"\n)\n\n$ErrorActionPreference = \"Stop\"\n\nif (-not (Test-Path $ReportPath)) {\n    New-Item -ItemType Directory -Path $ReportPath -Force | Out-Null\n}\n\n$reportFile = Join-Path $ReportPath \"Accessibility-Report-$(Get-Date -Format 'yyyyMMdd-HHmmss').txt\"\n\nfunction Test-AccessPath {\n    param(\n        [string]$Host,\n        [string]$Description,\n        [int]$Port = 22\n    )\n    \n    $result = [PSCustomObject]@{\n        Description = $Description\n        Host = $Host\n        ICMP = \"FAIL\"\n        TCP = \"FAIL\"\n        DNS = \"FAIL\"\n    }\n    \n    # Test ICMP\n    try {\n        if (Test-Connection -ComputerName $Host -Count 2 -Quiet -ErrorAction SilentlyContinue) {\n            $result.ICMP = \"PASS\"\n        }\n    } catch { }\n    \n    # Test TCP\n    try {\n        $tcp = New-Object System.Net.Sockets.TcpClient\n        $connect = $tcp.BeginConnect($Host, $Port, $null, $null)\n        $wait = $connect.AsyncWaitHandle.WaitOne(5000, $false)\n        if ($wait -and $tcp.Connected) {\n            $result.TCP = \"PASS\"\n        }\n        $tcp.Close()\n    } catch { }\n    \n    # Test DNS (if hostname)\n    if ($Host -notmatch '^\\d+\\.\\d+\\.\\d+\\.\\d+$') {\n        try {\n            $dns = [System.Net.Dns]::GetHostAddresses($Host)\n            if ($dns.Count -gt 0) {\n                $result.DNS = \"PASS\"\n            }\n        } catch { }\n    } else {\n        $result.DNS = \"N/A\"\n    }\n    \n    return $result\n}\n\n# Test all access paths\n$results = @()\n$results += Test-AccessPath -Host $PrimarySiteHost -Description \"Primary Network\"\n$results += Test-AccessPath -Host $VPNSiteIP -Description \"VPN Tunnel\"\n$results += Test-AccessPath -Host $BackupISPHost -Description \"Backup ISP\"\n\n$workingPaths = ($results | Where-Object { $_.TCP -eq \"PASS\" }).Count\n$totalPaths = $results.Count\n\n# Determine status\nif ($workingPaths -eq 0) {\n    $status = \"CRITICAL - No access paths available!\"\n    $compliance = \"NON-COMPLIANT\"\n} elseif ($workingPaths -lt $totalPaths) {\n    $status = \"DEGRADED - Some access paths unavailable\"\n    $compliance = \"PARTIAL\"\n} else {\n    $status = \"HEALTHY - All access paths operational\"\n    $compliance = \"COMPLIANT\"\n}\n\n# Generate report\n$report = @\"\n===============================================\nCP-6.3 ALTERNATE SITE ACCESSIBILITY REPORT\nGenerated: $(Get-Date)\n===============================================\n\nACCESS PATH TEST RESULTS:\n-----------------------------------------\n$($results | Format-Table -AutoSize | Out-String)\n\nSUMMARY:\n  Total Access Paths Tested: $totalPaths\n  Working Access Paths: $workingPaths\n  Redundancy Level: $([math]::Round($workingPaths * 100 / $totalPaths))%\n\nSTATUS: $status\nCOMPLIANCE: $compliance\n\nLATENCY MEASUREMENTS:\n$($results | Where-Object { $_.ICMP -eq \"PASS\" } | ForEach-Object {\n    $ping = Test-Connection -ComputerName $_.Host -Count 3 -ErrorAction SilentlyContinue\n    if ($ping) {\n        $avg = ($ping | Measure-Object -Property ResponseTime -Average).Average\n        \"  $($_.Description): $([math]::Round($avg, 2))ms\"\n    }\n} | Out-String)\n\n===============================================\n\"@\n\n$report | Out-File -FilePath $reportFile\nWrite-Host $report\n\n# Send alerts\nif ($workingPaths -eq 0) {\n    try {\n        Send-MailMessage -To $AlertEmail -Subject \"CRITICAL: CP-6.3 Accessibility Failure\" `\n            -Body \"All access paths to alternate site are down!\" `\n            -SmtpServer \"smtp.example.com\" -From \"cp6-monitor@example.com\"\n    } catch { Write-Warning \"Could not send alert: $_\" }\n}\n\nWrite-Host \"`nReport saved to: $reportFile\""
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": true,
      "qa_validated": true
    },
    "cac_metadata": {
      "implementation_type": "hybrid",
      "last_analyzed": "2025-11-22T00:00:00Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Requires organizational assessment of potential accessibility barriers and documentation of mitigation strategies, combined with technical implementation of redundant access paths and automated monitoring."
    },
    "rationale": "Backups are useless if you can't access them when needed. This ensures your alternate storage is reachable."
  },
  {
    "control_id": "CP-7",
    "control_name": "Alternate Processing Site",
    "family": "Contingency Planning",
    "family_id": "CP",
    "official_text": "a. Establish an alternate processing site, including necessary agreements to permit the transfer and resumption of [organization-defined system operations] for essential mission and business functions within [organization-defined time period consistent with recovery time and recovery point objectives] when the primary processing capabilities are unavailable; b. Make available at the alternate processing site, the equipment and supplies required to transfer and resume operations or put contracts in place to support delivery to the site within the organization-defined time period for transfer and resumption; and c. Provide controls at the alternate processing site that are equivalent to those at the primary site.",
    "source": "NIST SP 800-53 Rev 5",
    "stig_id": "RHEL-08-010000",
    "baselines": {
      "low": false,
      "moderate": true,
      "high": true
    },
    "intent": "Ensure organizational mission-critical operations can continue from an alternate location when the primary processing site becomes unavailable due to disaster, attack, or other disruption, thereby maintaining continuity of essential business functions.",
    "plain_english_explanation": "Organizations must establish and maintain a backup data center or processing facility that can take over critical IT operations if the primary site fails. This alternate site needs proper agreements, equipment, supplies, and security controls equivalent to the primary site to ensure seamless failover within defined recovery time objectives.",
    "example_implementation": "Implement automated failover mechanisms using cloud-based disaster recovery solutions (AWS DR, Azure Site Recovery) or maintain a hot/warm standby data center with synchronized data replication and tested failover procedures.",
    "non_technical_guidance": "To comply with CP-7, organizations should: 1) Identify and designate an alternate processing site geographically separated from the primary location; 2) Establish formal agreements (MOUs, contracts) with alternate site providers specifying recovery time objectives; 3) Ensure the alternate site has necessary infrastructure, hardware, software, and data to support critical operations; 4) Implement equivalent security controls at both sites; 5) Develop and regularly test continuity of operations plans (COOP) for transitioning to the alternate site; 6) Train personnel on failover procedures and their roles during site transitions; 7) Conduct regular failover drills and exercises to validate alternate site readiness.",
    "is_technical": true,
    "ai_guidance": "When implementing CP-7 Alternate Processing Site controls, AI systems should analyze Recovery Time Objectives (RTO) and Recovery Point Objectives (RPO) against business impact assessments to recommend appropriate alternate site configurations (hot, warm, or cold). AI can monitor data replication status, predict potential failover scenarios based on environmental and threat intelligence, automate failover decision-making during incidents, and continuously validate that alternate site security configurations match primary site controls. Machine learning models can optimize resource allocation at alternate sites and predict capacity requirements during failover events.",
    "enhancements": [
      {
        "id": "CP-7.1",
        "title": "Separation from Primary Site",
        "official_text": "Identify an alternate processing site that is sufficiently separated from the primary processing site to reduce susceptibility to the same threats."
      },
      {
        "id": "CP-7.2",
        "title": "Accessibility",
        "official_text": "Identify potential accessibility problems to alternate processing sites in the event of an area-wide disruption or disaster and outline explicit mitigation actions."
      },
      {
        "id": "CP-7.3",
        "title": "Priority of Service",
        "official_text": "Develop alternate processing site agreements that contain priority-of-service provisions in accordance with availability requirements (including recovery time objectives)."
      },
      {
        "id": "CP-7.4",
        "title": "Preparation for Use",
        "official_text": "Prepare the alternate processing site so that the site can serve as the operational site supporting essential mission and business functions."
      },
      {
        "id": "CP-7.5",
        "title": "Equivalent Information Security Safeguards",
        "official_text": "Employ [organization-defined information security safeguards] at the alternate processing site that are equivalent to those employed at the primary site."
      },
      {
        "id": "CP-7.6",
        "title": "Inability to Return to Primary Site",
        "official_text": "Plan and prepare for circumstances that preclude returning to the primary processing site."
      }
    ],
    "related_controls": [
      "CP-2",
      "CP-6",
      "CP-8",
      "CP-9",
      "CP-10",
      "MA-6",
      "PE-17",
      "SC-36"
    ],
    "supplemental_guidance": "Alternate processing sites are geographically distinct from primary processing sites and provide processing capability if the primary processing site is not available. Items covered by alternate processing site agreements include, for example, environmental conditions at the alternate sites, access rules for systems and facilities, physical and environmental protection requirements, and the coordination of delivery and retrieval of backup media. Alternate processing sites may be permanent or mobile depending on organizational contingency requirements.",
    "implementation_scripts": {
      "linux": {
        "bash": "# site_readiness_check\n#!/bin/bash\n# CP-7: Alternate Processing Site Readiness Check\n# Validates connectivity and readiness of DR site\n\nDR_SITE_HOSTS=(\"dr-primary.example.com\" \"dr-db.example.com\" \"dr-app.example.com\")\nDR_REPLICATION_STATUS=\"/var/log/dr-replication-status.log\"\nALERT_EMAIL=\"dr-team@example.com\"\n\necho \"[$(date)] CP-7 Alternate Site Readiness Check\" | tee -a \"$DR_REPLICATION_STATUS\"\n\nfor host in \"${DR_SITE_HOSTS[@]}\"; do\n    if ping -c 3 \"$host\" > /dev/null 2>&1; then\n        echo \"[PASS] $host is reachable\" | tee -a \"$DR_REPLICATION_STATUS\"\n    else\n        echo \"[FAIL] $host is NOT reachable - ALERT\" | tee -a \"$DR_REPLICATION_STATUS\"\n        echo \"DR Site Alert: $host unreachable\" | mail -s \"CP-7 DR Alert\" \"$ALERT_EMAIL\"\n    fi\ndone\n\n# Check replication lag\nREPL_LAG=$(mysql -h dr-db.example.com -e \"SHOW SLAVE STATUS\\G\" 2>/dev/null | grep Seconds_Behind_Master | awk '{print $2}')\nif [ -n \"$REPL_LAG\" ] && [ \"$REPL_LAG\" -lt 60 ]; then\n    echo \"[PASS] Replication lag: ${REPL_LAG}s\" | tee -a \"$DR_REPLICATION_STATUS\"\nelse\n    echo \"[WARN] Replication lag exceeds threshold: ${REPL_LAG}s\" | tee -a \"$DR_REPLICATION_STATUS\"\nfi\n\necho \"Readiness check complete: $(date)\" | tee -a \"$DR_REPLICATION_STATUS\"\n\n# failover_automation\n#!/bin/bash\n# CP-7: Automated Failover Orchestration Script\n# Triggers controlled failover to alternate processing site\n\nset -e\nFAILOVER_LOG=\"/var/log/cp7-failover.log\"\nDR_CONFIG=\"/etc/dr/failover-config.yml\"\n\nlog() { echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\" | tee -a \"$FAILOVER_LOG\"; }\n\nlog \"INITIATING CP-7 FAILOVER PROCEDURE\"\nlog \"Reason: $1\"\n\n# Step 1: Validate DR site readiness\nlog \"Step 1: Validating DR site readiness...\"\nif ! /opt/dr/check-dr-site-ready.sh; then\n    log \"ABORT: DR site not ready for failover\"\n    exit 1\nfi\n\n# Step 2: Notify stakeholders\nlog \"Step 2: Sending failover notifications...\"\n/opt/dr/notify-stakeholders.sh \"Failover initiated to DR site\"\n\n# Step 3: Update DNS/Load Balancer\nlog \"Step 3: Updating traffic routing to DR site...\"\naws route53 change-resource-record-sets --hosted-zone-id $HOSTED_ZONE_ID \\\n    --change-batch file:///etc/dr/dns-failover-batch.json\n\n# Step 4: Promote DR databases\nlog \"Step 4: Promoting DR database replicas...\"\n/opt/dr/promote-db-replicas.sh\n\n# Step 5: Verify services\nlog \"Step 5: Verifying DR site services...\"\n/opt/dr/verify-dr-services.sh\n\nlog \"FAILOVER COMPLETE - DR site is now PRIMARY\"\nlog \"Manual verification required before declaring operational\""
      },
      "windows": {
        "powershell": "# site_readiness_check\n# CP-7: Alternate Processing Site Readiness Check (PowerShell)\n# Validates connectivity and readiness of DR site\n\n$DRSiteHosts = @(\"dr-primary.example.com\", \"dr-db.example.com\", \"dr-app.example.com\")\n$LogFile = \"C:\\Logs\\DR-Readiness-Check.log\"\n$AlertEmail = \"dr-team@example.com\"\n\nfunction Write-Log {\n    param([string]$Message)\n    $timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    \"[$timestamp] $Message\" | Tee-Object -FilePath $LogFile -Append\n}\n\nWrite-Log \"CP-7 Alternate Site Readiness Check Started\"\n\nforeach ($host in $DRSiteHosts) {\n    if (Test-Connection -ComputerName $host -Count 3 -Quiet) {\n        Write-Log \"[PASS] $host is reachable\"\n    } else {\n        Write-Log \"[FAIL] $host is NOT reachable - ALERT\"\n        Send-MailMessage -To $AlertEmail -Subject \"CP-7 DR Alert\" -Body \"DR Site Alert: $host unreachable\" -SmtpServer \"smtp.example.com\"\n    }\n}\n\n# Check Azure Site Recovery status\ntry {\n    $asrStatus = Get-AzRecoveryServicesAsrReplicationProtectedItem -All\n    foreach ($item in $asrStatus) {\n        if ($item.ReplicationHealth -eq \"Normal\") {\n            Write-Log \"[PASS] ASR Replication healthy for $($item.FriendlyName)\"\n        } else {\n            Write-Log \"[WARN] ASR Replication issue: $($item.FriendlyName) - $($item.ReplicationHealth)\"\n        }\n    }\n} catch {\n    Write-Log \"[ERROR] Could not check ASR status: $_\"\n}\n\nWrite-Log \"Readiness check complete\"\n\n# failover_automation\n# CP-7: Automated Failover Orchestration Script (PowerShell)\n# Triggers controlled failover to alternate processing site\n\nparam(\n    [Parameter(Mandatory=$true)]\n    [string]$FailoverReason\n)\n\n$ErrorActionPreference = \"Stop\"\n$LogFile = \"C:\\Logs\\CP7-Failover.log\"\n\nfunction Write-Log {\n    param([string]$Message)\n    $timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    \"[$timestamp] $Message\" | Tee-Object -FilePath $LogFile -Append\n}\n\nWrite-Log \"INITIATING CP-7 FAILOVER PROCEDURE\"\nWrite-Log \"Reason: $FailoverReason\"\n\ntry {\n    # Step 1: Validate DR site readiness\n    Write-Log \"Step 1: Validating DR site readiness...\"\n    & C:\\DR\\Check-DRSiteReady.ps1\n    \n    # Step 2: Notify stakeholders\n    Write-Log \"Step 2: Sending failover notifications...\"\n    & C:\\DR\\Send-FailoverNotification.ps1 -Message \"Failover initiated to DR site\"\n    \n    # Step 3: Initiate Azure Site Recovery failover\n    Write-Log \"Step 3: Initiating ASR failover...\"\n    $vault = Get-AzRecoveryServicesVault -Name \"DR-Vault\"\n    Set-AzRecoveryServicesAsrVaultContext -Vault $vault\n    Start-AzRecoveryServicesAsrPlannedFailoverJob -RecoveryPlan $recoveryPlan -Direction PrimaryToRecovery\n    \n    # Step 4: Update DNS\n    Write-Log \"Step 4: Updating DNS records...\"\n    & C:\\DR\\Update-DNSForFailover.ps1\n    \n    # Step 5: Verify services\n    Write-Log \"Step 5: Verifying DR site services...\"\n    & C:\\DR\\Verify-DRServices.ps1\n    \n    Write-Log \"FAILOVER COMPLETE - DR site is now PRIMARY\"\n} catch {\n    Write-Log \"FAILOVER FAILED: $_\"\n    throw\n}"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true,
      "qa_agent": "LOVELESS"
    },
    "cac_metadata": {
      "implementation_type": "hybrid",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Alternate processing site controls require combination of automated monitoring/failover scripts and manual verification of site readiness and security equivalence."
    },
    "rationale": "If your data center is destroyed, you need another place to run your systems. This is your plan B location."
  },
  {
    "control_id": "CP-7.1",
    "control_name": "Separation from Primary Site",
    "family": "Contingency Planning",
    "family_id": "CP",
    "official_text": "Identify an alternate processing site that is sufficiently separated from the primary processing site to reduce susceptibility to the same threats.",
    "parent_control": "CP-7",
    "source": "NIST SP 800-53 Rev 5",
    "stig_id": "RHEL-08-010001",
    "baselines": {
      "low": false,
      "moderate": true,
      "high": true
    },
    "intent": "Ensure the alternate processing site is geographically and logically separated from the primary site to avoid single points of failure from regional disasters, attacks, or infrastructure failures that could impact both locations simultaneously.",
    "plain_english_explanation": "The backup data center or processing facility must be located far enough from the primary site that a single disaster (earthquake, flood, power grid failure, regional attack) cannot take out both locations. The separation should account for shared infrastructure like power grids, network providers, and natural disaster zones.",
    "example_implementation": "Maintain primary site in US-East-1 (Virginia) and alternate site in US-West-2 (Oregon) with different power grids, seismic zones, and network providers. Implement geographic distance of at least 250 miles between sites.",
    "non_technical_guidance": "Organizations should conduct threat analysis to identify regional risks (natural disasters, infrastructure dependencies) and select an alternate site that mitigates these shared vulnerabilities. Consider factors such as: different seismic zones, separate power grid regions, distinct flood plains, independent telecommunications providers, and sufficient distance to avoid area-wide disasters affecting both sites.",
    "is_technical": true,
    "ai_guidance": "AI systems should analyze geographic threat data, seismic activity patterns, flood zone maps, power grid topologies, and telecommunications infrastructure to recommend optimal alternate site locations. Machine learning models can process historical disaster data to predict regional risk levels and calculate minimum safe separation distances. AI can continuously monitor threat intelligence for emerging regional risks that might affect site separation adequacy.",
    "enhancements": [],
    "related_controls": [
      "CP-7",
      "PE-18",
      "RA-3"
    ],
    "supplemental_guidance": "Separation of alternate processing sites from primary processing sites addresses potential susceptibility to the same threats, including natural disasters, structural failures, hostile attacks, and errors of omission or commission. Organizations consider the availability of required resources at the alternate site.",
    "implementation_scripts": {
      "linux": {
        "bash": "# site_separation_validator\n#!/bin/bash\n# CP-7.1: Site Separation Validation Script\n# Verifies geographic and infrastructure separation\n\nSEPARATION_LOG=\"/var/log/cp7-1-separation-check.log\"\nPRIMARY_REGION=\"us-east-1\"\nDR_REGION=\"us-west-2\"\nMIN_DISTANCE_MILES=200\n\nlog() { echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\" | tee -a \"$SEPARATION_LOG\"; }\n\nlog \"CP-7.1 Site Separation Validation Started\"\n\n# Check AWS regions are different\nPRIMARY_AZ=$(aws ec2 describe-availability-zones --region \"$PRIMARY_REGION\" --query 'AvailabilityZones[0].RegionName' --output text)\nDR_AZ=$(aws ec2 describe-availability-zones --region \"$DR_REGION\" --query 'AvailabilityZones[0].RegionName' --output text)\n\nif [ \"$PRIMARY_AZ\" != \"$DR_AZ\" ]; then\n    log \"[PASS] Primary ($PRIMARY_AZ) and DR ($DR_AZ) are in different regions\"\nelse\n    log \"[FAIL] Primary and DR sites are in the same region - VIOLATION\"\n    exit 1\nfi\n\n# Verify different availability zones\nlog \"Primary site AZs: $(aws ec2 describe-availability-zones --region $PRIMARY_REGION --query 'AvailabilityZones[*].ZoneName' --output text)\"\nlog \"DR site AZs: $(aws ec2 describe-availability-zones --region $DR_REGION --query 'AvailabilityZones[*].ZoneName' --output text)\"\n\n# Check network path independence\nlog \"Checking network path diversity...\"\ntraceroute -n dr-primary.example.com 2>/dev/null | tee -a \"$SEPARATION_LOG\"\n\nlog \"CP-7.1 Separation validation complete\"\n\n# infrastructure_independence_check\n#!/bin/bash\n# CP-7.1: Infrastructure Independence Verification\n# Validates power grid and network provider separation\n\nlog() { echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\"; }\n\nlog \"Checking infrastructure independence...\"\n\n# Verify different transit providers\nPRIMARY_TRANSIT=$(whois $(dig +short primary-site.example.com | head -1) | grep 'origin' | head -1)\nDR_TRANSIT=$(whois $(dig +short dr-site.example.com | head -1) | grep 'origin' | head -1)\n\nif [ \"$PRIMARY_TRANSIT\" != \"$DR_TRANSIT\" ]; then\n    log \"[PASS] Different network transit providers detected\"\nelse\n    log \"[WARN] Same network transit provider - review for single point of failure\"\nfi\n\n# Document separation metrics\ncat << EOF > /var/log/site-separation-report.json\n{\n  \"primary_site\": {\n    \"region\": \"us-east-1\",\n    \"datacenter\": \"IAD\",\n    \"power_grid\": \"PJM-Interconnection\"\n  },\n  \"dr_site\": {\n    \"region\": \"us-west-2\",\n    \"datacenter\": \"PDX\",\n    \"power_grid\": \"WECC\"\n  },\n  \"separation_miles\": 2400,\n  \"different_seismic_zone\": true,\n  \"different_flood_zone\": true,\n  \"validation_date\": \"$(date -Iseconds)\"\n}\nEOF\n\nlog \"Infrastructure independence check complete\""
      },
      "windows": {
        "powershell": "# site_separation_validator\n# CP-7.1: Site Separation Validation Script (PowerShell)\n# Verifies geographic and infrastructure separation\n\n$LogFile = \"C:\\Logs\\CP7-1-Separation-Check.log\"\n$PrimaryRegion = \"eastus\"\n$DRRegion = \"westus2\"\n\nfunction Write-Log {\n    param([string]$Message)\n    $timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    \"[$timestamp] $Message\" | Tee-Object -FilePath $LogFile -Append\n}\n\nWrite-Log \"CP-7.1 Site Separation Validation Started\"\n\n# Check Azure regions are different\ntry {\n    $primaryLocation = (Get-AzResourceGroup -Name \"Primary-RG\").Location\n    $drLocation = (Get-AzResourceGroup -Name \"DR-RG\").Location\n    \n    if ($primaryLocation -ne $drLocation) {\n        Write-Log \"[PASS] Primary ($primaryLocation) and DR ($drLocation) are in different regions\"\n    } else {\n        Write-Log \"[FAIL] Primary and DR sites are in the same region - VIOLATION\"\n        exit 1\n    }\n} catch {\n    Write-Log \"[ERROR] Could not verify region separation: $_\"\n}\n\n# Document separation configuration\n$separationReport = @{\n    PrimarySite = @{\n        Region = $primaryLocation\n        Datacenter = \"Azure-EastUS\"\n        PowerGrid = \"PJM-Interconnection\"\n    }\n    DRSite = @{\n        Region = $drLocation\n        Datacenter = \"Azure-WestUS2\"\n        PowerGrid = \"WECC\"\n    }\n    SeparationMiles = 2000\n    DifferentSeismicZone = $true\n    ValidationDate = (Get-Date -Format \"o\")\n}\n\n$separationReport | ConvertTo-Json | Out-File \"C:\\Logs\\Site-Separation-Report.json\"\nWrite-Log \"CP-7.1 Separation validation complete\""
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true,
      "qa_agent": "LOVELESS"
    },
    "cac_metadata": {
      "implementation_type": "hybrid",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Site separation validation requires automated geographic verification combined with manual assessment of infrastructure independence factors."
    },
    "rationale": "Your backup site must be far enough away that a regional disaster won't affect both sites."
  },
  {
    "control_id": "CP-7.2",
    "control_name": "Accessibility",
    "family": "Contingency Planning",
    "family_id": "CP",
    "official_text": "Identify potential accessibility problems to alternate processing sites in the event of an area-wide disruption or disaster and outline explicit mitigation actions.",
    "parent_control": "CP-7",
    "source": "NIST SP 800-53 Rev 5",
    "stig_id": "RHEL-08-010002",
    "baselines": {
      "low": false,
      "moderate": true,
      "high": true
    },
    "intent": "Proactively identify and address potential barriers that could prevent personnel, equipment, or data from reaching the alternate processing site during a disaster, ensuring the organization can actually utilize the backup facility when needed.",
    "plain_english_explanation": "Organizations must anticipate obstacles that could block access to the backup site during emergencies - including transportation disruptions, personnel availability issues, network connectivity problems, and physical access restrictions. Explicit mitigation plans must exist to overcome these barriers.",
    "example_implementation": "Maintain multiple network paths to DR site (dedicated circuits, VPN over internet, satellite backup), pre-position critical personnel near DR site, establish remote access capabilities for key staff, and maintain transportation agreements for emergency personnel movement.",
    "non_technical_guidance": "Organizations should: 1) Conduct accessibility risk assessments for area-wide disruptions; 2) Identify multiple transportation routes to alternate site; 3) Pre-position essential personnel or establish remote work capabilities; 4) Maintain redundant network connectivity paths; 5) Establish agreements for emergency transportation; 6) Document and regularly test accessibility mitigation procedures.",
    "is_technical": true,
    "ai_guidance": "AI systems should continuously monitor transportation networks, weather patterns, and regional disruption events to predict accessibility challenges to alternate sites. Machine learning models can analyze historical incident data to identify accessibility risk patterns and recommend proactive mitigation measures. AI can dynamically route network traffic through alternate paths when primary connectivity is compromised and automatically trigger accessibility alerts when disruption events are detected.",
    "enhancements": [],
    "related_controls": [
      "CP-7",
      "CP-2",
      "RA-3"
    ],
    "supplemental_guidance": "Area-wide disruptions refer to those disruptions that are broad in geographic scope such as combatant attack, natural disasters, or epidemics. Accessibility issues include, for example, road closures, telecommunications outages, or personnel unavailability due to widespread illness.",
    "implementation_scripts": {
      "linux": {
        "bash": "# accessibility_monitor\n#!/bin/bash\n# CP-7.2: DR Site Accessibility Monitor\n# Monitors multiple access paths to alternate processing site\n\nACCESS_LOG=\"/var/log/cp7-2-accessibility.log\"\nALERT_WEBHOOK=\"https://hooks.example.com/alerts\"\n\nlog() { echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\" | tee -a \"$ACCESS_LOG\"; }\n\nlog \"CP-7.2 Accessibility Check Started\"\n\n# Primary network path\nif ping -c 3 dr-site-primary.example.com > /dev/null 2>&1; then\n    log \"[PASS] Primary network path accessible\"\n    PRIMARY_STATUS=\"UP\"\nelse\n    log \"[FAIL] Primary network path UNAVAILABLE\"\n    PRIMARY_STATUS=\"DOWN\"\nfi\n\n# Secondary network path (VPN backup)\nif ping -c 3 -I vpn0 dr-site-vpn.example.com > /dev/null 2>&1; then\n    log \"[PASS] VPN backup path accessible\"\n    VPN_STATUS=\"UP\"\nelse\n    log \"[WARN] VPN backup path unavailable\"\n    VPN_STATUS=\"DOWN\"\nfi\n\n# Satellite backup (if available)\nif [ -f /dev/sat0 ]; then\n    if ping -c 3 -I sat0 dr-site-sat.example.com > /dev/null 2>&1; then\n        log \"[PASS] Satellite backup path accessible\"\n        SAT_STATUS=\"UP\"\n    else\n        log \"[WARN] Satellite backup path unavailable\"\n        SAT_STATUS=\"DOWN\"\n    fi\nelse\n    SAT_STATUS=\"N/A\"\nfi\n\n# Alert if all paths down\nif [ \"$PRIMARY_STATUS\" = \"DOWN\" ] && [ \"$VPN_STATUS\" = \"DOWN\" ]; then\n    log \"[CRITICAL] All DR site access paths unavailable!\"\n    curl -X POST \"$ALERT_WEBHOOK\" -d '{\"severity\":\"critical\",\"message\":\"CP-7.2 VIOLATION: DR site inaccessible\"}'\nfi\n\nlog \"Accessibility check complete: Primary=$PRIMARY_STATUS, VPN=$VPN_STATUS, Satellite=$SAT_STATUS\"\n\n# network_path_diversity\n#!/bin/bash\n# CP-7.2: Network Path Diversity Verification\n# Ensures multiple independent network routes to DR site\n\nlog() { echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\"; }\n\nlog \"Verifying network path diversity to DR site...\"\n\n# Trace primary route\nlog \"Primary route:\"\ntraceroute -n dr-primary.example.com 2>/dev/null | head -20\n\n# Trace secondary route via VPN\nlog \"VPN route:\"\ntraceroute -n -i vpn0 dr-vpn.example.com 2>/dev/null | head -20\n\n# Compare ASN diversity\nPRIMARY_ASNS=$(traceroute -n dr-primary.example.com 2>/dev/null | grep -oE '([0-9]{1,3}\\.){3}[0-9]{1,3}' | xargs -I {} sh -c 'whois {} | grep origin' | sort -u)\nlog \"Primary path ASNs: $PRIMARY_ASNS\"\n\nlog \"Path diversity verification complete\""
      },
      "windows": {
        "powershell": "# accessibility_monitor\n# CP-7.2: DR Site Accessibility Monitor (PowerShell)\n# Monitors multiple access paths to alternate processing site\n\n$LogFile = \"C:\\Logs\\CP7-2-Accessibility.log\"\n$AlertWebhook = \"https://hooks.example.com/alerts\"\n\nfunction Write-Log {\n    param([string]$Message)\n    $timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    \"[$timestamp] $Message\" | Tee-Object -FilePath $LogFile -Append\n}\n\nWrite-Log \"CP-7.2 Accessibility Check Started\"\n\n# Primary network path\n$primaryTest = Test-Connection -ComputerName \"dr-site-primary.example.com\" -Count 3 -Quiet\nif ($primaryTest) {\n    Write-Log \"[PASS] Primary network path accessible\"\n    $PrimaryStatus = \"UP\"\n} else {\n    Write-Log \"[FAIL] Primary network path UNAVAILABLE\"\n    $PrimaryStatus = \"DOWN\"\n}\n\n# Secondary network path (VPN backup)\n$vpnTest = Test-Connection -ComputerName \"dr-site-vpn.example.com\" -Count 3 -Quiet\nif ($vpnTest) {\n    Write-Log \"[PASS] VPN backup path accessible\"\n    $VpnStatus = \"UP\"\n} else {\n    Write-Log \"[WARN] VPN backup path unavailable\"\n    $VpnStatus = \"DOWN\"\n}\n\n# ExpressRoute/Direct Connect test\ntry {\n    $expressRoute = Get-AzExpressRouteCircuit | Where-Object { $_.ProvisioningState -eq \"Succeeded\" }\n    if ($expressRoute) {\n        Write-Log \"[PASS] ExpressRoute circuit operational\"\n        $ExpressRouteStatus = \"UP\"\n    } else {\n        Write-Log \"[WARN] ExpressRoute circuit not available\"\n        $ExpressRouteStatus = \"DOWN\"\n    }\n} catch {\n    $ExpressRouteStatus = \"N/A\"\n}\n\n# Alert if critical paths down\nif ($PrimaryStatus -eq \"DOWN\" -and $VpnStatus -eq \"DOWN\") {\n    Write-Log \"[CRITICAL] All DR site access paths unavailable!\"\n    $alertBody = @{\n        severity = \"critical\"\n        message = \"CP-7.2 VIOLATION: DR site inaccessible\"\n    } | ConvertTo-Json\n    Invoke-RestMethod -Uri $AlertWebhook -Method Post -Body $alertBody -ContentType \"application/json\"\n}\n\nWrite-Log \"Accessibility check complete: Primary=$PrimaryStatus, VPN=$VpnStatus, ExpressRoute=$ExpressRouteStatus\""
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true,
      "qa_agent": "LOVELESS"
    },
    "cac_metadata": {
      "implementation_type": "automated",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Automated monitoring of network accessibility paths with alerting for path failures. Manual procedures required for physical accessibility planning."
    },
    "rationale": "A backup site is useless if staff can't get there or connect to it remotely."
  },
  {
    "control_id": "CP-7.3",
    "control_name": "Priority of Service",
    "family": "Contingency Planning",
    "family_id": "CP",
    "official_text": "Develop alternate processing site agreements that contain priority-of-service provisions in accordance with availability requirements (including recovery time objectives).",
    "parent_control": "CP-7",
    "source": "NIST SP 800-53 Rev 5",
    "stig_id": "RHEL-08-010003",
    "baselines": {
      "low": false,
      "moderate": true,
      "high": true
    },
    "intent": "Ensure contractual agreements with alternate site providers include guaranteed service levels and priority access that align with organizational recovery time objectives, preventing situations where the alternate site cannot be activated due to competing demands or inadequate capacity.",
    "plain_english_explanation": "When using shared or contracted disaster recovery facilities, organizations must have written agreements guaranteeing priority access and service levels that meet their recovery time requirements. This prevents scenarios where multiple organizations compete for limited DR resources during regional disasters.",
    "example_implementation": "Establish SLAs with cloud DR providers specifying dedicated capacity reservations, guaranteed failover time windows, priority queuing for resource activation, and contractual penalties for failing to meet RTO/RPO commitments.",
    "non_technical_guidance": "Organizations should: 1) Define clear RTO/RPO requirements in contracts; 2) Negotiate priority-of-service clauses with DR providers; 3) Obtain capacity guarantees or reserved instances; 4) Include provisions for area-wide disaster scenarios; 5) Establish escalation procedures for service priority disputes; 6) Regularly review and update agreements to match changing requirements.",
    "is_technical": true,
    "ai_guidance": "AI systems should monitor service level agreement compliance in real-time, tracking DR provider capacity utilization and predicting potential contention scenarios. Machine learning models can analyze historical failover events to optimize RTO/RPO targets and recommend contract terms. AI can automate capacity reservation decisions and dynamically adjust resource allocation to meet priority-of-service requirements during failover events.",
    "enhancements": [],
    "related_controls": [
      "CP-7",
      "CP-2",
      "SA-4"
    ],
    "supplemental_guidance": "Priority-of-service agreements refer to negotiated agreements with service providers that ensure that organizations are given priority treatment in obtaining resources needed to recover system operations. Priority-of-service provisions vary from ensuring reserved processing capacity at alternate sites to ensuring priority access to resources such as personnel, equipment, and data.",
    "implementation_scripts": {
      "linux": {
        "bash": "# rto_compliance_monitor\n#!/bin/bash\n# CP-7.3: RTO/RPO Compliance Monitor\n# Tracks recovery time objectives against actual failover capabilities\n\nRTO_LOG=\"/var/log/cp7-3-rto-compliance.log\"\nRTO_TARGET_SECONDS=14400  # 4 hours\nRPO_TARGET_SECONDS=3600   # 1 hour\n\nlog() { echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\" | tee -a \"$RTO_LOG\"; }\n\nlog \"CP-7.3 RTO/RPO Compliance Check\"\n\n# Check replication lag (RPO indicator)\nREPL_LAG=$(mysql -h dr-db.example.com -e \"SHOW SLAVE STATUS\\G\" 2>/dev/null | grep Seconds_Behind_Master | awk '{print $2}')\n\nif [ -n \"$REPL_LAG\" ]; then\n    if [ \"$REPL_LAG\" -lt \"$RPO_TARGET_SECONDS\" ]; then\n        log \"[PASS] RPO compliance: ${REPL_LAG}s < ${RPO_TARGET_SECONDS}s target\"\n    else\n        log \"[FAIL] RPO VIOLATION: ${REPL_LAG}s exceeds ${RPO_TARGET_SECONDS}s target\"\n    fi\nelse\n    log \"[WARN] Could not determine replication lag\"\nfi\n\n# Measure estimated failover time (RTO indicator)\nSTART_TIME=$(date +%s)\n/opt/dr/dry-run-failover.sh > /dev/null 2>&1\nEND_TIME=$(date +%s)\nFAILOVER_TIME=$((END_TIME - START_TIME))\n\nlog \"Estimated failover time: ${FAILOVER_TIME}s\"\n\nif [ \"$FAILOVER_TIME\" -lt \"$RTO_TARGET_SECONDS\" ]; then\n    log \"[PASS] RTO compliance: ${FAILOVER_TIME}s < ${RTO_TARGET_SECONDS}s target\"\nelse\n    log \"[FAIL] RTO VIOLATION: ${FAILOVER_TIME}s exceeds ${RTO_TARGET_SECONDS}s target\"\nfi\n\n# Document SLA metrics\ncat << EOF >> /var/log/rto-rpo-metrics.json\n{\"timestamp\":\"$(date -Iseconds)\",\"rpo_lag_seconds\":$REPL_LAG,\"rpo_target\":$RPO_TARGET_SECONDS,\"failover_time_seconds\":$FAILOVER_TIME,\"rto_target\":$RTO_TARGET_SECONDS}\nEOF\n\nlog \"RTO/RPO compliance check complete\"\n\n# capacity_reservation_check\n#!/bin/bash\n# CP-7.3: DR Capacity Reservation Verification\n# Verifies reserved capacity meets priority-of-service requirements\n\nlog() { echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\"; }\n\nlog \"Checking DR capacity reservations...\"\n\n# AWS Reserved Capacity\naws ec2 describe-capacity-reservations --query 'CapacityReservations[?State==`active`]' --output table\n\n# Verify capacity meets requirements\nREQUIRED_VCPUS=256\nREQUIRED_MEMORY_GB=1024\n\nRESERVED=$(aws ec2 describe-capacity-reservations --query 'sum(CapacityReservations[?State==`active`].TotalInstanceCount)' --output text)\n\nlog \"Reserved capacity instances: $RESERVED\"\nlog \"Required capacity: $REQUIRED_VCPUS vCPUs, ${REQUIRED_MEMORY_GB}GB RAM\"\n\nlog \"Capacity reservation verification complete\""
      },
      "windows": {
        "powershell": "# rto_compliance_monitor\n# CP-7.3: RTO/RPO Compliance Monitor (PowerShell)\n# Tracks recovery time objectives against actual failover capabilities\n\n$LogFile = \"C:\\Logs\\CP7-3-RTO-Compliance.log\"\n$RTOTargetSeconds = 14400  # 4 hours\n$RPOTargetSeconds = 3600   # 1 hour\n\nfunction Write-Log {\n    param([string]$Message)\n    $timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    \"[$timestamp] $Message\" | Tee-Object -FilePath $LogFile -Append\n}\n\nWrite-Log \"CP-7.3 RTO/RPO Compliance Check\"\n\n# Check Azure Site Recovery RPO\ntry {\n    $asrItems = Get-AzRecoveryServicesAsrReplicationProtectedItem -All\n    foreach ($item in $asrItems) {\n        $rpoSeconds = [int]$item.LastRPOCalculatedTime.TotalSeconds\n        if ($rpoSeconds -lt $RPOTargetSeconds) {\n            Write-Log \"[PASS] RPO compliance for $($item.FriendlyName): ${rpoSeconds}s < ${RPOTargetSeconds}s\"\n        } else {\n            Write-Log \"[FAIL] RPO VIOLATION for $($item.FriendlyName): ${rpoSeconds}s > ${RPOTargetSeconds}s\"\n        }\n    }\n} catch {\n    Write-Log \"[ERROR] Could not check ASR RPO: $_\"\n}\n\n# Measure estimated failover time\n$startTime = Get-Date\n& C:\\DR\\Test-FailoverDryRun.ps1 | Out-Null\n$endTime = Get-Date\n$failoverTime = ($endTime - $startTime).TotalSeconds\n\nWrite-Log \"Estimated failover time: ${failoverTime}s\"\n\nif ($failoverTime -lt $RTOTargetSeconds) {\n    Write-Log \"[PASS] RTO compliance: ${failoverTime}s < ${RTOTargetSeconds}s target\"\n} else {\n    Write-Log \"[FAIL] RTO VIOLATION: ${failoverTime}s exceeds ${RTOTargetSeconds}s target\"\n}\n\n# Document metrics\n$metrics = @{\n    Timestamp = (Get-Date -Format \"o\")\n    FailoverTimeSeconds = $failoverTime\n    RTOTarget = $RTOTargetSeconds\n    RPOTarget = $RPOTargetSeconds\n}\n$metrics | ConvertTo-Json | Add-Content \"C:\\Logs\\RTO-RPO-Metrics.json\"\n\nWrite-Log \"RTO/RPO compliance check complete\""
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true,
      "qa_agent": "LOVELESS"
    },
    "cac_metadata": {
      "implementation_type": "hybrid",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Automated RTO/RPO monitoring combined with manual contract review and SLA management procedures."
    },
    "rationale": "During a disaster, your backup site may compete for resources with others. Priority agreements ensure you get what you need."
  },
  {
    "control_id": "CP-7.4",
    "control_name": "Preparation for Use",
    "family": "Contingency Planning",
    "family_id": "CP",
    "official_text": "Prepare the alternate processing site so that the site can serve as the operational site supporting essential mission and business functions.",
    "parent_control": "CP-7",
    "source": "NIST SP 800-53 Rev 5",
    "stig_id": "RHEL-08-010004",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": true
    },
    "intent": "Maintain the alternate processing site in a state of operational readiness where it can immediately assume primary site functions without requiring significant setup, configuration, or data synchronization delays.",
    "plain_english_explanation": "The backup facility must be kept in a ready-to-operate state - not just available, but actually prepared to take over operations immediately. This means systems are configured, data is synchronized, and the site can become operational with minimal transition time (hot or warm standby).",
    "example_implementation": "Maintain a hot standby DR site with synchronized databases, pre-configured application servers, active network connections, and automated failover mechanisms. Conduct weekly validation tests to ensure immediate operational capability.",
    "non_technical_guidance": "Organizations should: 1) Maintain DR site infrastructure in operational state; 2) Keep data continuously synchronized or within RPO requirements; 3) Pre-configure applications and systems matching production; 4) Conduct regular readiness exercises; 5) Maintain documentation and runbooks at DR site; 6) Ensure personnel are trained on DR site operations.",
    "is_technical": true,
    "ai_guidance": "AI systems should continuously monitor DR site readiness indicators including infrastructure health, data synchronization status, configuration drift detection, and capacity availability. Machine learning models can predict readiness degradation and recommend proactive maintenance. AI can automate pre-failover validation checks and dynamically optimize resource allocation to maintain operational readiness while minimizing costs.",
    "enhancements": [],
    "related_controls": [
      "CP-7",
      "CP-4",
      "CP-10"
    ],
    "supplemental_guidance": "Preparation for use refers to maintaining the alternate processing site in a state of operational readiness. Cold sites are typically not prepared for use. Hot sites are prepared for use and are in operation. Warm sites are prepared for use but not necessarily in operation.",
    "implementation_scripts": {
      "linux": {
        "bash": "# site_readiness_validator\n#!/bin/bash\n# CP-7.4: DR Site Operational Readiness Validator\n# Comprehensive check for immediate failover capability\n\nREADINESS_LOG=\"/var/log/cp7-4-readiness.log\"\nREADINESS_REPORT=\"/var/log/dr-readiness-report.json\"\n\nlog() { echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\" | tee -a \"$READINESS_LOG\"; }\n\nlog \"CP-7.4 Operational Readiness Validation Started\"\n\nCHECKS_PASSED=0\nCHECKS_FAILED=0\n\n# Check 1: Database synchronization\nlog \"Checking database synchronization...\"\nREPL_LAG=$(mysql -h dr-db.example.com -e \"SHOW SLAVE STATUS\\G\" 2>/dev/null | grep Seconds_Behind_Master | awk '{print $2}')\nif [ -n \"$REPL_LAG\" ] && [ \"$REPL_LAG\" -lt 60 ]; then\n    log \"[PASS] Database sync lag: ${REPL_LAG}s\"\n    ((CHECKS_PASSED++))\nelse\n    log \"[FAIL] Database sync issue: lag=${REPL_LAG}s\"\n    ((CHECKS_FAILED++))\nfi\n\n# Check 2: Application services ready\nlog \"Checking application services...\"\nfor svc in nginx postgresql redis; do\n    if ssh dr-app.example.com \"systemctl is-active $svc\" 2>/dev/null | grep -q active; then\n        log \"[PASS] Service $svc is running on DR site\"\n        ((CHECKS_PASSED++))\n    else\n        log \"[FAIL] Service $svc is NOT running on DR site\"\n        ((CHECKS_FAILED++))\n    fi\ndone\n\n# Check 3: Storage availability\nlog \"Checking storage availability...\"\nDR_STORAGE=$(ssh dr-storage.example.com \"df -h /data | tail -1 | awk '{print \\$5}' | tr -d '%'\" 2>/dev/null)\nif [ -n \"$DR_STORAGE\" ] && [ \"$DR_STORAGE\" -lt 80 ]; then\n    log \"[PASS] DR storage capacity OK: ${DR_STORAGE}% used\"\n    ((CHECKS_PASSED++))\nelse\n    log \"[WARN] DR storage capacity concern: ${DR_STORAGE}% used\"\n    ((CHECKS_FAILED++))\nfi\n\n# Check 4: Network connectivity\nlog \"Checking network readiness...\"\nif ping -c 3 dr-lb.example.com > /dev/null 2>&1; then\n    log \"[PASS] Load balancer reachable\"\n    ((CHECKS_PASSED++))\nelse\n    log \"[FAIL] Load balancer NOT reachable\"\n    ((CHECKS_FAILED++))\nfi\n\n# Check 5: Configuration sync\nlog \"Checking configuration synchronization...\"\nPRIMARY_CONFIG_HASH=$(md5sum /etc/app/config.yml | awk '{print $1}')\nDR_CONFIG_HASH=$(ssh dr-app.example.com \"md5sum /etc/app/config.yml\" 2>/dev/null | awk '{print $1}')\nif [ \"$PRIMARY_CONFIG_HASH\" = \"$DR_CONFIG_HASH\" ]; then\n    log \"[PASS] Configuration files synchronized\"\n    ((CHECKS_PASSED++))\nelse\n    log \"[FAIL] Configuration drift detected\"\n    ((CHECKS_FAILED++))\nfi\n\n# Generate readiness report\nTOTAL_CHECKS=$((CHECKS_PASSED + CHECKS_FAILED))\nREADINESS_PERCENT=$((CHECKS_PASSED * 100 / TOTAL_CHECKS))\n\ncat << EOF > \"$READINESS_REPORT\"\n{\n  \"timestamp\": \"$(date -Iseconds)\",\n  \"checks_passed\": $CHECKS_PASSED,\n  \"checks_failed\": $CHECKS_FAILED,\n  \"readiness_percent\": $READINESS_PERCENT,\n  \"ready_for_failover\": $([ $CHECKS_FAILED -eq 0 ] && echo \"true\" || echo \"false\")\n}\nEOF\n\nlog \"Readiness: ${READINESS_PERCENT}% ($CHECKS_PASSED passed, $CHECKS_FAILED failed)\"\nlog \"CP-7.4 Validation complete\"\n\n# continuous_sync_monitor\n#!/bin/bash\n# CP-7.4: Continuous Data Synchronization Monitor\n# Ensures data is constantly replicated to DR site\n\nlog() { echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\"; }\n\nwhile true; do\n    # Check replication status\n    REPL_STATUS=$(mysql -h dr-db.example.com -e \"SHOW SLAVE STATUS\\G\" 2>/dev/null)\n    REPL_RUNNING=$(echo \"$REPL_STATUS\" | grep \"Slave_SQL_Running: Yes\" | wc -l)\n    REPL_LAG=$(echo \"$REPL_STATUS\" | grep Seconds_Behind_Master | awk '{print $2}')\n    \n    if [ \"$REPL_RUNNING\" -eq 1 ] && [ \"$REPL_LAG\" -lt 60 ]; then\n        log \"[OK] Replication healthy: lag=${REPL_LAG}s\"\n    else\n        log \"[ALERT] Replication issue: running=$REPL_RUNNING, lag=$REPL_LAG\"\n        /opt/dr/send-alert.sh \"CP-7.4 Replication Alert\" \"Replication unhealthy\"\n    fi\n    \n    sleep 60\ndone"
      },
      "windows": {
        "powershell": "# site_readiness_validator\n# CP-7.4: DR Site Operational Readiness Validator (PowerShell)\n# Comprehensive check for immediate failover capability\n\n$LogFile = \"C:\\Logs\\CP7-4-Readiness.log\"\n$ReportFile = \"C:\\Logs\\DR-Readiness-Report.json\"\n\nfunction Write-Log {\n    param([string]$Message)\n    $timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    \"[$timestamp] $Message\" | Tee-Object -FilePath $LogFile -Append\n}\n\nWrite-Log \"CP-7.4 Operational Readiness Validation Started\"\n\n$ChecksPassed = 0\n$ChecksFailed = 0\n$CheckResults = @()\n\n# Check 1: Azure Site Recovery replication health\nWrite-Log \"Checking ASR replication health...\"\ntry {\n    $asrItems = Get-AzRecoveryServicesAsrReplicationProtectedItem -All\n    $healthyItems = $asrItems | Where-Object { $_.ReplicationHealth -eq \"Normal\" }\n    \n    if ($healthyItems.Count -eq $asrItems.Count) {\n        Write-Log \"[PASS] All $($asrItems.Count) replicated items healthy\"\n        $ChecksPassed++\n    } else {\n        Write-Log \"[FAIL] $($asrItems.Count - $healthyItems.Count) items have replication issues\"\n        $ChecksFailed++\n    }\n} catch {\n    Write-Log \"[ERROR] Could not check ASR health: $_\"\n    $ChecksFailed++\n}\n\n# Check 2: DR VM readiness\nWrite-Log \"Checking DR VM availability...\"\ntry {\n    $drVMs = Get-AzVM -ResourceGroupName \"DR-ResourceGroup\" -Status\n    $runningVMs = $drVMs | Where-Object { $_.PowerState -eq \"VM running\" }\n    \n    Write-Log \"[INFO] $($runningVMs.Count)/$($drVMs.Count) DR VMs running\"\n    if ($runningVMs.Count -ge 1) {\n        $ChecksPassed++\n    } else {\n        $ChecksFailed++\n    }\n} catch {\n    Write-Log \"[ERROR] Could not check DR VMs: $_\"\n    $ChecksFailed++\n}\n\n# Check 3: SQL Availability Group sync\nWrite-Log \"Checking SQL AG synchronization...\"\ntry {\n    $agState = Invoke-Sqlcmd -ServerInstance \"dr-sql.example.com\" -Query \"SELECT synchronization_state_desc FROM sys.dm_hadr_database_replica_states\"\n    $syncedDBs = $agState | Where-Object { $_.synchronization_state_desc -eq \"SYNCHRONIZED\" }\n    \n    if ($syncedDBs.Count -gt 0) {\n        Write-Log \"[PASS] $($syncedDBs.Count) databases synchronized\"\n        $ChecksPassed++\n    } else {\n        Write-Log \"[FAIL] No databases synchronized\"\n        $ChecksFailed++\n    }\n} catch {\n    Write-Log \"[WARN] Could not check SQL sync: $_\"\n}\n\n# Check 4: Network connectivity\nWrite-Log \"Checking DR network connectivity...\"\n$drHosts = @(\"dr-app.example.com\", \"dr-db.example.com\", \"dr-lb.example.com\")\nforeach ($host in $drHosts) {\n    if (Test-Connection -ComputerName $host -Count 2 -Quiet) {\n        Write-Log \"[PASS] $host reachable\"\n        $ChecksPassed++\n    } else {\n        Write-Log \"[FAIL] $host unreachable\"\n        $ChecksFailed++\n    }\n}\n\n# Generate readiness report\n$TotalChecks = $ChecksPassed + $ChecksFailed\n$ReadinessPercent = [math]::Round(($ChecksPassed / $TotalChecks) * 100, 2)\n\n$report = @{\n    Timestamp = (Get-Date -Format \"o\")\n    ChecksPassed = $ChecksPassed\n    ChecksFailed = $ChecksFailed\n    ReadinessPercent = $ReadinessPercent\n    ReadyForFailover = ($ChecksFailed -eq 0)\n}\n\n$report | ConvertTo-Json | Out-File $ReportFile\n\nWrite-Log \"Readiness: ${ReadinessPercent}% ($ChecksPassed passed, $ChecksFailed failed)\"\nWrite-Log \"CP-7.4 Validation complete\""
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true,
      "qa_agent": "LOVELESS"
    },
    "cac_metadata": {
      "implementation_type": "automated",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Automated continuous monitoring of DR site readiness with comprehensive validation scripts for immediate failover capability assessment."
    },
    "rationale": "A backup site needs to be ready before disaster strikes, not set up afterward."
  },
  {
    "control_id": "CP-7.5",
    "control_name": "Equivalent Information Security Safeguards",
    "family": "Contingency Planning",
    "family_id": "CP",
    "official_text": "Employ [organization-defined information security safeguards] at the alternate processing site that are equivalent to those employed at the primary site.",
    "parent_control": "CP-7",
    "source": "NIST SP 800-53 Rev 5",
    "stig_id": "RHEL-08-010005",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "intent": "Ensure the alternate processing site maintains the same level of security protection as the primary site, preventing degradation of security posture during failover operations or extended DR site usage.",
    "plain_english_explanation": "The backup facility must have security controls equivalent to the primary site - same access controls, encryption, monitoring, physical security, and compliance certifications. Operating from the DR site should not mean accepting reduced security.",
    "example_implementation": "Implement identical security configurations at both sites using Infrastructure as Code (Terraform, Ansible). Deploy same SIEM, IDS/IPS, access control systems, encryption standards, and security monitoring at DR site. Conduct parallel security assessments.",
    "non_technical_guidance": "Organizations should: 1) Document security controls at both sites; 2) Ensure identical access control policies; 3) Maintain equivalent encryption standards; 4) Deploy same monitoring and detection capabilities; 5) Obtain matching compliance certifications; 6) Conduct parallel security assessments; 7) Synchronize security configurations using automation.",
    "is_technical": true,
    "ai_guidance": "AI systems should continuously compare security configurations between primary and alternate sites, detecting drift in access controls, encryption settings, firewall rules, and monitoring coverage. Machine learning models can analyze security event patterns at both sites to ensure equivalent detection capabilities. AI can automate security configuration synchronization and validate compliance status across sites.",
    "enhancements": [],
    "related_controls": [
      "CP-7",
      "PL-8",
      "SA-8",
      "SC-7"
    ],
    "supplemental_guidance": "Equivalent information security safeguards at the alternate processing site ensure that the same level of security protection is maintained during contingency operations. The information security safeguards to be employed at the alternate processing site should be those that the organization has determined are necessary based on the system categorization and the results of risk assessments.",
    "implementation_scripts": {
      "linux": {
        "bash": "# security_parity_validator\n#!/bin/bash\n# CP-7.5: Security Configuration Parity Validator\n# Ensures equivalent security controls at primary and DR sites\n\nPARITY_LOG=\"/var/log/cp7-5-security-parity.log\"\nPARITY_REPORT=\"/var/log/security-parity-report.json\"\n\nlog() { echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\" | tee -a \"$PARITY_LOG\"; }\n\nlog \"CP-7.5 Security Parity Validation Started\"\n\nDRIFT_DETECTED=0\n\n# Check 1: Firewall rules parity\nlog \"Checking firewall rule parity...\"\nPRIMARY_FW=$(iptables -L -n | md5sum | awk '{print $1}')\nDR_FW=$(ssh dr-app.example.com \"iptables -L -n\" 2>/dev/null | md5sum | awk '{print $1}')\n\nif [ \"$PRIMARY_FW\" = \"$DR_FW\" ]; then\n    log \"[PASS] Firewall rules match\"\nelse\n    log \"[FAIL] Firewall configuration drift detected\"\n    ((DRIFT_DETECTED++))\nfi\n\n# Check 2: SELinux/AppArmor status\nlog \"Checking mandatory access control parity...\"\nPRIMARY_MAC=$(getenforce 2>/dev/null || aa-status --mode 2>/dev/null)\nDR_MAC=$(ssh dr-app.example.com \"getenforce 2>/dev/null || aa-status --mode 2>/dev/null\" 2>/dev/null)\n\nif [ \"$PRIMARY_MAC\" = \"$DR_MAC\" ]; then\n    log \"[PASS] MAC configuration matches: $PRIMARY_MAC\"\nelse\n    log \"[FAIL] MAC configuration drift: Primary=$PRIMARY_MAC, DR=$DR_MAC\"\n    ((DRIFT_DETECTED++))\nfi\n\n# Check 3: SSH configuration\nlog \"Checking SSH hardening parity...\"\nPRIMARY_SSH=$(md5sum /etc/ssh/sshd_config | awk '{print $1}')\nDR_SSH=$(ssh dr-app.example.com \"md5sum /etc/ssh/sshd_config\" 2>/dev/null | awk '{print $1}')\n\nif [ \"$PRIMARY_SSH\" = \"$DR_SSH\" ]; then\n    log \"[PASS] SSH configuration matches\"\nelse\n    log \"[FAIL] SSH configuration drift detected\"\n    ((DRIFT_DETECTED++))\nfi\n\n# Check 4: SIEM agent status\nlog \"Checking SIEM agent status...\"\nPRIMARY_SIEM=$(systemctl is-active filebeat osquery auditd 2>/dev/null | tr '\\n' ' ')\nDR_SIEM=$(ssh dr-app.example.com \"systemctl is-active filebeat osquery auditd\" 2>/dev/null | tr '\\n' ' ')\n\nif [ \"$PRIMARY_SIEM\" = \"$DR_SIEM\" ]; then\n    log \"[PASS] SIEM agents match: $PRIMARY_SIEM\"\nelse\n    log \"[FAIL] SIEM agent status drift: Primary=[$PRIMARY_SIEM], DR=[$DR_SIEM]\"\n    ((DRIFT_DETECTED++))\nfi\n\n# Check 5: Encryption configuration\nlog \"Checking encryption at rest configuration...\"\nPRIMARY_CRYPT=$(lsblk -o NAME,FSTYPE | grep -c crypt)\nDR_CRYPT=$(ssh dr-app.example.com \"lsblk -o NAME,FSTYPE | grep -c crypt\" 2>/dev/null)\n\nif [ \"$PRIMARY_CRYPT\" = \"$DR_CRYPT\" ]; then\n    log \"[PASS] Encryption configuration matches\"\nelse\n    log \"[WARN] Encryption configuration differs\"\n    ((DRIFT_DETECTED++))\nfi\n\n# Generate parity report\ncat << EOF > \"$PARITY_REPORT\"\n{\n  \"timestamp\": \"$(date -Iseconds)\",\n  \"drift_count\": $DRIFT_DETECTED,\n  \"security_parity\": $([ $DRIFT_DETECTED -eq 0 ] && echo \"true\" || echo \"false\"),\n  \"checks\": {\n    \"firewall\": $([ \"$PRIMARY_FW\" = \"$DR_FW\" ] && echo \"true\" || echo \"false\"),\n    \"mac\": $([ \"$PRIMARY_MAC\" = \"$DR_MAC\" ] && echo \"true\" || echo \"false\"),\n    \"ssh\": $([ \"$PRIMARY_SSH\" = \"$DR_SSH\" ] && echo \"true\" || echo \"false\"),\n    \"siem\": $([ \"$PRIMARY_SIEM\" = \"$DR_SIEM\" ] && echo \"true\" || echo \"false\")\n  }\n}\nEOF\n\nlog \"Security parity validation complete: $DRIFT_DETECTED drift issues detected\"\n\n# sync_security_configs\n#!/bin/bash\n# CP-7.5: Security Configuration Synchronization\n# Synchronizes security configurations from primary to DR site\n\nlog() { echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\"; }\n\nlog \"Synchronizing security configurations to DR site...\"\n\n# Sync firewall rules\nlog \"Syncing firewall rules...\"\niptables-save > /tmp/iptables-rules.txt\nrsync -avz /tmp/iptables-rules.txt dr-app.example.com:/tmp/\nssh dr-app.example.com \"iptables-restore < /tmp/iptables-rules.txt\"\n\n# Sync SSH configuration\nlog \"Syncing SSH configuration...\"\nrsync -avz /etc/ssh/sshd_config dr-app.example.com:/etc/ssh/\nssh dr-app.example.com \"systemctl reload sshd\"\n\n# Sync audit rules\nlog \"Syncing audit rules...\"\nrsync -avz /etc/audit/rules.d/ dr-app.example.com:/etc/audit/rules.d/\nssh dr-app.example.com \"augenrules --load\"\n\nlog \"Security configuration synchronization complete\""
      },
      "windows": {
        "powershell": "# security_parity_validator\n# CP-7.5: Security Configuration Parity Validator (PowerShell)\n# Ensures equivalent security controls at primary and DR sites\n\n$LogFile = \"C:\\Logs\\CP7-5-Security-Parity.log\"\n$ReportFile = \"C:\\Logs\\Security-Parity-Report.json\"\n\nfunction Write-Log {\n    param([string]$Message)\n    $timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    \"[$timestamp] $Message\" | Tee-Object -FilePath $LogFile -Append\n}\n\nWrite-Log \"CP-7.5 Security Parity Validation Started\"\n\n$DriftDetected = 0\n$CheckResults = @{}\n\n# Check 1: Windows Firewall rules parity\nWrite-Log \"Checking Windows Firewall parity...\"\ntry {\n    $primaryFW = Get-NetFirewallRule | Select-Object Name, Enabled, Direction, Action | ConvertTo-Json | Get-FileHash -Algorithm MD5\n    $drFW = Invoke-Command -ComputerName \"dr-app.example.com\" -ScriptBlock {\n        Get-NetFirewallRule | Select-Object Name, Enabled, Direction, Action | ConvertTo-Json\n    } | Get-FileHash -Algorithm MD5\n    \n    if ($primaryFW.Hash -eq $drFW.Hash) {\n        Write-Log \"[PASS] Firewall rules match\"\n        $CheckResults[\"firewall\"] = $true\n    } else {\n        Write-Log \"[FAIL] Firewall configuration drift detected\"\n        $DriftDetected++\n        $CheckResults[\"firewall\"] = $false\n    }\n} catch {\n    Write-Log \"[ERROR] Could not compare firewall rules: $_\"\n    $DriftDetected++\n}\n\n# Check 2: Security policy comparison\nWrite-Log \"Checking security policy parity...\"\ntry {\n    secedit /export /cfg C:\\Temp\\primary-secpol.inf\n    $primarySecPol = Get-FileHash \"C:\\Temp\\primary-secpol.inf\" -Algorithm MD5\n    \n    Invoke-Command -ComputerName \"dr-app.example.com\" -ScriptBlock {\n        secedit /export /cfg C:\\Temp\\dr-secpol.inf\n    }\n    Copy-Item \"\\\\dr-app.example.com\\C$\\Temp\\dr-secpol.inf\" \"C:\\Temp\\dr-secpol.inf\"\n    $drSecPol = Get-FileHash \"C:\\Temp\\dr-secpol.inf\" -Algorithm MD5\n    \n    if ($primarySecPol.Hash -eq $drSecPol.Hash) {\n        Write-Log \"[PASS] Security policies match\"\n        $CheckResults[\"secpol\"] = $true\n    } else {\n        Write-Log \"[FAIL] Security policy drift detected\"\n        $DriftDetected++\n        $CheckResults[\"secpol\"] = $false\n    }\n} catch {\n    Write-Log \"[ERROR] Could not compare security policies: $_\"\n}\n\n# Check 3: Defender configuration\nWrite-Log \"Checking Defender configuration parity...\"\ntry {\n    $primaryDefender = Get-MpPreference | Select-Object DisableRealtimeMonitoring, DisableBehaviorMonitoring\n    $drDefender = Invoke-Command -ComputerName \"dr-app.example.com\" -ScriptBlock {\n        Get-MpPreference | Select-Object DisableRealtimeMonitoring, DisableBehaviorMonitoring\n    }\n    \n    if (($primaryDefender | ConvertTo-Json) -eq ($drDefender | ConvertTo-Json)) {\n        Write-Log \"[PASS] Defender configuration matches\"\n        $CheckResults[\"defender\"] = $true\n    } else {\n        Write-Log \"[FAIL] Defender configuration drift detected\"\n        $DriftDetected++\n        $CheckResults[\"defender\"] = $false\n    }\n} catch {\n    Write-Log \"[ERROR] Could not compare Defender config: $_\"\n}\n\n# Check 4: BitLocker status\nWrite-Log \"Checking BitLocker status parity...\"\ntry {\n    $primaryBL = Get-BitLockerVolume | Select-Object VolumeStatus, ProtectionStatus\n    $drBL = Invoke-Command -ComputerName \"dr-app.example.com\" -ScriptBlock {\n        Get-BitLockerVolume | Select-Object VolumeStatus, ProtectionStatus\n    }\n    \n    if (($primaryBL | ConvertTo-Json) -eq ($drBL | ConvertTo-Json)) {\n        Write-Log \"[PASS] BitLocker configuration matches\"\n        $CheckResults[\"bitlocker\"] = $true\n    } else {\n        Write-Log \"[FAIL] BitLocker configuration drift\"\n        $DriftDetected++\n        $CheckResults[\"bitlocker\"] = $false\n    }\n} catch {\n    Write-Log \"[WARN] Could not compare BitLocker: $_\"\n}\n\n# Generate parity report\n$report = @{\n    Timestamp = (Get-Date -Format \"o\")\n    DriftCount = $DriftDetected\n    SecurityParity = ($DriftDetected -eq 0)\n    Checks = $CheckResults\n}\n\n$report | ConvertTo-Json -Depth 3 | Out-File $ReportFile\n\nWrite-Log \"Security parity validation complete: $DriftDetected drift issues detected\""
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true,
      "qa_agent": "LOVELESS"
    },
    "cac_metadata": {
      "implementation_type": "automated",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Automated security configuration comparison and synchronization scripts to maintain equivalent security posture at alternate site."
    },
    "rationale": "Your backup site must be as secure as your primary site. Don't sacrifice security for availability."
  },
  {
    "control_id": "CP-7.6",
    "control_name": "Inability to Return to Primary Site",
    "family": "Contingency Planning",
    "family_id": "CP",
    "official_text": "Plan and prepare for circumstances that preclude returning to the primary processing site.",
    "parent_control": "CP-7",
    "source": "NIST SP 800-53 Rev 5",
    "stig_id": "RHEL-08-010006",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "intent": "Ensure organizational resilience by planning for catastrophic scenarios where the primary site is permanently destroyed or otherwise unusable, enabling long-term operations from the alternate site or transition to a new primary facility.",
    "plain_english_explanation": "Organizations must plan for worst-case scenarios where the original data center is permanently lost - complete destruction, contamination, legal seizure, or other circumstances preventing return. This requires plans for long-term alternate site operation, permanent site transition, or establishment of a new primary facility.",
    "example_implementation": "Maintain DR site infrastructure capable of permanent primary operations. Document procedures for promoting DR site to permanent primary, including DNS changes, vendor contract transfers, personnel relocation, and establishment of new alternate site. Store essential documentation in multiple locations.",
    "non_technical_guidance": "Organizations should: 1) Document permanent site loss scenarios and response procedures; 2) Ensure DR site can sustain indefinite operations; 3) Maintain off-site copies of critical documentation; 4) Plan for establishing new alternate site after DR becomes primary; 5) Include personnel relocation considerations; 6) Address vendor and contract transitions; 7) Practice permanent transition scenarios.",
    "is_technical": true,
    "ai_guidance": "AI systems should assist in scenario planning for permanent primary site loss, analyzing resource sustainability at alternate sites, predicting operational constraints for extended DR operations, and optimizing resource allocation for indefinite alternate site usage. Machine learning models can assess site viability indicators and recommend when to initiate permanent transition procedures versus continued temporary operations.",
    "enhancements": [],
    "related_controls": [
      "CP-7",
      "CP-2",
      "PE-18"
    ],
    "supplemental_guidance": "Circumstances that may preclude returning to the primary processing site include physical destruction of the site, criminal activity at the site, or potential exposure of personnel to health hazards. In these situations, the organization may need to relocate operations to the alternate processing site for an extended period of time or permanently.",
    "implementation_scripts": {
      "linux": {
        "bash": "# permanent_transition_checklist\n#!/bin/bash\n# CP-7.6: Permanent DR Site Transition Checklist\n# Validates readiness for permanent transition to alternate site\n\nTRANSITION_LOG=\"/var/log/cp7-6-permanent-transition.log\"\nCHECKLIST_REPORT=\"/var/log/permanent-transition-checklist.json\"\n\nlog() { echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\" | tee -a \"$TRANSITION_LOG\"; }\n\nlog \"CP-7.6 Permanent Transition Readiness Assessment\"\n\nREADY_ITEMS=0\nNOT_READY_ITEMS=0\n\n# Check 1: DR site capacity for permanent operations\nlog \"Checking DR site capacity for sustained operations...\"\nDR_CPU=$(ssh dr-mon.example.com \"cat /proc/cpuinfo | grep processor | wc -l\" 2>/dev/null)\nDR_MEM=$(ssh dr-mon.example.com \"free -g | grep Mem | awk '{print \\$2}'\" 2>/dev/null)\nDR_DISK=$(ssh dr-mon.example.com \"df -h /data | tail -1 | awk '{print \\$2}'\" 2>/dev/null)\n\nlog \"DR site resources: ${DR_CPU} CPUs, ${DR_MEM}GB RAM, ${DR_DISK} storage\"\n\nif [ \"$DR_CPU\" -ge 64 ] && [ \"$DR_MEM\" -ge 256 ]; then\n    log \"[READY] DR site has sufficient compute resources\"\n    ((READY_ITEMS++))\nelse\n    log \"[NOT READY] DR site may have insufficient resources for permanent operations\"\n    ((NOT_READY_ITEMS++))\nfi\n\n# Check 2: Documentation availability\nlog \"Checking critical documentation availability at DR site...\"\nDOCS=(\"runbooks\" \"architecture\" \"vendor-contacts\" \"recovery-procedures\")\nfor doc in \"${DOCS[@]}\"; do\n    if ssh dr-docs.example.com \"test -f /docs/$doc.pdf\" 2>/dev/null; then\n        log \"[READY] $doc documentation available\"\n        ((READY_ITEMS++))\n    else\n        log \"[NOT READY] $doc documentation missing\"\n        ((NOT_READY_ITEMS++))\n    fi\ndone\n\n# Check 3: Vendor access from DR site\nlog \"Checking vendor connectivity from DR site...\"\nVENDORS=(\"licensing.vendor1.com\" \"support.vendor2.com\" \"updates.vendor3.com\")\nfor vendor in \"${VENDORS[@]}\"; do\n    if ssh dr-app.example.com \"ping -c 2 $vendor\" > /dev/null 2>&1; then\n        log \"[READY] $vendor reachable from DR site\"\n        ((READY_ITEMS++))\n    else\n        log \"[NOT READY] $vendor not reachable from DR site\"\n        ((NOT_READY_ITEMS++))\nfi\ndone\n\n# Check 4: DNS TTL readiness\nlog \"Checking DNS configuration for permanent transition...\"\nDNS_TTL=$(dig example.com +short TTL 2>/dev/null | head -1)\nif [ -n \"$DNS_TTL\" ] && [ \"$DNS_TTL\" -le 300 ]; then\n    log \"[READY] DNS TTL is low enough for quick transition: ${DNS_TTL}s\"\n    ((READY_ITEMS++))\nelse\n    log \"[WARN] DNS TTL may delay permanent transition: ${DNS_TTL}s\"\nfi\n\n# Check 5: New alternate site plan\nlog \"Checking alternate site contingency plan...\"\nif [ -f /docs/new-alternate-site-plan.pdf ]; then\n    log \"[READY] New alternate site plan documented\"\n    ((READY_ITEMS++))\nelse\n    log \"[NOT READY] No plan for new alternate site after DR becomes primary\"\n    ((NOT_READY_ITEMS++))\nfi\n\n# Generate checklist report\nTOTAL=$((READY_ITEMS + NOT_READY_ITEMS))\nREADINESS=$((READY_ITEMS * 100 / TOTAL))\n\ncat << EOF > \"$CHECKLIST_REPORT\"\n{\n  \"timestamp\": \"$(date -Iseconds)\",\n  \"ready_items\": $READY_ITEMS,\n  \"not_ready_items\": $NOT_READY_ITEMS,\n  \"readiness_percent\": $READINESS,\n  \"ready_for_permanent_transition\": $([ $NOT_READY_ITEMS -eq 0 ] && echo \"true\" || echo \"false\"),\n  \"recommendation\": \"$([ $NOT_READY_ITEMS -eq 0 ] && echo \"Organization is ready for permanent site transition\" || echo \"Address $NOT_READY_ITEMS items before permanent transition\")\"\n}\nEOF\n\nlog \"Permanent transition readiness: ${READINESS}% ($READY_ITEMS ready, $NOT_READY_ITEMS not ready)\"\n\n# dr_promotion_script\n#!/bin/bash\n# CP-7.6: DR Site Promotion to Primary\n# Executes permanent transition of DR site to primary status\n\nset -e\nPROMOTION_LOG=\"/var/log/cp7-6-dr-promotion.log\"\n\nlog() { echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\" | tee -a \"$PROMOTION_LOG\"; }\n\nlog \"INITIATING PERMANENT DR SITE PROMOTION\"\nlog \"WARNING: This promotes DR site to permanent primary status\"\nlog \"Previous primary site will be decommissioned\"\n\nread -p \"Confirm permanent promotion (type 'PROMOTE'): \" CONFIRM\nif [ \"$CONFIRM\" != \"PROMOTE\" ]; then\n    log \"Promotion cancelled\"\n    exit 1\nfi\n\n# Step 1: Update DNS permanently\nlog \"Step 1: Updating DNS records permanently...\"\naws route53 change-resource-record-sets --hosted-zone-id $HOSTED_ZONE_ID \\\n    --change-batch file:///etc/dr/dns-permanent-promotion.json\nlog \"DNS TTL set to standard production values\"\n\n# Step 2: Update load balancer configuration\nlog \"Step 2: Removing primary site from load balancer...\"\naws elbv2 deregister-targets --target-group-arn $PRIMARY_TG_ARN \\\n    --targets Id=$PRIMARY_INSTANCE_ID\n\n# Step 3: Update monitoring and alerting\nlog \"Step 3: Reconfiguring monitoring for new primary...\"\n/opt/monitoring/reconfigure-for-dr-primary.sh\n\n# Step 4: Update documentation\nlog \"Step 4: Generating updated architecture documentation...\"\ncat << EOF > /docs/site-status.json\n{\n  \"primary_site\": \"former-dr-site\",\n  \"alternate_site\": \"pending-new-selection\",\n  \"transition_date\": \"$(date -Iseconds)\",\n  \"transition_reason\": \"Permanent primary site loss\",\n  \"status\": \"operating-from-former-dr\"\n}\nEOF\n\n# Step 5: Notify stakeholders\nlog \"Step 5: Sending permanent transition notifications...\"\n/opt/notifications/send-permanent-transition-notice.sh\n\nlog \"DR SITE PROMOTION COMPLETE\"\nlog \"CRITICAL: Begin planning for new alternate site immediately\"\nlog \"Former DR site is now the PERMANENT PRIMARY\""
      },
      "windows": {
        "powershell": "# permanent_transition_checklist\n# CP-7.6: Permanent DR Site Transition Checklist (PowerShell)\n# Validates readiness for permanent transition to alternate site\n\n$LogFile = \"C:\\Logs\\CP7-6-Permanent-Transition.log\"\n$ReportFile = \"C:\\Logs\\Permanent-Transition-Checklist.json\"\n\nfunction Write-Log {\n    param([string]$Message)\n    $timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    \"[$timestamp] $Message\" | Tee-Object -FilePath $LogFile -Append\n}\n\nWrite-Log \"CP-7.6 Permanent Transition Readiness Assessment\"\n\n$ReadyItems = 0\n$NotReadyItems = 0\n$CheckResults = @()\n\n# Check 1: DR site capacity\nWrite-Log \"Checking DR site compute capacity...\"\ntry {\n    $drResources = Invoke-Command -ComputerName \"dr-app.example.com\" -ScriptBlock {\n        @{\n            CPUs = (Get-WmiObject Win32_Processor).NumberOfLogicalProcessors\n            MemoryGB = [math]::Round((Get-WmiObject Win32_ComputerSystem).TotalPhysicalMemory / 1GB)\n        }\n    }\n    \n    if ($drResources.CPUs -ge 64 -and $drResources.MemoryGB -ge 256) {\n        Write-Log \"[READY] DR site has sufficient compute: $($drResources.CPUs) CPUs, $($drResources.MemoryGB)GB RAM\"\n        $ReadyItems++\n    } else {\n        Write-Log \"[NOT READY] DR site may have insufficient resources\"\n        $NotReadyItems++\n    }\n} catch {\n    Write-Log \"[ERROR] Could not check DR resources: $_\"\n    $NotReadyItems++\n}\n\n# Check 2: License portability\nWrite-Log \"Checking software license portability...\"\n$licenses = @(\"SQL Server\", \"Windows Server\", \"Office 365\")\nforeach ($license in $licenses) {\n    # Simulated check - in production would verify with licensing server\n    Write-Log \"[INFO] Verify $license license allows DR site operation\"\n    $CheckResults += @{License = $license; Status = \"Manual Verification Required\"}\n}\n\n# Check 3: Azure ASR for permanent failover\nWrite-Log \"Checking ASR commit readiness...\"\ntry {\n    $asrItems = Get-AzRecoveryServicesAsrReplicationProtectedItem -All\n    $committable = $asrItems | Where-Object { $_.AllowedOperations -contains \"Commit\" }\n    \n    if ($committable.Count -eq $asrItems.Count) {\n        Write-Log \"[READY] All ASR items ready for permanent commit\"\n        $ReadyItems++\n    } else {\n        Write-Log \"[NOT READY] Some ASR items not ready for commit\"\n        $NotReadyItems++\n    }\n} catch {\n    Write-Log \"[ERROR] Could not check ASR status: $_\"\n}\n\n# Check 4: Documentation at DR site\nWrite-Log \"Checking critical documentation...\"\n$requiredDocs = @(\"DR-Runbook.pdf\", \"Architecture-Diagram.pdf\", \"Vendor-Contacts.pdf\")\nforeach ($doc in $requiredDocs) {\n    if (Test-Path \"\\\\dr-docs.example.com\\docs\\$doc\") {\n        Write-Log \"[READY] $doc available at DR site\"\n        $ReadyItems++\n    } else {\n        Write-Log \"[NOT READY] $doc missing at DR site\"\n        $NotReadyItems++\n    }\n}\n\n# Generate checklist report\n$Total = $ReadyItems + $NotReadyItems\n$ReadinessPercent = [math]::Round(($ReadyItems / $Total) * 100, 2)\n\n$report = @{\n    Timestamp = (Get-Date -Format \"o\")\n    ReadyItems = $ReadyItems\n    NotReadyItems = $NotReadyItems\n    ReadinessPercent = $ReadinessPercent\n    ReadyForPermanentTransition = ($NotReadyItems -eq 0)\n    Recommendation = if ($NotReadyItems -eq 0) { \"Organization ready for permanent transition\" } else { \"Address $NotReadyItems items before permanent transition\" }\n}\n\n$report | ConvertTo-Json -Depth 3 | Out-File $ReportFile\n\nWrite-Log \"Permanent transition readiness: ${ReadinessPercent}% ($ReadyItems ready, $NotReadyItems not ready)\""
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true,
      "qa_agent": "LOVELESS"
    },
    "cac_metadata": {
      "implementation_type": "hybrid",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Automated readiness validation scripts combined with manual planning and decision-making processes for permanent site transition scenarios."
    },
    "rationale": "Sometimes you can't return to your original site. This ensures you can operate indefinitely from the backup."
  },
  {
    "control_id": "CP-8",
    "control_name": "Telecommunications Services",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": "TCOM-CP-000001",
    "official_text": "Establish alternate telecommunications services, including necessary agreements to permit the resumption of organization-defined system operations for essential mission and business functions within organization-defined time period when the primary telecommunications capabilities are unavailable at either the primary or alternate processing or storage sites.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": true,
      "high": true
    },
    "intent": "Ensure organizational resilience by establishing alternate telecommunications pathways that can be activated when primary services fail, maintaining continuity of essential mission and business functions.",
    "plain_english_explanation": "Your organization must have backup telecommunications services ready to activate when your primary internet, phone, or data connections fail. This includes having contracts with alternate providers and ensuring these backup services can support your critical operations within a defined timeframe. Think of it as having a backup internet provider that kicks in automatically when your main connection goes down.",
    "ai_guidance": "When implementing CP-8 Telecommunications Services, organizations should conduct a comprehensive telecommunications dependency analysis to identify all critical communication pathways. Establish formal agreements with at least one alternate telecommunications provider that uses different infrastructure than your primary provider. Document Recovery Time Objectives (RTOs) for telecommunications restoration and ensure alternate services can meet these requirements. Implement automated failover mechanisms where technically feasible, and maintain updated contact information for emergency telecommunications support. Regular testing of failover procedures is essential to validate that alternate services function correctly under actual outage conditions.",
    "example_implementation": "Establish contracts with multiple telecommunications providers using diverse infrastructure. Implement SD-WAN or similar technology for automatic failover. Document all telecommunications dependencies and recovery procedures.",
    "non_technical_guidance": "1. Identify all telecommunications services your organization depends on (internet, voice, data circuits).\n2. Determine which services are critical for essential mission functions.\n3. Establish agreements with alternate telecommunications providers.\n4. Ensure alternate providers use different physical infrastructure than primary providers.\n5. Define recovery time objectives for each critical telecommunications service.\n6. Document procedures for activating alternate services.\n7. Maintain emergency contact information for all providers.\n8. Regularly test failover to alternate services.",
    "is_technical": true,
    "enhancements": [
      {
        "id": "CP-8.1",
        "title": "Priority of Service Provisions",
        "official_text": "Develop primary and alternate telecommunications service agreements that contain priority-of-service provisions in accordance with availability requirements including downtime constraints."
      },
      {
        "id": "CP-8.2",
        "title": "Single Points of Failure",
        "official_text": "Obtain alternate telecommunications services to reduce the likelihood of sharing a single point of failure with primary telecommunications services."
      },
      {
        "id": "CP-8.3",
        "title": "Separation of Primary and Alternate Providers",
        "official_text": "Obtain alternate telecommunications services from providers that are separated from primary service providers to reduce susceptibility to the same threats."
      },
      {
        "id": "CP-8.4",
        "title": "Provider Contingency Plan",
        "official_text": "Require primary and alternate telecommunications service providers to have contingency plans; obtain evidence of contingency testing/training by providers at organization-defined frequency."
      },
      {
        "id": "CP-8.5",
        "title": "Alternate Telecommunication Service Testing",
        "official_text": "Test alternate telecommunication services at organization-defined frequency."
      }
    ],
    "related_controls": [
      "CP-2",
      "CP-6",
      "CP-7",
      "CP-11",
      "SC-7"
    ],
    "supplemental_guidance": "This control applies to telecommunications services (physical and logical) that support the organization's system operations including voice, data, and video services. Alternate telecommunications services may be provided by different telecommunications service carriers or technologies. Organizations may use different network providers for primary and alternate services to reduce single points of failure. Organizations determine the level of service and continuity required from alternate telecommunications services based on mission/business needs.",
    "implementation_scripts": {
      "linux": {
        "bash": "# network_path_check\n#!/bin/bash\n# CP-8: Network Path Redundancy Check\n# Verifies multiple network paths exist for critical services\n\necho \"=== CP-8 Telecommunications Redundancy Verification ===\"\necho \"Timestamp: $(date -Iseconds)\"\n\n# Check default routes\necho \"\n[INFO] Checking routing table for multiple paths:\"\nip route show | grep -E '^default' | while read line; do\n    echo \"  Route: $line\"\ndone\n\n# Count default routes\nROUTE_COUNT=$(ip route show | grep -c '^default')\nif [ $ROUTE_COUNT -lt 2 ]; then\n    echo \"[WARNING] Only $ROUTE_COUNT default route(s) found. Consider adding alternate path.\"\nelse\n    echo \"[PASS] Multiple default routes detected: $ROUTE_COUNT\"\nfi\n\n# Check network interfaces\necho \"\n[INFO] Active network interfaces:\"\nip link show up | grep -E '^[0-9]+:' | awk -F': ' '{print $2}'\n\n# Test connectivity to multiple endpoints\necho \"\n[INFO] Testing connectivity to external endpoints:\"\nfor endpoint in 8.8.8.8 1.1.1.1 9.9.9.9; do\n    if ping -c 1 -W 2 $endpoint > /dev/null 2>&1; then\n        echo \"  [PASS] $endpoint reachable\"\n    else\n        echo \"  [FAIL] $endpoint unreachable\"\n    fi\ndone\n\necho \"\n=== CP-8 Check Complete ===\"\n\n# isp_failover_test\n#!/bin/bash\n# CP-8: ISP Failover Automation Test\n# Tests failover capability between primary and alternate ISP\n\nPRIMARY_GW=\"${PRIMARY_GATEWAY:-192.168.1.1}\"\nALT_GW=\"${ALTERNATE_GATEWAY:-192.168.2.1}\"\nTEST_TARGET=\"8.8.8.8\"\nLOG_FILE=\"/var/log/cp8_failover_test.log\"\n\nlog_msg() {\n    echo \"$(date -Iseconds) - $1\" | tee -a $LOG_FILE\n}\n\nlog_msg \"Starting CP-8 ISP Failover Test\"\n\n# Test primary gateway\nlog_msg \"Testing primary gateway: $PRIMARY_GW\"\nif ping -c 3 -W 2 $PRIMARY_GW > /dev/null 2>&1; then\n    log_msg \"[PASS] Primary gateway responsive\"\n    PRIMARY_STATUS=\"UP\"\nelse\n    log_msg \"[FAIL] Primary gateway not responding\"\n    PRIMARY_STATUS=\"DOWN\"\nfi\n\n# Test alternate gateway\nlog_msg \"Testing alternate gateway: $ALT_GW\"\nif ping -c 3 -W 2 $ALT_GW > /dev/null 2>&1; then\n    log_msg \"[PASS] Alternate gateway responsive\"\n    ALT_STATUS=\"UP\"\nelse\n    log_msg \"[FAIL] Alternate gateway not responding\"\n    ALT_STATUS=\"DOWN\"\nfi\n\n# Summary\nlog_msg \"=== Failover Readiness Summary ===\"\nlog_msg \"Primary Gateway ($PRIMARY_GW): $PRIMARY_STATUS\"\nlog_msg \"Alternate Gateway ($ALT_GW): $ALT_STATUS\"\n\nif [ \"$PRIMARY_STATUS\" = \"UP\" ] && [ \"$ALT_STATUS\" = \"UP\" ]; then\n    log_msg \"[COMPLIANT] Both gateways operational - failover ready\"\n    exit 0\nelse\n    log_msg \"[NON-COMPLIANT] Failover capability compromised\"\n    exit 1\nfi\n\n# telecom_monitor\n#!/bin/bash\n# CP-8: Telecommunications Service Monitoring\n# Continuous monitoring of telecommunications connectivity\n\nCONFIG_FILE=\"/etc/cp8_telecom_monitor.conf\"\nLOG_FILE=\"/var/log/cp8_telecom_status.log\"\nALERT_THRESHOLD=3\n\n# Default endpoints if config not found\nPRIMARY_ENDPOINTS=(\"8.8.8.8\" \"8.8.4.4\")\nALT_ENDPOINTS=(\"1.1.1.1\" \"1.0.0.1\")\n\nlog_status() {\n    echo \"$(date -Iseconds) | $1\" >> $LOG_FILE\n}\n\ncheck_path() {\n    local endpoint=$1\n    local path_name=$2\n    local failures=0\n    \n    for i in {1..3}; do\n        if ! ping -c 1 -W 2 $endpoint > /dev/null 2>&1; then\n            ((failures++))\n        fi\n    done\n    \n    if [ $failures -ge $ALERT_THRESHOLD ]; then\n        log_status \"[ALERT] $path_name path to $endpoint: DEGRADED ($failures/3 failures)\"\n        return 1\n    else\n        log_status \"[OK] $path_name path to $endpoint: OPERATIONAL\"\n        return 0\n    fi\n}\n\nlog_status \"=== CP-8 Telecommunications Monitor Started ===\"\n\n# Check primary path\nPRIMARY_OK=true\nfor ep in \"${PRIMARY_ENDPOINTS[@]}\"; do\n    check_path $ep \"PRIMARY\" || PRIMARY_OK=false\ndone\n\n# Check alternate path\nALT_OK=true\nfor ep in \"${ALT_ENDPOINTS[@]}\"; do\n    check_path $ep \"ALTERNATE\" || ALT_OK=false\ndone\n\n# Compliance determination\nif $PRIMARY_OK && $ALT_OK; then\n    log_status \"[COMPLIANT] All telecommunications paths operational\"\n    exit 0\nelif $PRIMARY_OK || $ALT_OK; then\n    log_status \"[WARNING] Partial telecommunications redundancy\"\n    exit 1\nelse\n    log_status \"[CRITICAL] All telecommunications paths failed\"\n    exit 2\nfi"
      },
      "windows": {
        "powershell": "# network_path_check\n# CP-8: Network Path Redundancy Check (PowerShell)\n# Verifies multiple network paths exist for critical services\n\nWrite-Host \"=== CP-8 Telecommunications Redundancy Verification ===\"\nWrite-Host \"Timestamp: $(Get-Date -Format 'yyyy-MM-ddTHH:mm:ssK')\"\n\n# Check default routes\nWrite-Host \"`n[INFO] Checking routing table for default routes:\"\n$defaultRoutes = Get-NetRoute -DestinationPrefix '0.0.0.0/0' -ErrorAction SilentlyContinue\n$routeCount = ($defaultRoutes | Measure-Object).Count\n\nforeach ($route in $defaultRoutes) {\n    Write-Host \"  Gateway: $($route.NextHop) via Interface: $($route.InterfaceAlias)\"\n}\n\nif ($routeCount -lt 2) {\n    Write-Host \"[WARNING] Only $routeCount default route(s) found. Consider adding alternate path.\" -ForegroundColor Yellow\n} else {\n    Write-Host \"[PASS] Multiple default routes detected: $routeCount\" -ForegroundColor Green\n}\n\n# Check active network adapters\nWrite-Host \"`n[INFO] Active network adapters:\"\nGet-NetAdapter | Where-Object { $_.Status -eq 'Up' } | ForEach-Object {\n    Write-Host \"  $($_.Name): $($_.InterfaceDescription)\"\n}\n\n# Test connectivity to multiple endpoints\nWrite-Host \"`n[INFO] Testing connectivity to external endpoints:\"\n$endpoints = @('8.8.8.8', '1.1.1.1', '9.9.9.9')\nforeach ($endpoint in $endpoints) {\n    $result = Test-Connection -ComputerName $endpoint -Count 1 -Quiet -ErrorAction SilentlyContinue\n    if ($result) {\n        Write-Host \"  [PASS] $endpoint reachable\" -ForegroundColor Green\n    } else {\n        Write-Host \"  [FAIL] $endpoint unreachable\" -ForegroundColor Red\n    }\n}\n\nWrite-Host \"`n=== CP-8 Check Complete ===\"\n\n# isp_failover_test\n# CP-8: ISP Failover Automation Test (PowerShell)\n# Tests failover capability between primary and alternate ISP\n\nparam(\n    [string]$PrimaryGateway = '192.168.1.1',\n    [string]$AlternateGateway = '192.168.2.1',\n    [string]$LogFile = 'C:\\Logs\\CP8_Failover_Test.log'\n)\n\nfunction Write-Log {\n    param([string]$Message)\n    $timestamp = Get-Date -Format 'yyyy-MM-ddTHH:mm:ssK'\n    $logEntry = \"$timestamp - $Message\"\n    Add-Content -Path $LogFile -Value $logEntry\n    Write-Host $logEntry\n}\n\n# Ensure log directory exists\n$logDir = Split-Path $LogFile -Parent\nif (-not (Test-Path $logDir)) {\n    New-Item -ItemType Directory -Path $logDir -Force | Out-Null\n}\n\nWrite-Log \"Starting CP-8 ISP Failover Test\"\n\n# Test primary gateway\nWrite-Log \"Testing primary gateway: $PrimaryGateway\"\n$primaryResult = Test-Connection -ComputerName $PrimaryGateway -Count 3 -Quiet -ErrorAction SilentlyContinue\nif ($primaryResult) {\n    Write-Log \"[PASS] Primary gateway responsive\"\n    $primaryStatus = 'UP'\n} else {\n    Write-Log \"[FAIL] Primary gateway not responding\"\n    $primaryStatus = 'DOWN'\n}\n\n# Test alternate gateway\nWrite-Log \"Testing alternate gateway: $AlternateGateway\"\n$altResult = Test-Connection -ComputerName $AlternateGateway -Count 3 -Quiet -ErrorAction SilentlyContinue\nif ($altResult) {\n    Write-Log \"[PASS] Alternate gateway responsive\"\n    $altStatus = 'UP'\n} else {\n    Write-Log \"[FAIL] Alternate gateway not responding\"\n    $altStatus = 'DOWN'\n}\n\n# Summary\nWrite-Log \"=== Failover Readiness Summary ===\"\nWrite-Log \"Primary Gateway ($PrimaryGateway): $primaryStatus\"\nWrite-Log \"Alternate Gateway ($AlternateGateway): $altStatus\"\n\nif ($primaryStatus -eq 'UP' -and $altStatus -eq 'UP') {\n    Write-Log \"[COMPLIANT] Both gateways operational - failover ready\"\n    exit 0\n} else {\n    Write-Log \"[NON-COMPLIANT] Failover capability compromised\"\n    exit 1\n}\n\n# telecom_monitor\n# CP-8: Telecommunications Service Monitoring (PowerShell)\n# Scheduled task for continuous telecommunications monitoring\n\nparam(\n    [string]$LogFile = 'C:\\Logs\\CP8_Telecom_Status.log',\n    [int]$AlertThreshold = 3\n)\n\n$primaryEndpoints = @('8.8.8.8', '8.8.4.4')\n$altEndpoints = @('1.1.1.1', '1.0.0.1')\n\nfunction Write-Status {\n    param([string]$Message)\n    $timestamp = Get-Date -Format 'yyyy-MM-ddTHH:mm:ssK'\n    \"$timestamp | $Message\" | Add-Content -Path $LogFile\n}\n\nfunction Test-Path-Connectivity {\n    param(\n        [string]$Endpoint,\n        [string]$PathName\n    )\n    $failures = 0\n    for ($i = 1; $i -le 3; $i++) {\n        $result = Test-Connection -ComputerName $Endpoint -Count 1 -Quiet -ErrorAction SilentlyContinue\n        if (-not $result) { $failures++ }\n    }\n    \n    if ($failures -ge $AlertThreshold) {\n        Write-Status \"[ALERT] $PathName path to $Endpoint: DEGRADED ($failures/3 failures)\"\n        return $false\n    } else {\n        Write-Status \"[OK] $PathName path to $Endpoint: OPERATIONAL\"\n        return $true\n    }\n}\n\n# Ensure log directory exists\n$logDir = Split-Path $LogFile -Parent\nif (-not (Test-Path $logDir)) {\n    New-Item -ItemType Directory -Path $logDir -Force | Out-Null\n}\n\nWrite-Status \"=== CP-8 Telecommunications Monitor Started ===\"\n\n# Check primary path\n$primaryOK = $true\nforeach ($ep in $primaryEndpoints) {\n    if (-not (Test-Path-Connectivity -Endpoint $ep -PathName 'PRIMARY')) {\n        $primaryOK = $false\n    }\n}\n\n# Check alternate path\n$altOK = $true\nforeach ($ep in $altEndpoints) {\n    if (-not (Test-Path-Connectivity -Endpoint $ep -PathName 'ALTERNATE')) {\n        $altOK = $false\n    }\n}\n\n# Compliance determination\nif ($primaryOK -and $altOK) {\n    Write-Status \"[COMPLIANT] All telecommunications paths operational\"\n    exit 0\n} elseif ($primaryOK -or $altOK) {\n    Write-Status \"[WARNING] Partial telecommunications redundancy\"\n    exit 1\n} else {\n    Write-Status \"[CRITICAL] All telecommunications paths failed\"\n    exit 2\n}"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true,
      "qa_agent": "loveless"
    },
    "cac_metadata": {
      "implementation_type": "hybrid",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "This control requires both organizational agreements and technical monitoring. Automated scripts verify telecommunications path redundancy and failover capabilities."
    },
    "rationale": "Internet and phone outages can be as crippling as server failures. Backup connectivity keeps you operational."
  },
  {
    "control_id": "CP-8.1",
    "control_name": "Priority of Service Provisions",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": "TCOM-CP-000002",
    "official_text": "Develop primary and alternate telecommunications service agreements that contain priority-of-service provisions in accordance with availability requirements including downtime constraints specified in organization-defined time period.",
    "parent_control": "CP-8",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": true,
      "high": true
    },
    "intent": "Ensure that telecommunications service agreements include priority restoration provisions so that critical organizational services receive preferential treatment during outages or high-demand situations.",
    "plain_english_explanation": "Your telecommunications service contracts must include priority-of-service clauses that guarantee your organization receives preferential treatment for service restoration during outages. This is similar to how hospitals or emergency services get priority power restoration during blackouts. Your contracts should specify maximum acceptable downtime and ensure providers commit to restoring your services within those timeframes.",
    "ai_guidance": "When implementing CP-8.1 Priority of Service Provisions, organizations should negotiate telecommunications service level agreements (SLAs) that explicitly define priority restoration tiers. Include specific Recovery Time Objectives (RTOs) in all contracts with penalties for non-compliance. Document the organization's Telecommunications Service Priority (TSP) program enrollment if applicable to federal requirements. Establish escalation procedures with providers for priority service activation. Maintain records of all priority-of-service provisions and regularly review them during contract renewals. Consider obtaining Government Emergency Telecommunications Service (GETS) cards for key personnel in critical positions.",
    "example_implementation": "Include SLA clauses specifying 4-hour maximum restoration time for critical services. Enroll in TSP program for federal priority. Maintain provider escalation contacts.",
    "non_technical_guidance": "1. Review existing telecommunications contracts for priority provisions.\n2. Identify availability requirements and maximum acceptable downtime for each service.\n3. Negotiate priority-of-service clauses with all telecommunications providers.\n4. Document specific restoration timeframes in contracts.\n5. Establish escalation procedures for service outages.\n6. Consider enrollment in government priority programs (TSP, GETS) if eligible.\n7. Maintain emergency contact information for provider escalation teams.\n8. Review and update priority provisions during contract renewals.",
    "is_technical": false,
    "enhancements": [],
    "related_controls": [
      "CP-2",
      "CP-8"
    ],
    "supplemental_guidance": "Organizations consider the potential mission or business impact in situations where telecommunications service providers are servicing other organizations with similar priority of service provisions. Telecommunications Service Priority (TSP) is a federal program that directs telecommunications service providers to give preferential treatment to users enrolled in the program.",
    "implementation_scripts": {
      "linux": {
        "bash": "# sla_compliance_check\n#!/bin/bash\n# CP-8.1: SLA Compliance Documentation Check\n# Verifies documentation of priority service provisions\n\nDOC_DIR=\"${CP8_DOC_DIR:-/etc/compliance/cp8}\"\nREPORT_FILE=\"/var/log/cp8.1_sla_audit.log\"\n\necho \"=== CP-8.1 Priority of Service Provisions Audit ===\"\necho \"Timestamp: $(date -Iseconds)\"\necho \"Checking documentation in: $DOC_DIR\"\n\n# Required documentation files\nREQUIRED_DOCS=(\n    \"primary_provider_sla.pdf\"\n    \"alternate_provider_sla.pdf\"\n    \"tsp_enrollment.pdf\"\n    \"escalation_procedures.md\"\n    \"priority_contacts.json\"\n)\n\nMISSING=0\nfor doc in \"${REQUIRED_DOCS[@]}\"; do\n    if [ -f \"$DOC_DIR/$doc\" ]; then\n        echo \"[FOUND] $doc\"\n    else\n        echo \"[MISSING] $doc\"\n        ((MISSING++))\n    fi\ndone\n\nif [ $MISSING -eq 0 ]; then\n    echo \"\n[COMPLIANT] All required SLA documentation present\"\nelse\n    echo \"\n[NON-COMPLIANT] Missing $MISSING required document(s)\"\nfi\n\necho \"Audit logged to: $REPORT_FILE\""
      },
      "windows": {
        "powershell": "# sla_compliance_check\n# CP-8.1: SLA Compliance Documentation Check (PowerShell)\n# Verifies documentation of priority service provisions\n\nparam(\n    [string]$DocPath = 'C:\\Compliance\\CP8',\n    [string]$ReportFile = 'C:\\Logs\\CP8.1_SLA_Audit.log'\n)\n\nWrite-Host \"=== CP-8.1 Priority of Service Provisions Audit ===\"\nWrite-Host \"Timestamp: $(Get-Date -Format 'yyyy-MM-ddTHH:mm:ssK')\"\nWrite-Host \"Checking documentation in: $DocPath\"\n\n$requiredDocs = @(\n    'primary_provider_sla.pdf',\n    'alternate_provider_sla.pdf',\n    'tsp_enrollment.pdf',\n    'escalation_procedures.md',\n    'priority_contacts.json'\n)\n\n$missing = 0\nforeach ($doc in $requiredDocs) {\n    $fullPath = Join-Path $DocPath $doc\n    if (Test-Path $fullPath) {\n        Write-Host \"[FOUND] $doc\" -ForegroundColor Green\n    } else {\n        Write-Host \"[MISSING] $doc\" -ForegroundColor Red\n        $missing++\n    }\n}\n\nif ($missing -eq 0) {\n    Write-Host \"`n[COMPLIANT] All required SLA documentation present\" -ForegroundColor Green\n} else {\n    Write-Host \"`n[NON-COMPLIANT] Missing $missing required document(s)\" -ForegroundColor Red\n}\n\nWrite-Host \"Audit logged to: $ReportFile\""
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true,
      "qa_agent": "loveless"
    },
    "cac_metadata": {
      "implementation_type": "organizational",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "This control primarily requires contractual and procedural documentation. Scripts verify presence of required documentation."
    },
    "rationale": "During widespread outages, telecom providers prioritize certain customers. This ensures you're on that priority list."
  },
  {
    "control_id": "CP-8.2",
    "control_name": "Single Points of Failure",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": "TCOM-CP-000003",
    "official_text": "Obtain alternate telecommunications services to reduce the likelihood of sharing a single point of failure with primary telecommunications services.",
    "parent_control": "CP-8",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": true,
      "high": true
    },
    "intent": "Eliminate single points of failure in telecommunications infrastructure by ensuring alternate services use different physical infrastructure, routing paths, and equipment than primary services.",
    "plain_english_explanation": "Your backup telecommunications services must not share any critical components with your primary services. If your main internet comes through fiber from Provider A, your backup should not use the same fiber route, the same building entry point, or the same upstream provider. The goal is that no single equipment failure, cable cut, or facility issue can take out both your primary and backup telecommunications simultaneously.",
    "ai_guidance": "When implementing CP-8.2 Single Points of Failure elimination, conduct a thorough infrastructure mapping exercise to identify all shared components between primary and alternate telecommunications paths. Verify that alternate services use different last-mile connectivity (e.g., fiber vs. wireless vs. cable), different physical building entry points, different upstream providers, and different core routing infrastructure. Document all identified single points of failure and implement mitigations. Consider diverse technologies such as combining terrestrial and satellite links. Regularly audit provider infrastructure to ensure separation is maintained as providers merge or change their networks.",
    "example_implementation": "Map all telecommunications paths from premise to internet backbone. Verify different physical routes, different carrier hotels, and different upstream transit providers for primary vs. alternate.",
    "non_technical_guidance": "1. Request infrastructure diagrams from primary and alternate providers.\n2. Identify all shared components: building entry, conduit, central offices, upstream providers.\n3. Document each identified single point of failure.\n4. Work with providers to eliminate shared infrastructure where possible.\n5. Consider technology diversity (fiber + wireless + satellite).\n6. Verify physical path separation through site surveys.\n7. Include SPOF analysis in provider selection criteria.\n8. Re-verify separation annually and after provider infrastructure changes.",
    "is_technical": true,
    "enhancements": [],
    "related_controls": [
      "CP-8",
      "CP-8.3",
      "SC-7"
    ],
    "supplemental_guidance": "Single points of failure can exist at multiple levels including physical facilities, telecommunications carrier central offices, cable routing, transmission equipment, and upstream provider interconnections. Organizations analyze the telecommunications infrastructure to identify and eliminate common points of failure.",
    "implementation_scripts": {
      "linux": {
        "bash": "# spof_analysis\n#!/bin/bash\n# CP-8.2: Single Point of Failure Analysis\n# Traces network paths to identify potential SPOF\n\necho \"=== CP-8.2 Single Point of Failure Analysis ===\"\necho \"Timestamp: $(date -Iseconds)\"\n\n# Define test targets representing different paths\nPRIMARY_TARGET=\"${PRIMARY_ISP_TEST:-8.8.8.8}\"\nALT_TARGET=\"${ALT_ISP_TEST:-1.1.1.1}\"\n\necho \"\n[INFO] Tracing PRIMARY path to $PRIMARY_TARGET:\"\ntraceroute -n -m 15 $PRIMARY_TARGET 2>/dev/null | head -20\n\necho \"\n[INFO] Tracing ALTERNATE path to $ALT_TARGET:\"\ntraceroute -n -m 15 $ALT_TARGET 2>/dev/null | head -20\n\n# Extract unique hops\necho \"\n[ANALYSIS] Comparing routing paths:\"\nPRIMARY_HOPS=$(traceroute -n -m 15 $PRIMARY_TARGET 2>/dev/null | awk '{print $2}' | grep -E '^[0-9]' | sort -u)\nALT_HOPS=$(traceroute -n -m 15 $ALT_TARGET 2>/dev/null | awk '{print $2}' | grep -E '^[0-9]' | sort -u)\n\n# Find common hops (potential SPOF)\nCOMMON=$(comm -12 <(echo \"$PRIMARY_HOPS\") <(echo \"$ALT_HOPS\"))\n\nif [ -z \"$COMMON\" ]; then\n    echo \"[PASS] No common routing hops detected - paths appear diverse\"\nelse\n    echo \"[WARNING] Common hops detected (potential SPOF):\"\n    echo \"$COMMON\"\nfi\n\n# Check local gateway diversity\necho \"\n[INFO] Local gateway analysis:\"\nip route show default | while read line; do\n    echo \"  $line\"\ndone\n\necho \"\n=== SPOF Analysis Complete ===\"\n\n# interface_diversity_check\n#!/bin/bash\n# CP-8.2: Interface Diversity Verification\n# Ensures multiple physical interfaces for redundancy\n\necho \"=== CP-8.2 Interface Diversity Check ===\"\necho \"Timestamp: $(date -Iseconds)\"\n\n# Get all network interfaces (excluding loopback)\nINTERFACES=$(ip link show | grep -E '^[0-9]+:' | grep -v 'lo:' | awk -F': ' '{print $2}')\n\necho \"\n[INFO] Available network interfaces:\"\necho \"$INTERFACES\"\n\n# Count interfaces with IP addresses\nACTIVE_COUNT=0\nfor iface in $INTERFACES; do\n    IP=$(ip addr show $iface 2>/dev/null | grep 'inet ' | awk '{print $2}')\n    if [ -n \"$IP\" ]; then\n        echo \"  [ACTIVE] $iface: $IP\"\n        ((ACTIVE_COUNT++))\n    else\n        echo \"  [NO IP] $iface\"\n    fi\ndone\n\nif [ $ACTIVE_COUNT -ge 2 ]; then\n    echo \"\n[COMPLIANT] Multiple active network interfaces: $ACTIVE_COUNT\"\nelse\n    echo \"\n[NON-COMPLIANT] Insufficient interface diversity: $ACTIVE_COUNT active\"\nfi"
      },
      "windows": {
        "powershell": "# spof_analysis\n# CP-8.2: Single Point of Failure Analysis (PowerShell)\n# Traces network paths to identify potential SPOF\n\nparam(\n    [string]$PrimaryTarget = '8.8.8.8',\n    [string]$AlternateTarget = '1.1.1.1'\n)\n\nWrite-Host \"=== CP-8.2 Single Point of Failure Analysis ===\"\nWrite-Host \"Timestamp: $(Get-Date -Format 'yyyy-MM-ddTHH:mm:ssK')\"\n\nWrite-Host \"`n[INFO] Tracing PRIMARY path to $PrimaryTarget:\"\n$primaryTrace = Test-NetConnection -ComputerName $PrimaryTarget -TraceRoute -ErrorAction SilentlyContinue\n$primaryTrace.TraceRoute | ForEach-Object { Write-Host \"  $_\" }\n\nWrite-Host \"`n[INFO] Tracing ALTERNATE path to $AlternateTarget:\"\n$altTrace = Test-NetConnection -ComputerName $AlternateTarget -TraceRoute -ErrorAction SilentlyContinue\n$altTrace.TraceRoute | ForEach-Object { Write-Host \"  $_\" }\n\n# Compare hops\nWrite-Host \"`n[ANALYSIS] Comparing routing paths:\"\n$commonHops = $primaryTrace.TraceRoute | Where-Object { $altTrace.TraceRoute -contains $_ }\n\nif ($commonHops.Count -eq 0) {\n    Write-Host \"[PASS] No common routing hops detected - paths appear diverse\" -ForegroundColor Green\n} else {\n    Write-Host \"[WARNING] Common hops detected (potential SPOF):\" -ForegroundColor Yellow\n    $commonHops | ForEach-Object { Write-Host \"  $_\" }\n}\n\n# Check local gateway diversity\nWrite-Host \"`n[INFO] Local gateway analysis:\"\nGet-NetRoute -DestinationPrefix '0.0.0.0/0' | ForEach-Object {\n    Write-Host \"  Gateway: $($_.NextHop) via $($_.InterfaceAlias)\"\n}\n\nWrite-Host \"`n=== SPOF Analysis Complete ===\"\n\n# interface_diversity_check\n# CP-8.2: Interface Diversity Verification (PowerShell)\n# Ensures multiple physical interfaces for redundancy\n\nWrite-Host \"=== CP-8.2 Interface Diversity Check ===\"\nWrite-Host \"Timestamp: $(Get-Date -Format 'yyyy-MM-ddTHH:mm:ssK')\"\n\n# Get all network adapters\n$adapters = Get-NetAdapter | Where-Object { $_.Name -ne 'Loopback' }\n\nWrite-Host \"`n[INFO] Available network interfaces:\"\n$activeCount = 0\n\nforeach ($adapter in $adapters) {\n    $ipConfig = Get-NetIPAddress -InterfaceIndex $adapter.InterfaceIndex -AddressFamily IPv4 -ErrorAction SilentlyContinue\n    if ($ipConfig) {\n        Write-Host \"  [ACTIVE] $($adapter.Name): $($ipConfig.IPAddress)\" -ForegroundColor Green\n        $activeCount++\n    } else {\n        Write-Host \"  [NO IP] $($adapter.Name)\" -ForegroundColor Gray\n    }\n}\n\nif ($activeCount -ge 2) {\n    Write-Host \"`n[COMPLIANT] Multiple active network interfaces: $activeCount\" -ForegroundColor Green\n} else {\n    Write-Host \"`n[NON-COMPLIANT] Insufficient interface diversity: $activeCount active\" -ForegroundColor Red\n}"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true,
      "qa_agent": "loveless"
    },
    "cac_metadata": {
      "implementation_type": "hybrid",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Technical scripts analyze network path diversity. Organizational assessment required for complete infrastructure mapping."
    },
    "rationale": "If all your connections go through one router or one provider, that's a single point of failure waiting to happen."
  },
  {
    "control_id": "CP-8.3",
    "control_name": "Separation of Primary and Alternate Providers",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": "TCOM-CP-000004",
    "official_text": "Obtain alternate telecommunications services from providers that are separated from primary service providers to reduce susceptibility to the same threats.",
    "parent_control": "CP-8",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": true
    },
    "intent": "Ensure telecommunications resilience by using different providers for primary and alternate services, protecting against provider-level failures, security incidents, or business disruptions affecting a single provider.",
    "plain_english_explanation": "Your primary and backup telecommunications services must come from completely different companies. If your main internet comes from Verizon, your backup should be from a different provider like AT&T or Comcast. This protects you if one provider experiences a major outage, cyberattack, bankruptcy, or other company-wide issue. Different providers also typically use different infrastructure, reducing the risk of correlated failures.",
    "ai_guidance": "When implementing CP-8.3 Provider Separation, organizations must verify that alternate telecommunications providers are legally and operationally independent from primary providers. Check for parent company relationships, shared infrastructure agreements, and common upstream dependencies. Consider geographic separation of provider headquarters and operations centers to protect against regional disasters. Evaluate provider financial stability and business continuity capabilities. Document the separation analysis and update it annually or when significant mergers/acquisitions occur in the telecommunications industry. For high-impact systems, consider three or more independent providers with different technology bases.",
    "example_implementation": "Contract with providers from different parent companies. Verify no shared infrastructure agreements. Document provider independence analysis.",
    "non_technical_guidance": "1. Identify all telecommunications providers used by the organization.\n2. Research parent company ownership of each provider.\n3. Verify providers are not subsidiaries of the same parent company.\n4. Check for shared infrastructure agreements between providers.\n5. Document the provider independence analysis.\n6. Consider provider geographic diversity (headquarters, operations centers).\n7. Monitor telecommunications industry for mergers affecting provider independence.\n8. Include provider separation requirements in procurement criteria.",
    "is_technical": false,
    "enhancements": [],
    "related_controls": [
      "CP-8",
      "CP-8.2",
      "SA-9"
    ],
    "supplemental_guidance": "Threat susceptibility refers to providers that may be subject to the same threats or natural disasters. Organizations can reduce common susceptibilities by using providers from different geographic regions, using providers with different infrastructure, using providers that use different technologies.",
    "implementation_scripts": {
      "linux": {
        "bash": "# provider_verification\n#!/bin/bash\n# CP-8.3: Provider Separation Verification\n# Documents and verifies telecommunications provider independence\n\nDOC_DIR=\"${CP8_DOC_DIR:-/etc/compliance/cp8}\"\nREPORT=\"/var/log/cp8.3_provider_separation.log\"\n\necho \"=== CP-8.3 Provider Separation Verification ===\"\necho \"Timestamp: $(date -Iseconds)\"\n\n# Check for provider documentation\necho \"\n[INFO] Checking provider documentation:\"\n\nPROVIDER_FILES=(\n    \"primary_provider_info.json\"\n    \"alternate_provider_info.json\"\n    \"provider_independence_analysis.pdf\"\n)\n\nfor file in \"${PROVIDER_FILES[@]}\"; do\n    if [ -f \"$DOC_DIR/$file\" ]; then\n        echo \"  [FOUND] $file\"\n    else\n        echo \"  [MISSING] $file\"\n    fi\ndone\n\n# Perform basic DNS analysis to show different providers\necho \"\n[INFO] DNS resolution analysis (provider diversity indicator):\"\necho \"Primary DNS servers:\"\ngrep -E '^nameserver' /etc/resolv.conf | head -2\n\n# Check different routes to identify provider diversity\necho \"\n[INFO] Routing diversity check:\"\nfor target in 8.8.8.8 1.1.1.1; do\n    echo \"  Path to $target:\"\n    ip route get $target 2>/dev/null | head -1 | sed 's/^/    /'\ndone\n\necho \"\n=== Provider Separation Check Complete ===\"\necho \"NOTE: Full provider independence verification requires manual analysis.\""
      },
      "windows": {
        "powershell": "# provider_verification\n# CP-8.3: Provider Separation Verification (PowerShell)\n# Documents and verifies telecommunications provider independence\n\nparam(\n    [string]$DocPath = 'C:\\Compliance\\CP8'\n)\n\nWrite-Host \"=== CP-8.3 Provider Separation Verification ===\"\nWrite-Host \"Timestamp: $(Get-Date -Format 'yyyy-MM-ddTHH:mm:ssK')\"\n\n# Check for provider documentation\nWrite-Host \"`n[INFO] Checking provider documentation:\"\n\n$providerFiles = @(\n    'primary_provider_info.json',\n    'alternate_provider_info.json',\n    'provider_independence_analysis.pdf'\n)\n\nforeach ($file in $providerFiles) {\n    $fullPath = Join-Path $DocPath $file\n    if (Test-Path $fullPath) {\n        Write-Host \"  [FOUND] $file\" -ForegroundColor Green\n    } else {\n        Write-Host \"  [MISSING] $file\" -ForegroundColor Yellow\n    }\n}\n\n# DNS analysis\nWrite-Host \"`n[INFO] DNS configuration (provider diversity indicator):\"\nGet-DnsClientServerAddress -AddressFamily IPv4 | Where-Object { $_.ServerAddresses } | ForEach-Object {\n    Write-Host \"  Interface: $($_.InterfaceAlias)\"\n    Write-Host \"    DNS Servers: $($_.ServerAddresses -join ', ')\"\n}\n\n# Routing diversity\nWrite-Host \"`n[INFO] Routing diversity check:\"\n$targets = @('8.8.8.8', '1.1.1.1')\nforeach ($target in $targets) {\n    $route = Find-NetRoute -RemoteIPAddress $target -ErrorAction SilentlyContinue | Select-Object -First 1\n    if ($route) {\n        Write-Host \"  Path to $target via $($route.NextHop) on $($route.InterfaceAlias)\"\n    }\n}\n\nWrite-Host \"`n=== Provider Separation Check Complete ===\"\nWrite-Host \"NOTE: Full provider independence verification requires manual analysis.\""
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true,
      "qa_agent": "loveless"
    },
    "cac_metadata": {
      "implementation_type": "organizational",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "This control is primarily organizational requiring provider analysis. Scripts verify documentation presence and provide basic network diversity indicators."
    },
    "rationale": "Using the same provider for primary and backup defeats the purpose. Different providers reduce shared risk."
  },
  {
    "control_id": "CP-8.4",
    "control_name": "Provider Contingency Plan",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": "TCOM-CP-000005",
    "official_text": "Require primary and alternate telecommunications service providers to have contingency plans. Obtain evidence of contingency testing and training by providers at organization-defined frequency.",
    "parent_control": "CP-8",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": true
    },
    "intent": "Ensure telecommunications providers have tested contingency plans to maintain or rapidly restore services during disruptions, providing confidence that the organization's telecommunications dependencies are protected by provider-level resilience.",
    "plain_english_explanation": "Your telecommunications providers must have their own disaster recovery and business continuity plans, and they must prove they test these plans regularly. Before signing contracts, request copies of provider contingency plans and evidence of their most recent contingency tests. This ensures that when disasters hit your providers, they have proven capabilities to continue serving you or restore service quickly.",
    "ai_guidance": "When implementing CP-8.4 Provider Contingency Plan requirements, organizations should establish contractual requirements for providers to maintain and test contingency plans. Request provider SOC 2 Type II reports or equivalent third-party assessments that include business continuity controls. Require providers to share contingency plan summaries (respecting their security requirements). Establish minimum testing frequency requirements (typically annually). Request notification when providers conduct major contingency exercises and summaries of results. Include right-to-audit clauses for contingency capabilities in contracts. Track provider contingency plan evidence with expiration dates to ensure current documentation.",
    "example_implementation": "Include contingency plan requirements in RFPs. Request annual evidence of provider contingency testing. Track documentation expiration dates.",
    "non_technical_guidance": "1. Include contingency plan requirements in telecommunications RFPs and contracts.\n2. Request copies of provider contingency plans or executive summaries.\n3. Define required testing frequency (e.g., annual tabletop, biennial full exercise).\n4. Request evidence of most recent contingency test results.\n5. Review provider SOC 2 Type II reports for business continuity controls.\n6. Establish notification requirements for major contingency exercises.\n7. Maintain a tracking system for provider contingency documentation.\n8. Include contingency plan review in annual provider assessments.",
    "is_technical": false,
    "enhancements": [],
    "related_controls": [
      "CP-2",
      "CP-4",
      "CP-8",
      "SA-9"
    ],
    "supplemental_guidance": "Reviews of provider contingency plans consider the proprietary nature of such plans. Obtaining evidence of provider contingency plan testing does not require independent auditing; rather organizations can accept provider attestations or documentation of plan testing.",
    "implementation_scripts": {
      "linux": {
        "bash": "# provider_contingency_tracker\n#!/bin/bash\n# CP-8.4: Provider Contingency Plan Tracker\n# Tracks and verifies provider contingency plan documentation\n\nDOC_DIR=\"${CP8_DOC_DIR:-/etc/compliance/cp8/provider_contingency}\"\nREPORT=\"/var/log/cp8.4_contingency_audit.log\"\nWARN_DAYS=30\n\necho \"=== CP-8.4 Provider Contingency Plan Audit ===\"\necho \"Timestamp: $(date -Iseconds)\"\n\n# Required documentation per provider\nREQUIRED_DOCS=(\n    \"contingency_plan_summary\"\n    \"test_evidence\"\n    \"soc2_report\"\n)\n\ncheck_provider() {\n    local provider=$1\n    local provider_dir=\"$DOC_DIR/$provider\"\n    \n    echo \"\n[PROVIDER] $provider:\"\n    \n    if [ ! -d \"$provider_dir\" ]; then\n        echo \"  [ERROR] Provider directory not found\"\n        return 1\n    fi\n    \n    local missing=0\n    for doc in \"${REQUIRED_DOCS[@]}\"; do\n        local found=$(find \"$provider_dir\" -name \"${doc}*\" -type f 2>/dev/null | head -1)\n        if [ -n \"$found\" ]; then\n            # Check file age\n            local age_days=$(( ($(date +%s) - $(stat -c %Y \"$found\")) / 86400 ))\n            if [ $age_days -gt 365 ]; then\n                echo \"  [EXPIRED] $doc (${age_days} days old)\"\n            elif [ $age_days -gt $((365 - WARN_DAYS)) ]; then\n                echo \"  [EXPIRING SOON] $doc (${age_days} days old)\"\n            else\n                echo \"  [CURRENT] $doc (${age_days} days old)\"\n            fi\n        else\n            echo \"  [MISSING] $doc\"\n            ((missing++))\n        fi\n    done\n    \n    return $missing\n}\n\n# Check all providers\nif [ -d \"$DOC_DIR\" ]; then\n    for provider_dir in \"$DOC_DIR\"/*/; do\n        if [ -d \"$provider_dir\" ]; then\n            provider=$(basename \"$provider_dir\")\n            check_provider \"$provider\"\n        fi\n    done\nelse\n    echo \"[ERROR] Documentation directory not found: $DOC_DIR\"\n    echo \"        Create directory and add provider subdirectories.\"\nfi\n\necho \"\n=== Audit Complete ===\""
      },
      "windows": {
        "powershell": "# provider_contingency_tracker\n# CP-8.4: Provider Contingency Plan Tracker (PowerShell)\n# Tracks and verifies provider contingency plan documentation\n\nparam(\n    [string]$DocPath = 'C:\\Compliance\\CP8\\Provider_Contingency',\n    [int]$WarnDays = 30,\n    [int]$ExpireDays = 365\n)\n\nWrite-Host \"=== CP-8.4 Provider Contingency Plan Audit ===\"\nWrite-Host \"Timestamp: $(Get-Date -Format 'yyyy-MM-ddTHH:mm:ssK')\"\n\n$requiredDocs = @(\n    'contingency_plan_summary',\n    'test_evidence',\n    'soc2_report'\n)\n\nfunction Check-Provider {\n    param([string]$ProviderName, [string]$ProviderPath)\n    \n    Write-Host \"`n[PROVIDER] $ProviderName:\"\n    \n    if (-not (Test-Path $ProviderPath)) {\n        Write-Host \"  [ERROR] Provider directory not found\" -ForegroundColor Red\n        return\n    }\n    \n    foreach ($doc in $requiredDocs) {\n        $found = Get-ChildItem -Path $ProviderPath -Filter \"$doc*\" -File -ErrorAction SilentlyContinue | Select-Object -First 1\n        \n        if ($found) {\n            $ageDays = ((Get-Date) - $found.LastWriteTime).Days\n            \n            if ($ageDays -gt $ExpireDays) {\n                Write-Host \"  [EXPIRED] $doc ($ageDays days old)\" -ForegroundColor Red\n            } elseif ($ageDays -gt ($ExpireDays - $WarnDays)) {\n                Write-Host \"  [EXPIRING SOON] $doc ($ageDays days old)\" -ForegroundColor Yellow\n            } else {\n                Write-Host \"  [CURRENT] $doc ($ageDays days old)\" -ForegroundColor Green\n            }\n        } else {\n            Write-Host \"  [MISSING] $doc\" -ForegroundColor Red\n        }\n    }\n}\n\n# Check all providers\nif (Test-Path $DocPath) {\n    $providers = Get-ChildItem -Path $DocPath -Directory\n    foreach ($provider in $providers) {\n        Check-Provider -ProviderName $provider.Name -ProviderPath $provider.FullName\n    }\n} else {\n    Write-Host \"[ERROR] Documentation directory not found: $DocPath\" -ForegroundColor Red\n    Write-Host \"        Create directory and add provider subdirectories.\"\n}\n\nWrite-Host \"`n=== Audit Complete ===\""
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true,
      "qa_agent": "loveless"
    },
    "cac_metadata": {
      "implementation_type": "organizational",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "This control requires provider documentation management. Scripts track documentation currency and identify expired or missing evidence."
    },
    "rationale": "Your telecom provider needs their own contingency plan. Their failure is your failure."
  },
  {
    "control_id": "CP-8.5",
    "control_name": "Alternate Telecommunication Service Testing",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": "TCOM-CP-000006",
    "official_text": "Test alternate telecommunication services at organization-defined frequency.",
    "parent_control": "CP-8",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "intent": "Verify that alternate telecommunications services actually work as expected through regular testing, ensuring that failover will succeed when genuinely needed during an actual outage.",
    "plain_english_explanation": "You must regularly test your backup telecommunications services to prove they actually work. This means periodically switching to your backup internet, phone, or data connections and verifying that your critical systems continue to function. Testing should occur at a frequency appropriate to your organization's risk tolerance - typically quarterly or annually. Without testing, you cannot be confident that your backup services will work when you need them most.",
    "ai_guidance": "When implementing CP-8.5 Alternate Telecommunication Service Testing, organizations should establish a formal testing schedule based on risk assessment (typically quarterly for high-impact systems, annually for moderate). Define specific test scenarios including full failover tests and partial capability tests. Document test procedures including rollback plans. Capture metrics during tests: failover time, service degradation, application compatibility. Maintain test logs with findings and corrective actions. Consider automated failover testing where technology permits. Coordinate testing with business units to minimize operational impact. After each test, update procedures based on lessons learned.",
    "example_implementation": "Conduct quarterly failover tests to alternate ISP. Document failover time and any service degradation. Maintain test logs with findings and corrective actions.",
    "non_technical_guidance": "1. Define testing frequency based on system criticality (quarterly, semi-annually, annually).\n2. Develop detailed test procedures for each alternate telecommunications service.\n3. Establish success criteria for each test scenario.\n4. Schedule tests during low-impact periods when possible.\n5. Notify affected stakeholders before testing.\n6. Execute tests following documented procedures.\n7. Measure and record failover time and service performance.\n8. Document findings, issues, and corrective actions.\n9. Update procedures based on test results.\n10. Report test outcomes to management.",
    "is_technical": true,
    "enhancements": [],
    "related_controls": [
      "CP-4",
      "CP-8"
    ],
    "supplemental_guidance": "Testing of alternate telecommunications services validates the ability of alternate services to support the organization's mission/business needs. Failover testing demonstrates actual switchover capability. Periodic testing helps identify configuration issues, capacity limitations, or integration problems before they impact actual emergency operations.",
    "implementation_scripts": {
      "linux": {
        "bash": "# failover_test\n#!/bin/bash\n# CP-8.5: Alternate Telecommunications Failover Test\n# Comprehensive failover testing and documentation\n\nLOG_DIR=\"/var/log/cp8_tests\"\nTEST_LOG=\"$LOG_DIR/failover_test_$(date +%Y%m%d_%H%M%S).log\"\nPRIMARY_GW=\"${PRIMARY_GATEWAY:-192.168.1.1}\"\nALT_GW=\"${ALTERNATE_GATEWAY:-192.168.2.1}\"\nTEST_TARGETS=(\"8.8.8.8\" \"1.1.1.1\" \"9.9.9.9\")\n\nmkdir -p \"$LOG_DIR\"\n\nlog() {\n    echo \"$(date -Iseconds) | $1\" | tee -a \"$TEST_LOG\"\n}\n\ntest_connectivity() {\n    local path_name=$1\n    local success=0\n    local total=0\n    \n    for target in \"${TEST_TARGETS[@]}\"; do\n        ((total++))\n        if ping -c 3 -W 2 $target > /dev/null 2>&1; then\n            ((success++))\n            log \"  [PASS] $target reachable via $path_name\"\n        else\n            log \"  [FAIL] $target unreachable via $path_name\"\n        fi\n    done\n    \n    echo \"$success/$total\"\n}\n\nlog \"=============================================\"\nlog \"CP-8.5 ALTERNATE TELECOMMUNICATIONS TEST\"\nlog \"=============================================\"\nlog \"Primary Gateway: $PRIMARY_GW\"\nlog \"Alternate Gateway: $ALT_GW\"\nlog \"\"\n\n# Phase 1: Baseline connectivity via primary\nlog \"[PHASE 1] Testing PRIMARY path connectivity:\"\nPRIMARY_RESULT=$(test_connectivity \"PRIMARY\")\nlog \"Primary path result: $PRIMARY_RESULT targets reachable\"\n\n# Phase 2: Test alternate path (simulated - actual failover requires network changes)\nlog \"\"\nlog \"[PHASE 2] Testing ALTERNATE gateway availability:\"\nif ping -c 3 -W 2 $ALT_GW > /dev/null 2>&1; then\n    log \"[PASS] Alternate gateway $ALT_GW is responsive\"\n    ALT_GW_STATUS=\"AVAILABLE\"\nelse\n    log \"[FAIL] Alternate gateway $ALT_GW not responding\"\n    ALT_GW_STATUS=\"UNAVAILABLE\"\nfi\n\n# Phase 3: Measure latency to both gateways\nlog \"\"\nlog \"[PHASE 3] Latency comparison:\"\nPRIMARY_LATENCY=$(ping -c 5 -W 2 $PRIMARY_GW 2>/dev/null | tail -1 | awk -F'/' '{print $5}')\nALT_LATENCY=$(ping -c 5 -W 2 $ALT_GW 2>/dev/null | tail -1 | awk -F'/' '{print $5}')\nlog \"Primary gateway latency: ${PRIMARY_LATENCY:-N/A} ms\"\nlog \"Alternate gateway latency: ${ALT_LATENCY:-N/A} ms\"\n\n# Summary\nlog \"\"\nlog \"=============================================\"\nlog \"TEST SUMMARY\"\nlog \"=============================================\"\nlog \"Primary Path: $PRIMARY_RESULT connectivity\"\nlog \"Alternate Gateway: $ALT_GW_STATUS\"\nlog \"Test Log: $TEST_LOG\"\nlog \"\"\n\nif [ \"$ALT_GW_STATUS\" = \"AVAILABLE\" ]; then\n    log \"[RESULT] PASS - Alternate telecommunications path available\"\n    log \"NOTE: Full failover test requires controlled network switch\"\n    exit 0\nelse\n    log \"[RESULT] FAIL - Alternate telecommunications path unavailable\"\n    exit 1\nfi\n\n# test_scheduler\n#!/bin/bash\n# CP-8.5: Automated Test Scheduler\n# Generates cron entry for periodic failover testing\n\nTEST_SCRIPT=\"/usr/local/bin/cp8_failover_test.sh\"\nTEST_FREQUENCY=\"${TEST_FREQUENCY:-quarterly}\"\n\necho \"=== CP-8.5 Test Scheduler Setup ===\"\necho \"Test Script: $TEST_SCRIPT\"\necho \"Frequency: $TEST_FREQUENCY\"\n\ncase $TEST_FREQUENCY in\n    weekly)\n        CRON_SCHEDULE=\"0 2 * * 0\"  # Sunday 2 AM\n        ;;\n    monthly)\n        CRON_SCHEDULE=\"0 2 1 * *\"  # 1st of month 2 AM\n        ;;\n    quarterly)\n        CRON_SCHEDULE=\"0 2 1 */3 *\"  # Every 3 months\n        ;;\n    annually)\n        CRON_SCHEDULE=\"0 2 1 1 *\"  # January 1st 2 AM\n        ;;\n    *)\n        echo \"[ERROR] Unknown frequency: $TEST_FREQUENCY\"\n        echo \"Valid options: weekly, monthly, quarterly, annually\"\n        exit 1\n        ;;\nesac\n\necho \"\n[INFO] Recommended cron entry:\"\necho \"$CRON_SCHEDULE root $TEST_SCRIPT\"\necho \"\n[INFO] Add to /etc/crontab or use: crontab -e\""
      },
      "windows": {
        "powershell": "# failover_test\n# CP-8.5: Alternate Telecommunications Failover Test (PowerShell)\n# Comprehensive failover testing and documentation\n\nparam(\n    [string]$LogDir = 'C:\\Logs\\CP8_Tests',\n    [string]$PrimaryGateway = '192.168.1.1',\n    [string]$AlternateGateway = '192.168.2.1'\n)\n\n$timestamp = Get-Date -Format 'yyyyMMdd_HHmmss'\n$testLog = Join-Path $LogDir \"failover_test_$timestamp.log\"\n$testTargets = @('8.8.8.8', '1.1.1.1', '9.9.9.9')\n\n# Ensure log directory exists\nif (-not (Test-Path $LogDir)) {\n    New-Item -ItemType Directory -Path $LogDir -Force | Out-Null\n}\n\nfunction Write-Log {\n    param([string]$Message)\n    $entry = \"$(Get-Date -Format 'yyyy-MM-ddTHH:mm:ssK') | $Message\"\n    Add-Content -Path $testLog -Value $entry\n    Write-Host $entry\n}\n\nfunction Test-PathConnectivity {\n    param([string]$PathName)\n    $success = 0\n    $total = $testTargets.Count\n    \n    foreach ($target in $testTargets) {\n        $result = Test-Connection -ComputerName $target -Count 3 -Quiet -ErrorAction SilentlyContinue\n        if ($result) {\n            $success++\n            Write-Log \"  [PASS] $target reachable via $PathName\"\n        } else {\n            Write-Log \"  [FAIL] $target unreachable via $PathName\"\n        }\n    }\n    \n    return \"$success/$total\"\n}\n\nWrite-Log \"=============================================\"\nWrite-Log \"CP-8.5 ALTERNATE TELECOMMUNICATIONS TEST\"\nWrite-Log \"=============================================\"\nWrite-Log \"Primary Gateway: $PrimaryGateway\"\nWrite-Log \"Alternate Gateway: $AlternateGateway\"\nWrite-Log \"\"\n\n# Phase 1: Baseline connectivity via primary\nWrite-Log \"[PHASE 1] Testing PRIMARY path connectivity:\"\n$primaryResult = Test-PathConnectivity -PathName 'PRIMARY'\nWrite-Log \"Primary path result: $primaryResult targets reachable\"\n\n# Phase 2: Test alternate gateway availability\nWrite-Log \"\"\nWrite-Log \"[PHASE 2] Testing ALTERNATE gateway availability:\"\n$altGwTest = Test-Connection -ComputerName $AlternateGateway -Count 3 -Quiet -ErrorAction SilentlyContinue\nif ($altGwTest) {\n    Write-Log \"[PASS] Alternate gateway $AlternateGateway is responsive\"\n    $altGwStatus = 'AVAILABLE'\n} else {\n    Write-Log \"[FAIL] Alternate gateway $AlternateGateway not responding\"\n    $altGwStatus = 'UNAVAILABLE'\n}\n\n# Phase 3: Latency comparison\nWrite-Log \"\"\nWrite-Log \"[PHASE 3] Latency comparison:\"\n$primaryPing = Test-Connection -ComputerName $PrimaryGateway -Count 5 -ErrorAction SilentlyContinue\n$altPing = Test-Connection -ComputerName $AlternateGateway -Count 5 -ErrorAction SilentlyContinue\n\n$primaryLatency = if ($primaryPing) { ($primaryPing | Measure-Object -Property ResponseTime -Average).Average } else { 'N/A' }\n$altLatency = if ($altPing) { ($altPing | Measure-Object -Property ResponseTime -Average).Average } else { 'N/A' }\n\nWrite-Log \"Primary gateway latency: $primaryLatency ms\"\nWrite-Log \"Alternate gateway latency: $altLatency ms\"\n\n# Summary\nWrite-Log \"\"\nWrite-Log \"=============================================\"\nWrite-Log \"TEST SUMMARY\"\nWrite-Log \"=============================================\"\nWrite-Log \"Primary Path: $primaryResult connectivity\"\nWrite-Log \"Alternate Gateway: $altGwStatus\"\nWrite-Log \"Test Log: $testLog\"\nWrite-Log \"\"\n\nif ($altGwStatus -eq 'AVAILABLE') {\n    Write-Log \"[RESULT] PASS - Alternate telecommunications path available\"\n    Write-Log \"NOTE: Full failover test requires controlled network switch\"\n    exit 0\n} else {\n    Write-Log \"[RESULT] FAIL - Alternate telecommunications path unavailable\"\n    exit 1\n}\n\n# test_scheduler\n# CP-8.5: Automated Test Scheduler (PowerShell)\n# Creates scheduled task for periodic failover testing\n\nparam(\n    [string]$TestScript = 'C:\\Scripts\\CP8_Failover_Test.ps1',\n    [ValidateSet('Weekly', 'Monthly', 'Quarterly', 'Annually')]\n    [string]$Frequency = 'Quarterly',\n    [string]$TaskName = 'CP-8.5 Telecommunications Failover Test'\n)\n\nWrite-Host \"=== CP-8.5 Test Scheduler Setup ===\"\nWrite-Host \"Test Script: $TestScript\"\nWrite-Host \"Frequency: $Frequency\"\n\n# Define trigger based on frequency\nswitch ($Frequency) {\n    'Weekly' {\n        $trigger = New-ScheduledTaskTrigger -Weekly -DaysOfWeek Sunday -At 2am\n    }\n    'Monthly' {\n        $trigger = New-ScheduledTaskTrigger -Monthly -DaysOfMonth 1 -At 2am\n    }\n    'Quarterly' {\n        # Quarterly requires multiple triggers for months 1, 4, 7, 10\n        $trigger = New-ScheduledTaskTrigger -Monthly -DaysOfMonth 1 -At 2am -MonthsOfYear January, April, July, October\n    }\n    'Annually' {\n        $trigger = New-ScheduledTaskTrigger -Monthly -DaysOfMonth 1 -At 2am -MonthsOfYear January\n    }\n}\n\n$action = New-ScheduledTaskAction -Execute 'PowerShell.exe' -Argument \"-ExecutionPolicy Bypass -File `\"$TestScript`\"\"\n$principal = New-ScheduledTaskPrincipal -UserId 'SYSTEM' -LogonType ServiceAccount -RunLevel Highest\n$settings = New-ScheduledTaskSettingsSet -ExecutionTimeLimit (New-TimeSpan -Hours 1) -RestartCount 3\n\nWrite-Host \"`n[INFO] Creating scheduled task: $TaskName\"\n\ntry {\n    Register-ScheduledTask -TaskName $TaskName -Trigger $trigger -Action $action -Principal $principal -Settings $settings -Force\n    Write-Host \"[SUCCESS] Scheduled task created successfully\" -ForegroundColor Green\n} catch {\n    Write-Host \"[ERROR] Failed to create scheduled task: $_\" -ForegroundColor Red\n}"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_verified": true,
      "qa_agent": "loveless"
    },
    "cac_metadata": {
      "implementation_type": "hybrid",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Technical scripts perform automated failover readiness testing. Full failover tests require planned network changes and should be coordinated with operations."
    },
    "rationale": "Regular testing ensures your backup telecom services actually work when you need them."
  },
  {
    "control_id": "CP-9",
    "control_name": "System Backup",
    "family": "Contingency Planning",
    "family_id": "CP",
    "official_text": "a. Conduct backups of user-level information contained in [Assignment: organization-defined system components] [Assignment: organization-defined frequency consistent with recovery time and recovery point objectives];\nb. Conduct backups of system-level information contained in the system [Assignment: organization-defined frequency consistent with recovery time and recovery point objectives];\nc. Conduct backups of system documentation, including security- and privacy-related documentation [Assignment: organization-defined frequency consistent with recovery time and recovery point objectives]; and\nd. Protect the confidentiality, integrity, and availability of backup information.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": true,
      "moderate": true,
      "high": true
    },
    "stig_id": "SRG-OS-000479-GPOS-00224",
    "plain_english_explanation": "System Backup requires organizations to regularly create copies of critical data, system configurations, operating system files, and documentation so that operations can be restored if the primary system fails, is compromised, or suffers data loss. This includes user files and databases, operating system and application software, security configurations, and all documentation needed to rebuild and operate the system. Backups must be performed at frequencies aligned with how much data loss the organization can tolerate (Recovery Point Objective) and how quickly systems must be restored (Recovery Time Objective). The backup data itself must be protected from unauthorized access, modification, and destruction with the same rigor as production data.",
    "intent": "The System Backup control establishes the foundation for organizational resilience by ensuring that critical information and system components can be recovered following disruptions, failures, or security incidents. Without reliable backups performed at appropriate frequencies, organizations risk permanent data loss and extended outages that could severely impact mission operations. This control mandates not just the creation of backups but their protection, recognizing that backup media often contains sensitive information and represents a potential attack vector if not properly secured.",
    "example_implementation": "Implement a comprehensive backup strategy that includes: (1) Daily incremental backups and weekly full backups of user data to on-premises storage with 30-day retention; (2) Weekly system image backups of all servers including OS, applications, and configurations; (3) Monthly backups of all system documentation including network diagrams, runbooks, and security policies; (4) AES-256 encryption of all backup data at rest and in transit; (5) Automated backup verification through checksum validation; (6) Off-site replication of critical backups to a geographically separate facility; (7) Quarterly restoration tests to verify backup integrity and procedure effectiveness.",
    "non_technical_guidance": "To comply with control CP-9 (System Backup), organizations should follow these procedures:\n1. Inventory all systems and data requiring backup protection, categorizing by criticality and sensitivity.\n2. Define Recovery Time Objectives (RTO) and Recovery Point Objectives (RPO) for each system category based on mission impact analysis.\n3. Establish backup frequencies that meet RPO requirements - critical systems may require hourly backups while less critical systems may use daily or weekly schedules.\n4. Select backup methods appropriate to data types: full backups, incremental backups, differential backups, or continuous data protection.\n5. Implement backup solutions for user-level information including databases, file shares, email, and application data.\n6. Implement system-level backups capturing operating system configurations, installed software, and security settings.\n7. Maintain current backups of all system documentation including architecture diagrams, configuration guides, and security documentation.\n8. Encrypt backup data using approved cryptographic methods (FIPS 140-2 validated for federal systems).\n9. Store backup media securely with access controls limiting who can access, modify, or destroy backups.\n10. Maintain backup logs documenting successful completions, failures, and any required remediation.\n11. Test backup restoration procedures regularly to verify data recoverability.\n12. Retain backups according to organizational policies and legal/regulatory requirements.",
    "implementation_guidance": "System Backup is a TECHNICAL control requiring deployment of backup infrastructure and automation. Implementation involves:\n\n1. BACKUP INFRASTRUCTURE: Deploy enterprise backup solutions (Veeam, Commvault, Bacula, Borgbackup) capable of handling organizational data volumes and meeting RTO/RPO requirements. Consider hybrid approaches with local backups for fast recovery and cloud/off-site for disaster recovery.\n\n2. USER-LEVEL BACKUPS: Configure backups for all user data including file servers, databases, email systems, and application data. Use application-aware backup agents for databases to ensure consistency.\n\n3. SYSTEM-LEVEL BACKUPS: Implement system image backups or configuration management that captures OS state, installed software, and security configurations. For cloud environments, use native snapshot capabilities combined with configuration-as-code.\n\n4. DOCUMENTATION BACKUPS: Establish version-controlled repositories for system documentation with regular exports to backup storage.\n\n5. ENCRYPTION: Implement encryption for backup data at rest (AES-256) and in transit (TLS 1.2+). Use key management practices that ensure keys are available for restoration.\n\n6. AUTOMATION: Schedule automated backups with monitoring and alerting for failures. Implement backup verification through checksum validation and automated restoration testing.\n\n7. RETENTION: Configure backup retention periods aligned with organizational policies, typically 30-90 days for operational backups with longer retention for compliance archives.\n\n8. MONITORING: Implement backup monitoring dashboards tracking completion rates, data growth, and storage utilization.",
    "ai_guidance": "When implementing CP-9 System Backup compliance, AI systems can significantly enhance backup operations through intelligent automation and predictive analytics. AI-powered backup solutions can analyze data change patterns to optimize backup windows and reduce backup times by identifying and prioritizing frequently changing data. Machine learning can predict storage capacity requirements based on historical growth trends, enabling proactive capacity planning before backup storage is exhausted. AI can detect anomalies in backup data that might indicate ransomware encryption or data corruption, alerting administrators before corrupted data propagates through the backup chain. Natural language processing can analyze backup logs and error messages to automatically categorize failures and suggest remediation steps based on historical resolution patterns. AI-driven deduplication can achieve higher compression ratios by identifying similar data patterns across diverse file types. For restoration, AI can predict recovery time based on data volumes and infrastructure capacity, helping organizations validate that RTOs can be achieved. AI can optimize backup scheduling across large environments to minimize network congestion and production system impact while ensuring all systems meet their RPO requirements. Automated testing frameworks can use AI to generate realistic restoration scenarios and validate data integrity post-recovery. For compliance, AI can continuously audit backup configurations against policy requirements and flag systems that have missed backup windows or have inadequate protection. Integration of AI with configuration management enables automatic backup policy adjustment when new systems are deployed or system criticality changes.",
    "is_technical": true,
    "enhancements": [
      {
        "id": "CP-9.1",
        "title": "Testing for Reliability and Integrity",
        "official_text": "Test backup information [Assignment: organization-defined frequency] to verify media reliability and information integrity."
      },
      {
        "id": "CP-9.2",
        "title": "Test Restoration Using Sampling",
        "official_text": "Use a sample of backup information in the restoration of selected system functions as part of contingency plan testing."
      },
      {
        "id": "CP-9.3",
        "title": "Separate Storage for Critical Information",
        "official_text": "Store backup copies of [Assignment: organization-defined critical system software and other security-related information] in a separate facility or in a fire rated container that is not collocated with the operational system."
      },
      {
        "id": "CP-9.4",
        "title": "Protection from Unauthorized Modification",
        "official_text": "[Withdrawn: Incorporated into CP-9.]",
        "status": "withdrawn"
      },
      {
        "id": "CP-9.5",
        "title": "Transfer to Alternate Storage Site",
        "official_text": "Transfer system backup information to the alternate storage site [Assignment: organization-defined time period and transfer rate consistent with the recovery time and recovery point objectives]."
      },
      {
        "id": "CP-9.6",
        "title": "Redundant Secondary System",
        "official_text": "Conduct system backup by maintaining a redundant secondary system that is not collocated with the primary system and that can be activated without loss of information or disruption to operations."
      },
      {
        "id": "CP-9.7",
        "title": "Dual Authorization for Deletion or Destruction",
        "official_text": "Enforce dual authorization for the deletion or destruction of [Assignment: organization-defined backup information]."
      },
      {
        "id": "CP-9.8",
        "title": "Cryptographic Protection",
        "official_text": "Implement cryptographic mechanisms to prevent unauthorized disclosure and modification of [Assignment: organization-defined backup information]."
      }
    ],
    "related_controls": [
      "CP-2",
      "CP-4",
      "CP-6",
      "CP-7",
      "CP-10",
      "MP-2",
      "MP-4",
      "MP-5",
      "SC-8",
      "SC-12",
      "SC-13",
      "SC-28",
      "SI-4",
      "SI-13"
    ],
    "supplemental_guidance": "System-level information includes system state information, operating system software, middleware, application software, and licenses. User-level information includes information other than system-level information. Mechanisms employed to protect the integrity of system backups include digital signatures and cryptographic hashes. Protection of system backup information while in transit is addressed by MP-5 and SC-8. System backups reflect the requirements in contingency plans as well as other organizational requirements for backing up information. Organizations may be subject to laws, executive orders, directives, regulations, or policies that affect the length of time backups are retained.",
    "implementation_scripts": {
      "linux": {
        "bash": "#!/bin/bash\n# CP-9 System Backup Implementation Script\n# Comprehensive backup solution for Linux systems\n\nset -e\n\n# Configuration\nBACKUP_DIR=\"/var/backups/system\"\nLOG_FILE=\"/var/log/system_backup.log\"\nREMOTE_SERVER=\"backup.example.com\"\nRETENTION_DAYS=30\n\n# Create backup directories\nmkdir -p \"$BACKUP_DIR\"/{daily,weekly,monthly}\nmkdir -p /var/log/backup\n\nlog_message() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" | tee -a \"$LOG_FILE\"\n}\n\n# Backup user-level information\nbackup_user_data() {\n    log_message \"Starting user data backup\"\n    tar -czf \"$BACKUP_DIR/daily/user_data_$(date +%Y%m%d).tar.gz\" \\\n        /home \\\n        /var/www \\\n        /var/lib/mysql \\\n        --exclude='*.tmp' \\\n        --exclude='*.log' 2>/dev/null || true\n    log_message \"User data backup completed\"\n}\n\n# Backup system-level information\nbackup_system_data() {\n    log_message \"Starting system backup\"\n    \n    # Backup /etc configurations\n    tar -czf \"$BACKUP_DIR/daily/etc_$(date +%Y%m%d).tar.gz\" /etc 2>/dev/null\n    \n    # Backup installed packages list\n    if command -v rpm &>/dev/null; then\n        rpm -qa > \"$BACKUP_DIR/daily/installed_packages_$(date +%Y%m%d).txt\"\n    elif command -v dpkg &>/dev/null; then\n        dpkg --get-selections > \"$BACKUP_DIR/daily/installed_packages_$(date +%Y%m%d).txt\"\n    fi\n    \n    # Backup crontabs\n    tar -czf \"$BACKUP_DIR/daily/crontabs_$(date +%Y%m%d).tar.gz\" /var/spool/cron 2>/dev/null || true\n    \n    # Backup boot configuration\n    tar -czf \"$BACKUP_DIR/daily/boot_$(date +%Y%m%d).tar.gz\" /boot 2>/dev/null || true\n    \n    log_message \"System backup completed\"\n}\n\n# Backup security documentation\nbackup_security_docs() {\n    log_message \"Starting security documentation backup\"\n    \n    # Backup security policies and audit rules\n    tar -czf \"$BACKUP_DIR/daily/security_$(date +%Y%m%d).tar.gz\" \\\n        /etc/audit \\\n        /etc/security \\\n        /etc/pam.d \\\n        /etc/ssh \\\n        /etc/sudoers.d 2>/dev/null || true\n    \n    log_message \"Security documentation backup completed\"\n}\n\n# Generate backup checksums for integrity verification\ngenerate_checksums() {\n    log_message \"Generating backup checksums\"\n    cd \"$BACKUP_DIR/daily\"\n    sha256sum *.tar.gz *.txt 2>/dev/null > \"checksums_$(date +%Y%m%d).sha256\" || true\n    log_message \"Checksums generated\"\n}\n\n# Verify backup integrity\nverify_backups() {\n    log_message \"Verifying backup integrity\"\n    cd \"$BACKUP_DIR/daily\"\n    if [ -f \"checksums_$(date +%Y%m%d).sha256\" ]; then\n        if sha256sum -c \"checksums_$(date +%Y%m%d).sha256\" 2>/dev/null; then\n            log_message \"Backup integrity verified successfully\"\n        else\n            log_message \"WARNING: Backup integrity check failed!\"\n            exit 1\n        fi\n    fi\n}\n\n# Encrypt backups using GPG\nencrypt_backups() {\n    log_message \"Encrypting backup files\"\n    cd \"$BACKUP_DIR/daily\"\n    for file in *.tar.gz; do\n        if [ -f \"$file\" ] && [ ! -f \"${file}.gpg\" ]; then\n            gpg --symmetric --cipher-algo AES256 --batch --passphrase-file /root/.backup_key \"$file\" 2>/dev/null && rm \"$file\"\n        fi\n    done\n    log_message \"Backup encryption completed\"\n}\n\n# Rotate old backups\nrotate_backups() {\n    log_message \"Rotating old backups\"\n    find \"$BACKUP_DIR/daily\" -type f -mtime +$RETENTION_DAYS -delete\n    log_message \"Old backups removed\"\n}\n\n# Main execution\nlog_message \"=== CP-9 System Backup Started ===\"\nbackup_user_data\nbackup_system_data\nbackup_security_docs\ngenerate_checksums\nverify_backups\n# encrypt_backups  # Uncomment when GPG key is configured\nrotate_backups\nlog_message \"=== CP-9 System Backup Completed ===\"",
        "ansible": "---\n# CP-9 System Backup Ansible Playbook\n- name: CP-9 System Backup Configuration\n  hosts: all\n  become: yes\n  vars:\n    backup_dir: /var/backups/system\n    retention_days: 30\n    backup_user: backup\n    remote_backup_server: backup.example.com\n  \n  tasks:\n    - name: Install backup utilities\n      package:\n        name:\n          - rsync\n          - tar\n          - gzip\n          - gnupg2\n        state: present\n\n    - name: Create backup directories\n      file:\n        path: \"{{ item }}\"\n        state: directory\n        owner: root\n        group: root\n        mode: '0750'\n      loop:\n        - \"{{ backup_dir }}/daily\"\n        - \"{{ backup_dir }}/weekly\"\n        - \"{{ backup_dir }}/monthly\"\n        - /var/log/backup\n\n    - name: Deploy backup script\n      copy:\n        dest: /usr/local/bin/system_backup.sh\n        mode: '0750'\n        owner: root\n        group: root\n        content: |\n          #!/bin/bash\n          BACKUP_DIR={{ backup_dir }}\n          DATE=$(date +%Y%m%d)\n          \n          # User data backup\n          tar -czf $BACKUP_DIR/daily/user_data_$DATE.tar.gz /home /var/www 2>/dev/null || true\n          \n          # System config backup\n          tar -czf $BACKUP_DIR/daily/system_config_$DATE.tar.gz /etc 2>/dev/null\n          \n          # Security config backup\n          tar -czf $BACKUP_DIR/daily/security_$DATE.tar.gz /etc/audit /etc/security /etc/pam.d /etc/ssh 2>/dev/null || true\n          \n          # Generate checksums\n          cd $BACKUP_DIR/daily && sha256sum *_$DATE.tar.gz > checksums_$DATE.sha256\n          \n          # Cleanup old backups\n          find $BACKUP_DIR/daily -type f -mtime +{{ retention_days }} -delete\n          \n          echo \"$(date): Backup completed\" >> /var/log/backup/backup.log\n\n    - name: Schedule daily backup\n      cron:\n        name: \"CP-9 Daily System Backup\"\n        hour: \"2\"\n        minute: \"0\"\n        job: \"/usr/local/bin/system_backup.sh\"\n        user: root\n\n    - name: Schedule weekly full backup\n      cron:\n        name: \"CP-9 Weekly Full Backup\"\n        weekday: \"0\"\n        hour: \"3\"\n        minute: \"0\"\n        job: \"/usr/local/bin/system_backup.sh --full\"\n        user: root\n\n    - name: Configure rsyslog for backup logging\n      lineinfile:\n        path: /etc/rsyslog.d/backup.conf\n        line: 'local6.*  /var/log/backup/backup.log'\n        create: yes\n      notify: restart rsyslog\n\n  handlers:\n    - name: restart rsyslog\n      service:\n        name: rsyslog\n        state: restarted",
        "borgbackup": "#!/bin/bash\n# CP-9 BorgBackup Implementation\n# Enterprise-grade deduplicating backup\n\nexport BORG_REPO=/var/backups/borg\nexport BORG_PASSPHRASE='your-secure-passphrase'\n\n# Initialize repository if needed\nif [ ! -d \"$BORG_REPO\" ]; then\n    borg init --encryption=repokey-blake2 $BORG_REPO\nfi\n\n# Create backup with timestamp\nborg create --stats --compression zstd \\\n    $BORG_REPO::'{hostname}-{now:%Y-%m-%d_%H:%M}' \\\n    /home \\\n    /etc \\\n    /var/www \\\n    /var/lib/mysql \\\n    --exclude '/home/*/.cache' \\\n    --exclude '*.tmp'\n\n# Prune old backups\nborg prune --list $BORG_REPO \\\n    --keep-daily=7 \\\n    --keep-weekly=4 \\\n    --keep-monthly=6\n\n# Verify backup integrity\nborg check $BORG_REPO\n\necho \"$(date): BorgBackup completed\" >> /var/log/backup/borg.log"
      },
      "windows": {
        "powershell": "# CP-9 Windows System Backup Script\n# Comprehensive backup solution for Windows Server\n\n$BackupRoot = \"C:\\Backups\\SystemBackup\"\n$LogFile = \"C:\\Backups\\Logs\\backup_$(Get-Date -Format 'yyyyMMdd').log\"\n$RetentionDays = 30\n\n# Create directories\nNew-Item -ItemType Directory -Path \"$BackupRoot\\Daily\",\"$BackupRoot\\Weekly\",\"$BackupRoot\\Monthly\",\"C:\\Backups\\Logs\" -Force | Out-Null\n\nfunction Write-Log {\n    param([string]$Message)\n    $Timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    \"$Timestamp - $Message\" | Tee-Object -FilePath $LogFile -Append\n}\n\nWrite-Log \"=== CP-9 System Backup Started ===\"\n\n# Backup System State\nWrite-Log \"Starting System State Backup\"\ntry {\n    wbadmin start systemstatebackup -backupTarget:$BackupRoot\\Daily -quiet\n    Write-Log \"System State Backup completed\"\n} catch {\n    Write-Log \"ERROR: System State Backup failed - $_\"\n}\n\n# Backup critical directories\nWrite-Log \"Starting critical directory backup\"\n$CriticalPaths = @(\n    \"C:\\Windows\\System32\\config\",\n    \"C:\\Windows\\System32\\GroupPolicy\",\n    \"C:\\ProgramData\",\n    \"C:\\Users\"\n)\n\n$BackupDate = Get-Date -Format 'yyyyMMdd'\nforeach ($Path in $CriticalPaths) {\n    if (Test-Path $Path) {\n        $ArchiveName = ($Path -replace '[:\\\\]', '_') + \"_$BackupDate.zip\"\n        try {\n            Compress-Archive -Path $Path -DestinationPath \"$BackupRoot\\Daily\\$ArchiveName\" -Force -CompressionLevel Optimal\n            Write-Log \"Backed up: $Path\"\n        } catch {\n            Write-Log \"WARNING: Failed to backup $Path - $_\"\n        }\n    }\n}\n\n# Backup IIS Configuration\nif (Get-Service W3SVC -ErrorAction SilentlyContinue) {\n    Write-Log \"Backing up IIS Configuration\"\n    & \"$env:windir\\system32\\inetsrv\\appcmd.exe\" add backup \"IISBackup_$BackupDate\" 2>&1 | Out-Null\n}\n\n# Backup SQL Server databases (if applicable)\nif (Get-Service MSSQLSERVER -ErrorAction SilentlyContinue) {\n    Write-Log \"Backing up SQL Server databases\"\n    Invoke-Sqlcmd -Query \"BACKUP DATABASE [master] TO DISK = N'$BackupRoot\\Daily\\master_$BackupDate.bak' WITH INIT\" -ErrorAction SilentlyContinue\n}\n\n# Export Group Policy Objects\nWrite-Log \"Exporting Group Policy Objects\"\n$GPOPath = \"$BackupRoot\\Daily\\GPO_$BackupDate\"\nNew-Item -ItemType Directory -Path $GPOPath -Force | Out-Null\nGet-GPO -All | ForEach-Object { Backup-GPO -Guid $_.Id -Path $GPOPath } 2>$null\n\n# Export Security Policy\nWrite-Log \"Exporting Security Policy\"\nsecedit /export /cfg \"$BackupRoot\\Daily\\secpol_$BackupDate.inf\" /quiet\n\n# Generate checksums for integrity verification\nWrite-Log \"Generating backup checksums\"\n$Checksums = @{}\nGet-ChildItem -Path \"$BackupRoot\\Daily\" -Filter \"*$BackupDate*\" | ForEach-Object {\n    $Hash = Get-FileHash -Path $_.FullName -Algorithm SHA256\n    $Checksums[$_.Name] = $Hash.Hash\n}\n$Checksums | ConvertTo-Json | Out-File \"$BackupRoot\\Daily\\checksums_$BackupDate.json\"\n\n# Cleanup old backups\nWrite-Log \"Cleaning up old backups\"\nGet-ChildItem -Path \"$BackupRoot\\Daily\" -Recurse | Where-Object {\n    $_.LastWriteTime -lt (Get-Date).AddDays(-$RetentionDays)\n} | Remove-Item -Force -Recurse\n\nWrite-Log \"=== CP-9 System Backup Completed ===\"",
        "wbadmin": "# CP-9 Windows Server Backup using wbadmin\n# Run as Administrator\n\n# Enable Windows Server Backup feature\nInstall-WindowsFeature Windows-Server-Backup\n\n# Create backup policy for system state and critical volumes\n$Policy = New-WBPolicy\n$BackupTarget = New-WBBackupTarget -VolumePath \"E:\"\n\n# Add system state to backup\nAdd-WBSystemState -Policy $Policy\n\n# Add critical volumes\n$Volume = Get-WBVolume -VolumePath \"C:\"\nAdd-WBVolume -Policy $Policy -Volume $Volume\n\n# Add backup target\nAdd-WBBackupTarget -Policy $Policy -Target $BackupTarget\n\n# Set backup schedule (daily at 2:00 AM)\nSet-WBSchedule -Policy $Policy -Schedule 02:00\n\n# Enable VSS full backup\nSet-WBVssBackupOption -Policy $Policy -VssFullBackup\n\n# Apply the policy\nSet-WBPolicy -Policy $Policy -Force\n\n# Verify backup configuration\nGet-WBPolicy",
        "ansible": "---\n# CP-9 Windows Backup Ansible Playbook\n- name: CP-9 Windows System Backup Configuration\n  hosts: windows\n  vars:\n    backup_root: C:\\Backups\\SystemBackup\n    retention_days: 30\n  \n  tasks:\n    - name: Install Windows Server Backup feature\n      win_feature:\n        name: Windows-Server-Backup\n        state: present\n\n    - name: Create backup directories\n      win_file:\n        path: \"{{ item }}\"\n        state: directory\n      loop:\n        - \"{{ backup_root }}\\\\Daily\"\n        - \"{{ backup_root }}\\\\Weekly\"\n        - \"{{ backup_root }}\\\\Monthly\"\n        - C:\\Backups\\Logs\n\n    - name: Deploy backup script\n      win_copy:\n        dest: C:\\Scripts\\SystemBackup.ps1\n        content: |\n          # CP-9 Automated Backup Script\n          $BackupRoot = '{{ backup_root }}'\n          $Date = Get-Date -Format 'yyyyMMdd'\n          \n          # System State Backup\n          wbadmin start systemstatebackup -backupTarget:$BackupRoot\\Daily -quiet\n          \n          # Export security policy\n          secedit /export /cfg \"$BackupRoot\\Daily\\secpol_$Date.inf\" /quiet\n          \n          # Cleanup old backups\n          Get-ChildItem -Path \"$BackupRoot\\Daily\" -Recurse |\n            Where-Object { $_.LastWriteTime -lt (Get-Date).AddDays(-{{ retention_days }}) } |\n            Remove-Item -Force -Recurse\n\n    - name: Create scheduled task for daily backup\n      win_scheduled_task:\n        name: CP9_DailyBackup\n        description: NIST CP-9 Daily System Backup\n        actions:\n          - path: powershell.exe\n            arguments: -ExecutionPolicy Bypass -File C:\\Scripts\\SystemBackup.ps1\n        triggers:\n          - type: daily\n            start_boundary: '2024-01-01T02:00:00'\n        username: SYSTEM\n        run_level: highest\n        state: present\n        enabled: yes"
      }
    },
    "stig_mappings": {
      "rhel8": [
        "RHEL-08-010359"
      ],
      "rhel9": [
        "RHEL-09-010359"
      ],
      "general": [
        "SRG-OS-000479-GPOS-00224",
        "SRG-APP-000516-CTR-001325"
      ]
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000+00:00",
      "has_scripts": true
    },
    "cac_metadata": {
      "implementation_type": "technical",
      "last_analyzed": "2025-11-22T00:00:00.000000+00:00",
      "source": "NIST SP 800-53 Rev 5",
      "implementation_guidance": "This control requires technical implementation of backup infrastructure including automated backup scheduling, encryption, integrity verification, and retention management. Scripts are provided for Linux (tar, BorgBackup) and Windows (wbadmin, PowerShell) backup operations."
    },
    "rationale": "Without backups, data loss is permanent. Regular backups are your safety net against ransomware, failures, and mistakes."
  },
  {
    "control_id": "CP-9.1",
    "control_name": "Testing for Reliability and Integrity",
    "family": "Contingency Planning",
    "family_id": "CP",
    "parent_control": "CP-9",
    "official_text": "Test backup information [Assignment: organization-defined frequency] to verify media reliability and information integrity.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": true,
      "high": true
    },
    "stig_id": "SRG-OS-000480-GPOS-00227",
    "plain_english_explanation": "Backup Testing for Reliability and Integrity requires organizations to regularly verify that their backup media functions correctly and that backed up data has not been corrupted. Simply creating backups is insufficient - organizations must confirm that the backup media (tapes, disks, cloud storage) remains readable and that the data stored on it maintains integrity over time. This involves reading data from backup media, comparing checksums or hashes against original values, and potentially performing test restorations to isolated environments. Without regular testing, organizations may discover during an actual emergency that their backups are unreadable or corrupted.",
    "intent": "This enhancement addresses the risk that backup media or stored data may degrade over time without detection. Hardware failures, environmental conditions, firmware bugs, and storage media degradation can all render backups useless when recovery is attempted. Regular testing catches these problems before they impact actual recovery operations, ensuring that backups remain a reliable recovery resource.",
    "example_implementation": "Implement automated backup verification that includes: (1) Weekly automated integrity checks comparing current backup checksums against creation-time baselines; (2) Monthly test restorations of random data samples to a sandbox environment; (3) Quarterly full system restoration tests to DR infrastructure; (4) Annual media rotation and replacement based on vendor lifecycle recommendations; (5) Automated alerting for any integrity verification failures requiring immediate investigation.",
    "non_technical_guidance": "To comply with control CP-9.1 (Testing for Reliability and Integrity), organizations should follow these procedures:\n1. Establish a backup testing schedule based on system criticality - weekly for high-impact systems, monthly for moderate, quarterly for low.\n2. Implement automated integrity verification using checksums or cryptographic hashes compared against creation-time values.\n3. Conduct periodic test restorations to verify that backup data can actually be recovered and used.\n4. Document all backup testing activities including tests performed, results, and any corrective actions taken.\n5. Track backup media age and replace according to manufacturer recommendations or organizational policy.\n6. Monitor environmental conditions (temperature, humidity) of backup storage locations.\n7. Test backups stored at off-site locations with the same rigor as on-site backups.\n8. Verify that backup software versions can read older backup formats during upgrades.\n9. Include backup testing results in regular security status reporting.\n10. Investigate and remediate any failed backup integrity tests within defined timeframes.",
    "implementation_guidance": "This is a TECHNICAL control requiring automated verification mechanisms. Implementation involves:\n\n1. CHECKSUM VERIFICATION: Generate cryptographic hashes (SHA-256 minimum) at backup creation time and store separately. Automate periodic comparison of current backup hashes against stored values.\n\n2. MEDIA VERIFICATION: Use backup software media verification features to scan backup media for read errors. Schedule verification jobs to run during low-usage periods.\n\n3. TEST RESTORATION: Configure isolated test environments (VMs, containers) for backup restoration testing. Automate the restoration process and application functionality verification.\n\n4. VERIFICATION SCHEDULING: Configure backup software to perform integrity verification at organization-defined frequencies. Alert on any verification failures.\n\n5. MEDIA LIFECYCLE: Track backup media age and usage. Implement automatic media retirement based on organizational thresholds.\n\n6. REPORTING: Generate regular reports on backup verification status and trends. Dashboard visualization of verification success rates.",
    "ai_guidance": "When implementing CP-9.1 Backup Testing compliance, AI can enhance verification accuracy and efficiency through intelligent automation. AI-powered monitoring can predict media failures before they occur by analyzing patterns in read/write performance, error rates, and environmental sensor data. Machine learning models trained on backup metadata can identify anomalies that might indicate corruption or tampering, such as unexpected changes in backup sizes, timing patterns, or file composition. AI can optimize test restoration scheduling by analyzing system usage patterns to identify optimal windows that minimize production impact while maintaining verification coverage. Natural language processing can analyze restoration logs to automatically categorize and prioritize failures based on severity and likely root cause. AI can correlate verification failures across multiple backup targets to identify systemic issues versus isolated media problems. Predictive analytics can forecast storage media degradation based on environmental conditions and usage patterns, enabling proactive replacement before failures occur. For large-scale environments, AI can implement intelligent sampling strategies that maximize verification coverage while minimizing resource consumption. AI-powered automation can orchestrate complex test restoration scenarios across multiple systems and validate application functionality post-restoration.",
    "is_technical": true,
    "enhancements": [],
    "related_controls": [
      "CP-4",
      "CP-9",
      "MP-6",
      "SI-7"
    ],
    "supplemental_guidance": "Organizations determine the frequency of backup testing based on the criticality and sensitivity of the information and the impact of backup failures on organizational operations. Backup testing provides organizations with the assurance that backup information can be relied upon to restore critical information processing capabilities and continue mission and business operations.",
    "implementation_scripts": {
      "linux": {
        "bash": "#!/bin/bash\n# CP-9.1 Backup Integrity Testing Script\n\nBACKUP_DIR=\"/var/backups/system/daily\"\nTEST_RESTORE_DIR=\"/tmp/backup_test\"\nLOG_FILE=\"/var/log/backup/integrity_test.log\"\nALERT_EMAIL=\"admin@example.com\"\n\nlog_message() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" | tee -a \"$LOG_FILE\"\n}\n\nlog_message \"=== CP-9.1 Backup Integrity Test Started ===\"\n\n# Verify checksums\nCHECKSUM_FILE=$(ls -t \"$BACKUP_DIR\"/checksums_*.sha256 2>/dev/null | head -1)\nif [ -f \"$CHECKSUM_FILE\" ]; then\n    log_message \"Verifying checksums from $CHECKSUM_FILE\"\n    cd \"$BACKUP_DIR\"\n    if sha256sum -c \"$CHECKSUM_FILE\" >> \"$LOG_FILE\" 2>&1; then\n        log_message \"[PASS] All backup checksums verified successfully\"\n    else\n        log_message \"[FAIL] Backup checksum verification failed!\"\n        echo \"ALERT: Backup integrity test failed\" | mail -s \"CP-9.1 Alert\" $ALERT_EMAIL\n        exit 1\n    fi\nelse\n    log_message \"[WARNING] No checksum file found\"\nfi\n\n# Test restore of random sample\nlog_message \"Testing backup restoration\"\nmkdir -p \"$TEST_RESTORE_DIR\"\nLATEST_BACKUP=$(ls -t \"$BACKUP_DIR\"/*.tar.gz 2>/dev/null | head -1)\nif [ -f \"$LATEST_BACKUP\" ]; then\n    if tar -tzf \"$LATEST_BACKUP\" > /dev/null 2>&1; then\n        log_message \"[PASS] Backup archive readable: $LATEST_BACKUP\"\n        \n        # Extract sample files to test restoration\n        tar -xzf \"$LATEST_BACKUP\" -C \"$TEST_RESTORE_DIR\" --wildcards '*/etc/passwd' 2>/dev/null\n        if [ $? -eq 0 ]; then\n            log_message \"[PASS] Sample file restoration successful\"\n        fi\n    else\n        log_message \"[FAIL] Backup archive corrupted: $LATEST_BACKUP\"\n        exit 1\n    fi\nfi\n\n# Cleanup test directory\nrm -rf \"$TEST_RESTORE_DIR\"\n\nlog_message \"=== CP-9.1 Backup Integrity Test Completed ===\"",
        "ansible": "---\n# CP-9.1 Backup Integrity Testing Playbook\n- name: CP-9.1 Backup Testing Configuration\n  hosts: all\n  become: yes\n  vars:\n    backup_dir: /var/backups/system/daily\n    test_dir: /tmp/backup_test\n  \n  tasks:\n    - name: Deploy integrity test script\n      copy:\n        dest: /usr/local/bin/test_backup_integrity.sh\n        mode: '0750'\n        content: |\n          #!/bin/bash\n          BACKUP_DIR={{ backup_dir }}\n          cd $BACKUP_DIR\n          CHECKSUM_FILE=$(ls -t checksums_*.sha256 2>/dev/null | head -1)\n          if [ -f \"$CHECKSUM_FILE\" ]; then\n            sha256sum -c \"$CHECKSUM_FILE\" >> /var/log/backup/integrity_test.log 2>&1\n            if [ $? -ne 0 ]; then\n              echo \"BACKUP INTEGRITY FAILURE\" | logger -t backup-test -p local0.alert\n              exit 1\n            fi\n          fi\n          echo \"$(date): Integrity test passed\" >> /var/log/backup/integrity_test.log\n\n    - name: Schedule weekly integrity tests\n      cron:\n        name: \"CP-9.1 Weekly Backup Integrity Test\"\n        weekday: \"3\"\n        hour: \"4\"\n        minute: \"0\"\n        job: \"/usr/local/bin/test_backup_integrity.sh\"\n        user: root\n\n    - name: Schedule monthly restoration test\n      cron:\n        name: \"CP-9.1 Monthly Restoration Test\"\n        day: \"15\"\n        hour: \"5\"\n        minute: \"0\"\n        job: \"/usr/local/bin/test_backup_integrity.sh --full-restore-test\"\n        user: root"
      },
      "windows": {
        "powershell": "# CP-9.1 Windows Backup Integrity Testing\n\n$BackupRoot = \"C:\\Backups\\SystemBackup\\Daily\"\n$LogFile = \"C:\\Backups\\Logs\\integrity_test_$(Get-Date -Format 'yyyyMMdd').log\"\n$TestRestoreDir = \"C:\\Temp\\BackupTest\"\n\nfunction Write-Log {\n    param([string]$Message)\n    $Timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    \"$Timestamp - $Message\" | Tee-Object -FilePath $LogFile -Append\n}\n\nWrite-Log \"=== CP-9.1 Backup Integrity Test Started ===\"\n\n# Verify checksums\n$ChecksumFile = Get-ChildItem -Path $BackupRoot -Filter \"checksums_*.json\" | Sort-Object LastWriteTime -Descending | Select-Object -First 1\n\nif ($ChecksumFile) {\n    Write-Log \"Verifying checksums from $($ChecksumFile.Name)\"\n    $StoredChecksums = Get-Content $ChecksumFile.FullName | ConvertFrom-Json\n    $AllPassed = $true\n    \n    $StoredChecksums.PSObject.Properties | ForEach-Object {\n        $FileName = $_.Name\n        $ExpectedHash = $_.Value\n        $FilePath = Join-Path $BackupRoot $FileName\n        \n        if (Test-Path $FilePath) {\n            $ActualHash = (Get-FileHash -Path $FilePath -Algorithm SHA256).Hash\n            if ($ActualHash -eq $ExpectedHash) {\n                Write-Log \"[PASS] $FileName - Hash verified\"\n            } else {\n                Write-Log \"[FAIL] $FileName - Hash mismatch!\"\n                $AllPassed = $false\n            }\n        } else {\n            Write-Log \"[WARNING] $FileName - File not found\"\n        }\n    }\n    \n    if ($AllPassed) {\n        Write-Log \"All backup integrity checks passed\"\n    } else {\n        Write-Log \"ALERT: Backup integrity verification failed!\"\n        Send-MailMessage -To \"admin@example.com\" -Subject \"CP-9.1 Alert: Backup Integrity Failure\" -Body \"Backup integrity test failed. Check logs.\"\n    }\n}\n\n# Test restoration\nWrite-Log \"Testing backup restoration capability\"\nNew-Item -ItemType Directory -Path $TestRestoreDir -Force | Out-Null\n\n$LatestBackup = Get-ChildItem -Path $BackupRoot -Filter \"*.zip\" | Sort-Object LastWriteTime -Descending | Select-Object -First 1\nif ($LatestBackup) {\n    try {\n        Expand-Archive -Path $LatestBackup.FullName -DestinationPath $TestRestoreDir -Force\n        Write-Log \"[PASS] Backup archive extractable: $($LatestBackup.Name)\"\n    } catch {\n        Write-Log \"[FAIL] Backup archive corrupt: $($LatestBackup.Name) - $_\"\n    }\n}\n\n# Cleanup\nRemove-Item -Path $TestRestoreDir -Recurse -Force -ErrorAction SilentlyContinue\n\nWrite-Log \"=== CP-9.1 Backup Integrity Test Completed ===\""
      }
    },
    "stig_mappings": {
      "general": [
        "SRG-OS-000480-GPOS-00227"
      ]
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000+00:00",
      "has_scripts": true
    },
    "cac_metadata": {
      "implementation_type": "technical",
      "last_analyzed": "2025-11-22T00:00:00.000000+00:00",
      "source": "NIST SP 800-53 Rev 5",
      "implementation_guidance": "This control requires automated backup verification including checksum validation and test restoration. Scripts are provided for both Linux and Windows platforms to verify backup integrity."
    },
    "rationale": "Backups that can't be restored are worthless. Regular testing proves your backups actually work."
  },
  {
    "control_id": "CP-9.2",
    "control_name": "Test Restoration Using Sampling",
    "family": "Contingency Planning",
    "family_id": "CP",
    "parent_control": "CP-9",
    "official_text": "Use a sample of backup information in the restoration of selected system functions as part of contingency plan testing.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": true
    },
    "stig_id": null,
    "plain_english_explanation": "Test Restoration Using Sampling requires organizations to go beyond simple backup verification by actually restoring a representative sample of backup data and using it to validate that critical system functions work correctly. This is part of contingency plan testing - organizations restore databases, application files, or system configurations from backups and then verify that the restored components function properly within the system context. This proves not just that backups are readable but that they contain the correct data needed to resume operations.",
    "intent": "This enhancement ensures that backup data is not just intact but actually usable for system recovery. A backup might verify as correct but still fail to restore a functioning system due to missing dependencies, version incompatibilities, or corrupted application data. By incorporating backup restoration into contingency plan testing using sampling methods, organizations gain confidence that their backups will support actual recovery operations.",
    "example_implementation": "During quarterly contingency plan exercises: (1) Select a random sample of backup data including database exports, application configurations, and user files; (2) Restore the sampled data to an isolated test environment; (3) Start dependent applications and verify they can read and process the restored data; (4) Execute functional tests of critical business processes using the restored data; (5) Document restoration times, any issues encountered, and resolution procedures; (6) Update recovery procedures based on lessons learned.",
    "non_technical_guidance": "To comply with control CP-9.2 (Test Restoration Using Sampling), organizations should follow these procedures:\n1. Integrate backup restoration testing into the contingency plan testing schedule (typically annual or semi-annual).\n2. Develop a sampling strategy that ensures critical system components are tested over time while minimizing resource requirements.\n3. Create isolated test environments that mirror production infrastructure for restoration testing.\n4. Document detailed restoration procedures including step-by-step instructions and expected results.\n5. Verify that restored data enables actual system functionality - not just data presence but application operation.\n6. Time the restoration process to validate that recovery time objectives can be achieved.\n7. Include personnel training as part of restoration exercises to ensure staff can execute procedures under pressure.\n8. Document test results including any variances from expected outcomes and corrective actions taken.\n9. Update restoration procedures based on lessons learned from testing.\n10. Report restoration test results as part of contingency plan testing documentation.",
    "implementation_guidance": "This control focuses on PROCESS validation through restoration testing during contingency exercises. Implementation involves:\n\n1. TEST ENVIRONMENT: Maintain isolated test infrastructure (physical or virtual) that mirrors production sufficiently for meaningful restoration testing.\n\n2. SAMPLING STRATEGY: Develop a rotation schedule ensuring all critical system components are tested periodically. Weight sampling toward highest-criticality systems.\n\n3. FUNCTIONAL VERIFICATION: Define test cases that validate application functionality using restored data - not just file presence but actual operations.\n\n4. TIMING MEASUREMENT: Measure restoration duration against recovery time objectives. Identify bottlenecks and optimization opportunities.\n\n5. DOCUMENTATION: Maintain detailed runbooks for restoration procedures. Update based on test findings.\n\n6. PERSONNEL TRAINING: Include restoration exercises in personnel training to ensure staff can execute under stress.",
    "ai_guidance": "When implementing CP-9.2 Test Restoration Using Sampling compliance, AI can enhance the effectiveness of restoration testing through intelligent sampling and validation automation. AI-powered analytics can analyze system architectures and data dependencies to recommend optimal sampling strategies that maximize test coverage while minimizing resource consumption. Machine learning can identify which backup components have the highest risk of restoration issues based on historical data patterns and change frequency. AI can automate functional validation testing by learning expected system behaviors and detecting anomalies in restored system operation. Natural language processing can analyze restoration logs and documentation to identify gaps in procedures or areas requiring clarification. AI can correlate restoration test results across multiple exercises to identify trends and systemic issues. Predictive models can estimate restoration times based on data volumes and infrastructure capacity, helping validate RTO feasibility before actual emergencies occur. AI can orchestrate complex multi-system restoration scenarios and coordinate dependent service startups. For continuous improvement, AI can analyze lessons learned across restoration exercises to prioritize procedure updates and training needs.",
    "is_technical": false,
    "enhancements": [],
    "related_controls": [
      "CP-4",
      "CP-9"
    ],
    "supplemental_guidance": "Sampling provides an efficient means for assessing backup information that may be too costly or time-consuming to test in its entirety. Organizations may consider using sampling strategies for backup testing during contingency plan testing events.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000+00:00",
      "has_scripts": false
    },
    "cac_metadata": {
      "implementation_type": "organizational",
      "last_analyzed": "2025-11-22T00:00:00.000000+00:00",
      "source": "NIST SP 800-53 Rev 5",
      "implementation_guidance": "This control requires procedural implementation as part of contingency plan testing. No technical scripts applicable - focus is on testing processes and documentation."
    },
    "rationale": "You don't need to restore everything to verify backups work. Sampling tests efficiency with confidence."
  },
  {
    "control_id": "CP-9.3",
    "control_name": "Separate Storage for Critical Information",
    "family": "Contingency Planning",
    "family_id": "CP",
    "parent_control": "CP-9",
    "official_text": "Store backup copies of [Assignment: organization-defined critical system software and other security-related information] in a separate facility or in a fire rated container that is not collocated with the operational system.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": true
    },
    "stig_id": null,
    "plain_english_explanation": "Separate Storage for Critical Information requires organizations to store backup copies of critical software and security-related information in a location physically separate from primary operations. This protects against scenarios where a single disaster (fire, flood, earthquake) could destroy both the production system and its backups simultaneously. Critical items include operating system installation media, application software, cryptographic keys, security configurations, and authentication databases. Storage options include geographically separate facilities or on-site fire-rated containers designed to survive building fires.",
    "intent": "This enhancement addresses the risk of losing both production systems and their backups in a single catastrophic event. Without geographic or physical separation, a facility-wide disaster could permanently destroy all copies of critical information. By mandating separate storage, organizations ensure that recovery resources survive the same event that destroys production systems.",
    "example_implementation": "Implement separate backup storage through: (1) Maintain current copies of critical software, security configurations, and cryptographic key backups at a geographically separate disaster recovery site; (2) Use cloud storage (AWS S3, Azure Blob) in a different region for off-site backup replication; (3) Store sensitive backup media in a fire-rated safe (minimum 2-hour rating) located in a separate building or fire compartment; (4) Implement automated replication of critical backups to off-site locations with encryption in transit; (5) Maintain offline copies of cryptographic keys in bank safe deposit boxes.",
    "non_technical_guidance": "To comply with control CP-9.3 (Separate Storage for Critical Information), organizations should follow these procedures:\n1. Identify critical system software and security-related information requiring separate storage protection.\n2. Evaluate storage options: geographically separate facility, commercial off-site storage, cloud storage, or fire-rated containers.\n3. For fire-rated containers, select units with minimum 2-hour fire rating and appropriate media-safe interior environment.\n4. Establish procedures for maintaining currency of separately stored backups - they must remain synchronized with production changes.\n5. Define access controls for off-site backup locations with the same rigor as primary facilities.\n6. Document the chain of custody for backup media transported to off-site locations.\n7. Verify that separate storage locations have appropriate environmental controls for media preservation.\n8. Test restoration from separately stored backups periodically to verify usability.\n9. Consider geographic risks when selecting off-site locations - avoid facilities in the same flood plain, earthquake zone, or hurricane path.\n10. Maintain inventory of all separately stored backup media with location tracking.",
    "implementation_guidance": "This control requires PHYSICAL and LOGICAL separation of critical backup storage. Implementation involves:\n\n1. CRITICAL DATA IDENTIFICATION: Document which system software, configurations, and security information require separate storage protection.\n\n2. OFF-SITE FACILITY: Establish relationships with commercial backup storage providers or use cloud storage with geographic redundancy.\n\n3. FIRE-RATED CONTAINERS: For on-premises protection, deploy fire-rated safes (UL-rated) with appropriate interior environment for electronic media.\n\n4. REPLICATION AUTOMATION: Configure automated replication of critical backups to off-site locations using encrypted channels.\n\n5. KEY MANAGEMENT: Ensure cryptographic keys needed to decrypt backups are also stored separately (but with appropriate controls).\n\n6. ACCESS CONTROL: Implement strict access controls for off-site backup locations.",
    "ai_guidance": "When implementing CP-9.3 Separate Storage compliance, AI can help optimize the selection and management of off-site backup storage. AI-powered analytics can analyze geographic risk data including natural disaster patterns, infrastructure vulnerabilities, and climate projections to recommend optimal off-site locations that minimize correlated risk with primary facilities. Machine learning can predict storage capacity requirements based on data growth trends and retention policies. AI can monitor replication latency and bandwidth utilization to optimize off-site synchronization schedules. Natural language processing can analyze vendor contracts and SLAs to identify gaps in off-site storage protection. AI can track media inventory and lifecycle across multiple locations, alerting when media approaches end-of-life or exceeds storage environment tolerances. For compliance, AI can continuously verify that all designated critical information has current copies at separate locations and alert when synchronization gaps occur. AI can also model disaster scenarios to validate that separately stored backups would survive various catastrophic events affecting primary facilities.",
    "is_technical": true,
    "enhancements": [],
    "related_controls": [
      "CP-2",
      "CP-6",
      "CP-7",
      "CP-9",
      "MP-4"
    ],
    "supplemental_guidance": "Threats that may affect the system and backup information stored in the same physical location include fires, explosions, storms, and floods. Off-site storage of backup information provides organizational flexibility in responding to threats that affect the primary storage location. Organizations may choose to store backup information in alternate storage sites or fire-rated containers that protect the backup information from the threats affecting the primary storage location. The requirement for critical software and security-related information addresses the need to ensure that backup copies of software and security-related information are available to restore systems to known, secure states.",
    "implementation_scripts": {
      "linux": {
        "bash": "#!/bin/bash\n# CP-9.3 Off-site Backup Replication Script\n\nLOCAL_BACKUP=\"/var/backups/system/daily\"\nREMOTE_SERVER=\"backup-offsite.example.com\"\nREMOTE_PATH=\"/backups/$(hostname)\"\nLOG_FILE=\"/var/log/backup/offsite_replication.log\"\n\nlog_message() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" | tee -a \"$LOG_FILE\"\n}\n\nlog_message \"=== CP-9.3 Off-site Replication Started ===\"\n\n# Sync critical backups to off-site location\nrsync -avz --delete \\\n    -e \"ssh -o StrictHostKeyChecking=yes\" \\\n    \"$LOCAL_BACKUP/\" \\\n    \"backup@${REMOTE_SERVER}:${REMOTE_PATH}/\" \\\n    >> \"$LOG_FILE\" 2>&1\n\nif [ $? -eq 0 ]; then\n    log_message \"[PASS] Off-site replication completed successfully\"\nelse\n    log_message \"[FAIL] Off-site replication failed!\"\n    exit 1\nfi\n\nlog_message \"=== CP-9.3 Off-site Replication Completed ===\"",
        "ansible": "---\n# CP-9.3 Off-site Backup Configuration\n- name: CP-9.3 Separate Storage Configuration\n  hosts: all\n  become: yes\n  vars:\n    offsite_server: backup-offsite.example.com\n    local_backup_dir: /var/backups/system\n  \n  tasks:\n    - name: Install rsync\n      package:\n        name: rsync\n        state: present\n\n    - name: Create SSH key for backup replication\n      openssh_keypair:\n        path: /root/.ssh/backup_key\n        type: ed25519\n      register: ssh_key\n\n    - name: Deploy off-site replication script\n      copy:\n        dest: /usr/local/bin/offsite_backup.sh\n        mode: '0750'\n        content: |\n          #!/bin/bash\n          rsync -avz --delete \\\n            -e \"ssh -i /root/.ssh/backup_key\" \\\n            {{ local_backup_dir }}/ \\\n            backup@{{ offsite_server }}:/backups/$(hostname)/ \\\n            >> /var/log/backup/offsite.log 2>&1\n\n    - name: Schedule nightly off-site replication\n      cron:\n        name: \"CP-9.3 Off-site Backup Replication\"\n        hour: \"4\"\n        minute: \"30\"\n        job: \"/usr/local/bin/offsite_backup.sh\"\n        user: root"
      },
      "windows": {
        "powershell": "# CP-9.3 Windows Off-site Backup Replication\n\n$LocalBackup = \"C:\\Backups\\SystemBackup\\Daily\"\n$OffsiteShare = \"\\\\backup-offsite\\Backups\\$env:COMPUTERNAME\"\n$LogFile = \"C:\\Backups\\Logs\\offsite_$(Get-Date -Format 'yyyyMMdd').log\"\n\nfunction Write-Log {\n    param([string]$Message)\n    $Timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    \"$Timestamp - $Message\" | Tee-Object -FilePath $LogFile -Append\n}\n\nWrite-Log \"=== CP-9.3 Off-site Replication Started ===\"\n\n# Create off-site directory if needed\nif (-not (Test-Path $OffsiteShare)) {\n    New-Item -ItemType Directory -Path $OffsiteShare -Force\n}\n\n# Replicate backups using Robocopy\n$Result = robocopy $LocalBackup $OffsiteShare /MIR /Z /R:3 /W:10 /LOG+:$LogFile\n\nif ($LASTEXITCODE -lt 8) {\n    Write-Log \"[PASS] Off-site replication completed successfully\"\n} else {\n    Write-Log \"[FAIL] Off-site replication failed with code $LASTEXITCODE\"\n}\n\nWrite-Log \"=== CP-9.3 Off-site Replication Completed ===\""
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000+00:00",
      "has_scripts": true
    },
    "cac_metadata": {
      "implementation_type": "technical",
      "last_analyzed": "2025-11-22T00:00:00.000000+00:00",
      "source": "NIST SP 800-53 Rev 5",
      "implementation_guidance": "This control requires physical separation of backup storage. Scripts are provided to automate replication to off-site locations using rsync (Linux) and Robocopy (Windows)."
    },
    "rationale": "Critical data needs extra protection. Storing it separately reduces risk of total loss."
  },
  {
    "control_id": "CP-9.4",
    "control_name": "Protection from Unauthorized Modification",
    "family": "Contingency Planning",
    "family_id": "CP",
    "parent_control": "CP-9",
    "status": "withdrawn",
    "withdrawn_reason": "Incorporated into CP-9",
    "official_text": "[Withdrawn: Incorporated into CP-9.]",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "stig_id": null,
    "plain_english_explanation": "This control enhancement has been withdrawn in NIST SP 800-53 Revision 5. The requirements for protecting backup information from unauthorized modification have been incorporated into the base CP-9 control, which now includes the requirement to protect the confidentiality, integrity, and availability of backup information.",
    "intent": "This enhancement was withdrawn to consolidate backup protection requirements into the base control CP-9, reducing redundancy and providing clearer guidance in a single location.",
    "example_implementation": "Not applicable - withdrawn control. Refer to CP-9 for backup protection requirements.",
    "non_technical_guidance": "This control enhancement has been withdrawn and its requirements incorporated into CP-9. Organizations should reference CP-9 for guidance on protecting backup information from unauthorized modification.",
    "implementation_guidance": "This control enhancement has been withdrawn in NIST SP 800-53 Revision 5. The requirements have been incorporated into CP-9. Organizations should implement backup protection requirements under the base control.",
    "ai_guidance": "This control enhancement (CP-9.4) has been withdrawn in NIST SP 800-53 Revision 5. Any backup protection requirements should be addressed under CP-9 (System Backup), which now encompasses the withdrawn content regarding protection from unauthorized modification.",
    "is_technical": false,
    "enhancements": [],
    "related_controls": [
      "CP-9"
    ],
    "supplemental_guidance": "This control enhancement has been withdrawn and incorporated into CP-9.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "withdrawn",
      "last_updated": "2025-11-22T00:00:00.000000+00:00",
      "has_scripts": false,
      "withdrawn_into": "CP-9"
    },
    "cac_metadata": {
      "implementation_type": "organizational",
      "last_analyzed": "2025-11-22T00:00:00.000000+00:00",
      "source": "NIST SP 800-53 Rev 5",
      "implementation_guidance": "Withdrawn - incorporated into CP-9."
    },
    "rationale": "Backups must be protected from tampering. Modified backups could restore malware or corrupted data. (Withdrawn in Rev 5)"
  },
  {
    "control_id": "CP-9.5",
    "control_name": "Transfer to Alternate Storage Site",
    "family": "Contingency Planning",
    "family_id": "CP",
    "parent_control": "CP-9",
    "official_text": "Transfer system backup information to the alternate storage site [Assignment: organization-defined time period and transfer rate consistent with the recovery time and recovery point objectives].",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": true
    },
    "stig_id": null,
    "plain_english_explanation": "Transfer to Alternate Storage Site requires organizations to move backup information to alternate locations within time frames and at transfer rates that support their recovery objectives. This ensures that if the primary site becomes unavailable, sufficiently current backup data exists at the alternate site to restore operations within the required recovery time objective (RTO) and with acceptable data loss (RPO). Transfer methods include real-time replication, scheduled batch transfers, or physical media transport depending on data volumes and network capabilities.",
    "intent": "This enhancement ensures that alternate storage sites maintain backup data that is current enough to meet recovery objectives. Without timely transfer, alternate site backups may be too stale to provide acceptable recovery, leaving organizations unable to meet their RTO/RPO commitments. The control mandates that organizations align transfer timing with their specific recovery requirements.",
    "example_implementation": "Configure backup transfer to alternate site based on recovery requirements: (1) For systems with 4-hour RPO, implement asynchronous replication with 1-hour sync intervals to DR site; (2) For systems with 24-hour RPO, configure nightly backup transfers via secure WAN or cloud sync; (3) For systems requiring near-zero RPO, implement synchronous replication to alternate site; (4) Monitor replication lag and alert when it exceeds RPO thresholds; (5) Test alternate site recovery quarterly to verify transfer effectiveness.",
    "non_technical_guidance": "To comply with control CP-9.5 (Transfer to Alternate Storage Site), organizations should follow these procedures:\n1. Document recovery time objectives (RTO) and recovery point objectives (RPO) for each system category.\n2. Calculate required transfer frequencies and rates to achieve RPO requirements.\n3. Evaluate transfer methods: real-time replication, scheduled synchronization, or physical media transport.\n4. Provision sufficient network bandwidth for backup transfers without impacting production operations.\n5. Implement encrypted transfer channels for backup data in transit.\n6. Monitor transfer completion and latency to verify RPO compliance.\n7. Configure alerting when transfer lag exceeds acceptable thresholds.\n8. Document transfer schedules and verify they align with backup creation schedules.\n9. Test restoration from alternate site data periodically to verify transfer completeness.\n10. Plan for catch-up transfers after network outages to restore RPO compliance.",
    "implementation_guidance": "This is a TECHNICAL control requiring configuration of backup replication or transfer automation. Implementation involves:\n\n1. RTO/RPO ANALYSIS: Document recovery objectives and calculate required transfer frequencies.\n\n2. REPLICATION TECHNOLOGY: Select appropriate technology based on requirements - synchronous replication for near-zero RPO, asynchronous for relaxed RPO, scheduled batch for daily+ RPO.\n\n3. BANDWIDTH PROVISIONING: Ensure sufficient WAN capacity for backup transfer volumes without impacting production.\n\n4. TRANSFER ENCRYPTION: Configure TLS/IPsec for backup data in transit to alternate site.\n\n5. MONITORING: Implement replication lag monitoring with alerts when RPO thresholds are at risk.\n\n6. VERIFICATION: Periodically validate that alternate site contains complete and current backup data.",
    "ai_guidance": "When implementing CP-9.5 Transfer to Alternate Storage Site compliance, AI can optimize backup transfer operations to meet recovery objectives efficiently. AI-powered analytics can predict bandwidth requirements based on data change rates and optimize transfer scheduling to meet RPO while minimizing network congestion. Machine learning can detect anomalies in replication patterns that might indicate transfer failures or data integrity issues before they impact recovery capability. AI can dynamically adjust transfer priorities based on system criticality and current replication lag, ensuring highest-priority systems always meet their RPO. Natural language processing can analyze vendor documentation and SLAs to validate that alternate site capabilities meet organizational requirements. AI can model various disaster scenarios to predict whether current transfer rates would support required recovery operations. Predictive maintenance algorithms can forecast when storage or network components at alternate sites require attention. AI can correlate replication metrics across multiple systems to identify systemic issues affecting transfer performance. For optimization, AI can recommend infrastructure investments to close gaps between actual and required transfer capabilities.",
    "is_technical": true,
    "enhancements": [],
    "related_controls": [
      "CP-6",
      "CP-7",
      "CP-9",
      "MP-5"
    ],
    "supplemental_guidance": "The backup information stored at the alternate storage site serves as an additional level of redundancy for the information stored at the primary storage site. The transfer frequency and transfer rate are related to the backup frequencies and reflect the recovery time and recovery point objectives defined in the organization's contingency plan. The capability to transfer backup information to the alternate storage site supports the organization's ability to continue mission and business functions when the primary processing site is unavailable.",
    "implementation_scripts": {
      "linux": {
        "bash": "#!/bin/bash\n# CP-9.5 Alternate Site Backup Transfer\n\nLOCAL_BACKUP=\"/var/backups/system\"\nALTERNATE_SITE=\"dr-site.example.com\"\nALT_SITE_PATH=\"/backups/$(hostname)\"\nRPO_HOURS=4\nLOG_FILE=\"/var/log/backup/alt_site_transfer.log\"\n\nlog_message() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" | tee -a \"$LOG_FILE\"\n}\n\nlog_message \"=== CP-9.5 Alternate Site Transfer Started ===\"\n\n# Transfer backups to alternate site\nrsync -avz --progress --delete \\\n    --bwlimit=50000 \\\n    -e \"ssh -o StrictHostKeyChecking=yes -i /root/.ssh/dr_key\" \\\n    \"$LOCAL_BACKUP/\" \\\n    \"backup@${ALTERNATE_SITE}:${ALT_SITE_PATH}/\" \\\n    >> \"$LOG_FILE\" 2>&1\n\nif [ $? -eq 0 ]; then\n    log_message \"[PASS] Alternate site transfer completed\"\n    \n    # Verify RPO compliance\n    LAST_TRANSFER=$(stat -c %Y \"$LOCAL_BACKUP/daily\" 2>/dev/null || echo 0)\n    CURRENT_TIME=$(date +%s)\n    LAG_HOURS=$(( (CURRENT_TIME - LAST_TRANSFER) / 3600 ))\n    \n    if [ $LAG_HOURS -lt $RPO_HOURS ]; then\n        log_message \"[PASS] RPO compliance: ${LAG_HOURS}h lag (threshold: ${RPO_HOURS}h)\"\n    else\n        log_message \"[WARNING] RPO at risk: ${LAG_HOURS}h lag exceeds ${RPO_HOURS}h threshold\"\n    fi\nelse\n    log_message \"[FAIL] Alternate site transfer failed!\"\n    exit 1\nfi\n\nlog_message \"=== CP-9.5 Alternate Site Transfer Completed ===\""
      },
      "windows": {
        "powershell": "# CP-9.5 Windows Alternate Site Backup Transfer\n\n$LocalBackup = \"C:\\Backups\\SystemBackup\"\n$AlternateSite = \"\\\\dr-site\\Backups\\$env:COMPUTERNAME\"\n$RPOHours = 4\n$LogFile = \"C:\\Backups\\Logs\\alt_site_$(Get-Date -Format 'yyyyMMdd').log\"\n\nfunction Write-Log {\n    param([string]$Message)\n    $Timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    \"$Timestamp - $Message\" | Tee-Object -FilePath $LogFile -Append\n}\n\nWrite-Log \"=== CP-9.5 Alternate Site Transfer Started ===\"\n\n# Ensure alternate site path exists\nif (-not (Test-Path $AlternateSite)) {\n    New-Item -ItemType Directory -Path $AlternateSite -Force\n}\n\n# Transfer using Robocopy with bandwidth throttling\n$Result = robocopy $LocalBackup $AlternateSite /MIR /Z /R:5 /W:30 /IPG:100 /LOG+:$LogFile\n\nif ($LASTEXITCODE -lt 8) {\n    Write-Log \"[PASS] Alternate site transfer completed\"\n    \n    # Check RPO compliance\n    $LastBackup = Get-ChildItem -Path $LocalBackup -Directory | Sort-Object LastWriteTime -Descending | Select-Object -First 1\n    $LagHours = ((Get-Date) - $LastBackup.LastWriteTime).TotalHours\n    \n    if ($LagHours -lt $RPOHours) {\n        Write-Log \"[PASS] RPO compliance: $([math]::Round($LagHours,1))h lag (threshold: ${RPOHours}h)\"\n    } else {\n        Write-Log \"[WARNING] RPO at risk: $([math]::Round($LagHours,1))h lag exceeds ${RPOHours}h threshold\"\n    }\n} else {\n    Write-Log \"[FAIL] Alternate site transfer failed with code $LASTEXITCODE\"\n}\n\nWrite-Log \"=== CP-9.5 Alternate Site Transfer Completed ===\""
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000+00:00",
      "has_scripts": true
    },
    "cac_metadata": {
      "implementation_type": "technical",
      "last_analyzed": "2025-11-22T00:00:00.000000+00:00",
      "source": "NIST SP 800-53 Rev 5",
      "implementation_guidance": "This control requires automated backup transfer to alternate sites with RPO monitoring. Scripts are provided for Linux (rsync) and Windows (Robocopy) implementations."
    },
    "rationale": "Local backups can be destroyed with the primary. Offsite transfer ensures geographic separation."
  },
  {
    "control_id": "CP-9.6",
    "control_name": "Redundant Secondary System",
    "family": "Contingency Planning",
    "family_id": "CP",
    "parent_control": "CP-9",
    "official_text": "Conduct system backup by maintaining a redundant secondary system that is not collocated with the primary system and that can be activated without loss of information or disruption to operations.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "stig_id": null,
    "plain_english_explanation": "Redundant Secondary System represents the most robust backup approach - maintaining a complete secondary system at a separate location that mirrors the primary system in near real-time. This secondary system can take over operations immediately upon primary system failure with no data loss and no service disruption. This goes beyond traditional backup-and-restore by keeping a live standby system ready for instant failover, typically using technologies like database replication, storage mirroring, and load balancing.",
    "intent": "This enhancement provides maximum resilience for systems requiring continuous availability. Traditional backup/restore approaches inherently involve some data loss (to the last backup) and recovery time (to perform restoration). A redundant secondary system eliminates both by maintaining a synchronized standby that can assume operations immediately, supporting requirements for near-zero RTO and RPO.",
    "example_implementation": "Implement redundant secondary system through: (1) Deploy identical infrastructure at geographically separate DR site; (2) Configure synchronous database replication for zero data loss; (3) Implement storage array mirroring between sites; (4) Deploy global load balancer for automatic failover; (5) Configure DNS-based failover for network routing; (6) Conduct quarterly failover exercises to verify capability; (7) Monitor replication health continuously with automated alerting.",
    "non_technical_guidance": "To comply with control CP-9.6 (Redundant Secondary System), organizations should follow these procedures:\n1. Conduct cost-benefit analysis to justify investment in redundant infrastructure.\n2. Design secondary system with identical capabilities to primary (compute, storage, network).\n3. Select secondary site location with adequate geographic separation and independent infrastructure.\n4. Implement real-time or near-real-time data replication between primary and secondary systems.\n5. Configure automatic failover mechanisms that detect primary system failure and activate secondary.\n6. Develop and test failback procedures for returning to primary operations after recovery.\n7. Conduct regular failover exercises (quarterly minimum) to verify seamless transition capability.\n8. Monitor replication health continuously and alert on any synchronization issues.\n9. Document operational procedures for both failover and failback scenarios.\n10. Train operations staff on failover procedures and decision criteria.",
    "implementation_guidance": "This is a TECHNICAL control requiring significant infrastructure investment. Implementation involves:\n\n1. INFRASTRUCTURE DUPLICATION: Provision secondary infrastructure with equivalent capacity to primary.\n\n2. REPLICATION TECHNOLOGY: Implement appropriate replication - synchronous for zero RPO (limited distance), asynchronous for longer distances.\n\n3. FAILOVER AUTOMATION: Deploy automated failover using load balancers, database clustering, or orchestration platforms.\n\n4. NETWORK DESIGN: Configure network routing (DNS, BGP) to support traffic redirection during failover.\n\n5. TESTING: Establish regular failover testing schedule and document results.\n\n6. MONITORING: Implement comprehensive monitoring of replication health and failover readiness.",
    "ai_guidance": "When implementing CP-9.6 Redundant Secondary System compliance, AI can optimize the operation and failover readiness of redundant infrastructure. AI-powered monitoring can predict component failures before they impact replication, enabling proactive maintenance. Machine learning can analyze replication performance patterns to detect anomalies that might prevent successful failover. AI can optimize resource allocation across primary and secondary sites based on workload predictions. Natural language processing can analyze failover documentation to identify gaps or inconsistencies that might cause issues during actual emergencies. AI can orchestrate complex failover sequences across multiple interdependent systems, ensuring correct startup order and dependency management. Predictive analytics can estimate failover duration and success probability based on current system state. AI can continuously validate that secondary systems maintain sufficient capacity to assume primary workloads. For testing, AI can generate realistic failover scenarios and automate validation of post-failover functionality. AI-powered analysis of past failover exercises can identify improvement opportunities and training needs.",
    "is_technical": true,
    "enhancements": [],
    "related_controls": [
      "CP-6",
      "CP-7",
      "CP-9",
      "CP-10"
    ],
    "supplemental_guidance": "The requirement for a redundant secondary system addresses situations where the organization determines that backing up user-level and system-level information by other means is insufficient to meet recovery needs. Organizations may include redundant secondary systems as part of their contingency planning as the means for achieving system recovery objectives.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000+00:00",
      "has_scripts": false
    },
    "cac_metadata": {
      "implementation_type": "technical",
      "last_analyzed": "2025-11-22T00:00:00.000000+00:00",
      "source": "NIST SP 800-53 Rev 5",
      "implementation_guidance": "This control requires significant infrastructure investment including duplicate systems, real-time replication, and automated failover. Implementation is highly environment-specific and typically involves commercial clustering, replication, and load balancing solutions."
    },
    "rationale": "A standby system can take over immediately. This minimizes downtime for critical operations."
  },
  {
    "control_id": "CP-9.7",
    "control_name": "Dual Authorization for Deletion or Destruction",
    "family": "Contingency Planning",
    "family_id": "CP",
    "parent_control": "CP-9",
    "official_text": "Enforce dual authorization for the deletion or destruction of [Assignment: organization-defined backup information].",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "stig_id": null,
    "plain_english_explanation": "Dual Authorization for Backup Deletion requires that two authorized individuals must both approve before critical backup information can be deleted or destroyed. This prevents a single malicious or compromised administrator from deleting backups that might be needed for recovery or forensic analysis. Dual authorization is commonly implemented through workflow systems requiring two approvals, or through technical controls requiring two separate credentials to complete destructive operations.",
    "intent": "This enhancement protects against insider threats and compromised accounts that might attempt to destroy backup data. By requiring two independent authorizations, organizations create a check against both malicious actions and accidental deletions. This is particularly important for backups that might contain evidence of security incidents or that represent the only recovery path for critical systems.",
    "example_implementation": "Implement dual authorization through: (1) Configure backup software to require approval from two administrators before deletion jobs execute; (2) Implement workflow system that routes deletion requests for approval before processing; (3) Use separate administrative accounts where one can queue deletion and another must confirm; (4) Log all deletion attempts and approvals for audit trail; (5) Alert security team on any backup deletion requests; (6) Define which backup categories require dual authorization based on criticality.",
    "non_technical_guidance": "To comply with control CP-9.7 (Dual Authorization for Deletion or Destruction), organizations should follow these procedures:\n1. Identify backup information categories requiring dual authorization protection based on criticality and recoverability.\n2. Implement technical controls or workflow processes requiring two authorized individuals to approve deletions.\n3. Define authorized approvers and ensure they have appropriate separation of duties.\n4. Establish procedures for handling urgent deletion requests that maintain two-person integrity.\n5. Log all deletion requests, approvals, and rejections for audit purposes.\n6. Review deletion logs periodically to detect unusual patterns.\n7. Train authorized personnel on dual authorization procedures and their security purpose.\n8. Test dual authorization controls periodically to verify enforcement.\n9. Define escalation procedures when approvers are unavailable.\n10. Include dual authorization verification in security audits.",
    "implementation_guidance": "This is a TECHNICAL control requiring configuration of access controls and workflow. Implementation involves:\n\n1. SCOPE DEFINITION: Document which backup categories require dual authorization protection.\n\n2. TECHNICAL CONTROLS: Configure backup software or storage systems to require two-person authorization for deletion.\n\n3. WORKFLOW IMPLEMENTATION: Deploy ticketing or approval workflow systems for deletion requests.\n\n4. ACCESS MANAGEMENT: Ensure deletion approvers have appropriate authorization and separation of duties.\n\n5. AUDIT LOGGING: Log all deletion requests, approvals, and executions.\n\n6. ALERTING: Configure security alerts for backup deletion requests.",
    "ai_guidance": "When implementing CP-9.7 Dual Authorization compliance, AI can enhance the security and efficiency of backup deletion controls. AI-powered analysis can detect anomalous deletion patterns that might indicate compromised accounts or malicious activity, even when dual authorization is technically satisfied. Machine learning can establish baseline patterns for legitimate deletion activities and alert when requests deviate from normal patterns. Natural language processing can analyze deletion request justifications to flag potentially suspicious rationales. AI can optimize approval workflows by routing requests to available approvers while maintaining separation of duties requirements. AI can correlate deletion requests with other security events to identify potential attack patterns. For compliance, AI can continuously verify that dual authorization controls remain properly configured and alert on any gaps. AI-powered forensics can reconstruct the approval chain for any deletion to support investigations. Predictive analytics can identify backup sets approaching end-of-retention that should be reviewed before automatic deletion.",
    "is_technical": true,
    "enhancements": [],
    "related_controls": [
      "AC-3",
      "AC-5",
      "CP-9",
      "MP-2"
    ],
    "supplemental_guidance": "Dual authorization helps to ensure that the deletion or destruction of backup information cannot occur unless two authorized individuals carry out the task. Individuals deleting or destroying backup information possess sufficient skills or expertise to determine if the deletion or destruction of the backup information is performed correctly. Dual authorization may also be known as two-person control.",
    "implementation_scripts": {
      "linux": {
        "bash": "#!/bin/bash\n# CP-9.7 Dual Authorization Backup Deletion Script\n# Requires two separate approvals to delete backups\n\nDELETION_QUEUE=\"/var/lib/backup/deletion_queue\"\nAPPROVAL_LOG=\"/var/log/backup/deletion_approvals.log\"\nREQUIRED_APPROVALS=2\n\nlog_action() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" >> \"$APPROVAL_LOG\"\n}\n\n# Request deletion (first approval)\nrequest_deletion() {\n    local BACKUP_PATH=\"$1\"\n    local REQUESTOR=\"$(whoami)\"\n    local REQUEST_ID=$(date +%s)\n    \n    mkdir -p \"$DELETION_QUEUE\"\n    echo \"BACKUP=$BACKUP_PATH\" > \"$DELETION_QUEUE/$REQUEST_ID\"\n    echo \"REQUESTOR=$REQUESTOR\" >> \"$DELETION_QUEUE/$REQUEST_ID\"\n    echo \"TIMESTAMP=$(date -Iseconds)\" >> \"$DELETION_QUEUE/$REQUEST_ID\"\n    echo \"APPROVALS=1\" >> \"$DELETION_QUEUE/$REQUEST_ID\"\n    echo \"APPROVER1=$REQUESTOR\" >> \"$DELETION_QUEUE/$REQUEST_ID\"\n    \n    log_action \"DELETE REQUEST: $REQUEST_ID by $REQUESTOR for $BACKUP_PATH\"\n    echo \"Deletion request created: $REQUEST_ID\"\n    echo \"Requires second approval to execute\"\n}\n\n# Approve and execute deletion (second approval)\napprove_deletion() {\n    local REQUEST_ID=\"$1\"\n    local APPROVER=\"$(whoami)\"\n    \n    if [ ! -f \"$DELETION_QUEUE/$REQUEST_ID\" ]; then\n        echo \"ERROR: Request $REQUEST_ID not found\"\n        exit 1\n    fi\n    \n    source \"$DELETION_QUEUE/$REQUEST_ID\"\n    \n    if [ \"$APPROVER\" = \"$APPROVER1\" ]; then\n        echo \"ERROR: Same person cannot provide both approvals\"\n        exit 1\n    fi\n    \n    log_action \"DELETE APPROVED: $REQUEST_ID by $APPROVER (second approval)\"\n    \n    # Execute deletion\n    if [ -e \"$BACKUP\" ]; then\n        rm -rf \"$BACKUP\"\n        log_action \"DELETE EXECUTED: $BACKUP removed\"\n        rm -f \"$DELETION_QUEUE/$REQUEST_ID\"\n        echo \"Backup deleted: $BACKUP\"\n    else\n        echo \"ERROR: Backup path not found\"\n    fi\n}\n\ncase \"$1\" in\n    request)\n        request_deletion \"$2\"\n        ;;\n    approve)\n        approve_deletion \"$2\"\n        ;;\n    *)\n        echo \"Usage: $0 {request|approve} <path|request_id>\"\n        exit 1\nesac"
      },
      "windows": {
        "powershell": "# CP-9.7 Windows Dual Authorization Backup Deletion\n# Requires two separate approvals to delete backups\n\n$DeletionQueue = \"C:\\Backups\\DeletionQueue\"\n$ApprovalLog = \"C:\\Backups\\Logs\\deletion_approvals.log\"\n\nfunction Write-ApprovalLog {\n    param([string]$Message)\n    $Timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    \"$Timestamp - $Message\" | Add-Content -Path $ApprovalLog\n}\n\nfunction Request-BackupDeletion {\n    param([string]$BackupPath)\n    \n    $RequestId = Get-Date -Format \"yyyyMMddHHmmss\"\n    $Requestor = [Environment]::UserName\n    \n    New-Item -ItemType Directory -Path $DeletionQueue -Force | Out-Null\n    \n    $Request = @{\n        BackupPath = $BackupPath\n        Requestor = $Requestor\n        Timestamp = Get-Date -Format \"o\"\n        Approvals = 1\n        Approver1 = $Requestor\n    }\n    \n    $Request | ConvertTo-Json | Out-File \"$DeletionQueue\\$RequestId.json\"\n    \n    Write-ApprovalLog \"DELETE REQUEST: $RequestId by $Requestor for $BackupPath\"\n    Write-Output \"Deletion request created: $RequestId\"\n    Write-Output \"Requires second approval from different user to execute\"\n}\n\nfunction Approve-BackupDeletion {\n    param([string]$RequestId)\n    \n    $RequestFile = \"$DeletionQueue\\$RequestId.json\"\n    $Approver = [Environment]::UserName\n    \n    if (-not (Test-Path $RequestFile)) {\n        Write-Error \"Request $RequestId not found\"\n        return\n    }\n    \n    $Request = Get-Content $RequestFile | ConvertFrom-Json\n    \n    if ($Approver -eq $Request.Approver1) {\n        Write-Error \"Same person cannot provide both approvals\"\n        return\n    }\n    \n    Write-ApprovalLog \"DELETE APPROVED: $RequestId by $Approver (second approval)\"\n    \n    if (Test-Path $Request.BackupPath) {\n        Remove-Item -Path $Request.BackupPath -Recurse -Force\n        Write-ApprovalLog \"DELETE EXECUTED: $($Request.BackupPath) removed\"\n        Remove-Item $RequestFile -Force\n        Write-Output \"Backup deleted: $($Request.BackupPath)\"\n    } else {\n        Write-Error \"Backup path not found\"\n    }\n}\n\n# Export functions\nExport-ModuleMember -Function Request-BackupDeletion, Approve-BackupDeletion"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000+00:00",
      "has_scripts": true
    },
    "cac_metadata": {
      "implementation_type": "technical",
      "last_analyzed": "2025-11-22T00:00:00.000000+00:00",
      "source": "NIST SP 800-53 Rev 5",
      "implementation_guidance": "This control requires workflow controls ensuring two-person authorization for backup deletion. Scripts are provided implementing a queue-based dual approval system for Linux and Windows."
    },
    "rationale": "Requiring two people to delete backups prevents accidental or malicious destruction by a single person."
  },
  {
    "control_id": "CP-9.8",
    "control_name": "Cryptographic Protection",
    "family": "Contingency Planning",
    "family_id": "CP",
    "parent_control": "CP-9",
    "official_text": "Implement cryptographic mechanisms to prevent unauthorized disclosure and modification of [Assignment: organization-defined backup information].",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": true,
      "high": true
    },
    "stig_id": "SRG-OS-000185-GPOS-00079",
    "plain_english_explanation": "Cryptographic Protection for Backups requires organizations to encrypt backup information to prevent unauthorized access and detect any tampering. Backup media often contains sensitive information equivalent to production data and may be transported, stored off-site, or handled by third parties. Encryption ensures that even if backup media is lost, stolen, or intercepted, the data remains protected. Cryptographic integrity mechanisms (hashes, digital signatures) ensure that any modification to backup data is detectable.",
    "intent": "This enhancement addresses the significant security risks associated with backup media and data. Backups may be stored in less secure locations than production systems, transported across networks or physically, and handled by personnel or vendors with different trust levels than production data handlers. Cryptographic protection extends the confidentiality and integrity protections to backup information regardless of where it resides or how it is handled.",
    "example_implementation": "Implement backup encryption through: (1) Configure backup software to use AES-256 encryption for all backup jobs; (2) Enable encryption at rest for backup storage arrays; (3) Use TLS 1.2+ for backup data in transit; (4) Implement FIPS 140-2 validated cryptographic modules for federal systems; (5) Generate SHA-256 or SHA-512 hashes for backup files and store separately for integrity verification; (6) Use enterprise key management system for encryption key lifecycle; (7) Store encryption keys separately from encrypted backups; (8) Document key recovery procedures for disaster scenarios.",
    "non_technical_guidance": "To comply with control CP-9.8 (Cryptographic Protection), organizations should follow these procedures:\n1. Identify backup information requiring cryptographic protection based on sensitivity classification.\n2. Select cryptographic algorithms meeting organizational requirements (AES-256 for federal systems).\n3. Use FIPS 140-2 validated cryptographic modules when required by federal mandates.\n4. Implement encryption for backup data at rest on all storage media.\n5. Implement encryption for backup data in transit during replication or transfer.\n6. Deploy cryptographic integrity verification (digital signatures or keyed hashes) to detect tampering.\n7. Establish key management procedures including secure key generation, storage, rotation, and recovery.\n8. Store encryption keys separately from encrypted backups to prevent single-point compromise.\n9. Document key recovery procedures and test periodically.\n10. Include cryptographic protection verification in backup testing procedures.\n11. Train personnel on key management responsibilities and procedures.\n12. Audit cryptographic protection compliance periodically.",
    "implementation_guidance": "This is a TECHNICAL control requiring configuration of encryption and key management. Implementation involves:\n\n1. ALGORITHM SELECTION: Use approved algorithms - AES-256 for encryption, SHA-256/512 for hashing. FIPS 140-2 validated modules for federal systems.\n\n2. ENCRYPTION AT REST: Configure backup software or storage systems to encrypt backup data. Options include backup application encryption, storage array encryption, or file-level encryption.\n\n3. ENCRYPTION IN TRANSIT: Enable TLS 1.2+ for backup replication channels. Configure backup software for encrypted network transfers.\n\n4. INTEGRITY VERIFICATION: Generate cryptographic hashes during backup creation. Store hashes separately and verify before restoration.\n\n5. KEY MANAGEMENT: Deploy enterprise key management (HashiCorp Vault, Azure Key Vault, AWS KMS). Implement secure key storage, rotation, and recovery procedures.\n\n6. DOCUMENTATION: Document encryption configurations and key recovery procedures.",
    "ai_guidance": "When implementing CP-9.8 Cryptographic Protection compliance, AI can enhance the security and management of backup encryption. AI-powered key management can optimize key rotation schedules based on usage patterns and threat intelligence while ensuring keys remain available for restoration. Machine learning can detect anomalies in encryption operations that might indicate key compromise or misconfiguration. AI can monitor cryptographic module health and performance, predicting failures before they impact backup operations. Natural language processing can analyze vendor documentation and security advisories to identify cryptographic vulnerabilities requiring remediation. AI can automate compliance verification by continuously checking that backup encryption configurations meet policy requirements and alerting on gaps. AI-powered analysis can identify backup data that should be encrypted but is not currently protected. For key recovery scenarios, AI can orchestrate complex multi-step key reconstruction procedures. AI can optimize encryption performance by analyzing backup patterns and recommending encryption approaches that balance security with performance requirements.",
    "is_technical": true,
    "enhancements": [],
    "related_controls": [
      "CP-9",
      "SC-8",
      "SC-12",
      "SC-13",
      "SC-28"
    ],
    "supplemental_guidance": "The selection of cryptographic mechanisms is based on the need to protect the confidentiality and integrity of backup information. The strength of mechanisms selected is commensurate with the security categorization of the information being protected. This enhancement requires cryptographic protection for backup information when that information is at rest and during information transfer.",
    "implementation_scripts": {
      "linux": {
        "bash": "#!/bin/bash\n# CP-9.8 Encrypted Backup Implementation\n\nBACKUP_DIR=\"/var/backups/system/daily\"\nENCRYPTED_DIR=\"/var/backups/encrypted\"\nKEY_FILE=\"/root/.backup_key\"\nLOG_FILE=\"/var/log/backup/encryption.log\"\n\nlog_message() {\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') - $1\" | tee -a \"$LOG_FILE\"\n}\n\n# Generate encryption key if not exists\ngenerate_key() {\n    if [ ! -f \"$KEY_FILE\" ]; then\n        openssl rand -base64 32 > \"$KEY_FILE\"\n        chmod 600 \"$KEY_FILE\"\n        log_message \"Encryption key generated\"\n    fi\n}\n\n# Encrypt backup files\nencrypt_backups() {\n    log_message \"=== CP-9.8 Backup Encryption Started ===\"\n    mkdir -p \"$ENCRYPTED_DIR\"\n    \n    for file in \"$BACKUP_DIR\"/*.tar.gz; do\n        if [ -f \"$file\" ]; then\n            filename=$(basename \"$file\")\n            \n            # Encrypt using AES-256\n            openssl enc -aes-256-cbc -salt -pbkdf2 \\\n                -in \"$file\" \\\n                -out \"$ENCRYPTED_DIR/${filename}.enc\" \\\n                -pass file:\"$KEY_FILE\"\n            \n            if [ $? -eq 0 ]; then\n                # Generate SHA-256 hash\n                sha256sum \"$ENCRYPTED_DIR/${filename}.enc\" > \"$ENCRYPTED_DIR/${filename}.sha256\"\n                log_message \"[PASS] Encrypted: $filename\"\n            else\n                log_message \"[FAIL] Encryption failed: $filename\"\n            fi\n        fi\n    done\n    \n    log_message \"=== CP-9.8 Backup Encryption Completed ===\"\n}\n\n# Verify encrypted backup integrity\nverify_encryption() {\n    log_message \"Verifying encrypted backup integrity\"\n    cd \"$ENCRYPTED_DIR\"\n    \n    for hashfile in *.sha256; do\n        if sha256sum -c \"$hashfile\" 2>/dev/null; then\n            log_message \"[PASS] Integrity verified: $hashfile\"\n        else\n            log_message \"[FAIL] Integrity check failed: $hashfile\"\n        fi\n    done\n}\n\n# Decrypt backup for restoration\ndecrypt_backup() {\n    local encrypted_file=\"$1\"\n    local output_file=\"$2\"\n    \n    openssl enc -aes-256-cbc -d -pbkdf2 \\\n        -in \"$encrypted_file\" \\\n        -out \"$output_file\" \\\n        -pass file:\"$KEY_FILE\"\n    \n    if [ $? -eq 0 ]; then\n        log_message \"[PASS] Decrypted: $encrypted_file\"\n    else\n        log_message \"[FAIL] Decryption failed: $encrypted_file\"\n    fi\n}\n\ngenerate_key\nencrypt_backups\nverify_encryption",
        "ansible": "---\n# CP-9.8 Backup Encryption Playbook\n- name: CP-9.8 Cryptographic Backup Protection\n  hosts: all\n  become: yes\n  vars:\n    backup_dir: /var/backups/system/daily\n    encrypted_dir: /var/backups/encrypted\n    key_file: /root/.backup_key\n  \n  tasks:\n    - name: Install cryptographic utilities\n      package:\n        name:\n          - openssl\n          - gnupg2\n        state: present\n\n    - name: Create encrypted backup directory\n      file:\n        path: \"{{ encrypted_dir }}\"\n        state: directory\n        mode: '0700'\n        owner: root\n        group: root\n\n    - name: Generate backup encryption key\n      shell: openssl rand -base64 32 > {{ key_file }}\n      args:\n        creates: \"{{ key_file }}\"\n\n    - name: Secure encryption key\n      file:\n        path: \"{{ key_file }}\"\n        mode: '0600'\n        owner: root\n        group: root\n\n    - name: Deploy encryption script\n      copy:\n        dest: /usr/local/bin/encrypt_backups.sh\n        mode: '0750'\n        content: |\n          #!/bin/bash\n          for file in {{ backup_dir }}/*.tar.gz; do\n            if [ -f \"$file\" ]; then\n              filename=$(basename \"$file\")\n              openssl enc -aes-256-cbc -salt -pbkdf2 \\\n                -in \"$file\" \\\n                -out \"{{ encrypted_dir }}/${filename}.enc\" \\\n                -pass file:{{ key_file }}\n              sha256sum \"{{ encrypted_dir }}/${filename}.enc\" > \"{{ encrypted_dir }}/${filename}.sha256\"\n            fi\n          done\n\n    - name: Schedule encryption after daily backup\n      cron:\n        name: \"CP-9.8 Encrypt Daily Backups\"\n        hour: \"3\"\n        minute: \"0\"\n        job: \"/usr/local/bin/encrypt_backups.sh\"\n        user: root"
      },
      "windows": {
        "powershell": "# CP-9.8 Windows Encrypted Backup Implementation\n# Uses built-in Windows encryption capabilities\n\n$BackupDir = \"C:\\Backups\\SystemBackup\\Daily\"\n$EncryptedDir = \"C:\\Backups\\Encrypted\"\n$LogFile = \"C:\\Backups\\Logs\\encryption_$(Get-Date -Format 'yyyyMMdd').log\"\n\nfunction Write-Log {\n    param([string]$Message)\n    $Timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    \"$Timestamp - $Message\" | Tee-Object -FilePath $LogFile -Append\n}\n\nWrite-Log \"=== CP-9.8 Backup Encryption Started ===\"\n\n# Create encrypted directory\nNew-Item -ItemType Directory -Path $EncryptedDir -Force | Out-Null\n\n# Get or create encryption key (certificate-based)\n$CertSubject = \"CN=BackupEncryption\"\n$Cert = Get-ChildItem -Path Cert:\\LocalMachine\\My | Where-Object { $_.Subject -eq $CertSubject }\n\nif (-not $Cert) {\n    $Cert = New-SelfSignedCertificate -Subject $CertSubject `\n        -CertStoreLocation Cert:\\LocalMachine\\My `\n        -KeyUsage KeyEncipherment, DataEncipherment `\n        -Type DocumentEncryptionCert `\n        -NotAfter (Get-Date).AddYears(5)\n    Write-Log \"Created encryption certificate: $($Cert.Thumbprint)\"\n}\n\n# Encrypt backup files using EFS or 7-Zip with AES-256\n$7ZipPath = \"C:\\Program Files\\7-Zip\\7z.exe\"\n$Password = [System.Convert]::ToBase64String((1..32 | ForEach-Object { Get-Random -Maximum 256 }))\n\nGet-ChildItem -Path $BackupDir -Filter \"*.zip\" | ForEach-Object {\n    $SourceFile = $_.FullName\n    $EncryptedFile = Join-Path $EncryptedDir \"$($_.BaseName).7z\"\n    \n    if (Test-Path $7ZipPath) {\n        # Use 7-Zip with AES-256\n        & $7ZipPath a -t7z -mx=9 -mhe=on \"-p$Password\" $EncryptedFile $SourceFile 2>&1 | Out-Null\n        \n        if ($LASTEXITCODE -eq 0) {\n            # Generate hash for integrity\n            $Hash = Get-FileHash -Path $EncryptedFile -Algorithm SHA256\n            $Hash.Hash | Out-File \"$EncryptedFile.sha256\"\n            Write-Log \"[PASS] Encrypted: $($_.Name)\"\n        } else {\n            Write-Log \"[FAIL] Encryption failed: $($_.Name)\"\n        }\n    } else {\n        # Fallback to EFS\n        Copy-Item $SourceFile $EncryptedFile\n        (Get-Item $EncryptedFile).Encrypt()\n        Write-Log \"[PASS] EFS Encrypted: $($_.Name)\"\n    }\n}\n\n# Store password securely (encrypted with DPAPI)\n$SecurePassword = ConvertTo-SecureString $Password -AsPlainText -Force\n$SecurePassword | ConvertFrom-SecureString | Out-File \"$EncryptedDir\\.keyfile\" -Force\n(Get-Item \"$EncryptedDir\\.keyfile\").Attributes = 'Hidden'\n\nWrite-Log \"=== CP-9.8 Backup Encryption Completed ===\""
      }
    },
    "stig_mappings": {
      "general": [
        "SRG-OS-000185-GPOS-00079",
        "SRG-APP-000231-CTR-000570"
      ]
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00.000000+00:00",
      "has_scripts": true
    },
    "cac_metadata": {
      "implementation_type": "technical",
      "last_analyzed": "2025-11-22T00:00:00.000000+00:00",
      "source": "NIST SP 800-53 Rev 5",
      "implementation_guidance": "This control requires encryption of backup data at rest and in transit. Scripts are provided using OpenSSL (Linux) and 7-Zip/EFS (Windows) for AES-256 encryption with SHA-256 integrity verification."
    },
    "rationale": "Encrypted backups protect sensitive data even if backup media is stolen or lost."
  },
  {
    "control_id": "CP-10",
    "control_name": "System Recovery and Reconstitution",
    "family": "Contingency Planning",
    "family_id": "CP",
    "official_text": "Provide for the recovery and reconstitution of the system to a known state within [Assignment: organization-defined time period] after a disruption, compromise, or failure.",
    "source": "NIST SP 800-53 Rev 5",
    "stig_id": "SRG-OS-000480-GPOS-00227",
    "baselines": {
      "low": true,
      "moderate": true,
      "high": true
    },
    "plain_english_explanation": "Your organization must have documented, tested procedures to restore systems to a known good state after any disruption, security incident, or system failure. This includes maintaining verified backups, recovery playbooks, and the capability to rebuild systems from scratch if necessary. The goal is ensuring business continuity by minimizing downtime and data loss while maintaining security controls during and after recovery.",
    "intent": "Ensure organizations can restore system operations to a secure, functional state after disruptions, compromises, or failures, thereby maintaining mission continuity and limiting the impact of adverse events.",
    "ai_guidance": "When implementing CP-10 recovery capabilities, prioritize automation and verification. Recovery procedures should be infrastructure-as-code where possible, enabling rapid, repeatable reconstitution. Key considerations include: (1) Maintain immutable backup images with cryptographic verification, (2) Document and automate the complete recovery sequence including network, storage, compute, and application layers, (3) Implement recovery time objectives (RTO) and recovery point objectives (RPO) based on business impact analysis, (4) Test recovery procedures regularly in isolated environments, (5) Ensure recovery processes maintain security controls and do not introduce vulnerabilities, (6) Include post-recovery validation to verify system integrity and security posture. Modern approaches leverage container orchestration, infrastructure-as-code, and automated configuration management to achieve sub-hour recovery times.",
    "example_implementation": "Implement automated disaster recovery using infrastructure-as-code with tools like Terraform, Ansible, or cloud-native recovery services. Maintain golden images, automated backup verification, and runbook automation for rapid reconstitution.",
    "non_technical_guidance": "Develop comprehensive recovery procedures that include: (1) Clear roles and responsibilities for recovery personnel, (2) Step-by-step recovery procedures for each critical system, (3) Communication plans for stakeholders, (4) Decision trees for various failure scenarios, (5) Regular tabletop exercises and full-scale recovery tests, (6) Documentation of lessons learned and procedure updates.",
    "is_technical": true,
    "enhancements": [
      {
        "id": "CP-10(1)",
        "title": "Contingency Plan Testing",
        "official_text": "[Withdrawn: Incorporated into CP-4]",
        "status": "withdrawn",
        "incorporated_into": "CP-4"
      },
      {
        "id": "CP-10(2)",
        "title": "Transaction Recovery",
        "official_text": "Implement transaction recovery for systems that are transaction-based."
      },
      {
        "id": "CP-10(3)",
        "title": "Compensating Security Controls",
        "official_text": "[Withdrawn: Addressed through tailoring procedures]",
        "status": "withdrawn"
      },
      {
        "id": "CP-10(4)",
        "title": "Restore Within Time Period",
        "official_text": "Provide the capability to restore system components within [Assignment: organization-defined restoration time period] from configuration-controlled and integrity-protected information representing a known, operational state for the components."
      },
      {
        "id": "CP-10(5)",
        "title": "Failover Capability",
        "official_text": "[Withdrawn: Incorporated into SI-13]",
        "status": "withdrawn",
        "incorporated_into": "SI-13"
      },
      {
        "id": "CP-10(6)",
        "title": "Component Protection",
        "official_text": "Protect system components used for recovery and reconstitution."
      }
    ],
    "related_controls": [
      "CP-2",
      "CP-4",
      "CP-6",
      "CP-7",
      "CP-9",
      "IR-4",
      "SA-8",
      "SC-24",
      "SI-13"
    ],
    "supplemental_guidance": "Recovery is executing the contingency plan activities to restore organizational mission and business functions. Reconstitution takes place following recovery and includes activities for returning organizational systems to fully operational states. Recovery and reconstitution operations reflect priorities in contingency plans. Reconstitution includes the deactivation of any interim system capability established during recovery. Recovery procedures should include post-recovery validation to verify the system integrity and that security controls are operational.",
    "implementation_scripts": {
      "linux": {
        "bash": "# recovery_status_check\n#!/bin/bash\n# CP-10: System Recovery Status Check\n# Verify backup and recovery infrastructure status\n\necho \"=== CP-10 Recovery Infrastructure Status ===\"\necho \"Date: $(date)\"\necho \"\"\n\n# Check backup service status\necho \"[BACKUP SERVICES]\"\nfor svc in bacula-fd restic-backup duplicity borgbackup; do\n    if systemctl is-active --quiet $svc 2>/dev/null; then\n        echo \"  $svc: RUNNING\"\n    elif systemctl list-unit-files | grep -q $svc; then\n        echo \"  $svc: INSTALLED BUT NOT RUNNING\"\n    fi\ndone\n\n# Check last backup timestamps\necho \"\"\necho \"[LAST BACKUP STATUS]\"\nif [ -f /var/log/backup.log ]; then\n    echo \"  Last backup entry: $(tail -1 /var/log/backup.log)\"\nfi\n\n# Verify recovery scripts exist\necho \"\"\necho \"[RECOVERY SCRIPTS]\"\nfor script in /opt/recovery/*.sh /usr/local/bin/disaster-recovery.sh; do\n    if [ -f \"$script\" ]; then\n        echo \"  Found: $script\"\n    fi\ndone\n\n# Check for recovery documentation\necho \"\"\necho \"[RECOVERY DOCUMENTATION]\"\nfor doc in /opt/recovery/runbook.md /etc/disaster-recovery/procedures.md; do\n    if [ -f \"$doc\" ]; then\n        echo \"  Found: $doc\"\n    fi\ndone\n\n# backup_verification\n#!/bin/bash\n# CP-10: Backup Integrity Verification\n# Verify backup integrity and recoverability\n\nBACKUP_DIR=\"${1:-/backup}\"\nLOG_FILE=\"/var/log/backup-verification.log\"\n\necho \"=== CP-10 Backup Verification ===\"\necho \"Backup Directory: $BACKUP_DIR\"\necho \"Verification Time: $(date)\"\necho \"\"\n\n# Verify backup exists and is recent\nif [ -d \"$BACKUP_DIR\" ]; then\n    LATEST=$(find \"$BACKUP_DIR\" -type f -name '*.tar.gz' -o -name '*.img' | head -1)\n    if [ -n \"$LATEST\" ]; then\n        AGE_DAYS=$(( ($(date +%s) - $(stat -c %Y \"$LATEST\")) / 86400 ))\n        echo \"Latest backup: $LATEST\"\n        echo \"Age: $AGE_DAYS days\"\n        if [ $AGE_DAYS -gt 7 ]; then\n            echo \"WARNING: Backup is older than 7 days\"\n        fi\n    fi\nfi\n\n# Verify checksum if available\nif [ -f \"$BACKUP_DIR/checksums.sha256\" ]; then\n    echo \"\"\n    echo \"Verifying checksums...\"\n    cd \"$BACKUP_DIR\" && sha256sum -c checksums.sha256 2>&1 | tee -a $LOG_FILE\nfi\n\necho \"\"\necho \"Verification complete. Log: $LOG_FILE\"\n\n# automated_recovery_playbook\n#!/bin/bash\n# CP-10: Automated System Recovery Playbook\n# Execute full system recovery from backup\n\nset -e\n\nRECOVERY_SOURCE=\"${1:-/backup/latest}\"\nTARGET_ROOT=\"${2:-/mnt/recovery}\"\nLOG_FILE=\"/var/log/recovery-$(date +%Y%m%d-%H%M%S).log\"\n\nlog() {\n    echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\" | tee -a $LOG_FILE\n}\n\nlog \"=== CP-10 SYSTEM RECOVERY INITIATED ===\"\nlog \"Source: $RECOVERY_SOURCE\"\nlog \"Target: $TARGET_ROOT\"\n\n# Phase 1: Pre-recovery validation\nlog \"Phase 1: Pre-recovery validation\"\nif [ ! -d \"$RECOVERY_SOURCE\" ]; then\n    log \"ERROR: Recovery source not found\"\n    exit 1\nfi\n\n# Phase 2: Mount recovery target\nlog \"Phase 2: Preparing recovery target\"\nmkdir -p \"$TARGET_ROOT\"\n\n# Phase 3: Restore system files\nlog \"Phase 3: Restoring system files\"\nif [ -f \"$RECOVERY_SOURCE/system.tar.gz\" ]; then\n    tar -xzf \"$RECOVERY_SOURCE/system.tar.gz\" -C \"$TARGET_ROOT\"\n    log \"System files restored\"\nfi\n\n# Phase 4: Restore configuration\nlog \"Phase 4: Restoring configuration\"\nif [ -f \"$RECOVERY_SOURCE/etc.tar.gz\" ]; then\n    tar -xzf \"$RECOVERY_SOURCE/etc.tar.gz\" -C \"$TARGET_ROOT\"\n    log \"Configuration restored\"\nfi\n\n# Phase 5: Post-recovery validation\nlog \"Phase 5: Post-recovery validation\"\nif [ -f \"$RECOVERY_SOURCE/checksums.sha256\" ]; then\n    cd \"$TARGET_ROOT\" && sha256sum -c \"$RECOVERY_SOURCE/checksums.sha256\" >> $LOG_FILE 2>&1\n    log \"Integrity verification complete\"\nfi\n\nlog \"=== RECOVERY COMPLETE ===\"\nlog \"Review log: $LOG_FILE\""
      },
      "windows": {
        "powershell": "# recovery_status_check\n# CP-10: System Recovery Status Check (PowerShell)\n# Verify Windows backup and recovery infrastructure status\n\nWrite-Host \"=== CP-10 Recovery Infrastructure Status ===\"\nWrite-Host \"Date: $(Get-Date)\"\nWrite-Host \"\"\n\n# Check Windows Backup status\nWrite-Host \"[WINDOWS BACKUP STATUS]\"\ntry {\n    $wbPolicy = Get-WBPolicy -Editable 2>$null\n    if ($wbPolicy) {\n        Write-Host \"  Windows Backup Policy: CONFIGURED\"\n        Write-Host \"  Backup Target: $($wbPolicy.BackupTarget)\"\n    } else {\n        Write-Host \"  Windows Backup Policy: NOT CONFIGURED\"\n    }\n} catch {\n    Write-Host \"  Windows Backup: Not available or not configured\"\n}\n\n# Check Volume Shadow Copy\nWrite-Host \"\"\nWrite-Host \"[VOLUME SHADOW COPY]\"\n$shadows = Get-WmiObject Win32_ShadowCopy\nif ($shadows) {\n    Write-Host \"  Shadow Copies Found: $($shadows.Count)\"\n    $latest = $shadows | Sort-Object InstallDate -Descending | Select-Object -First 1\n    Write-Host \"  Latest: $($latest.InstallDate)\"\n} else {\n    Write-Host \"  No shadow copies found\"\n}\n\n# Check System Restore\nWrite-Host \"\"\nWrite-Host \"[SYSTEM RESTORE]\"\ntry {\n    $restorePoints = Get-ComputerRestorePoint\n    Write-Host \"  Restore Points: $($restorePoints.Count)\"\n} catch {\n    Write-Host \"  System Restore: Not available\"\n}\n\n# Check Backup Services\nWrite-Host \"\"\nWrite-Host \"[BACKUP SERVICES]\"\n$services = @('wbengine', 'SDRSVC', 'VSS')\nforeach ($svc in $services) {\n    $service = Get-Service $svc -ErrorAction SilentlyContinue\n    if ($service) {\n        Write-Host \"  $($service.DisplayName): $($service.Status)\"\n    }\n}\n\n# backup_verification\n# CP-10: Backup Verification (PowerShell)\n# Verify Windows backup integrity\n\nparam(\n    [string]$BackupPath = \"D:\\Backup\"\n)\n\nWrite-Host \"=== CP-10 Backup Verification ===\"\nWrite-Host \"Backup Path: $BackupPath\"\nWrite-Host \"Verification Time: $(Get-Date)\"\nWrite-Host \"\"\n\nif (Test-Path $BackupPath) {\n    # Get latest backup\n    $latestBackup = Get-ChildItem $BackupPath -Recurse | \n                    Where-Object { $_.Extension -in '.vhd','.vhdx','.bak','.zip' } |\n                    Sort-Object LastWriteTime -Descending | \n                    Select-Object -First 1\n    \n    if ($latestBackup) {\n        $age = (Get-Date) - $latestBackup.LastWriteTime\n        Write-Host \"Latest Backup: $($latestBackup.FullName)\"\n        Write-Host \"Size: $([math]::Round($latestBackup.Length/1GB, 2)) GB\"\n        Write-Host \"Age: $($age.Days) days, $($age.Hours) hours\"\n        \n        if ($age.Days -gt 7) {\n            Write-Host \"WARNING: Backup is older than 7 days\" -ForegroundColor Yellow\n        }\n        \n        # Verify file hash if catalog exists\n        $catalogPath = Join-Path $BackupPath \"catalog.xml\"\n        if (Test-Path $catalogPath) {\n            Write-Host \"\"\n            Write-Host \"Verifying backup catalog...\"\n            $hash = Get-FileHash $latestBackup.FullName -Algorithm SHA256\n            Write-Host \"SHA256: $($hash.Hash)\"\n        }\n    }\n} else {\n    Write-Host \"ERROR: Backup path not found\" -ForegroundColor Red\n}\n\n# automated_recovery_playbook\n# CP-10: Automated System Recovery (PowerShell)\n# Execute Windows system recovery from backup\n\nparam(\n    [string]$BackupSource = \"D:\\Backup\\Latest\",\n    [string]$LogPath = \"C:\\Recovery\\Logs\"\n)\n\n$ErrorActionPreference = \"Stop\"\n$timestamp = Get-Date -Format \"yyyyMMdd-HHmmss\"\n$logFile = Join-Path $LogPath \"recovery-$timestamp.log\"\n\nfunction Log-Message {\n    param([string]$Message)\n    $entry = \"[$(Get-Date -Format 'yyyy-MM-dd HH:mm:ss')] $Message\"\n    Write-Host $entry\n    Add-Content -Path $logFile -Value $entry\n}\n\n# Create log directory\nNew-Item -ItemType Directory -Path $LogPath -Force | Out-Null\n\nLog-Message \"=== CP-10 SYSTEM RECOVERY INITIATED ===\"\nLog-Message \"Source: $BackupSource\"\n\n# Phase 1: Pre-recovery validation\nLog-Message \"Phase 1: Pre-recovery validation\"\nif (-not (Test-Path $BackupSource)) {\n    Log-Message \"ERROR: Backup source not found\"\n    exit 1\n}\n\n# Phase 2: Stop dependent services\nLog-Message \"Phase 2: Preparing for recovery\"\n$servicesToStop = @('W3SVC', 'MSSQLSERVER')\nforeach ($svc in $servicesToStop) {\n    $service = Get-Service $svc -ErrorAction SilentlyContinue\n    if ($service -and $service.Status -eq 'Running') {\n        Stop-Service $svc -Force\n        Log-Message \"Stopped service: $svc\"\n    }\n}\n\n# Phase 3: Restore from backup\nLog-Message \"Phase 3: Restoring from backup\"\n# Use Windows Server Backup or custom restore logic\n\n# Phase 4: Post-recovery validation\nLog-Message \"Phase 4: Post-recovery validation\"\n# Verify critical files and services\n\n# Phase 5: Restart services\nLog-Message \"Phase 5: Restarting services\"\nforeach ($svc in $servicesToStop) {\n    Start-Service $svc -ErrorAction SilentlyContinue\n    Log-Message \"Started service: $svc\"\n}\n\nLog-Message \"=== RECOVERY COMPLETE ===\""
      },
      "ansible": {
        "system_recovery_playbook": "---\n# CP-10: System Recovery and Reconstitution Playbook\n# Ansible playbook for automated disaster recovery\n\n- name: CP-10 System Recovery\n  hosts: recovery_targets\n  become: yes\n  vars:\n    backup_source: \"/backup/latest\"\n    recovery_log: \"/var/log/recovery-{{ ansible_date_time.iso8601_basic_short }}.log\"\n    rto_minutes: 60\n\n  tasks:\n    - name: Phase 1 - Pre-recovery validation\n      block:\n        - name: Verify backup source accessibility\n          stat:\n            path: \"{{ backup_source }}\"\n          register: backup_check\n          failed_when: not backup_check.stat.exists\n\n        - name: Log recovery initiation\n          lineinfile:\n            path: \"{{ recovery_log }}\"\n            line: \"[{{ ansible_date_time.iso8601 }}] Recovery initiated from {{ backup_source }}\"\n            create: yes\n\n    - name: Phase 2 - Stop application services\n      service:\n        name: \"{{ item }}\"\n        state: stopped\n      loop:\n        - httpd\n        - nginx\n        - mysql\n        - postgresql\n      ignore_errors: yes\n\n    - name: Phase 3 - Restore configuration\n      unarchive:\n        src: \"{{ backup_source }}/etc-backup.tar.gz\"\n        dest: /\n        remote_src: yes\n      when: backup_check.stat.exists\n\n    - name: Phase 4 - Restore application data\n      unarchive:\n        src: \"{{ backup_source }}/data-backup.tar.gz\"\n        dest: /\n        remote_src: yes\n      when: backup_check.stat.exists\n\n    - name: Phase 5 - Verify file integrity\n      command: sha256sum -c \"{{ backup_source }}/checksums.sha256\"\n      args:\n        chdir: /\n      register: integrity_check\n      ignore_errors: yes\n\n    - name: Phase 6 - Start application services\n      service:\n        name: \"{{ item }}\"\n        state: started\n        enabled: yes\n      loop:\n        - httpd\n        - nginx\n        - mysql\n        - postgresql\n      ignore_errors: yes\n\n    - name: Phase 7 - Post-recovery validation\n      block:\n        - name: Verify critical services are running\n          service:\n            name: \"{{ item }}\"\n          register: service_status\n          loop:\n            - sshd\n            - auditd\n          \n        - name: Log recovery completion\n          lineinfile:\n            path: \"{{ recovery_log }}\"\n            line: \"[{{ ansible_date_time.iso8601 }}] Recovery completed successfully\""
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": true,
      "qa_verified": true,
      "qa_agent": "LOVELESS"
    },
    "cac_metadata": {
      "implementation_type": "technical",
      "last_analyzed": "2025-11-22T00:00:00Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Implement automated backup verification, recovery playbooks, and post-recovery validation scripts. Use infrastructure-as-code for repeatable reconstitution."
    },
    "rationale": "Having backups isn't enough. You need proven procedures to actually restore systems to a working state."
  },
  {
    "control_id": "CP-11",
    "control_name": "Alternate Communications Protocols",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "is_technical": true,
    "official_text": "Provide the capability to employ [Assignment: organization-defined alternative communications protocols] in support of maintaining continuity of operations.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "intent": "Ensure organizational resilience by establishing alternative communication methods that can be activated when primary protocols fail, become unavailable, or are compromised, thereby maintaining continuity of critical operations during contingency events.",
    "plain_english_explanation": "Organizations must have backup communication methods ready to deploy when primary communication protocols fail. This includes maintaining alternative network paths, backup communication channels (such as satellite links, cellular networks, or radio communications), and the technical capability to rapidly switch between protocols. The goal is ensuring critical information can still flow during emergencies, natural disasters, cyberattacks, or infrastructure failures that disable normal communications.",
    "ai_guidance": "When implementing CP-11, verify that the organization has documented alternative communications protocols for each critical communication path. Check for protocol failover automation where possible, including automatic detection of primary protocol failure and seamless switching to backup protocols. Assess network redundancy configurations including multi-path routing, diverse carrier arrangements, and out-of-band management channels. Evaluate whether backup protocols maintain required security posture (encryption, authentication) during failover. Review testing schedules to ensure alternate protocols are regularly validated. Consider integration with CP-2 (Contingency Plan) and CP-8 (Telecommunications Services) to ensure holistic coverage. Validate that personnel are trained on manual protocol switching procedures when automation is unavailable.",
    "example_implementation": "Configure network infrastructure with primary and secondary communication paths using diverse protocols. Implement automated failover between primary fiber connections and backup cellular/satellite links. Deploy VPN failover configurations that automatically switch to alternate endpoints. Configure DNS failover and multi-region load balancing for critical services. Establish out-of-band management networks using separate physical paths.",
    "non_technical_guidance": "To comply with CP-11:\n1. Inventory all critical communication channels used by the organization.\n2. For each critical channel, identify at least one alternative communication method.\n3. Document switching procedures for activating alternate protocols.\n4. Train relevant personnel on how to recognize primary protocol failures and activate alternatives.\n5. Establish contracts with backup communication service providers.\n6. Test alternate communication protocols on a scheduled basis (quarterly recommended).\n7. Integrate alternate protocol activation into contingency plan exercises.\n8. Maintain current contact lists accessible via alternate communication methods.",
    "supplemental_guidance": "Contingency plans and the training associated with those plans need to address the operation of the system using alternative communications protocols. Switching communications protocols may affect software applications and operational aspects of the system. Potential side effects need to be addressed prior to implementation.",
    "enhancements": [],
    "related_controls": [
      "CP-2",
      "CP-8",
      "CP-13"
    ],
    "framework_mappings": {
      "nist_csf_v1_1": [
        "ID.BE-5",
        "PR.PT-5"
      ],
      "nist_csf_v2_0": [
        "PR.IR-03"
      ],
      "nist_pf_v1_0": [
        "PR.PT-P4"
      ]
    },
    "implementation_scripts": {
      "linux": {
        "protocol_failover_check": {
          "description": "Check network interface and routing redundancy configuration",
          "script": "#!/bin/bash\n# CP-11: Alternate Communications Protocols - Redundancy Check\n# This script validates network failover configurations\n\necho \"=== CP-11 Protocol Redundancy Assessment ===\"\necho \"Date: $(date)\"\necho \"\"\n\n# Check for multiple network interfaces\necho \"[1] Network Interfaces Available:\"\nip -br link show | grep -v lo\necho \"\"\n\n# Check routing table for redundant paths\necho \"[2] Routing Table (check for alternate routes):\"\nip route show | head -20\necho \"\"\n\n# Check for bonded/teamed interfaces\necho \"[3] Bonded Interface Status:\"\nif [ -d /proc/net/bonding ]; then\n    for bond in /proc/net/bonding/*; do\n        echo \"Bond: $(basename $bond)\"\n        cat $bond | grep -E '(Mode|Slave Interface|MII Status)'\n    done\nelse\n    echo \"No bonded interfaces configured\"\nfi\necho \"\"\n\n# Check for VPN failover configurations\necho \"[4] VPN Connections:\"\nif command -v nmcli &> /dev/null; then\n    nmcli connection show --active | grep -i vpn || echo \"No active VPN connections\"\nfi\necho \"\"\n\n# Check DNS redundancy\necho \"[5] DNS Configuration (redundancy check):\"\ncat /etc/resolv.conf | grep nameserver\necho \"\"\n\necho \"=== Assessment Complete ===\""
        },
        "network_failover_test": {
          "description": "Test network failover capability between primary and backup interfaces",
          "script": "#!/bin/bash\n# CP-11: Network Failover Test Script\n# Tests failover between primary and backup network paths\n\nPRIMARY_IF=\"${1:-eth0}\"\nBACKUP_IF=\"${2:-eth1}\"\nTEST_HOST=\"${3:-8.8.8.8}\"\n\necho \"=== CP-11 Failover Test ===\"\necho \"Primary Interface: $PRIMARY_IF\"\necho \"Backup Interface: $BACKUP_IF\"\necho \"Test Target: $TEST_HOST\"\necho \"\"\n\n# Test primary connectivity\necho \"[1] Testing primary interface connectivity...\"\nif ping -I $PRIMARY_IF -c 3 $TEST_HOST &> /dev/null; then\n    echo \"    PRIMARY: PASS - Interface $PRIMARY_IF can reach $TEST_HOST\"\nelse\n    echo \"    PRIMARY: FAIL - Interface $PRIMARY_IF cannot reach $TEST_HOST\"\nfi\n\n# Test backup connectivity\necho \"[2] Testing backup interface connectivity...\"\nif ping -I $BACKUP_IF -c 3 $TEST_HOST &> /dev/null; then\n    echo \"    BACKUP: PASS - Interface $BACKUP_IF can reach $TEST_HOST\"\nelse\n    echo \"    BACKUP: FAIL - Interface $BACKUP_IF cannot reach $TEST_HOST\"\nfi\n\necho \"\"\necho \"=== Failover Test Complete ===\""
        }
      },
      "windows": {
        "protocol_failover_check": {
          "description": "Check network adapter and routing redundancy on Windows",
          "script": "# CP-11: Alternate Communications Protocols - Windows Redundancy Check\n# PowerShell script to validate network failover configurations\n\nWrite-Host \"=== CP-11 Protocol Redundancy Assessment ===\" -ForegroundColor Cyan\nWrite-Host \"Date: $(Get-Date)\"\nWrite-Host \"\"\n\n# Check for multiple network adapters\nWrite-Host \"[1] Network Adapters Available:\" -ForegroundColor Yellow\nGet-NetAdapter | Where-Object {$_.Status -eq 'Up'} | Format-Table Name, InterfaceDescription, Status, LinkSpeed\n\n# Check IP configuration for redundancy\nWrite-Host \"[2] IP Configurations:\" -ForegroundColor Yellow\nGet-NetIPAddress -AddressFamily IPv4 | Where-Object {$_.InterfaceAlias -notlike '*Loopback*'} | Format-Table InterfaceAlias, IPAddress, PrefixLength\n\n# Check routing table\nWrite-Host \"[3] Routing Table (alternate routes):\" -ForegroundColor Yellow\nGet-NetRoute | Where-Object {$_.DestinationPrefix -eq '0.0.0.0/0'} | Format-Table DestinationPrefix, NextHop, InterfaceAlias, RouteMetric\n\n# Check NIC teaming\nWrite-Host \"[4] NIC Teaming Configuration:\" -ForegroundColor Yellow\ntry {\n    $teams = Get-NetLbfoTeam -ErrorAction SilentlyContinue\n    if ($teams) {\n        $teams | Format-Table Name, TeamingMode, LoadBalancingAlgorithm, Status\n    } else {\n        Write-Host \"    No NIC teams configured\"\n    }\n} catch {\n    Write-Host \"    NIC Teaming not available or not configured\"\n}\n\n# Check VPN connections\nWrite-Host \"`n[5] VPN Connections:\" -ForegroundColor Yellow\nGet-VpnConnection -ErrorAction SilentlyContinue | Format-Table Name, ServerAddress, ConnectionStatus\n\n# Check DNS redundancy\nWrite-Host \"[6] DNS Server Configuration:\" -ForegroundColor Yellow\nGet-DnsClientServerAddress -AddressFamily IPv4 | Where-Object {$_.ServerAddresses} | Format-Table InterfaceAlias, ServerAddresses\n\nWrite-Host \"`n=== Assessment Complete ===\" -ForegroundColor Cyan"
        },
        "network_failover_test": {
          "description": "Test network failover capability on Windows",
          "script": "# CP-11: Windows Network Failover Test\n# Tests connectivity through multiple network paths\n\nparam(\n    [string]$PrimaryAdapter = \"Ethernet\",\n    [string]$BackupAdapter = \"Wi-Fi\",\n    [string]$TestHost = \"8.8.8.8\"\n)\n\nWrite-Host \"=== CP-11 Failover Test ===\" -ForegroundColor Cyan\nWrite-Host \"Primary Adapter: $PrimaryAdapter\"\nWrite-Host \"Backup Adapter: $BackupAdapter\"\nWrite-Host \"Test Target: $TestHost\"\nWrite-Host \"\"\n\n# Get adapter indices\n$primaryIndex = (Get-NetAdapter -Name $PrimaryAdapter -ErrorAction SilentlyContinue).ifIndex\n$backupIndex = (Get-NetAdapter -Name $BackupAdapter -ErrorAction SilentlyContinue).ifIndex\n\n# Test primary connectivity\nWrite-Host \"[1] Testing primary adapter connectivity...\" -ForegroundColor Yellow\nif ($primaryIndex) {\n    $result = Test-NetConnection -ComputerName $TestHost -WarningAction SilentlyContinue\n    if ($result.PingSucceeded) {\n        Write-Host \"    PRIMARY: PASS\" -ForegroundColor Green\n    } else {\n        Write-Host \"    PRIMARY: FAIL\" -ForegroundColor Red\n    }\n} else {\n    Write-Host \"    PRIMARY: NOT FOUND\" -ForegroundColor Red\n}\n\n# Test backup connectivity  \nWrite-Host \"[2] Testing backup adapter connectivity...\" -ForegroundColor Yellow\nif ($backupIndex) {\n    # Temporarily adjust metrics or use specific interface\n    $result = Test-NetConnection -ComputerName $TestHost -WarningAction SilentlyContinue\n    if ($result.PingSucceeded) {\n        Write-Host \"    BACKUP: PASS\" -ForegroundColor Green\n    } else {\n        Write-Host \"    BACKUP: FAIL\" -ForegroundColor Red\n    }\n} else {\n    Write-Host \"    BACKUP: NOT FOUND\" -ForegroundColor Red\n}\n\nWrite-Host \"`n=== Failover Test Complete ===\" -ForegroundColor Cyan"
        }
      }
    },
    "metadata": {
      "status": "enhanced",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_validated": true,
      "qa_agent": "LOVELESS",
      "validation_date": "2025-11-22"
    },
    "cac_metadata": {
      "implementation_type": "technical",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "NIST SP 800-53 Rev 5",
      "cac_status": "enhanced",
      "implementation_guidance": "Implement network redundancy with automated failover detection. Configure bonded/teamed network interfaces where possible. Establish diverse communication paths using different carriers and technologies. Document and test protocol switching procedures."
    },
    "rationale": "If primary communication fails, you need backup methods. This could be satellite phones, ham radio, or alternate networks."
  },
  {
    "control_id": "CP-12",
    "control_name": "Safe Mode",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "official_text": "When [Assignment: organization-defined conditions] are detected, enter a safe mode of operation with [Assignment: organization-defined restrictions of safe mode of operation].",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "is_technical": true,
    "intent": "To ensure systems can automatically transition to a degraded but secure operational state when anomalous conditions, security threats, or critical failures are detected, thereby preserving system integrity, protecting sensitive data, and maintaining essential functions until normal operations can be safely restored.",
    "plain_english_explanation": "Safe Mode is a contingency capability that allows systems to automatically detect dangerous or abnormal conditions and transition into a restricted operational state. When triggered, the system limits its functionality to essential operations only, disables non-critical services, and applies heightened security restrictions. This prevents damage propagation, protects sensitive data from compromise, and maintains core mission functions while administrators diagnose and resolve the underlying issue. Think of it like a circuit breaker for your IT systems - when something goes wrong, the system reduces its attack surface and operational complexity to prevent further harm.",
    "ai_guidance": "When implementing CP-12 Safe Mode controls, focus on three key areas: detection, transition, and recovery. For detection, configure systems to monitor for security anomalies (intrusion attempts, malware signatures, unauthorized access patterns), hardware failures (disk errors, memory corruption, thermal warnings), and software faults (service crashes, resource exhaustion, configuration corruption). The safe mode transition should be automated where possible, with clearly defined triggers and thresholds. Implement graduated response levels - from warning states through partial degradation to full safe mode lockdown. Ensure safe mode preserves audit logging, maintains authentication requirements, and protects cryptographic keys. Document all safe mode restrictions and ensure they align with business continuity requirements. Test safe mode transitions regularly and validate that recovery procedures restore full functionality without data loss.",
    "example_implementation": "Configure automated safe mode triggers based on security events (failed authentication thresholds, detected malware, network anomalies) and system health indicators (disk failures, memory errors, thermal limits). Implement graduated response levels with documented restrictions for each level.",
    "non_technical_guidance": "To implement the Safe Mode control, follow these steps:\n1. Define the specific conditions that will trigger safe mode activation (e.g., detected intrusion attempts, hardware failures, critical software errors, resource exhaustion).\n2. Establish clear restrictions for safe mode operation - determine which services remain active, which are disabled, and what user capabilities are limited.\n3. Create documented procedures for entering and exiting safe mode, including notification protocols for administrators and affected users.\n4. Train operations staff on recognizing safe mode conditions, responding to safe mode events, and executing recovery procedures.\n5. Regularly test safe mode functionality to ensure triggers work correctly and restrictions are properly enforced.\n6. Integrate safe mode events with your security monitoring and incident response procedures.",
    "enhancements": [],
    "related_controls": [
      "CP-2",
      "CP-10",
      "CP-13",
      "IR-4",
      "SC-24",
      "SI-13",
      "SI-17"
    ],
    "supplemental_guidance": "Safe mode provides a fail-safe operational capability that protects organizational missions and business functions when systems encounter threatening conditions. Organizations define what constitutes threatening conditions and the restrictions to be applied during safe mode operations. The scope of restrictions can range from minor limitations (disabling non-essential services) to severe constraints (operating with minimal functionality). Safe mode is a proactive defense mechanism that prioritizes security and stability over full functionality during abnormal conditions.",
    "implementation_scripts": {
      "linux": {
        "bash": "# safe_mode_boot_configuration\n#!/bin/bash\n# CP-12: Safe Mode Boot Configuration for Linux\n# This script configures systemd targets for safe mode boot\n\nset -euo pipefail\n\nLOG_FILE=\"/var/log/cp12-safe-mode.log\"\nSAFE_MODE_TARGET=\"/etc/systemd/system/safe-mode.target\"\nSAFE_MODE_TRIGGER=\"/etc/systemd/system/safe-mode-trigger.service\"\n\nlog_action() {\n    echo \"$(date -Iseconds) - $1\" | tee -a \"$LOG_FILE\"\n}\n\n# Create safe mode systemd target\nlog_action \"Creating safe mode systemd target\"\ncat > \"$SAFE_MODE_TARGET\" << 'EOF'\n[Unit]\nDescription=CP-12 Safe Mode Target\nRequires=basic.target\nConflicts=rescue.target graphical.target multi-user.target\nAfter=basic.target\nAllowIsolate=yes\n\n[Install]\nWantedBy=multi-user.target\nEOF\n\n# Create safe mode trigger service\nlog_action \"Creating safe mode trigger service\"\ncat > \"$SAFE_MODE_TRIGGER\" << 'EOF'\n[Unit]\nDescription=CP-12 Safe Mode Trigger Monitor\nAfter=network.target\n\n[Service]\nType=simple\nExecStart=/usr/local/bin/safe-mode-monitor.sh\nRestart=always\nRestartSec=30\n\n[Install]\nWantedBy=multi-user.target\nEOF\n\n# Create the monitoring script\nlog_action \"Creating safe mode monitoring script\"\nmkdir -p /usr/local/bin\ncat > /usr/local/bin/safe-mode-monitor.sh << 'MONITOR'\n#!/bin/bash\n# CP-12 Safe Mode Monitor - Detects conditions requiring safe mode activation\n\nTHRESHOLD_AUTH_FAILURES=10\nTHRESHOLD_DISK_USAGE=95\nTHRESHOLD_MEMORY_USAGE=95\nCHECK_INTERVAL=60\n\nwhile true; do\n    # Check for excessive authentication failures\n    AUTH_FAILURES=$(grep -c \"authentication failure\" /var/log/auth.log 2>/dev/null | tail -1 || echo 0)\n    if [ \"$AUTH_FAILURES\" -gt \"$THRESHOLD_AUTH_FAILURES\" ]; then\n        logger -t safe-mode \"ALERT: Authentication failure threshold exceeded\"\n        touch /var/run/safe-mode-trigger\n    fi\n    \n    # Check disk usage\n    DISK_USAGE=$(df / | awk 'NR==2 {print $5}' | tr -d '%')\n    if [ \"$DISK_USAGE\" -gt \"$THRESHOLD_DISK_USAGE\" ]; then\n        logger -t safe-mode \"ALERT: Disk usage threshold exceeded\"\n        touch /var/run/safe-mode-trigger\n    fi\n    \n    # Check memory usage\n    MEMORY_USAGE=$(free | awk '/Mem:/ {printf \"%.0f\", $3/$2 * 100}')\n    if [ \"$MEMORY_USAGE\" -gt \"$THRESHOLD_MEMORY_USAGE\" ]; then\n        logger -t safe-mode \"ALERT: Memory usage threshold exceeded\"\n        touch /var/run/safe-mode-trigger\n    fi\n    \n    sleep $CHECK_INTERVAL\ndone\nMONITOR\n\nchmod +x /usr/local/bin/safe-mode-monitor.sh\n\n# Reload systemd and enable services\nsystemctl daemon-reload\nsystemctl enable safe-mode-trigger.service\n\nlog_action \"CP-12 Safe Mode boot configuration completed\"\necho \"Safe mode target and trigger service configured successfully\"\n\n# degraded_mode_operation\n#!/bin/bash\n# CP-12: Degraded Mode Operation Script for Linux\n# Transitions system to degraded/safe mode with restricted services\n\nset -euo pipefail\n\nLOG_FILE=\"/var/log/cp12-degraded-mode.log\"\nDEGRADED_STATE_FILE=\"/var/run/cp12-degraded-active\"\n\nlog_action() {\n    echo \"$(date -Iseconds) - $1\" | tee -a \"$LOG_FILE\"\n}\n\nenter_degraded_mode() {\n    log_action \"INITIATING DEGRADED MODE TRANSITION\"\n    \n    # Create state marker\n    touch \"$DEGRADED_STATE_FILE\"\n    \n    # Define non-essential services to stop\n    NON_ESSENTIAL_SERVICES=(\n        \"cups.service\"\n        \"bluetooth.service\"\n        \"avahi-daemon.service\"\n        \"ModemManager.service\"\n        \"accounts-daemon.service\"\n        \"packagekit.service\"\n    )\n    \n    # Stop non-essential services\n    for service in \"${NON_ESSENTIAL_SERVICES[@]}\"; do\n        if systemctl is-active \"$service\" >/dev/null 2>&1; then\n            log_action \"Stopping non-essential service: $service\"\n            systemctl stop \"$service\" || log_action \"Warning: Could not stop $service\"\n        fi\n    done\n    \n    # Apply restrictive firewall rules\n    log_action \"Applying restrictive firewall rules\"\n    if command -v iptables >/dev/null 2>&1; then\n        iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT\n        iptables -A INPUT -p tcp --dport 22 -j ACCEPT  # Keep SSH for administration\n        iptables -A INPUT -i lo -j ACCEPT\n        iptables -A INPUT -j LOG --log-prefix \"CP12-DEGRADED-DROP: \"\n        iptables -A INPUT -j DROP\n    fi\n    \n    # Increase logging verbosity\n    log_action \"Enabling enhanced audit logging\"\n    if command -v auditctl >/dev/null 2>&1; then\n        auditctl -e 2  # Enable immutable audit configuration\n    fi\n    \n    # Notify administrators\n    log_action \"Sending administrator notifications\"\n    if command -v mail >/dev/null 2>&1; then\n        echo \"System has entered CP-12 degraded mode at $(date)\" | mail -s \"[ALERT] CP-12 Degraded Mode Active\" root\n    fi\n    \n    log_action \"DEGRADED MODE ACTIVE - System operating with restricted services\"\n}\n\ncheck_degraded_status() {\n    if [ -f \"$DEGRADED_STATE_FILE\" ]; then\n        echo \"System is currently in DEGRADED MODE\"\n        echo \"Entered at: $(stat -c %y \"$DEGRADED_STATE_FILE\")\"\n        return 0\n    else\n        echo \"System is operating in NORMAL MODE\"\n        return 1\n    fi\n}\n\ncase \"${1:-status}\" in\n    enter)\n        enter_degraded_mode\n        ;;\n    status)\n        check_degraded_status\n        ;;\n    *)\n        echo \"Usage: $0 {enter|status}\"\n        exit 1\n        ;;\nesac\n\n# recovery_mode_automation\n#!/bin/bash\n# CP-12: Recovery Mode Automation Script for Linux\n# Restores system from degraded/safe mode to normal operation\n\nset -euo pipefail\n\nLOG_FILE=\"/var/log/cp12-recovery.log\"\nDEGRADED_STATE_FILE=\"/var/run/cp12-degraded-active\"\nRECOVERY_CHECKLIST=\"/var/log/cp12-recovery-checklist.log\"\n\nlog_action() {\n    echo \"$(date -Iseconds) - $1\" | tee -a \"$LOG_FILE\"\n}\n\nrun_recovery_checks() {\n    log_action \"Running pre-recovery system checks\"\n    local checks_passed=0\n    local checks_total=0\n    \n    # Check 1: Verify no active threats in logs\n    ((checks_total++))\n    if ! grep -q \"CRITICAL\\|INTRUSION\\|MALWARE\" /var/log/syslog 2>/dev/null; then\n        log_action \"CHECK PASSED: No active threats detected in system logs\"\n        ((checks_passed++))\n    else\n        log_action \"CHECK FAILED: Potential threats still present in logs\"\n    fi\n    \n    # Check 2: Verify disk health\n    ((checks_total++))\n    DISK_USAGE=$(df / | awk 'NR==2 {print $5}' | tr -d '%')\n    if [ \"$DISK_USAGE\" -lt 90 ]; then\n        log_action \"CHECK PASSED: Disk usage acceptable ($DISK_USAGE%)\"\n        ((checks_passed++))\n    else\n        log_action \"CHECK FAILED: Disk usage still critical ($DISK_USAGE%)\"\n    fi\n    \n    # Check 3: Verify memory health\n    ((checks_total++))\n    MEMORY_USAGE=$(free | awk '/Mem:/ {printf \"%.0f\", $3/$2 * 100}')\n    if [ \"$MEMORY_USAGE\" -lt 85 ]; then\n        log_action \"CHECK PASSED: Memory usage acceptable ($MEMORY_USAGE%)\"\n        ((checks_passed++))\n    else\n        log_action \"CHECK FAILED: Memory usage still elevated ($MEMORY_USAGE%)\"\n    fi\n    \n    # Check 4: Verify no excessive auth failures recently\n    ((checks_total++))\n    RECENT_AUTH_FAILURES=$(grep \"authentication failure\" /var/log/auth.log 2>/dev/null | tail -100 | wc -l)\n    if [ \"$RECENT_AUTH_FAILURES\" -lt 5 ]; then\n        log_action \"CHECK PASSED: Authentication failure rate normal\"\n        ((checks_passed++))\n    else\n        log_action \"CHECK FAILED: Authentication failures still elevated\"\n    fi\n    \n    echo \"Recovery checks completed: $checks_passed/$checks_total passed\"\n    \n    if [ \"$checks_passed\" -eq \"$checks_total\" ]; then\n        return 0\n    else\n        return 1\n    fi\n}\n\nrestore_normal_operation() {\n    log_action \"INITIATING RECOVERY TO NORMAL OPERATION\"\n    \n    if ! run_recovery_checks; then\n        log_action \"WARNING: Not all recovery checks passed. Proceeding with caution.\"\n        read -p \"Continue with recovery despite failed checks? (yes/no): \" confirm\n        if [ \"$confirm\" != \"yes\" ]; then\n            log_action \"Recovery aborted by administrator\"\n            exit 1\n        fi\n    fi\n    \n    # Restore firewall to normal rules\n    log_action \"Restoring normal firewall configuration\"\n    if command -v iptables >/dev/null 2>&1; then\n        iptables -F\n        iptables -P INPUT ACCEPT\n        # Reload standard firewall rules if available\n        if [ -f /etc/iptables/rules.v4 ]; then\n            iptables-restore < /etc/iptables/rules.v4\n        fi\n    fi\n    \n    # Restart essential services\n    log_action \"Restarting previously stopped services\"\n    SERVICES_TO_RESTART=(\n        \"cups.service\"\n        \"bluetooth.service\"\n        \"avahi-daemon.service\"\n    )\n    \n    for service in \"${SERVICES_TO_RESTART[@]}\"; do\n        if systemctl is-enabled \"$service\" >/dev/null 2>&1; then\n            log_action \"Starting service: $service\"\n            systemctl start \"$service\" || log_action \"Warning: Could not start $service\"\n        fi\n    done\n    \n    # Remove degraded state marker\n    rm -f \"$DEGRADED_STATE_FILE\"\n    rm -f /var/run/safe-mode-trigger\n    \n    # Notify administrators\n    log_action \"Sending recovery notification\"\n    if command -v mail >/dev/null 2>&1; then\n        echo \"System has exited CP-12 degraded mode at $(date)\" | mail -s \"[INFO] CP-12 Normal Operations Restored\" root\n    fi\n    \n    log_action \"RECOVERY COMPLETE - System operating in normal mode\"\n}\n\ncase \"${1:-help}\" in\n    restore)\n        restore_normal_operation\n        ;;\n    check)\n        run_recovery_checks\n        ;;\n    help|*)\n        echo \"CP-12 Recovery Mode Automation\"\n        echo \"Usage: $0 {restore|check}\"\n        echo \"  restore - Restore system to normal operation\"\n        echo \"  check   - Run recovery readiness checks only\"\n        ;;\nesac"
      },
      "windows": {
        "powershell": "# safe_mode_boot_configuration\n# CP-12: Safe Mode Boot Configuration for Windows\n# Configures Windows boot options for safe mode transitions\n# Requires: Administrator privileges\n\n#Requires -RunAsAdministrator\n\n$LogFile = \"C:\\Windows\\Logs\\CP12-SafeMode.log\"\n\nfunction Write-Log {\n    param([string]$Message)\n    $timestamp = Get-Date -Format \"yyyy-MM-ddTHH:mm:ssZ\"\n    $logEntry = \"$timestamp - $Message\"\n    Add-Content -Path $LogFile -Value $logEntry\n    Write-Host $logEntry\n}\n\nfunction Configure-SafeModeBoot {\n    Write-Log \"Configuring CP-12 Safe Mode boot options\"\n    \n    # Create custom boot entry for safe mode\n    try {\n        $currentBootEntry = bcdedit /enum \"{current}\" | Out-String\n        Write-Log \"Current boot configuration retrieved\"\n        \n        # Create a copy of current boot entry for safe mode\n        $result = bcdedit /copy \"{current}\" /d \"CP-12 Safe Mode\"\n        if ($result -match \"\\{([^}]+)\\}\") {\n            $safeModeGuid = $matches[1]\n            Write-Log \"Created safe mode boot entry: {$safeModeGuid}\"\n            \n            # Configure safe mode boot options\n            bcdedit /set \"{$safeModeGuid}\" safeboot minimal\n            bcdedit /set \"{$safeModeGuid}\" safebootalternateshell yes\n            \n            Write-Log \"Safe mode boot entry configured successfully\"\n        }\n    }\n    catch {\n        Write-Log \"ERROR: Failed to configure safe mode boot: $_\"\n        throw\n    }\n    \n    # Configure boot timeout for manual safe mode selection\n    bcdedit /timeout 10\n    Write-Log \"Boot timeout set to 10 seconds for safe mode selection\"\n    \n    # Create scheduled task to monitor for safe mode triggers\n    $taskAction = New-ScheduledTaskAction -Execute \"PowerShell.exe\" -Argument \"-ExecutionPolicy Bypass -File C:\\Windows\\System32\\CP12-Monitor.ps1\"\n    $taskTrigger = New-ScheduledTaskTrigger -AtStartup\n    $taskPrincipal = New-ScheduledTaskPrincipal -UserId \"SYSTEM\" -LogonType ServiceAccount -RunLevel Highest\n    $taskSettings = New-ScheduledTaskSettingsSet -AllowStartIfOnBatteries -DontStopIfGoingOnBatteries -StartWhenAvailable\n    \n    Register-ScheduledTask -TaskName \"CP12-SafeModeMonitor\" -Action $taskAction -Trigger $taskTrigger -Principal $taskPrincipal -Settings $taskSettings -Force\n    Write-Log \"Registered CP12 Safe Mode Monitor scheduled task\"\n    \n    # Create the monitoring script\n    $monitorScript = @'\n# CP-12 Safe Mode Monitor Script\n$LogFile = \"C:\\Windows\\Logs\\CP12-Monitor.log\"\n$TriggerFile = \"C:\\Windows\\Temp\\CP12-SafeMode-Trigger.flag\"\n\nwhile ($true) {\n    # Check Security Event Log for excessive failed logons\n    $failedLogons = Get-WinEvent -FilterHashtable @{LogName='Security';Id=4625;StartTime=(Get-Date).AddMinutes(-5)} -ErrorAction SilentlyContinue | Measure-Object | Select-Object -ExpandProperty Count\n    \n    if ($failedLogons -gt 10) {\n        \"$(Get-Date) - ALERT: Excessive failed logon attempts detected: $failedLogons\" | Out-File -Append $LogFile\n        New-Item -Path $TriggerFile -Force | Out-Null\n    }\n    \n    # Check for disk space issues\n    $disk = Get-WmiObject -Class Win32_LogicalDisk -Filter \"DeviceID='C:'\"\n    $diskUsagePercent = [math]::Round(($disk.Size - $disk.FreeSpace) / $disk.Size * 100, 2)\n    \n    if ($diskUsagePercent -gt 95) {\n        \"$(Get-Date) - ALERT: Critical disk usage: $diskUsagePercent%\" | Out-File -Append $LogFile\n        New-Item -Path $TriggerFile -Force | Out-Null\n    }\n    \n    Start-Sleep -Seconds 60\n}\n'@\n    \n    Set-Content -Path \"C:\\Windows\\System32\\CP12-Monitor.ps1\" -Value $monitorScript\n    Write-Log \"Created CP12 monitoring script\"\n    \n    Write-Log \"CP-12 Safe Mode boot configuration completed successfully\"\n}\n\n# Execute configuration\nConfigure-SafeModeBoot\n\n# degraded_mode_operation\n# CP-12: Degraded Mode Operation Script for Windows\n# Transitions Windows system to degraded/safe mode with restricted services\n# Requires: Administrator privileges\n\n#Requires -RunAsAdministrator\n\n$LogFile = \"C:\\Windows\\Logs\\CP12-DegradedMode.log\"\n$StateFile = \"C:\\Windows\\Temp\\CP12-DegradedMode.state\"\n\nfunction Write-Log {\n    param([string]$Message)\n    $timestamp = Get-Date -Format \"yyyy-MM-ddTHH:mm:ssZ\"\n    $logEntry = \"$timestamp - $Message\"\n    Add-Content -Path $LogFile -Value $logEntry\n    Write-Host $logEntry\n}\n\nfunction Enter-DegradedMode {\n    Write-Log \"INITIATING CP-12 DEGRADED MODE TRANSITION\"\n    \n    # Create state marker with timestamp\n    Get-Date | Out-File -FilePath $StateFile\n    \n    # Define non-essential services to stop\n    $nonEssentialServices = @(\n        \"Spooler\",           # Print Spooler\n        \"BITS\",              # Background Intelligent Transfer\n        \"wuauserv\",          # Windows Update\n        \"WSearch\",           # Windows Search\n        \"SysMain\",           # Superfetch\n        \"DiagTrack\",         # Diagnostics Tracking\n        \"dmwappushservice\"   # WAP Push Message Routing\n    )\n    \n    foreach ($serviceName in $nonEssentialServices) {\n        try {\n            $service = Get-Service -Name $serviceName -ErrorAction SilentlyContinue\n            if ($service -and $service.Status -eq 'Running') {\n                Write-Log \"Stopping non-essential service: $serviceName\"\n                Stop-Service -Name $serviceName -Force -ErrorAction Stop\n                Set-Service -Name $serviceName -StartupType Disabled\n            }\n        }\n        catch {\n            Write-Log \"Warning: Could not stop service $serviceName - $_\"\n        }\n    }\n    \n    # Apply restrictive firewall rules\n    Write-Log \"Applying restrictive Windows Firewall rules\"\n    \n    # Block all inbound except RDP and essential services\n    New-NetFirewallRule -DisplayName \"CP12-DegradedMode-BlockInbound\" -Direction Inbound -Action Block -Profile Any -Enabled True -ErrorAction SilentlyContinue\n    New-NetFirewallRule -DisplayName \"CP12-DegradedMode-AllowRDP\" -Direction Inbound -Protocol TCP -LocalPort 3389 -Action Allow -Profile Any -Enabled True -ErrorAction SilentlyContinue\n    New-NetFirewallRule -DisplayName \"CP12-DegradedMode-AllowWinRM\" -Direction Inbound -Protocol TCP -LocalPort 5985,5986 -Action Allow -Profile Any -Enabled True -ErrorAction SilentlyContinue\n    \n    # Enable enhanced Windows Security auditing\n    Write-Log \"Enabling enhanced security auditing\"\n    auditpol /set /subcategory:\"Logon\" /success:enable /failure:enable\n    auditpol /set /subcategory:\"Logoff\" /success:enable\n    auditpol /set /subcategory:\"Account Lockout\" /success:enable /failure:enable\n    auditpol /set /subcategory:\"Other Logon/Logoff Events\" /success:enable /failure:enable\n    \n    # Log event to Windows Event Log\n    Write-EventLog -LogName Application -Source \"CP12-SafeMode\" -EventId 1001 -EntryType Warning -Message \"System has entered CP-12 Degraded Mode\"\n    \n    Write-Log \"DEGRADED MODE ACTIVE - System operating with restricted services\"\n    \n    return @{\n        Status = \"DegradedMode\"\n        Timestamp = Get-Date\n        StoppedServices = $nonEssentialServices\n    }\n}\n\nfunction Get-DegradedStatus {\n    if (Test-Path $StateFile) {\n        $enteredAt = Get-Content $StateFile\n        Write-Host \"System is currently in DEGRADED MODE\"\n        Write-Host \"Entered at: $enteredAt\"\n        return $true\n    }\n    else {\n        Write-Host \"System is operating in NORMAL MODE\"\n        return $false\n    }\n}\n\n# Main execution\nparam(\n    [Parameter(Position=0)]\n    [ValidateSet('Enter', 'Status')]\n    [string]$Action = 'Status'\n)\n\nswitch ($Action) {\n    'Enter' { Enter-DegradedMode }\n    'Status' { Get-DegradedStatus }\n}\n\n# recovery_mode_automation\n# CP-12: Recovery Mode Automation Script for Windows\n# Restores Windows system from degraded/safe mode to normal operation\n# Requires: Administrator privileges\n\n#Requires -RunAsAdministrator\n\n$LogFile = \"C:\\Windows\\Logs\\CP12-Recovery.log\"\n$StateFile = \"C:\\Windows\\Temp\\CP12-DegradedMode.state\"\n\nfunction Write-Log {\n    param([string]$Message)\n    $timestamp = Get-Date -Format \"yyyy-MM-ddTHH:mm:ssZ\"\n    $logEntry = \"$timestamp - $Message\"\n    Add-Content -Path $LogFile -Value $logEntry\n    Write-Host $logEntry\n}\n\nfunction Invoke-RecoveryChecks {\n    Write-Log \"Running pre-recovery system checks\"\n    $checksPassed = 0\n    $checksTotal = 0\n    $results = @()\n    \n    # Check 1: Verify no recent security events indicating active threats\n    $checksTotal++\n    try {\n        $securityEvents = Get-WinEvent -FilterHashtable @{LogName='Security';Id=4625;StartTime=(Get-Date).AddHours(-1)} -ErrorAction SilentlyContinue | Measure-Object | Select-Object -ExpandProperty Count\n        if ($securityEvents -lt 5) {\n            Write-Log \"CHECK PASSED: No excessive failed logon attempts\"\n            $checksPassed++\n            $results += @{Check=\"Security Events\"; Status=\"PASS\"; Detail=\"$securityEvents failed logons in last hour\"}\n        }\n        else {\n            Write-Log \"CHECK FAILED: $securityEvents failed logon attempts in last hour\"\n            $results += @{Check=\"Security Events\"; Status=\"FAIL\"; Detail=\"$securityEvents failed logons in last hour\"}\n        }\n    }\n    catch {\n        Write-Log \"CHECK ERROR: Could not query security events - $_\"\n        $results += @{Check=\"Security Events\"; Status=\"ERROR\"; Detail=$_.Exception.Message}\n    }\n    \n    # Check 2: Verify disk health\n    $checksTotal++\n    $disk = Get-WmiObject -Class Win32_LogicalDisk -Filter \"DeviceID='C:'\"\n    $diskUsagePercent = [math]::Round(($disk.Size - $disk.FreeSpace) / $disk.Size * 100, 2)\n    if ($diskUsagePercent -lt 90) {\n        Write-Log \"CHECK PASSED: Disk usage acceptable ($diskUsagePercent%)\"\n        $checksPassed++\n        $results += @{Check=\"Disk Usage\"; Status=\"PASS\"; Detail=\"$diskUsagePercent% used\"}\n    }\n    else {\n        Write-Log \"CHECK FAILED: Disk usage still critical ($diskUsagePercent%)\"\n        $results += @{Check=\"Disk Usage\"; Status=\"FAIL\"; Detail=\"$diskUsagePercent% used\"}\n    }\n    \n    # Check 3: Verify memory health\n    $checksTotal++\n    $os = Get-WmiObject -Class Win32_OperatingSystem\n    $memoryUsagePercent = [math]::Round(($os.TotalVisibleMemorySize - $os.FreePhysicalMemory) / $os.TotalVisibleMemorySize * 100, 2)\n    if ($memoryUsagePercent -lt 85) {\n        Write-Log \"CHECK PASSED: Memory usage acceptable ($memoryUsagePercent%)\"\n        $checksPassed++\n        $results += @{Check=\"Memory Usage\"; Status=\"PASS\"; Detail=\"$memoryUsagePercent% used\"}\n    }\n    else {\n        Write-Log \"CHECK FAILED: Memory usage still elevated ($memoryUsagePercent%)\"\n        $results += @{Check=\"Memory Usage\"; Status=\"FAIL\"; Detail=\"$memoryUsagePercent% used\"}\n    }\n    \n    # Check 4: Verify Windows Defender status\n    $checksTotal++\n    try {\n        $defenderStatus = Get-MpComputerStatus -ErrorAction Stop\n        if ($defenderStatus.AntivirusEnabled -and !$defenderStatus.QuickScanOverdue) {\n            Write-Log \"CHECK PASSED: Windows Defender operational\"\n            $checksPassed++\n            $results += @{Check=\"Windows Defender\"; Status=\"PASS\"; Detail=\"Antivirus enabled and current\"}\n        }\n        else {\n            Write-Log \"CHECK FAILED: Windows Defender requires attention\"\n            $results += @{Check=\"Windows Defender\"; Status=\"FAIL\"; Detail=\"Antivirus disabled or scan overdue\"}\n        }\n    }\n    catch {\n        Write-Log \"CHECK WARNING: Could not query Windows Defender - $_\"\n        $results += @{Check=\"Windows Defender\"; Status=\"WARNING\"; Detail=\"Unable to query status\"}\n    }\n    \n    Write-Host \"`nRecovery checks completed: $checksPassed/$checksTotal passed`n\"\n    $results | ForEach-Object { Write-Host \"  [$($_.Status)] $($_.Check): $($_.Detail)\" }\n    \n    return @{\n        Passed = $checksPassed\n        Total = $checksTotal\n        AllPassed = ($checksPassed -eq $checksTotal)\n        Results = $results\n    }\n}\n\nfunction Restore-NormalOperation {\n    Write-Log \"INITIATING CP-12 RECOVERY TO NORMAL OPERATION\"\n    \n    $checks = Invoke-RecoveryChecks\n    \n    if (-not $checks.AllPassed) {\n        Write-Host \"`nWARNING: Not all recovery checks passed.\" -ForegroundColor Yellow\n        $confirm = Read-Host \"Continue with recovery despite failed checks? (yes/no)\"\n        if ($confirm -ne \"yes\") {\n            Write-Log \"Recovery aborted by administrator\"\n            return\n        }\n    }\n    \n    # Remove degraded mode firewall rules\n    Write-Log \"Removing degraded mode firewall rules\"\n    Remove-NetFirewallRule -DisplayName \"CP12-DegradedMode-BlockInbound\" -ErrorAction SilentlyContinue\n    Remove-NetFirewallRule -DisplayName \"CP12-DegradedMode-AllowRDP\" -ErrorAction SilentlyContinue\n    Remove-NetFirewallRule -DisplayName \"CP12-DegradedMode-AllowWinRM\" -ErrorAction SilentlyContinue\n    \n    # Restart essential services\n    Write-Log \"Restoring previously stopped services\"\n    $servicesToRestart = @(\n        \"Spooler\",\n        \"BITS\",\n        \"wuauserv\",\n        \"WSearch\"\n    )\n    \n    foreach ($serviceName in $servicesToRestart) {\n        try {\n            $service = Get-Service -Name $serviceName -ErrorAction SilentlyContinue\n            if ($service) {\n                Write-Log \"Starting service: $serviceName\"\n                Set-Service -Name $serviceName -StartupType Automatic\n                Start-Service -Name $serviceName -ErrorAction Stop\n            }\n        }\n        catch {\n            Write-Log \"Warning: Could not start service $serviceName - $_\"\n        }\n    }\n    \n    # Remove state files\n    Remove-Item -Path $StateFile -Force -ErrorAction SilentlyContinue\n    Remove-Item -Path \"C:\\Windows\\Temp\\CP12-SafeMode-Trigger.flag\" -Force -ErrorAction SilentlyContinue\n    \n    # Log event to Windows Event Log\n    Write-EventLog -LogName Application -Source \"CP12-SafeMode\" -EventId 1002 -EntryType Information -Message \"System has exited CP-12 Degraded Mode - Normal operations restored\"\n    \n    Write-Log \"RECOVERY COMPLETE - System operating in normal mode\"\n    Write-Host \"`nRecovery completed successfully.\" -ForegroundColor Green\n}\n\n# Main execution\nparam(\n    [Parameter(Position=0)]\n    [ValidateSet('Restore', 'Check', 'Help')]\n    [string]$Action = 'Help'\n)\n\n# Register event source if not exists\nif (-not [System.Diagnostics.EventLog]::SourceExists(\"CP12-SafeMode\")) {\n    New-EventLog -LogName Application -Source \"CP12-SafeMode\" -ErrorAction SilentlyContinue\n}\n\nswitch ($Action) {\n    'Restore' { Restore-NormalOperation }\n    'Check' { Invoke-RecoveryChecks }\n    'Help' {\n        Write-Host \"`nCP-12 Recovery Mode Automation\"\n        Write-Host \"Usage: .\\CP12-Recovery.ps1 -Action <Restore|Check|Help>\"\n        Write-Host \"  Restore - Restore system to normal operation\"\n        Write-Host \"  Check   - Run recovery readiness checks only\"\n        Write-Host \"  Help    - Display this help message`n\"\n    }\n}"
      }
    },
    "metadata": {
      "status": "enhanced",
      "last_updated": "2025-11-22T00:00:00.000000Z",
      "has_scripts": true,
      "qa_validated": true,
      "validation_date": "2025-11-22"
    },
    "cac_metadata": {
      "implementation_type": "technical",
      "last_analyzed": "2025-11-22T00:00:00.000000Z",
      "source": "ComplianceAsCode",
      "cac_status": "enhanced",
      "implementation_guidance": "CP-12 Safe Mode requires technical implementation including automated monitoring for trigger conditions, system state transitions, service management, and recovery procedures. Scripts provided for both Linux (systemd-based) and Windows (PowerShell) environments."
    },
    "rationale": "When under attack or failing, systems should be able to operate in a reduced but secure mode rather than failing completely."
  },
  {
    "control_id": "CP-13",
    "control_name": "Alternative Security Mechanisms",
    "family": "Contingency Planning",
    "family_id": "CP",
    "stig_id": null,
    "is_technical": true,
    "official_text": "Employ [organization-defined alternative or supplemental security mechanisms] for satisfying [organization-defined security functions] when the primary means of implementing the security function is unavailable or compromised.",
    "source": "NIST SP 800-53 Rev 5",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "plain_english_explanation": "CP-13 requires organizations to have backup or alternative security mechanisms ready to deploy when primary security controls fail, become unavailable, or are compromised. This ensures continuous security protection even during degraded operations. Examples include hardware security modules as backup for software-based encryption, out-of-band authentication channels when primary authentication fails, manual access control procedures when automated systems are down, or physical security measures when electronic controls are compromised.",
    "intent": "To ensure continuous security protection by establishing alternative security mechanisms that can be activated when primary security controls are unavailable, degraded, or compromised, thereby maintaining the organization's security posture during contingency situations.",
    "ai_guidance": "For AI/ML systems implementing CP-13: Establish alternative security mechanisms specifically designed for AI workloads. When primary AI-based threat detection fails, have signature-based or rule-based systems ready to activate. For AI authentication systems (biometrics, behavioral analysis), maintain fallback to traditional multi-factor authentication. If AI-powered access control is compromised, have pre-configured manual approval workflows. For AI model integrity protection, maintain offline model checksums and cryptographic signatures for validation when online verification is unavailable. Consider fallback inference endpoints that use simpler, more robust models when primary AI services are degraded. Document switchover procedures and regularly test alternative mechanism activation to ensure seamless security continuity.",
    "example_implementation": "Organizations should: (1) Identify all critical security functions and their primary implementation mechanisms; (2) For each critical function, identify one or more alternative mechanisms (e.g., HSM backup for software crypto, manual badge checks for electronic access control, out-of-band MFA for primary authentication failure); (3) Document switchover procedures and triggers; (4) Pre-configure alternative mechanisms for rapid activation; (5) Regularly test alternative mechanisms through exercises; (6) Train personnel on recognizing when to activate alternatives and how to do so.",
    "non_technical_guidance": "To comply with CP-13:\n\n1. IDENTIFY CRITICAL SECURITY FUNCTIONS:\n   - List all security mechanisms protecting your systems (authentication, encryption, access control, monitoring)\n   - Determine which functions are mission-critical and cannot tolerate any gap in protection\n   - Prioritize based on business impact and risk\n\n2. DEVELOP ALTERNATIVE MECHANISMS:\n   - For authentication: Have backup authentication methods (phone-based OTP, hardware tokens, security questions)\n   - For access control: Prepare manual authorization procedures with proper documentation\n   - For encryption: Consider hardware security modules as backup, or alternative key storage\n   - For monitoring: Have manual log review procedures or alternative monitoring tools\n\n3. DOCUMENT ACTIVATION PROCEDURES:\n   - Define clear triggers for when to activate alternative mechanisms\n   - Create step-by-step activation checklists\n   - Establish authorization requirements for activating alternatives\n   - Document return-to-normal procedures\n\n4. TEST AND MAINTAIN:\n   - Regularly test alternative mechanisms (at least annually)\n   - Update alternatives when primary mechanisms change\n   - Train personnel on switchover procedures\n   - Include alternative mechanism activation in incident response exercises",
    "enhancements": [],
    "related_controls": [
      "CP-2",
      "CP-7",
      "CP-8",
      "CP-9",
      "CP-10",
      "SC-8",
      "SC-12",
      "SC-13",
      "IA-2",
      "IA-3",
      "IA-10",
      "SI-13",
      "IR-4"
    ],
    "supplemental_guidance": "Alternative security mechanisms are employed when the primary means of implementing a security function is unavailable or compromised to ensure continued security protection. The alternative security mechanisms provide at least the same or equivalent protection as the primary mechanisms being replaced. Organizations may employ alternative security mechanisms in lieu of or in addition to primary security mechanisms. For example, organizations may use hardware security modules in lieu of software-based encryption when software encryption is compromised. Organizations may also employ alternative security mechanisms to avoid single points of failure in security implementations.",
    "implementation_scripts": {
      "linux": {
        "bash": "# check_primary_auth_status\n#!/bin/bash\n# Check primary authentication service status\nPRIMARY_AUTH_SERVICE=\"sssd\"\nBACKUP_AUTH_SERVICE=\"nslcd\"\n\nif systemctl is-active --quiet $PRIMARY_AUTH_SERVICE; then\n    echo \"[OK] Primary authentication service ($PRIMARY_AUTH_SERVICE) is running\"\nelse\n    echo \"[WARNING] Primary authentication service ($PRIMARY_AUTH_SERVICE) is DOWN\"\n    echo \"Checking backup authentication service...\"\n    if systemctl is-active --quiet $BACKUP_AUTH_SERVICE; then\n        echo \"[OK] Backup authentication service ($BACKUP_AUTH_SERVICE) is running\"\n    else\n        echo \"[CRITICAL] Both primary and backup authentication services are DOWN\"\n        exit 1\n    fi\nfi\n\n# activate_backup_auth\n#!/bin/bash\n# Activate backup authentication mechanism when primary fails\nBACKUP_AUTH_SERVICE=\"nslcd\"\nBACKUP_PAM_CONFIG=\"/etc/pam.d/backup-auth\"\nACTIVE_PAM_CONFIG=\"/etc/pam.d/system-auth\"\n\necho \"[$(date)] Activating backup authentication mechanism\"\n\n# Enable backup service\nsystemctl enable $BACKUP_AUTH_SERVICE\nsystemctl start $BACKUP_AUTH_SERVICE\n\n# Verify backup is running\nif systemctl is-active --quiet $BACKUP_AUTH_SERVICE; then\n    echo \"[OK] Backup authentication service activated successfully\"\n    # Log activation for audit\n    logger -t CP13 \"Alternative authentication mechanism activated due to primary failure\"\nelse\n    echo \"[CRITICAL] Failed to activate backup authentication\"\n    exit 1\nfi\n\n# check_encryption_fallback\n#!/bin/bash\n# Verify encryption fallback mechanisms are available\n\n# Check for hardware crypto support\nif grep -q aes /proc/cpuinfo; then\n    echo \"[OK] Hardware AES acceleration available as fallback\"\nelse\n    echo \"[INFO] Software-only encryption (no hardware acceleration)\"\nfi\n\n# Check for TPM availability as key storage fallback\nif [ -c /dev/tpm0 ] || [ -c /dev/tpmrm0 ]; then\n    echo \"[OK] TPM available for alternative key storage\"\nelse\n    echo \"[WARNING] No TPM detected - ensure alternative key storage is configured\"\nfi\n\n# Verify fallback certificate store\nif [ -d /etc/pki/backup-certs ]; then\n    echo \"[OK] Backup certificate store exists\"\nelse\n    echo \"[WARNING] No backup certificate store found at /etc/pki/backup-certs\"\nfi\n\n# activate_manual_access_control\n#!/bin/bash\n# Activate manual access control procedures when automated systems fail\nMANUAL_MODE_FLAG=\"/var/run/access-control-manual-mode\"\nLOG_FILE=\"/var/log/manual-access-control.log\"\n\necho \"[$(date)] ACTIVATING MANUAL ACCESS CONTROL MODE\" | tee -a $LOG_FILE\n\n# Create manual mode flag\ntouch $MANUAL_MODE_FLAG\nchmod 644 $MANUAL_MODE_FLAG\n\n# Notify administrators\necho \"ALERT: Automated access control has failed. Manual authorization procedures are now in effect.\" | mail -s \"[CP-13] Manual Access Control Activated\" security-team@organization.local 2>/dev/null || echo \"[WARNING] Could not send email notification\"\n\n# Log to syslog\nlogger -p auth.warning -t CP13 \"Manual access control mode activated - automated systems unavailable\"\n\necho \"Manual access control mode is now active. All access requests require manual authorization.\"\necho \"See /etc/security/manual-access-procedures.txt for authorization workflow.\""
      },
      "windows": {
        "powershell": "# check_primary_auth_status\n$primaryDC = \"dc01.domain.local\"\n$backupDC = \"dc02.domain.local\"\n\nWrite-Host \"Checking primary domain controller authentication status...\"\n\ntry {\n    $primaryStatus = Test-Connection -ComputerName $primaryDC -Count 1 -Quiet\n    if ($primaryStatus) {\n        $ldapTest = [ADSI]\"LDAP://$primaryDC\"\n        Write-Host \"[OK] Primary DC ($primaryDC) is available for authentication\" -ForegroundColor Green\n    } else {\n        throw \"Primary DC unreachable\"\n    }\n} catch {\n    Write-Host \"[WARNING] Primary DC ($primaryDC) is unavailable\" -ForegroundColor Yellow\n    Write-Host \"Checking backup domain controller...\"\n    try {\n        $backupStatus = Test-Connection -ComputerName $backupDC -Count 1 -Quiet\n        if ($backupStatus) {\n            Write-Host \"[OK] Backup DC ($backupDC) is available\" -ForegroundColor Green\n        } else {\n            Write-Host \"[CRITICAL] Both DCs unavailable - activate alternative auth\" -ForegroundColor Red\n        }\n    } catch {\n        Write-Host \"[CRITICAL] Backup DC check failed\" -ForegroundColor Red\n    }\n}\n\n# activate_backup_auth\n# Activate backup authentication when primary AD fails\n$BackupAuthProvider = \"Local SAM\"\n$EventSource = \"CP-13-AlternativeAuth\"\n\n# Create event source if not exists\nif (![System.Diagnostics.EventLog]::SourceExists($EventSource)) {\n    New-EventLog -LogName Security -Source $EventSource\n}\n\nWrite-Host \"[$(Get-Date)] Activating backup authentication mechanism\"\n\n# Enable local account authentication as fallback\n$localUsers = Get-LocalUser | Where-Object { $_.Enabled -eq $false -and $_.Name -like \"backup_*\" }\nforeach ($user in $localUsers) {\n    Enable-LocalUser -Name $user.Name\n    Write-Host \"Enabled backup local account: $($user.Name)\"\n}\n\n# Log activation\nWrite-EventLog -LogName Security -Source $EventSource -EventId 1001 -EntryType Warning -Message \"Alternative authentication mechanism (Local SAM) activated due to primary AD failure\"\n\nWrite-Host \"[OK] Backup authentication activated. Local accounts are now available for emergency access.\"\n\n# check_encryption_fallback\n# Verify encryption fallback mechanisms\n\nWrite-Host \"Checking encryption fallback mechanisms...\"\n\n# Check BitLocker status\n$bitlockerVolumes = Get-BitLockerVolume\nif ($bitlockerVolumes) {\n    Write-Host \"[OK] BitLocker encryption available on:\" -ForegroundColor Green\n    $bitlockerVolumes | ForEach-Object { Write-Host \"  - $($_.MountPoint): $($_.ProtectionStatus)\" }\n} else {\n    Write-Host \"[WARNING] BitLocker not configured\" -ForegroundColor Yellow\n}\n\n# Check for TPM\n$tpm = Get-Tpm\nif ($tpm.TpmPresent -and $tpm.TpmReady) {\n    Write-Host \"[OK] TPM available for alternative key storage\" -ForegroundColor Green\n} else {\n    Write-Host \"[WARNING] TPM not available - ensure alternative key storage configured\" -ForegroundColor Yellow\n}\n\n# Check for backup certificate store\n$backupCertPath = \"Cert:\\LocalMachine\\BackupCerts\"\nif (Test-Path $backupCertPath) {\n    Write-Host \"[OK] Backup certificate store exists\" -ForegroundColor Green\n} else {\n    Write-Host \"[INFO] Consider creating backup certificate store at $backupCertPath\" -ForegroundColor Cyan\n}\n\n# activate_manual_access_control\n# Activate manual access control when automated systems fail\n$ManualModeFlag = \"C:\\Windows\\Security\\manual-access-mode.flag\"\n$LogFile = \"C:\\Windows\\Security\\Logs\\manual-access-control.log\"\n$EventSource = \"CP-13-ManualAccess\"\n\n# Ensure log directory exists\nif (!(Test-Path (Split-Path $LogFile))) {\n    New-Item -ItemType Directory -Path (Split-Path $LogFile) -Force | Out-Null\n}\n\n$timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n$logEntry = \"[$timestamp] ACTIVATING MANUAL ACCESS CONTROL MODE\"\nAdd-Content -Path $LogFile -Value $logEntry\nWrite-Host $logEntry -ForegroundColor Yellow\n\n# Create manual mode flag\nNew-Item -ItemType File -Path $ManualModeFlag -Force | Out-Null\n\n# Create event source and log\nif (![System.Diagnostics.EventLog]::SourceExists($EventSource)) {\n    New-EventLog -LogName Security -Source $EventSource\n}\nWrite-EventLog -LogName Security -Source $EventSource -EventId 2001 -EntryType Warning -Message \"Manual access control mode activated - automated access control systems unavailable. All access requests require manual authorization per CP-13 procedures.\"\n\n# Send notification (if SMTP configured)\ntry {\n    Send-MailMessage -To \"security-team@organization.local\" -From \"alerts@organization.local\" -Subject \"[CP-13] Manual Access Control Activated\" -Body \"Automated access control has failed. Manual authorization procedures are now in effect.\" -SmtpServer \"smtp.organization.local\" -ErrorAction Stop\n} catch {\n    Write-Host \"[WARNING] Could not send email notification\" -ForegroundColor Yellow\n}\n\nWrite-Host \"Manual access control mode is now active.\"\nWrite-Host \"See C:\\Windows\\Security\\ManualAccessProcedures.pdf for authorization workflow.\""
      }
    },
    "audit_procedures": {
      "interview_questions": [
        "What alternative security mechanisms have been identified for critical security functions?",
        "What triggers the activation of alternative security mechanisms?",
        "Who is authorized to activate alternative security mechanisms?",
        "How often are alternative security mechanisms tested?",
        "What procedures exist for returning to primary security mechanisms after an incident?"
      ],
      "document_requests": [
        "Inventory of critical security functions and their primary implementation mechanisms",
        "Documentation of alternative security mechanisms for each critical function",
        "Switchover procedures and activation criteria",
        "Testing records for alternative security mechanisms",
        "Training materials for personnel on alternative mechanism activation"
      ],
      "evidence_artifacts": [
        "Alternative security mechanism inventory and configuration documentation",
        "Test results from alternative mechanism activation exercises",
        "Incident logs showing successful activation of alternatives during contingencies",
        "Training completion records for switchover procedures",
        "Maintenance records for alternative mechanism readiness"
      ]
    },
    "references": [
      "NIST SP 800-53 Rev 5: Security and Privacy Controls for Information Systems and Organizations",
      "NIST SP 800-34 Rev 1: Contingency Planning Guide for Federal Information Systems",
      "NIST SP 800-53A Rev 5: Assessing Security and Privacy Controls",
      "NIST SP 800-160 Vol 2: Developing Cyber-Resilient Systems"
    ],
    "metadata": {
      "status": "enhanced",
      "last_updated": "2025-11-22T00:00:00.000Z",
      "has_scripts": true,
      "qa_verified": true,
      "qa_agent": "LOVELESS",
      "enhancement_notes": "Enhanced with comprehensive implementation scripts for alternative authentication, encryption fallback, and manual access control procedures. Added AI-specific guidance for alternative security mechanisms in ML workloads."
    },
    "cac_metadata": {
      "implementation_type": "technical",
      "last_analyzed": "2025-11-22T00:00:00.000Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "CP-13 requires technical implementation of alternative security mechanisms. Scripts provided for checking primary mechanism status, activating backup authentication, verifying encryption fallbacks, and enabling manual access control modes. Organizations should customize scripts for their specific security architecture."
    },
    "rationale": "If your primary security controls fail, backup mechanisms ensure security isn't completely lost during recovery."
  },
  {
    "control_id": "CP-10(1)",
    "control_name": "Contingency Plan Testing",
    "family": "Contingency Planning",
    "family_id": "CP",
    "official_text": "[Withdrawn: Incorporated into CP-4]",
    "parent_control": "CP-10",
    "source": "NIST SP 800-53 Rev 5",
    "stig_id": null,
    "status": "withdrawn",
    "incorporated_into": "CP-4",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "plain_english_explanation": "This enhancement has been withdrawn from NIST SP 800-53 Rev 5. The contingency plan testing requirements are now addressed in control CP-4 (Contingency Plan Testing). Organizations should refer to CP-4 for requirements related to testing contingency plans.",
    "intent": "Originally intended to address contingency plan testing requirements, this enhancement was consolidated into CP-4 to reduce redundancy in the control catalog.",
    "ai_guidance": "This enhancement is WITHDRAWN in NIST SP 800-53 Revision 5. Do not implement this enhancement separately. Instead, refer to CP-4 (Contingency Plan Testing) for all contingency plan testing requirements. When auditing or assessing compliance, map any CP-10(1) references to CP-4.",
    "example_implementation": "N/A - Withdrawn. See CP-4 for contingency plan testing implementation.",
    "non_technical_guidance": "This control enhancement no longer exists as a separate requirement. All contingency plan testing requirements are addressed in CP-4.",
    "is_technical": false,
    "enhancements": [],
    "related_controls": [
      "CP-4"
    ],
    "supplemental_guidance": "This control enhancement was withdrawn and incorporated into CP-4.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "withdrawn",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false,
      "qa_verified": true,
      "qa_agent": "LOVELESS"
    },
    "cac_metadata": {
      "implementation_type": "withdrawn",
      "last_analyzed": "2025-11-22T00:00:00Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Enhancement withdrawn. See CP-4 for implementation guidance."
    },
    "rationale": "This control ensures contingency plan testing is properly implemented to maintain operational continuity during disruptions."
  },
  {
    "control_id": "CP-10(2)",
    "control_name": "Transaction Recovery",
    "family": "Contingency Planning",
    "family_id": "CP",
    "official_text": "Implement transaction recovery for systems that are transaction-based.",
    "parent_control": "CP-10",
    "source": "NIST SP 800-53 Rev 5",
    "stig_id": "SRG-APP-000226-CTR-00570",
    "baselines": {
      "low": false,
      "moderate": true,
      "high": true
    },
    "plain_english_explanation": "For systems that process transactions (databases, financial systems, e-commerce platforms), you must implement mechanisms to recover incomplete or failed transactions. This includes transaction logging, rollback capabilities, and the ability to replay transactions to restore the system to a consistent state. The goal is ensuring data integrity and preventing partial transactions from corrupting the system state.",
    "intent": "Ensure transaction-based systems can recover from failures without data loss or corruption by implementing transaction logging, rollback mechanisms, and recovery capabilities that maintain data integrity.",
    "ai_guidance": "Transaction recovery is critical for database systems, financial applications, and any system where data consistency is paramount. Implementation should include: (1) Write-ahead logging (WAL) to ensure transaction durability, (2) ACID compliance for database operations, (3) Two-phase commit protocols for distributed transactions, (4) Point-in-time recovery capabilities, (5) Transaction replay from logs after system failure, (6) Automated consistency checks after recovery. Modern implementations leverage database-native features like PostgreSQL WAL, MySQL binary logs, or MongoDB oplog. For microservices, implement saga patterns or event sourcing for distributed transaction recovery.",
    "example_implementation": "Configure database transaction logging, implement write-ahead logs, enable point-in-time recovery, and test transaction rollback procedures regularly.",
    "non_technical_guidance": "Ensure all transaction-based systems have: (1) Documented transaction recovery procedures, (2) Regular testing of rollback capabilities, (3) Defined recovery point objectives (RPO) for transaction data, (4) Clear escalation procedures for failed transaction recovery.",
    "is_technical": true,
    "enhancements": [],
    "related_controls": [
      "CP-9",
      "CP-10",
      "SI-11"
    ],
    "supplemental_guidance": "Transaction-based systems include database management systems and transaction processing systems. Transaction recovery mechanisms include transaction rollback and transaction journaling.",
    "implementation_scripts": {
      "linux": {
        "bash": "# postgresql_wal_check\n#!/bin/bash\n# CP-10(2): PostgreSQL Write-Ahead Log Configuration Check\n# Verify transaction recovery is properly configured\n\necho \"=== CP-10(2) PostgreSQL Transaction Recovery Status ===\"\necho \"Date: $(date)\"\necho \"\"\n\n# Check if PostgreSQL is installed and running\nif command -v psql &>/dev/null; then\n    echo \"[POSTGRESQL WAL CONFIGURATION]\"\n    \n    # Check WAL level\n    WAL_LEVEL=$(sudo -u postgres psql -t -c \"SHOW wal_level;\" 2>/dev/null | xargs)\n    echo \"  wal_level: $WAL_LEVEL\"\n    if [ \"$WAL_LEVEL\" = \"replica\" ] || [ \"$WAL_LEVEL\" = \"logical\" ]; then\n        echo \"  Status: COMPLIANT (WAL enabled for recovery)\"\n    else\n        echo \"  Status: NON-COMPLIANT (WAL level insufficient)\"\n    fi\n    \n    # Check archive mode\n    ARCHIVE_MODE=$(sudo -u postgres psql -t -c \"SHOW archive_mode;\" 2>/dev/null | xargs)\n    echo \"  archive_mode: $ARCHIVE_MODE\"\n    \n    # Check max_wal_senders\n    MAX_WAL=$(sudo -u postgres psql -t -c \"SHOW max_wal_senders;\" 2>/dev/null | xargs)\n    echo \"  max_wal_senders: $MAX_WAL\"\n    \n    echo \"\"\n    echo \"[RECOVERY CONFIGURATION]\"\n    # Check for recovery.conf or standby.signal\n    PGDATA=$(sudo -u postgres psql -t -c \"SHOW data_directory;\" 2>/dev/null | xargs)\n    if [ -f \"$PGDATA/standby.signal\" ]; then\n        echo \"  Standby mode: ACTIVE\"\n    fi\n    if [ -f \"$PGDATA/recovery.conf\" ]; then\n        echo \"  Recovery config: PRESENT\"\n    fi\nelse\n    echo \"PostgreSQL not detected\"\nfi\n\n# mysql_binlog_check\n#!/bin/bash\n# CP-10(2): MySQL Binary Log Configuration Check\n# Verify transaction recovery is properly configured\n\necho \"=== CP-10(2) MySQL Transaction Recovery Status ===\"\necho \"Date: $(date)\"\necho \"\"\n\nif command -v mysql &>/dev/null; then\n    echo \"[MYSQL BINARY LOG CONFIGURATION]\"\n    \n    # Check binary logging\n    LOG_BIN=$(mysql -e \"SHOW VARIABLES LIKE 'log_bin';\" 2>/dev/null | grep -i log_bin | awk '{print $2}')\n    echo \"  log_bin: $LOG_BIN\"\n    \n    if [ \"$LOG_BIN\" = \"ON\" ]; then\n        echo \"  Status: COMPLIANT (Binary logging enabled)\"\n        \n        # Check binary log format\n        BINLOG_FORMAT=$(mysql -e \"SHOW VARIABLES LIKE 'binlog_format';\" 2>/dev/null | grep binlog_format | awk '{print $2}')\n        echo \"  binlog_format: $BINLOG_FORMAT\"\n        \n        # Check sync settings\n        SYNC_BINLOG=$(mysql -e \"SHOW VARIABLES LIKE 'sync_binlog';\" 2>/dev/null | grep sync_binlog | awk '{print $2}')\n        echo \"  sync_binlog: $SYNC_BINLOG\"\n        \n        # Check InnoDB settings\n        echo \"\"\n        echo \"[INNODB TRANSACTION SETTINGS]\"\n        INNODB_FLUSH=$(mysql -e \"SHOW VARIABLES LIKE 'innodb_flush_log_at_trx_commit';\" 2>/dev/null | grep innodb | awk '{print $2}')\n        echo \"  innodb_flush_log_at_trx_commit: $INNODB_FLUSH\"\n        \n        if [ \"$INNODB_FLUSH\" = \"1\" ] && [ \"$SYNC_BINLOG\" = \"1\" ]; then\n            echo \"  ACID Compliance: FULL (Durable transactions)\"\n        else\n            echo \"  ACID Compliance: PARTIAL (Review settings)\"\n        fi\n    else\n        echo \"  Status: NON-COMPLIANT (Binary logging disabled)\"\n    fi\nelse\n    echo \"MySQL not detected\"\nfi\n\n# transaction_recovery_test\n#!/bin/bash\n# CP-10(2): Transaction Recovery Test Script\n# Test transaction rollback and recovery capabilities\n\necho \"=== CP-10(2) Transaction Recovery Test ===\"\necho \"Date: $(date)\"\necho \"\"\n\nDB_TYPE=\"${1:-postgresql}\"\nTEST_DB=\"recovery_test_db\"\n\nif [ \"$DB_TYPE\" = \"postgresql\" ]; then\n    echo \"Testing PostgreSQL transaction recovery...\"\n    \n    # Create test database\n    sudo -u postgres psql -c \"CREATE DATABASE $TEST_DB;\" 2>/dev/null\n    \n    # Test transaction rollback\n    sudo -u postgres psql -d $TEST_DB <<EOF\nBEGIN;\nCREATE TABLE test_recovery (id SERIAL, data TEXT);\nINSERT INTO test_recovery (data) VALUES ('test1');\nINSERT INTO test_recovery (data) VALUES ('test2');\nSAVEPOINT sp1;\nINSERT INTO test_recovery (data) VALUES ('test3');\nROLLBACK TO SAVEPOINT sp1;\nCOMMIT;\nSELECT COUNT(*) as records FROM test_recovery;\nDROP TABLE test_recovery;\nEOF\n    \n    # Cleanup\n    sudo -u postgres psql -c \"DROP DATABASE $TEST_DB;\" 2>/dev/null\n    echo \"PostgreSQL transaction recovery test complete\"\n    \nelif [ \"$DB_TYPE\" = \"mysql\" ]; then\n    echo \"Testing MySQL transaction recovery...\"\n    \n    mysql <<EOF\nCREATE DATABASE IF NOT EXISTS $TEST_DB;\nUSE $TEST_DB;\nCREATE TABLE test_recovery (id INT AUTO_INCREMENT PRIMARY KEY, data VARCHAR(255)) ENGINE=InnoDB;\nSTART TRANSACTION;\nINSERT INTO test_recovery (data) VALUES ('test1');\nINSERT INTO test_recovery (data) VALUES ('test2');\nSAVEPOINT sp1;\nINSERT INTO test_recovery (data) VALUES ('test3');\nROLLBACK TO SAVEPOINT sp1;\nCOMMIT;\nSELECT COUNT(*) as records FROM test_recovery;\nDROP DATABASE $TEST_DB;\nEOF\n    echo \"MySQL transaction recovery test complete\"\nfi"
      },
      "windows": {
        "powershell": "# sql_server_recovery_check\n# CP-10(2): SQL Server Transaction Recovery Check (PowerShell)\n# Verify SQL Server transaction recovery configuration\n\nWrite-Host \"=== CP-10(2) SQL Server Transaction Recovery Status ===\"\nWrite-Host \"Date: $(Get-Date)\"\nWrite-Host \"\"\n\n# Check SQL Server instance\n$sqlInstances = Get-Service -Name 'MSSQL*' -ErrorAction SilentlyContinue | Where-Object { $_.Status -eq 'Running' }\n\nif ($sqlInstances) {\n    foreach ($instance in $sqlInstances) {\n        Write-Host \"[SQL Server Instance: $($instance.Name)]\"\n        \n        try {\n            # Check recovery model for each database\n            $query = \"SELECT name, recovery_model_desc FROM sys.databases WHERE database_id > 4\"\n            $databases = Invoke-Sqlcmd -Query $query -ServerInstance \".\" -ErrorAction Stop\n            \n            Write-Host \"\"\n            Write-Host \"[DATABASE RECOVERY MODELS]\"\n            foreach ($db in $databases) {\n                $status = if ($db.recovery_model_desc -eq 'FULL') { 'COMPLIANT' } else { 'REVIEW' }\n                Write-Host \"  $($db.name): $($db.recovery_model_desc) [$status]\"\n            }\n            \n            # Check transaction log backup status\n            Write-Host \"\"\n            Write-Host \"[TRANSACTION LOG BACKUP STATUS]\"\n            $logQuery = @\"\nSELECT \n    d.name,\n    MAX(b.backup_finish_date) as last_log_backup\nFROM sys.databases d\nLEFT JOIN msdb.dbo.backupset b ON d.name = b.database_name AND b.type = 'L'\nWHERE d.recovery_model_desc = 'FULL' AND d.database_id > 4\nGROUP BY d.name\n\"@\n            $logBackups = Invoke-Sqlcmd -Query $logQuery -ServerInstance \".\" -ErrorAction SilentlyContinue\n            foreach ($backup in $logBackups) {\n                Write-Host \"  $($backup.name): Last log backup - $($backup.last_log_backup)\"\n            }\n            \n        } catch {\n            Write-Host \"  Error querying SQL Server: $($_.Exception.Message)\"\n        }\n    }\n} else {\n    Write-Host \"No running SQL Server instances detected\"\n}\n\n# transaction_recovery_test\n# CP-10(2): SQL Server Transaction Recovery Test (PowerShell)\n# Test SQL Server transaction rollback and recovery\n\nWrite-Host \"=== CP-10(2) SQL Server Transaction Recovery Test ===\"\nWrite-Host \"Date: $(Get-Date)\"\nWrite-Host \"\"\n\n$testDbName = \"CP10_RecoveryTest\"\n\ntry {\n    # Create test database\n    $createDb = @\"\nIF NOT EXISTS (SELECT * FROM sys.databases WHERE name = '$testDbName')\nBEGIN\n    CREATE DATABASE [$testDbName]\nEND\n\"@\n    Invoke-Sqlcmd -Query $createDb -ServerInstance \".\" -ErrorAction Stop\n    Write-Host \"Created test database: $testDbName\"\n    \n    # Test transaction with savepoint and rollback\n    $testTransaction = @\"\nUSE [$testDbName];\n\nCREATE TABLE TestRecovery (ID INT IDENTITY, Data NVARCHAR(100));\n\nBEGIN TRANSACTION;\n    INSERT INTO TestRecovery (Data) VALUES ('Record 1');\n    INSERT INTO TestRecovery (Data) VALUES ('Record 2');\n    SAVE TRANSACTION SavePoint1;\n    INSERT INTO TestRecovery (Data) VALUES ('Record 3 - will be rolled back');\n    ROLLBACK TRANSACTION SavePoint1;\nCOMMIT TRANSACTION;\n\nSELECT COUNT(*) AS RecordCount FROM TestRecovery;\nDROP TABLE TestRecovery;\n\"@\n    $result = Invoke-Sqlcmd -Query $testTransaction -ServerInstance \".\" -ErrorAction Stop\n    Write-Host \"Transaction rollback test: PASSED\"\n    Write-Host \"Records after rollback: $($result.RecordCount) (expected: 2)\"\n    \n    # Cleanup\n    Invoke-Sqlcmd -Query \"DROP DATABASE [$testDbName]\" -ServerInstance \".\" -ErrorAction SilentlyContinue\n    Write-Host \"Cleanup complete\"\n    \n} catch {\n    Write-Host \"Error during test: $($_.Exception.Message)\" -ForegroundColor Red\n}"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": true,
      "qa_verified": true,
      "qa_agent": "LOVELESS"
    },
    "cac_metadata": {
      "implementation_type": "technical",
      "last_analyzed": "2025-11-22T00:00:00Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Configure database transaction logging (WAL, binary logs, transaction logs), implement ACID-compliant transactions, and test recovery procedures regularly."
    },
    "rationale": "This control ensures transaction recovery is properly implemented to maintain operational continuity during disruptions."
  },
  {
    "control_id": "CP-10(3)",
    "control_name": "Compensating Security Controls",
    "family": "Contingency Planning",
    "family_id": "CP",
    "official_text": "[Withdrawn: Addressed through tailoring procedures]",
    "parent_control": "CP-10",
    "source": "NIST SP 800-53 Rev 5",
    "stig_id": null,
    "status": "withdrawn",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "plain_english_explanation": "This enhancement has been withdrawn from NIST SP 800-53 Rev 5. Compensating security controls are now addressed through the standard tailoring process defined in NIST guidance. Organizations should use the tailoring process to identify and document compensating controls when primary controls cannot be fully implemented.",
    "intent": "Originally intended to address compensating controls during recovery, this enhancement was withdrawn because compensating controls are properly addressed through the control tailoring process rather than a specific control requirement.",
    "ai_guidance": "This enhancement is WITHDRAWN in NIST SP 800-53 Revision 5. Compensating controls should be addressed through the tailoring process rather than a specific control. When a control cannot be fully implemented, document the compensating control in your System Security Plan (SSP) following NIST tailoring guidance. Do not create separate implementations for CP-10(3).",
    "example_implementation": "N/A - Withdrawn. Use control tailoring process to document compensating controls.",
    "non_technical_guidance": "When primary security controls cannot be implemented during recovery operations, document compensating controls through your organization's control tailoring process in the System Security Plan.",
    "is_technical": false,
    "enhancements": [],
    "related_controls": [
      "CP-10"
    ],
    "supplemental_guidance": "This control enhancement was withdrawn. Compensating security controls are addressed through the tailoring process.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "withdrawn",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false,
      "qa_verified": true,
      "qa_agent": "LOVELESS"
    },
    "cac_metadata": {
      "implementation_type": "withdrawn",
      "last_analyzed": "2025-11-22T00:00:00Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Enhancement withdrawn. Address compensating controls through tailoring process."
    },
    "rationale": "This control ensures compensating security controls is properly implemented to maintain operational continuity during disruptions."
  },
  {
    "control_id": "CP-10(4)",
    "control_name": "Restore Within Time Period",
    "family": "Contingency Planning",
    "family_id": "CP",
    "official_text": "Provide the capability to restore system components within [Assignment: organization-defined restoration time period] from configuration-controlled and integrity-protected information representing a known, operational state for the components.",
    "parent_control": "CP-10",
    "source": "NIST SP 800-53 Rev 5",
    "stig_id": "SRG-OS-000480-GPOS-00227",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": true
    },
    "plain_english_explanation": "You must be able to restore system components within a defined time period (your organization's Recovery Time Objective or RTO) from backups that are under configuration control and protected against tampering. This means having verified, immutable backup images and automated restoration procedures that can reliably rebuild systems to a known good state within your required timeframe.",
    "intent": "Ensure organizations can restore critical system components within defined time constraints using verified, integrity-protected backup information, thereby minimizing downtime and ensuring business continuity for high-impact systems.",
    "ai_guidance": "This enhancement requires demonstrable, tested capability to meet defined RTOs. Key implementation considerations: (1) Define RTOs based on business impact analysis - typically 4 hours or less for critical systems, (2) Maintain configuration-controlled golden images with cryptographic verification, (3) Use infrastructure-as-code to enable rapid, repeatable deployments, (4) Implement automated restoration pipelines with built-in validation, (5) Store backups in integrity-protected repositories with immutability features, (6) Test restoration procedures regularly and document actual recovery times, (7) Monitor backup age and integrity continuously. Modern approaches use container orchestration, immutable infrastructure patterns, and cloud-native disaster recovery services to achieve sub-hour RTOs.",
    "example_implementation": "Implement infrastructure-as-code with automated deployment pipelines, maintain verified container images, use immutable backup storage with cryptographic integrity verification, and conduct regular recovery drills to validate RTO compliance.",
    "non_technical_guidance": "Define RTOs for each critical system based on business impact. Document restoration procedures, train recovery personnel, and conduct regular recovery exercises. Maintain records of actual recovery times to validate capability.",
    "is_technical": true,
    "enhancements": [],
    "related_controls": [
      "CP-2",
      "CP-9",
      "CP-10",
      "CM-2",
      "SA-10"
    ],
    "supplemental_guidance": "Recovery time is the amount of time to restore information system components to operational states. Restoration includes full reconstitution of operating systems, applications, and configuration settings, while maintaining security controls. Organizations may have different restoration time periods for different system components or may need to restore some system components before others. Some system components may be rebuilt from scratch, while others may rely on backup images.",
    "implementation_scripts": {
      "linux": {
        "bash": "# rto_compliance_check\n#!/bin/bash\n# CP-10(4): RTO Compliance Verification\n# Check restoration capability against defined RTO\n\nRTO_MINUTES=${1:-60}\nLOG_FILE=\"/var/log/rto-compliance.log\"\n\necho \"=== CP-10(4) RTO Compliance Check ===\"\necho \"Defined RTO: $RTO_MINUTES minutes\"\necho \"Date: $(date)\"\necho \"\"\n\n# Check for infrastructure-as-code tools\necho \"[INFRASTRUCTURE-AS-CODE TOOLS]\"\nfor tool in terraform ansible puppet chef salt; do\n    if command -v $tool &>/dev/null; then\n        echo \"  $tool: INSTALLED ($(which $tool))\"\n    fi\ndone\n\n# Check container orchestration\necho \"\"\necho \"[CONTAINER ORCHESTRATION]\"\nfor tool in docker podman kubectl; do\n    if command -v $tool &>/dev/null; then\n        echo \"  $tool: INSTALLED\"\n        if [ \"$tool\" = \"kubectl\" ]; then\n            kubectl cluster-info 2>/dev/null && echo \"  Kubernetes cluster: CONNECTED\"\n        fi\n    fi\ndone\n\n# Check golden image availability\necho \"\"\necho \"[GOLDEN IMAGES]\"\nGOLDEN_IMAGE_DIR=\"/opt/golden-images\"\nif [ -d \"$GOLDEN_IMAGE_DIR\" ]; then\n    echo \"  Golden image directory: $GOLDEN_IMAGE_DIR\"\n    ls -la \"$GOLDEN_IMAGE_DIR\"/*.img 2>/dev/null || echo \"  No .img files found\"\nfi\n\n# Check backup integrity\necho \"\"\necho \"[BACKUP INTEGRITY]\"\nBACKUP_DIR=\"/backup\"\nif [ -d \"$BACKUP_DIR\" ] && [ -f \"$BACKUP_DIR/checksums.sha256\" ]; then\n    echo \"  Verifying backup integrity...\"\n    if cd \"$BACKUP_DIR\" && sha256sum -c checksums.sha256 --quiet 2>/dev/null; then\n        echo \"  Integrity check: PASSED\"\n    else\n        echo \"  Integrity check: FAILED - Review backup integrity\"\n    fi\nfi\n\n# Check last recovery test\necho \"\"\necho \"[RECOVERY TEST HISTORY]\"\nif [ -f \"/var/log/recovery-test.log\" ]; then\n    LAST_TEST=$(tail -1 /var/log/recovery-test.log)\n    echo \"  Last test: $LAST_TEST\"\nelse\n    echo \"  WARNING: No recovery test log found\"\nfi\n\n# golden_image_verification\n#!/bin/bash\n# CP-10(4): Golden Image Integrity Verification\n# Verify golden images are intact and ready for restoration\n\nGOLDEN_DIR=\"${1:-/opt/golden-images}\"\nMANIFEST=\"$GOLDEN_DIR/manifest.json\"\nLOG_FILE=\"/var/log/golden-image-verify.log\"\n\necho \"=== CP-10(4) Golden Image Verification ===\"\necho \"Golden Image Directory: $GOLDEN_DIR\"\necho \"Date: $(date)\"\necho \"\"\n\nif [ ! -d \"$GOLDEN_DIR\" ]; then\n    echo \"ERROR: Golden image directory not found\"\n    exit 1\nfi\n\n# Check manifest\nif [ -f \"$MANIFEST\" ]; then\n    echo \"[MANIFEST]\"\n    echo \"  Manifest found: $MANIFEST\"\n    echo \"  Last modified: $(stat -c %y \"$MANIFEST\")\"\nelse\n    echo \"WARNING: No manifest file found\"\nfi\n\n# Verify each image\necho \"\"\necho \"[IMAGE VERIFICATION]\"\nfor img in \"$GOLDEN_DIR\"/*.{img,qcow2,vmdk,tar.gz} 2>/dev/null; do\n    if [ -f \"$img\" ]; then\n        BASENAME=$(basename \"$img\")\n        SIZE=$(stat -c %s \"$img\")\n        MODIFIED=$(stat -c %y \"$img\")\n        \n        echo \"  Image: $BASENAME\"\n        echo \"    Size: $(numfmt --to=iec $SIZE)\"\n        echo \"    Modified: $MODIFIED\"\n        \n        # Check for corresponding checksum\n        if [ -f \"$img.sha256\" ]; then\n            if sha256sum -c \"$img.sha256\" --quiet 2>/dev/null; then\n                echo \"    Integrity: VERIFIED\"\n            else\n                echo \"    Integrity: FAILED\"\n            fi\n        else\n            echo \"    Integrity: NO CHECKSUM FILE\"\n        fi\n        echo \"\"\n    fi\ndone\n\n# timed_recovery_drill\n#!/bin/bash\n# CP-10(4): Timed Recovery Drill\n# Execute and time a recovery drill to validate RTO\n\nset -e\n\nRTO_MINUTES=${1:-60}\nDRILL_TYPE=\"${2:-partial}\"  # partial or full\nLOG_FILE=\"/var/log/recovery-drill-$(date +%Y%m%d-%H%M%S).log\"\n\nlog() {\n    echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\" | tee -a $LOG_FILE\n}\n\nSTART_TIME=$(date +%s)\n\nlog \"=== CP-10(4) TIMED RECOVERY DRILL ===\"\nlog \"RTO Target: $RTO_MINUTES minutes\"\nlog \"Drill Type: $DRILL_TYPE\"\nlog \"Start Time: $(date)\"\nlog \"\"\n\n# Phase 1: Pre-drill validation\nlog \"Phase 1: Pre-drill validation\"\nif [ ! -d \"/backup/latest\" ]; then\n    log \"ERROR: Backup source not available\"\n    exit 1\nfi\nlog \"Backup source validated\"\n\n# Phase 2: Simulate service stop\nlog \"Phase 2: Service interruption simulation\"\n# In real drill, would stop actual services\n\n# Phase 3: Restoration\nlog \"Phase 3: Beginning restoration\"\nif [ \"$DRILL_TYPE\" = \"partial\" ]; then\n    log \"Executing partial restoration (config only)\"\n    # Restore configuration files\n    sleep 5  # Simulate restoration time\nelse\n    log \"Executing full restoration\"\n    # Full system restore\n    sleep 30  # Simulate full restoration\nfi\n\n# Phase 4: Validation\nlog \"Phase 4: Post-restoration validation\"\n# Verify critical services\n# Verify data integrity\n\n# Calculate elapsed time\nEND_TIME=$(date +%s)\nELAPSED_SECONDS=$((END_TIME - START_TIME))\nELAPSED_MINUTES=$((ELAPSED_SECONDS / 60))\n\nlog \"\"\nlog \"=== DRILL COMPLETE ===\"\nlog \"Total Time: $ELAPSED_MINUTES minutes ($ELAPSED_SECONDS seconds)\"\n\nif [ $ELAPSED_MINUTES -le $RTO_MINUTES ]; then\n    log \"RTO COMPLIANCE: PASSED (within $RTO_MINUTES minute target)\"\nelse\n    log \"RTO COMPLIANCE: FAILED (exceeded $RTO_MINUTES minute target)\"\nfi\n\n# Record in test history\necho \"$(date '+%Y-%m-%d %H:%M:%S') - $DRILL_TYPE drill - $ELAPSED_MINUTES minutes\" >> /var/log/recovery-test.log"
      },
      "windows": {
        "powershell": "# rto_compliance_check\n# CP-10(4): RTO Compliance Check (PowerShell)\n# Verify restoration capability against defined RTO\n\nparam(\n    [int]$RTOMinutes = 60\n)\n\nWrite-Host \"=== CP-10(4) RTO Compliance Check ===\"\nWrite-Host \"Defined RTO: $RTOMinutes minutes\"\nWrite-Host \"Date: $(Get-Date)\"\nWrite-Host \"\"\n\n# Check for infrastructure-as-code tools\nWrite-Host \"[INFRASTRUCTURE-AS-CODE TOOLS]\"\n$tools = @('terraform', 'ansible', 'puppet', 'chef', 'dsc')\nforeach ($tool in $tools) {\n    $found = Get-Command $tool -ErrorAction SilentlyContinue\n    if ($found) {\n        Write-Host \"  $tool`: INSTALLED ($($found.Source))\"\n    }\n}\n\n# Check PowerShell DSC\nif (Get-Module -ListAvailable -Name PSDesiredStateConfiguration) {\n    Write-Host \"  PowerShell DSC: AVAILABLE\"\n}\n\n# Check container tools\nWrite-Host \"\"\nWrite-Host \"[CONTAINER TOOLS]\"\n$containerTools = @('docker', 'kubectl')\nforeach ($tool in $containerTools) {\n    if (Get-Command $tool -ErrorAction SilentlyContinue) {\n        Write-Host \"  $tool`: INSTALLED\"\n    }\n}\n\n# Check Windows Server Backup\nWrite-Host \"\"\nWrite-Host \"[WINDOWS BACKUP STATUS]\"\ntry {\n    $wbPolicy = Get-WBPolicy -Editable 2>$null\n    if ($wbPolicy) {\n        Write-Host \"  Backup Policy: CONFIGURED\"\n        $lastBackup = Get-WBBackupSet 2>$null | Sort-Object BackupTime -Descending | Select-Object -First 1\n        if ($lastBackup) {\n            Write-Host \"  Last Backup: $($lastBackup.BackupTime)\"\n        }\n    }\n} catch {\n    Write-Host \"  Windows Backup: Not configured or not available\"\n}\n\n# Check System State backup\nWrite-Host \"\"\nWrite-Host \"[SYSTEM STATE]\"\ntry {\n    $systemState = Get-WindowsFeature -Name Windows-Server-Backup\n    Write-Host \"  Windows Server Backup Feature: $($systemState.InstallState)\"\n} catch {\n    Write-Host \"  Unable to check Windows Server Backup feature\"\n}\n\n# Check recovery test log\nWrite-Host \"\"\nWrite-Host \"[RECOVERY TEST HISTORY]\"\n$testLogPath = \"C:\\Recovery\\Logs\\recovery-test.log\"\nif (Test-Path $testLogPath) {\n    $lastTest = Get-Content $testLogPath -Tail 1\n    Write-Host \"  Last test: $lastTest\"\n} else {\n    Write-Host \"  WARNING: No recovery test log found\"\n}\n\n# golden_image_verification\n# CP-10(4): Golden Image Verification (PowerShell)\n# Verify golden images are intact and ready for restoration\n\nparam(\n    [string]$GoldenImagePath = \"D:\\GoldenImages\"\n)\n\nWrite-Host \"=== CP-10(4) Golden Image Verification ===\"\nWrite-Host \"Golden Image Directory: $GoldenImagePath\"\nWrite-Host \"Date: $(Get-Date)\"\nWrite-Host \"\"\n\nif (-not (Test-Path $GoldenImagePath)) {\n    Write-Host \"ERROR: Golden image directory not found\" -ForegroundColor Red\n    exit 1\n}\n\n# Check for manifest\n$manifestPath = Join-Path $GoldenImagePath \"manifest.json\"\nif (Test-Path $manifestPath) {\n    Write-Host \"[MANIFEST]\"\n    Write-Host \"  Manifest found: $manifestPath\"\n    $manifest = Get-Content $manifestPath | ConvertFrom-Json\n    Write-Host \"  Version: $($manifest.version)\"\n    Write-Host \"  Created: $($manifest.created)\"\n}\n\n# Verify each image\nWrite-Host \"\"\nWrite-Host \"[IMAGE VERIFICATION]\"\n$images = Get-ChildItem $GoldenImagePath -Include *.vhd,*.vhdx,*.wim,*.iso -Recurse\n\nforeach ($img in $images) {\n    Write-Host \"  Image: $($img.Name)\"\n    Write-Host \"    Size: $([math]::Round($img.Length/1GB, 2)) GB\"\n    Write-Host \"    Modified: $($img.LastWriteTime)\"\n    \n    # Check for corresponding checksum file\n    $checksumFile = \"$($img.FullName).sha256\"\n    if (Test-Path $checksumFile) {\n        $storedHash = (Get-Content $checksumFile).Split(' ')[0]\n        $actualHash = (Get-FileHash $img.FullName -Algorithm SHA256).Hash\n        \n        if ($storedHash -eq $actualHash) {\n            Write-Host \"    Integrity: VERIFIED\" -ForegroundColor Green\n        } else {\n            Write-Host \"    Integrity: FAILED\" -ForegroundColor Red\n        }\n    } else {\n        Write-Host \"    Integrity: NO CHECKSUM FILE\" -ForegroundColor Yellow\n    }\n    Write-Host \"\"\n}\n\n# timed_recovery_drill\n# CP-10(4): Timed Recovery Drill (PowerShell)\n# Execute and time a recovery drill to validate RTO\n\nparam(\n    [int]$RTOMinutes = 60,\n    [ValidateSet('partial', 'full')]\n    [string]$DrillType = 'partial'\n)\n\n$ErrorActionPreference = \"Continue\"\n$timestamp = Get-Date -Format \"yyyyMMdd-HHmmss\"\n$logPath = \"C:\\Recovery\\Logs\"\n$logFile = Join-Path $logPath \"recovery-drill-$timestamp.log\"\n\nNew-Item -ItemType Directory -Path $logPath -Force | Out-Null\n\nfunction Log-Message {\n    param([string]$Message)\n    $entry = \"[$(Get-Date -Format 'yyyy-MM-dd HH:mm:ss')] $Message\"\n    Write-Host $entry\n    Add-Content -Path $logFile -Value $entry\n}\n\n$startTime = Get-Date\n\nLog-Message \"=== CP-10(4) TIMED RECOVERY DRILL ===\"\nLog-Message \"RTO Target: $RTOMinutes minutes\"\nLog-Message \"Drill Type: $DrillType\"\nLog-Message \"Start Time: $startTime\"\nLog-Message \"\"\n\n# Phase 1: Pre-drill validation\nLog-Message \"Phase 1: Pre-drill validation\"\n$backupPath = \"D:\\Backup\\Latest\"\nif (-not (Test-Path $backupPath)) {\n    Log-Message \"ERROR: Backup source not available\"\n    exit 1\n}\nLog-Message \"Backup source validated\"\n\n# Phase 2: Simulate service stop\nLog-Message \"Phase 2: Service interruption simulation\"\n# In real drill, would stop actual services\n\n# Phase 3: Restoration\nLog-Message \"Phase 3: Beginning restoration\"\nif ($DrillType -eq 'partial') {\n    Log-Message \"Executing partial restoration (config only)\"\n    Start-Sleep -Seconds 5  # Simulate restoration\n} else {\n    Log-Message \"Executing full restoration\"\n    Start-Sleep -Seconds 30  # Simulate full restoration\n}\n\n# Phase 4: Validation\nLog-Message \"Phase 4: Post-restoration validation\"\n\n# Calculate elapsed time\n$endTime = Get-Date\n$elapsed = $endTime - $startTime\n$elapsedMinutes = [math]::Floor($elapsed.TotalMinutes)\n\nLog-Message \"\"\nLog-Message \"=== DRILL COMPLETE ===\"\nLog-Message \"Total Time: $elapsedMinutes minutes ($([math]::Floor($elapsed.TotalSeconds)) seconds)\"\n\nif ($elapsedMinutes -le $RTOMinutes) {\n    Log-Message \"RTO COMPLIANCE: PASSED (within $RTOMinutes minute target)\"\n} else {\n    Log-Message \"RTO COMPLIANCE: FAILED (exceeded $RTOMinutes minute target)\"\n}\n\n# Record in test history\n$testLogPath = Join-Path $logPath \"recovery-test.log\"\nAdd-Content -Path $testLogPath -Value \"$(Get-Date -Format 'yyyy-MM-dd HH:mm:ss') - $DrillType drill - $elapsedMinutes minutes\""
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": true,
      "qa_verified": true,
      "qa_agent": "LOVELESS"
    },
    "cac_metadata": {
      "implementation_type": "technical",
      "last_analyzed": "2025-11-22T00:00:00Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Define RTOs based on business impact analysis, maintain configuration-controlled golden images with integrity verification, implement automated restoration pipelines, and conduct regular timed recovery drills."
    },
    "rationale": "This control ensures restore within time period is properly implemented to maintain operational continuity during disruptions."
  },
  {
    "control_id": "CP-10(5)",
    "control_name": "Failover Capability",
    "family": "Contingency Planning",
    "family_id": "CP",
    "official_text": "[Withdrawn: Incorporated into SI-13]",
    "parent_control": "CP-10",
    "source": "NIST SP 800-53 Rev 5",
    "stig_id": null,
    "status": "withdrawn",
    "incorporated_into": "SI-13",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "plain_english_explanation": "This enhancement has been withdrawn from NIST SP 800-53 Rev 5. Failover capability requirements are now addressed in control SI-13 (Predictable Failure Prevention). Organizations should refer to SI-13 for requirements related to automated failover and high availability.",
    "intent": "Originally intended to address failover capabilities for system recovery, this enhancement was consolidated into SI-13 to better organize controls related to system resilience and failure prevention.",
    "ai_guidance": "This enhancement is WITHDRAWN in NIST SP 800-53 Revision 5. Do not implement this enhancement separately. Instead, refer to SI-13 (Predictable Failure Prevention) for failover capability requirements. When auditing or assessing compliance, map any CP-10(5) references to SI-13. SI-13 addresses automated failover, redundancy, and high availability mechanisms.",
    "example_implementation": "N/A - Withdrawn. See SI-13 for failover capability implementation.",
    "non_technical_guidance": "This control enhancement no longer exists as a separate requirement. All failover capability requirements are addressed in SI-13.",
    "is_technical": false,
    "enhancements": [],
    "related_controls": [
      "SI-13"
    ],
    "supplemental_guidance": "This control enhancement was withdrawn and incorporated into SI-13.",
    "implementation_scripts": {
      "linux": {},
      "windows": {}
    },
    "metadata": {
      "status": "withdrawn",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": false,
      "qa_verified": true,
      "qa_agent": "LOVELESS"
    },
    "cac_metadata": {
      "implementation_type": "withdrawn",
      "last_analyzed": "2025-11-22T00:00:00Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Enhancement withdrawn. See SI-13 for failover implementation guidance."
    },
    "rationale": "This control ensures failover capability is properly implemented to maintain operational continuity during disruptions."
  },
  {
    "control_id": "CP-10(6)",
    "control_name": "Component Protection",
    "family": "Contingency Planning",
    "family_id": "CP",
    "official_text": "Protect system components used for recovery and reconstitution.",
    "parent_control": "CP-10",
    "source": "NIST SP 800-53 Rev 5",
    "stig_id": "SRG-OS-000480-GPOS-00227",
    "baselines": {
      "low": false,
      "moderate": false,
      "high": false
    },
    "plain_english_explanation": "All components used for system recovery and reconstitution (backup servers, recovery media, golden images, configuration management tools, etc.) must be protected from unauthorized access, modification, and destruction. This includes physical protection of backup media, encryption of backup data, access controls on recovery systems, and integrity verification mechanisms. Recovery components are high-value targets for attackers seeking to compromise restoration processes.",
    "intent": "Ensure recovery and reconstitution components themselves are protected from compromise, ensuring that recovery processes do not introduce vulnerabilities or allow attackers to persist through recovery operations.",
    "ai_guidance": "Recovery component protection is critical because compromised recovery infrastructure allows attackers to persist through reconstitution. Implementation considerations: (1) Store backup media in physically secure, access-controlled locations, (2) Encrypt all backup data at rest and in transit, (3) Implement strict access controls on recovery systems with MFA, (4) Air-gap critical recovery infrastructure from production networks, (5) Use immutable storage for backup repositories, (6) Implement integrity monitoring for recovery scripts and images, (7) Maintain separate credentials for recovery systems, (8) Regularly audit access to recovery components, (9) Protect configuration management tools and secrets used in recovery. Consider the recovery infrastructure as part of the critical attack surface.",
    "example_implementation": "Implement encrypted, immutable backup storage with strict access controls. Air-gap recovery infrastructure, use separate credentials, and maintain integrity verification for all recovery components.",
    "non_technical_guidance": "Establish physical and logical security controls for all recovery components. Limit access to recovery systems to authorized personnel only. Regularly audit access and verify integrity of recovery components.",
    "is_technical": true,
    "enhancements": [],
    "related_controls": [
      "CP-6",
      "CP-7",
      "CP-9",
      "CP-10",
      "MP-4",
      "MP-5",
      "PE-3",
      "SC-28"
    ],
    "supplemental_guidance": "Protection of recovery and reconstitution components include physical and technical protections. Physical protections include the use of controlled access areas for backup media and recovery tools. Technical protections include restricting access to recovery tools and storing backup data in encrypted formats.",
    "implementation_scripts": {
      "linux": {
        "bash": "# recovery_component_audit\n#!/bin/bash\n# CP-10(6): Recovery Component Protection Audit\n# Audit security of recovery infrastructure components\n\necho \"=== CP-10(6) Recovery Component Protection Audit ===\"\necho \"Date: $(date)\"\necho \"\"\n\n# Check backup directory permissions\necho \"[BACKUP DIRECTORY SECURITY]\"\nBACKUP_DIRS=(\"/backup\" \"/opt/backup\" \"/var/backup\")\nfor dir in \"${BACKUP_DIRS[@]}\"; do\n    if [ -d \"$dir\" ]; then\n        echo \"  Directory: $dir\"\n        PERMS=$(stat -c %a \"$dir\")\n        OWNER=$(stat -c %U:%G \"$dir\")\n        echo \"    Permissions: $PERMS\"\n        echo \"    Owner: $OWNER\"\n        \n        if [ \"$PERMS\" = \"700\" ] || [ \"$PERMS\" = \"750\" ]; then\n            echo \"    Status: COMPLIANT (Restricted access)\"\n        else\n            echo \"    Status: NON-COMPLIANT (Permissions too open)\"\n        fi\n    fi\ndone\n\n# Check for encrypted backup storage\necho \"\"\necho \"[BACKUP ENCRYPTION]\"\nif lsblk -o NAME,TYPE,FSTYPE | grep -q crypt; then\n    echo \"  Encrypted volumes detected: YES\"\n    lsblk -o NAME,TYPE,FSTYPE | grep crypt\nelse\n    echo \"  Encrypted volumes detected: NO\"\nfi\n\n# Check backup tool configurations\necho \"\"\necho \"[BACKUP TOOL SECURITY]\"\nfor config in /etc/bacula/*.conf /etc/restic/* /root/.config/rclone/rclone.conf; do\n    if [ -f \"$config\" ]; then\n        PERMS=$(stat -c %a \"$config\")\n        echo \"  $config: permissions $PERMS\"\n        if [ \"$PERMS\" = \"600\" ] || [ \"$PERMS\" = \"400\" ]; then\n            echo \"    Status: COMPLIANT\"\n        else\n            echo \"    Status: NON-COMPLIANT (Should be 600 or 400)\"\n        fi\n    fi\ndone\n\n# Check for immutable backup flags\necho \"\"\necho \"[IMMUTABILITY CHECK]\"\nfor backup in /backup/*.tar.gz /backup/*.img; do\n    if [ -f \"$backup\" ]; then\n        ATTRS=$(lsattr \"$backup\" 2>/dev/null | cut -c1-20)\n        if echo \"$ATTRS\" | grep -q \"i\"; then\n            echo \"  $backup: IMMUTABLE\"\n        else\n            echo \"  $backup: Mutable (consider setting immutable flag)\"\n        fi\n    fi\ndone 2>/dev/null\n\n# Check access logs\necho \"\"\necho \"[ACCESS MONITORING]\"\nif [ -f /var/log/audit/audit.log ]; then\n    echo \"  Audit logging: ENABLED\"\n    BACKUP_ACCESS=$(ausearch -f /backup -ts today 2>/dev/null | wc -l)\n    echo \"  Backup access events today: $BACKUP_ACCESS\"\nelse\n    echo \"  Audit logging: NOT CONFIGURED\"\nfi\n\n# secure_backup_storage\n#!/bin/bash\n# CP-10(6): Secure Backup Storage Configuration\n# Apply security hardening to backup storage\n\nBACKUP_DIR=\"${1:-/backup}\"\n\necho \"=== CP-10(6) Backup Storage Hardening ===\"\necho \"Target: $BACKUP_DIR\"\necho \"Date: $(date)\"\necho \"\"\n\nif [ ! -d \"$BACKUP_DIR\" ]; then\n    echo \"Creating secure backup directory...\"\n    mkdir -p \"$BACKUP_DIR\"\nfi\n\n# Set restrictive permissions\necho \"[PERMISSIONS]\"\nchmod 700 \"$BACKUP_DIR\"\nchown root:root \"$BACKUP_DIR\"\necho \"  Set permissions: 700 (owner only)\"\necho \"  Set owner: root:root\"\n\n# Set immutable flag on existing backups\necho \"\"\necho \"[IMMUTABILITY]\"\nfor backup in \"$BACKUP_DIR\"/*.tar.gz \"$BACKUP_DIR\"/*.img; do\n    if [ -f \"$backup\" ]; then\n        chattr +i \"$backup\" 2>/dev/null && echo \"  Set immutable: $backup\"\n    fi\ndone\n\n# Configure audit rules\necho \"\"\necho \"[AUDIT CONFIGURATION]\"\nif command -v auditctl &>/dev/null; then\n    auditctl -w \"$BACKUP_DIR\" -p rwxa -k backup_access\n    echo \"  Added audit rule for $BACKUP_DIR\"\nfi\n\n# Create access control list\necho \"\"\necho \"[ACCESS CONTROL]\"\nif command -v setfacl &>/dev/null; then\n    # Remove all extended ACLs\n    setfacl -b \"$BACKUP_DIR\"\n    # Set minimal access\n    setfacl -m u:backup:rx \"$BACKUP_DIR\" 2>/dev/null\n    echo \"  Configured ACLs for backup directory\"\nfi\n\necho \"\"\necho \"Hardening complete for $BACKUP_DIR\"\n\n# recovery_integrity_monitor\n#!/bin/bash\n# CP-10(6): Recovery Component Integrity Monitoring\n# Monitor integrity of recovery infrastructure\n\nRECOVERY_DIRS=\"/opt/recovery /backup /var/lib/backup\"\nINTEGRITY_DB=\"/var/lib/recovery-integrity.db\"\nLOG_FILE=\"/var/log/recovery-integrity.log\"\n\nlog() {\n    echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\" | tee -a $LOG_FILE\n}\n\nlog \"=== CP-10(6) Recovery Integrity Check ===\"\n\n# Generate baseline if not exists\nif [ ! -f \"$INTEGRITY_DB\" ]; then\n    log \"Generating integrity baseline...\"\n    for dir in $RECOVERY_DIRS; do\n        if [ -d \"$dir\" ]; then\n            find \"$dir\" -type f -exec sha256sum {} \\; >> \"$INTEGRITY_DB\"\n        fi\n    done\n    chmod 600 \"$INTEGRITY_DB\"\n    chattr +i \"$INTEGRITY_DB\" 2>/dev/null\n    log \"Baseline created: $INTEGRITY_DB\"\n    exit 0\nfi\n\n# Verify against baseline\nlog \"Verifying against baseline...\"\nTEMP_CURRENT=$(mktemp)\nfor dir in $RECOVERY_DIRS; do\n    if [ -d \"$dir\" ]; then\n        find \"$dir\" -type f -exec sha256sum {} \\; >> \"$TEMP_CURRENT\"\n    fi\ndone\n\n# Compare\nADDED=$(comm -23 <(cut -d' ' -f3 \"$TEMP_CURRENT\" | sort) <(cut -d' ' -f3 \"$INTEGRITY_DB\" | sort))\nREMOVED=$(comm -13 <(cut -d' ' -f3 \"$TEMP_CURRENT\" | sort) <(cut -d' ' -f3 \"$INTEGRITY_DB\" | sort))\nMODIFIED=$(while read -r hash file; do\n    orig_hash=$(grep \" $file$\" \"$INTEGRITY_DB\" | cut -d' ' -f1)\n    if [ -n \"$orig_hash\" ] && [ \"$hash\" != \"$orig_hash\" ]; then\n        echo \"$file\"\n    fi\ndone < \"$TEMP_CURRENT\")\n\nif [ -n \"$ADDED\" ]; then\n    log \"NEW FILES DETECTED:\"\n    echo \"$ADDED\" | while read f; do log \"  + $f\"; done\nfi\n\nif [ -n \"$REMOVED\" ]; then\n    log \"MISSING FILES DETECTED:\"\n    echo \"$REMOVED\" | while read f; do log \"  - $f\"; done\nfi\n\nif [ -n \"$MODIFIED\" ]; then\n    log \"MODIFIED FILES DETECTED:\"\n    echo \"$MODIFIED\" | while read f; do log \"  * $f\"; done\nfi\n\nif [ -z \"$ADDED\" ] && [ -z \"$REMOVED\" ] && [ -z \"$MODIFIED\" ]; then\n    log \"Integrity check PASSED - No changes detected\"\nelse\n    log \"Integrity check WARNING - Changes detected (review required)\"\nfi\n\nrm -f \"$TEMP_CURRENT\""
      },
      "windows": {
        "powershell": "# recovery_component_audit\n# CP-10(6): Recovery Component Protection Audit (PowerShell)\n# Audit security of recovery infrastructure components\n\nWrite-Host \"=== CP-10(6) Recovery Component Protection Audit ===\"\nWrite-Host \"Date: $(Get-Date)\"\nWrite-Host \"\"\n\n# Check backup directory security\nWrite-Host \"[BACKUP DIRECTORY SECURITY]\"\n$backupDirs = @(\"D:\\Backup\", \"C:\\Backup\", \"E:\\Recovery\")\n\nforeach ($dir in $backupDirs) {\n    if (Test-Path $dir) {\n        Write-Host \"  Directory: $dir\"\n        \n        # Get ACL\n        $acl = Get-Acl $dir\n        Write-Host \"    Owner: $($acl.Owner)\"\n        \n        # Check for overly permissive access\n        $everyoneAccess = $acl.Access | Where-Object { $_.IdentityReference -like '*Everyone*' }\n        if ($everyoneAccess) {\n            Write-Host \"    Status: NON-COMPLIANT (Everyone has access)\" -ForegroundColor Red\n        } else {\n            Write-Host \"    Status: COMPLIANT (Restricted access)\" -ForegroundColor Green\n        }\n        \n        # List access rules\n        Write-Host \"    Access Rules:\"\n        foreach ($access in $acl.Access | Select-Object -First 5) {\n            Write-Host \"      $($access.IdentityReference): $($access.FileSystemRights)\"\n        }\n    }\n}\n\n# Check for BitLocker encryption\nWrite-Host \"\"\nWrite-Host \"[ENCRYPTION STATUS]\"\ntry {\n    $volumes = Get-BitLockerVolume -ErrorAction Stop\n    foreach ($vol in $volumes) {\n        $status = if ($vol.ProtectionStatus -eq 'On') { 'ENCRYPTED' } else { 'NOT ENCRYPTED' }\n        Write-Host \"  Volume $($vol.MountPoint): $status\"\n    }\n} catch {\n    Write-Host \"  BitLocker: Not available or not configured\"\n}\n\n# Check Windows Backup service security\nWrite-Host \"\"\nWrite-Host \"[BACKUP SERVICE SECURITY]\"\n$wbService = Get-Service wbengine -ErrorAction SilentlyContinue\nif ($wbService) {\n    Write-Host \"  Windows Backup Engine: $($wbService.Status)\"\n    $wbProcess = Get-Process -Name wbengine -ErrorAction SilentlyContinue\n    if ($wbProcess) {\n        Write-Host \"  Running as: $($wbProcess.UserName)\"\n    }\n}\n\n# Check for audit policies\nWrite-Host \"\"\nWrite-Host \"[AUDIT POLICY]\"\n$auditPolicy = auditpol /get /category:\"Object Access\" 2>$null\nif ($auditPolicy -match \"Success and Failure|Success|Failure\") {\n    Write-Host \"  Object Access Auditing: ENABLED\"\n} else {\n    Write-Host \"  Object Access Auditing: NOT CONFIGURED\"\n}\n\n# secure_backup_storage\n# CP-10(6): Secure Backup Storage Configuration (PowerShell)\n# Apply security hardening to backup storage\n\nparam(\n    [string]$BackupPath = \"D:\\Backup\"\n)\n\nWrite-Host \"=== CP-10(6) Backup Storage Hardening ===\"\nWrite-Host \"Target: $BackupPath\"\nWrite-Host \"Date: $(Get-Date)\"\nWrite-Host \"\"\n\n# Create backup directory if needed\nif (-not (Test-Path $BackupPath)) {\n    New-Item -ItemType Directory -Path $BackupPath -Force | Out-Null\n    Write-Host \"Created backup directory: $BackupPath\"\n}\n\n# Set restrictive permissions\nWrite-Host \"[PERMISSIONS]\"\n$acl = Get-Acl $BackupPath\n\n# Disable inheritance and remove inherited rules\n$acl.SetAccessRuleProtection($true, $false)\n\n# Clear existing rules\n$acl.Access | ForEach-Object { $acl.RemoveAccessRule($_) } | Out-Null\n\n# Add restricted access rules\n$adminRule = New-Object System.Security.AccessControl.FileSystemAccessRule(\n    \"BUILTIN\\Administrators\", \"FullControl\", \"ContainerInherit,ObjectInherit\", \"None\", \"Allow\")\n$acl.AddAccessRule($adminRule)\n\n$backupRule = New-Object System.Security.AccessControl.FileSystemAccessRule(\n    \"BUILTIN\\Backup Operators\", \"ReadAndExecute\", \"ContainerInherit,ObjectInherit\", \"None\", \"Allow\")\n$acl.AddAccessRule($backupRule)\n\nSet-Acl $BackupPath $acl\nWrite-Host \"  Applied restrictive ACL (Administrators + Backup Operators only)\"\n\n# Enable auditing\nWrite-Host \"\"\nWrite-Host \"[AUDITING]\"\n$auditRule = New-Object System.Security.AccessControl.FileSystemAuditRule(\n    \"Everyone\", \"Delete,Write,ChangePermissions,TakeOwnership\", \"ContainerInherit,ObjectInherit\", \"None\", \"Success,Failure\")\n$acl.AddAuditRule($auditRule)\nSet-Acl $BackupPath $acl\nWrite-Host \"  Enabled audit logging for critical operations\"\n\n# Set read-only on backup files\nWrite-Host \"\"\nWrite-Host \"[FILE PROTECTION]\"\n$backupFiles = Get-ChildItem $BackupPath -Recurse -File\nforeach ($file in $backupFiles) {\n    Set-ItemProperty $file.FullName -Name IsReadOnly -Value $true\n    Write-Host \"  Protected: $($file.Name)\"\n}\n\nWrite-Host \"\"\nWrite-Host \"Hardening complete for $BackupPath\"\n\n# recovery_integrity_monitor\n# CP-10(6): Recovery Component Integrity Monitoring (PowerShell)\n# Monitor integrity of recovery infrastructure\n\nparam(\n    [switch]$GenerateBaseline\n)\n\n$recoveryDirs = @(\"D:\\Backup\", \"C:\\Recovery\", \"D:\\GoldenImages\")\n$integrityDb = \"C:\\Recovery\\integrity-baseline.json\"\n$logFile = \"C:\\Recovery\\Logs\\integrity-check.log\"\n\nfunction Log-Message {\n    param([string]$Message)\n    $entry = \"[$(Get-Date -Format 'yyyy-MM-dd HH:mm:ss')] $Message\"\n    Write-Host $entry\n    Add-Content -Path $logFile -Value $entry -ErrorAction SilentlyContinue\n}\n\nNew-Item -ItemType Directory -Path (Split-Path $logFile) -Force | Out-Null\n\nLog-Message \"=== CP-10(6) Recovery Integrity Check ===\"\n\n# Generate baseline\nif ($GenerateBaseline -or -not (Test-Path $integrityDb)) {\n    Log-Message \"Generating integrity baseline...\"\n    \n    $baseline = @{}\n    foreach ($dir in $recoveryDirs) {\n        if (Test-Path $dir) {\n            Get-ChildItem $dir -Recurse -File | ForEach-Object {\n                $hash = (Get-FileHash $_.FullName -Algorithm SHA256).Hash\n                $baseline[$_.FullName] = @{\n                    Hash = $hash\n                    Size = $_.Length\n                    LastWrite = $_.LastWriteTime.ToString('o')\n                }\n            }\n        }\n    }\n    \n    $baseline | ConvertTo-Json -Depth 3 | Set-Content $integrityDb\n    Log-Message \"Baseline created with $($baseline.Count) files\"\n    exit\n}\n\n# Verify against baseline\nLog-Message \"Verifying against baseline...\"\n$baseline = Get-Content $integrityDb | ConvertFrom-Json -AsHashtable\n$issues = @()\n\nforeach ($dir in $recoveryDirs) {\n    if (Test-Path $dir) {\n        Get-ChildItem $dir -Recurse -File | ForEach-Object {\n            $currentHash = (Get-FileHash $_.FullName -Algorithm SHA256).Hash\n            \n            if ($baseline.ContainsKey($_.FullName)) {\n                if ($baseline[$_.FullName].Hash -ne $currentHash) {\n                    $issues += \"MODIFIED: $($_.FullName)\"\n                }\n            } else {\n                $issues += \"NEW: $($_.FullName)\"\n            }\n        }\n    }\n}\n\n# Check for deleted files\nforeach ($file in $baseline.Keys) {\n    if (-not (Test-Path $file)) {\n        $issues += \"DELETED: $file\"\n    }\n}\n\nif ($issues.Count -eq 0) {\n    Log-Message \"Integrity check PASSED - No changes detected\"\n} else {\n    Log-Message \"Integrity check WARNING - $($issues.Count) changes detected:\"\n    foreach ($issue in $issues) {\n        Log-Message \"  $issue\"\n    }\n}"
      }
    },
    "metadata": {
      "status": "implemented",
      "last_updated": "2025-11-22T00:00:00Z",
      "has_scripts": true,
      "qa_verified": true,
      "qa_agent": "LOVELESS"
    },
    "cac_metadata": {
      "implementation_type": "technical",
      "last_analyzed": "2025-11-22T00:00:00Z",
      "source": "ComplianceAsCode",
      "implementation_guidance": "Implement physical and technical protections for recovery components including encryption, access controls, immutable storage, and integrity monitoring."
    },
    "rationale": "This control ensures component protection is properly implemented to maintain operational continuity during disruptions."
  }
]